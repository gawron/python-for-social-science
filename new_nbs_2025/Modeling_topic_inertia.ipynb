{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b287d4",
   "metadata": {},
   "source": [
    "In a standard LDA topic model words are generated from $k$ topic-specific language models, where $k$ is the number of topics, and the choice of topic is made word by word.  Making topic choice independent of previous topic choices is true to the idea of topic models as providing the $k$ language models that best account for the overall distribution of words in a document set, but it is not the most natural assumption given our usual conception of\n",
    "what a topic is.  Indeed, it is impossible to conceive of a coherent text in which the topic changed every word.\n",
    "Here we explore the idea of **topic inertia**.  Once is topic is settled on; the model should make it difficult\n",
    "to change topics.  As we make out way through a document, topic shifts should be rare.\n",
    "\n",
    "We will begin by exploring a very simple idea.  Let's model the probability of a topic choice as\n",
    "an event that is as probable as the word at rank $r$ (a hyper-parameter to be chosen by some clever means).\n",
    "For concreteness, let's choose $r=100$,\n",
    "\n",
    "We'll load some standard English frequency data and see what that gets us.\n",
    "Data taken from [Adam Kilgfariff's BNC frequency page.](https://www.kilgarriff.co.uk/bnc-readme.html#raw)\n",
    "He describes the procedure for creating the data as follows:\n",
    "\n",
    ">The first 5,000 words of all documents (=files) longer than 5,000 words in the written part of the BNC were taken. There were 2018 of these, so the subcorpus was slightly over 10M words. (I used written-only on the premise that the spoken material would be too different to usefully treat as part of the same population - of course, one might say this about all sorts of subcorpora, but never mind.) A frequency list was produced for each of these (truncated) documents. Then, taking the 8189 word-pos pairs occurring 100 times or more in the sample, a 2018x8189 table giving the frequency of each word in each document was produced. For each word, the mean and variance was calculated. There were two ways to calculate mean and variance: including the zeros (eg always dividing by 2018) or excluding them (dividing by the number of documents the word occurred in). For most purposes, it is the former that is of interest so this is what I present. The \"exclusive\" figures may readily be reconstructed.\n",
    "\n",
    "So we set $N$ (the size of the corpus) at 10,000,000.\n",
    "\n",
    "See [Explaining LDA.](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ec82047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose topic boundary marker to license switching topics\n",
    "# prob of topic boundary marker depends on length of documeny and number of topics in the model.\n",
    "# model keeping the number of topic switches per doc low but not SO low it cant happen\n",
    "# let's say topic odel switch is about as probable as observing a token of the word at rank 101\n",
    "# \"said\" in the printout below.  Occurs 7,861 times in the 10 M word corpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "229c671e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"bnc_freq_stub.txt\", header=0,sep=r\"\\s+\",index_col=\"word\")#,engine=\"python\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f74d7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>freq</th>\n",
       "      <th>docs</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mn_per_var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>at0</td>\n",
       "      <td>677594</td>\n",
       "      <td>2018</td>\n",
       "      <td>335.8</td>\n",
       "      <td>5003.6</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>prf</td>\n",
       "      <td>353416</td>\n",
       "      <td>2018</td>\n",
       "      <td>175.1</td>\n",
       "      <td>2860.4</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>cjc</td>\n",
       "      <td>284466</td>\n",
       "      <td>2018</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1157.6</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>at0</td>\n",
       "      <td>215069</td>\n",
       "      <td>2018</td>\n",
       "      <td>106.6</td>\n",
       "      <td>550.5</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>prp</td>\n",
       "      <td>207531</td>\n",
       "      <td>2018</td>\n",
       "      <td>102.8</td>\n",
       "      <td>846.2</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    freq  docs   mean     var  mn_per_var\n",
       "word                                              \n",
       "the   at0  677594  2018  335.8  5003.6        14.9\n",
       "of    prf  353416  2018  175.1  2860.4        16.3\n",
       "and   cjc  284466  2018  141.0  1157.6         8.2\n",
       "a     at0  215069  2018  106.6   550.5         5.2\n",
       "in    prp  207531  2018  102.8   846.2         8.2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "075c4cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('said',\n",
       " pos            vvd\n",
       " freq          7861\n",
       " docs          1094\n",
       " mean           3.9\n",
       " var           56.8\n",
       " mn_per_var    14.6\n",
       " Name: said, dtype: object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 100\n",
    "df.index[r],df.iloc[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8879f9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007861"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=1e7\n",
    "r = 100\n",
    "freq= df.iloc[r][\"freq\"]\n",
    "p_top_switch = freq/N\n",
    "p_top_switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "505d5689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5445225814643666"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  prob of one or more topic switches in a 1_000 word sequence\n",
    "#  better than even\n",
    "p_no_switch_1000 = (1-p_top_switch)**1_000\n",
    "p_switch_1000 = 1 - p_no_switch_1000\n",
    "p_switch_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a50a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
