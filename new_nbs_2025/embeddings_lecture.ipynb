{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e7feb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:32:50) [Clang 16.0.6 ]'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c060cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "174a60b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gensim' (namespace) from ['/Users/gawron/opt/anaconda3/envs/p312/lib/python3.12/site-packages/gensim']>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd57341",
   "metadata": {},
   "source": [
    "## Modeling word meaning \n",
    "\n",
    "The old structuralist idea that word meanings can be modeled by word co-occurrence patterns, that\n",
    "words with similar meanings should have similar co-occurrence patterns:\n",
    "\n",
    "> You shall know a word by the company it keeps. -- Firth\n",
    "\n",
    "Our text  calls this idea the **Distributional Hypothesis**:\n",
    "\n",
    ">The distributional hypothesis $\\dots$ proposes that some aspects of meaning can be learned solely from the texts we encounter over our lives, based on the complex association of words with the words they co-occur with (and with the words that those words occur with) --  Chap 5, 7\n",
    "\n",
    "So to build a model of word meaning, let's build a model of that sort. \n",
    "\n",
    "But what kind of object (data structure) shall we use for a word meaning?\n",
    "\n",
    "Given the tight connection between word meaning and word distribution we're assuming,\n",
    "a reasonable place to look is at **language models**, which are probabilistic models\n",
    "of word distribution.  Bengio et al. discusses the idea of building **language models** based  on\n",
    "n-dimensional vectors, proposing a shift from **n-gram** models in which\n",
    "a 10-gram model for a vocab of 100,000 words has\n",
    "\n",
    "$$\n",
    "100,000^{10} - 1 = 10^{50} - 1\n",
    "$$\n",
    "\n",
    "parameters to, say, 100-dimensional vectors (or **embeddings**) for the same vocabulary, with\n",
    "$$\n",
    "100,000 * 100 = 10^{7}\n",
    "$$\n",
    "\n",
    "parameters.  The idea is that the vectors themselves will model the probability distribution  for\n",
    "the 10-word window around each word.  Aside from the smaller easier-to-train parameter space,\n",
    "Bengio et al. cites this reason to think word embeddings could provide an improvement in\n",
    "language modeling:\n",
    "\n",
    "> Model generalizability:  Suppose that we try to predict the occurrence of some word $c$ never seen before in the context of our target word $w$.  In a classic n-gram model all such words will receive the same probability (with a few qualifications here for certain smoothing strategies). In a vector-based model, words with distributions similar to words we **have** seen in the context can receive higher probabilities.  That is, for any given word $w$ the context coverage of our model expands from the words we have seen in context with $w$  to words similar to the words we have seen in context with $w$.  Their example:   Seeing *The cat is walking in the bedroom* should increase the probability of \n",
    "\n",
    "> The dog is walking in the bedroom.\n",
    "\n",
    "> A cat is walking in the bedroom.\n",
    "\n",
    "> The cat is running in the bedroom.\n",
    "\n",
    "> The dog is running in the bedroom.\n",
    "\n",
    "and so on.  Bengio et al. proposed a neural network model which achieved state-of-the-art perplexity scores\n",
    "(interestingly, because the NN models make very different kinds of errors from the best trigram model --an interpolated trigram -- the best scores were achieved by mixing the two models).  \n",
    "Collobert et al (2011) used a different NN architecture and achieved state-of-the-art performance on \n",
    "language modeling and a number of NLP tagging tasks, including part of speech tagging, semantic tagging, and parsing. The two systems shared the property of using multi-dimensional models of \n",
    "words coupled with a fairly simple Neural Net architecture.\n",
    "\n",
    "The 3-D model of affect. [See slides for word vectors textbookchapter].\n",
    "\n",
    "A preliminary **word vector** model.  Also **Latent Semantic Indexing** in\n",
    "the context of information-retrieval (Deerwester etal 1988, which introduces the term **embedding**).\n",
    "This uses truncated SVD representations of a matrix of co-occurrence counts of words.\n",
    "\n",
    "This move -- the move to word embeddings -- is one of the places where we can trace a clear \n",
    "connection between thinking about cognitive modeling and deep learning models (quote from Bengio 2008, Scholarpedia, where he traces a between work by connectionists like Hinton in the 80s\n",
    "> The idea of distributed representation has been at the core of the revival of artificial neural network research in the early 1980's, best represented by the connectionist bringing together computer scientists, cognitive psychologists, physicists, neuroscientists, and others. The main proponent of this idea has been Geoffrey Hinton, in articles such as (Hinton 1986) and (Hinton 1989). An early discussion can also be found in the Parallel Distributed Processing book (1986), a landmark of the connectionist approach.\n",
    "\n",
    "> The idea of distributed representations was introduced with reference to cognitive representations: a mental object can be represented efficiently (both in terms of number of bits and in terms of number of examples needed to generalize about it) by characterizing the object using many features, each of which can separately each be active or inactive. For example, with m binary features, one can describe up to 2m different objects. The idea is that the brain would be learning and using such representations because they help it generalize to new objects that are similar to known ones in many respects. A distributed representation is opposed to a local representation, in which only one neuron (or very few) is active at each time, i.e., as with grandmother cells. One can view n-gram models as a mostly local representation: only the units associated with the specific subsequences of the input sequence are turned on. Hence the number of units needed to capture the possible sequences of interest grows exponentially with sequence length\n",
    "\n",
    "So now we know: We can represent meaning with n-dimensional continuous vectors and this may\n",
    "offer significant advantages in both language-modeling and meaning representation.\n",
    "\n",
    "In this notebook we we explore the **Word2Vec** model of Mikolov et al. (2013), an approach that computes embeddings for words without coupling them to a neural net architecture.  Word vectors are simply\n",
    "trained to do language modeling as well as possible. This simplifies the learning\n",
    "task and yet produces vectors that poerform well on a number of benchmarks.\n",
    "\n",
    "The goal is to train the model so that words with similar co-occurrence\n",
    "patterns have similar vectors. The basic intuition of how that works is: We get a large \n",
    "sample (or, **corpus**) of naturally occurring language (usually written, usually on the internet)\n",
    "and apply some measure of how similar a word's vector is to the word vectors of its context\n",
    "words.  We define improving our model as increasing those similarity scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be989b6e",
   "metadata": {},
   "source": [
    "## Skip gram model (Mikolov 2013)\n",
    "\n",
    "First we need a way of measuring similarity of vectors.  Let's use a very simple idea:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\text{Similarity}(w,\\,c) & = & \\mathbf{c}\\cdot\\mathbf{w}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "To make our model probablistic (a la Bengio et al. 2003)\n",
    "we  map similarity scores to probabilities.  The more similar a word is\n",
    "to its context words the more probable the occurrence of those context words is.\n",
    "\n",
    "\n",
    "\n",
    "**Logistic** or **sigmoid** function beloved of logistic regression models:\n",
    "$$\n",
    "\\sigma:\\; R \\rightarrow ( 0,\\, 1 )\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "The probability that word $c$ is a real context word for target word $w$ is:\n",
    "$$\n",
    "\\text{P}(+\\mid\\, \\mathbf{w,c}) = \\sigma(\\mathbf{c}\\cdot\\mathbf{w}) =  \\frac{1}{1 + e^{-\\mathbf{c\\cdot w}}}\n",
    "$$\n",
    "\n",
    "Note that $\\text{P}(+\\mid\\mathbf{\\cdot})$ is a symmetric function. The probability of $w$ being a context word\n",
    "for $c$ is the same as the probability of $c$ being a context word\n",
    "for $w$.  This is consistent with our setup.  Since the left and right context windows are the\n",
    "same, for any given utterance, $w$ is a context word for $c$ if and only if $c$ is a context word for $w$.  \n",
    "\n",
    "Nevertheless, in the implementtion of the **Skip Gram with Negative Sampling** (SGNS) model, we train \n",
    "separate target word and context vectors for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b5b1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1 + np.exp(-x))**(-1)\n",
    "\n",
    "c = np.array([.2,.3, -.6])\n",
    "# A vector whose dot product with c is 0 is orthogonal to c.\n",
    "c_orth = np.array([5,1/.3, 2/(.6)])\n",
    "#sigmoid(0) =.5\n",
    "sigmoid(c.dot(c_orth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec95d07",
   "metadata": {},
   "source": [
    "Orthogonal vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae91aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-1.480297366166875e-17)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.dot(c_orth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f6aa4",
   "metadata": {},
   "source": [
    "Completely orthogonal vectors means the probability of being a target context word pair and not being a target context word pair is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c54f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(c.dot(c_orth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d8ce17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999546021312976)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44cc8d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.5397868702434395e-05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff08e8b",
   "metadata": {},
   "source": [
    "As desired, the larger $\\mathbf w\\cdot c$ is, the higher the probability of target-word/context-word relation;\n",
    "that is, the the more similar the target word and context word vectors are, the greater the probability of co-occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b5f42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8175744761936437)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c731c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f26d7be3",
   "metadata": {},
   "source": [
    "## Sampling model \n",
    "\n",
    "We can think of  the SGNS model as a probability-based classifier: given a target word $w$ we classify candidates\n",
    "$c$ as to whether they can or cannot be context words for $w$, depending\n",
    "on their probability of being a context word for $w$. To train a classifier we need\n",
    "to consider negative examples as well as positive ones, and the model\n",
    "we've chosen has a particularly elegant answer for negative examples:\n",
    "\n",
    "The probability that word $c$ is **not** a real context word for target word $w$ is:\n",
    "\n",
    "$$\n",
    "\\begin{array}[t]{lcl}\n",
    "\\text{P}(-\\mid\\, w,c) &=& 1 - \\text{P}(+\\mid\\, \\mathbf{w,c}) \\\\\n",
    "& = &1 - \\sigma(\\mathbf {c\\cdot w }) \\\\\n",
    "& = &\\sigma(-\\mathbf{c}\\cdot\\mathbf{w}) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "This follows because of a key property of the sigmoid function \n",
    "(which helps makes it attractive for probabilistic models  like\n",
    "logistic regression):  $1 - \\sigma(x) = \\sigma(-x)$\n",
    "$$\n",
    "1 - \\sigma(x)  = 1 - \\frac{1}{1 + e^{\\,-x}}\n",
    "=  \\frac{1 + e^{-x} -1}{1 + e^{\\,x}} = \n",
    "\\frac{e^{x}(e^{-x})}{e^{\\,x}(1 + e^{-x})} =\n",
    "\\frac{1}{1 + e^{\\, \\mathbf x}} =\n",
    "\\sigma(-x) \n",
    "$$\n",
    "\n",
    "Summarizing: we want a vector model of dimensionality $n$ for\n",
    "word co-occurrences.  We model co-coccurence with vector similarity\n",
    "because we have a particularly simple model of vector similarity,\n",
    "dot product. Our similarity \"scores\" range from $-\\infty$ to $\\infty$,\n",
    "so to get a probability model, we use $\\sigma$ to map from\n",
    "$\\mathbf c\\cdot w $ to the open interval from  0 to 1.\n",
    "$\\sigma$ has the advantage of a mathematically simple relation\n",
    "$\\sigma(x)$ = $1- \\sigma(-x)$, which will give oue learning\n",
    "algorithm parfticularly simple way of training with negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a321ce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10fd17fe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "(fig,ax) = plt.subplots(1,1)\n",
    "x = np.arange(-10,10,.01)\n",
    "y = sigmoid(x)\n",
    "y_prime = sigmoid(-x)\n",
    "ax.axhline(.5,c=\"r\")\n",
    "ax.annotate(r\"$\\sigma\\,(0) = .5$\",(.19,.525),)\n",
    "ax.annotate(r\"$\\sigma\\,(1.5)=.82$\",(1.7,.82),)\n",
    "ax.annotate(r\"$\\sigma\\,(-1.5)=.18$\",(-1.2,.18),)\n",
    "ax.scatter([-1.5,0,1.5],[.1824,.5,.8175],c=\"k\")\n",
    "ax.axhline(c=\"b\")\n",
    "ax.plot(x,y,label=r\"$\\sigma(x)$\")\n",
    "ax.plot(x,y_prime,linestyle=\"--\",label=r\"$\\sigma(-x)$\")\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "_ = ax.set_ylabel(r\"$\\sigma\\,(x)$\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c700710",
   "metadata": {},
   "source": [
    "To find negative examples: randomly choose $k$ noise words for each target word token.  First guess: We sample\n",
    "\"randomly\" in accordance with the known unigram distributions of the vocabulary V.  For each word $w$,\n",
    "we estimate $\\text{P}(w)$ with its relative frequency in the corpus:\n",
    "\n",
    "$$\n",
    "\\text{P}(w)= \\frac{\\text{count}(w)}{\\sum_{w'\\in \\text{V}}  \\text{count}(w')}\n",
    "$$\n",
    "\n",
    "This doesn't work that well because we get very small samples of rare words.  That's accurate probabilistically,\n",
    "but less than optimal from a model building point of view.  So we instead we use a hyper-parameter\n",
    "$\\alpha$ which slightly smooths the model as follows:\n",
    "\n",
    "$$\n",
    "\\text{P}_{\\alpha}(w)= \\frac{\\text{count}(w)^{\\alpha}}{\\sum_{w'\\in \\text{V}}  \\text{count}(w')^{\\alpha}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7187ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A three word example vocab:\n",
    " \n",
    "#### Default model\n",
    "counts= np.array([5,50,45])\n",
    "nm = counts.sum()\n",
    "ps = counts/nm\n",
    "####  alpha model\n",
    "alpha = .75\n",
    "counts_alpha= counts**alpha\n",
    "nm_alpha = counts_alpha.sum()\n",
    "ps_alpha = counts_alpha/nm_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2f2ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.5 , 0.45])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf615ef5",
   "metadata": {},
   "source": [
    "$\\alpha$-model increases probs of rare words, decreases probs of others as is usually the case for smoothed\n",
    "unigram models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0cccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08460548, 0.47577156, 0.43962296])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ef897",
   "metadata": {},
   "source": [
    "Probs still sum to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e0552f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.0), np.float64(1.0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.sum(),ps_alpha.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fcc586",
   "metadata": {},
   "source": [
    "Draw a graph of prob function applied to the 3-simplex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897af27",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f08ce",
   "metadata": {},
   "source": [
    "For Training we need a Loss function.  We want to maximize the probabilities and work with log probabilities\n",
    "for computational ease; and since a loss function is something we minimize during the learning phase,\n",
    "we put a minus sign out in front.  This loss function is called **Negative Log Likelihood**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc96bf1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\text{L}(\\mathbf{w;\\,c_{pos},\\,c_{neg_{1}},\\,\\dots,c_{neg_{k}}}) & =& -\\log \\left \\lbrack \\,\\text{P}(+\\mid\\, \\mathbf {w,c_{pos}})\\prod_{i=1}^{k} \\text{P}(-\\mid\\,\\mathbf {w,c_{neg_{i}}})\\,\\right \\rbrack\\\\\n",
    "            &=&  -\\left \\lbrack\\, \\log \\text{P}(+\\mid\\,\\mathbf{ w,c_{pos}}) + \\sum\\limits_{i}^{k} \\log \\text{P}(-\\mid\\,\\mathbf{w,c_{neg_{i}}})\\,\\right \\rbrack\\\\\n",
    "             &=&  -\\left \\lbrack\\, \\log \\sigma (\\mathbf{w} \\cdot \\mathbf{c_{pos}}) + \\sum_\\limits{i}^{k} \\log (\\sigma (- \\mathbf{w} \\cdot \\mathbf{c_{neg_{i}}}))\\,\\right \\rbrack\\\\\n",
    "\\end{array}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2c388",
   "metadata": {},
   "source": [
    "For a window size of $l$, and sampling of $k$ negative context words,\n",
    "each target word in context gives us three kinds of information for update:\n",
    "\n",
    "\n",
    "1.  Update $l$ context word embeddings $c_{pos_{1}}\\dots c_{pos_{l}}$ to be more similar to the target word.\n",
    "2.  Update $k$ negative word embedding $c_{neg_{1}} \\dots c_{neg_{k}} $ to be less similar to the target word.\n",
    "3.  Update the target word embedding $w$ to be more similar to the $c_{pos}$ words and less similar to the $c_{neg}$ words.\n",
    "\n",
    "Using **Stochastic Gradient Descent** means taking the partial derivative of the Loss function L\n",
    "with respect to each of these variables, to find vectors giving the direction of steepest descent,\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial \\,\\text{L}}{\\partial\\, \\mathbf{c_{pos}}}  =  \\lbrack \\,\\sigma (\\mathbf{c_{pos}\\cdot w} ) - 1 \\,\\rbrack\\, \\mathbf{w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial \\,\\text{L}}{\\partial\\, \\mathbf{c_{neg}}} =  \\lbrack \\,\\sigma (\\mathbf{c_{neg}\\cdot w }) \\,\\rbrack\\, \\mathbf{w }\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial \\,\\text{L}}{\\partial\\, \\mathbf{w}}  =  \\lbrack \\,\\sigma (\\mathbf{c_{pos}\\cdot w }) - 1 \\,\\rbrack\\,\\mathbf{c_{pos}} + \\sum_{i=1}^{k} \\left \\lbrack \\,\\sigma (\\mathbf{c_{{neg}_{i}}\\cdot w} ) \\,\\right \\rbrack\\, \\mathbf{c_{{neg}_{i}}}\n",
    "$$\n",
    "\n",
    "These derivatives are easily derived with a little Calculus. Their simplicity is due in large part \n",
    "to the definition of $\\sigma$ interacting with the $\\log$ function.\n",
    "\n",
    "Here are the updates that result from moving each of the three kinds of vectors in the appropriate direction by an amount determined by $\\eta$, the learning  rate:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\mathbf{c_{pos}} &= &\\mathbf{c_{pos}} - \\eta \\,\\lbrack \\,\\sigma (\\mathbf{c_{pos}\\cdot w} ) - 1 \\,\\rbrack\\, \\mathbf{w}\\\\\n",
    "\\mathbf{c_{neg}} &= &\\mathbf{c_{neg}} - \\eta \\,\\lbrack \\,\\sigma (\\mathbf{c_{neg}\\cdot w }) \\,\\rbrack\\, \\mathbf{w}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "And for updating $\\mathbf{w}$:\n",
    "$$\n",
    "\\mathbf{w} = \\mathbf{w} - \\eta \\left \\lbrack \\, \\left \\lbrack \\,\\sigma (\\mathbf{c_{pos}\\cdot w} ) - 1 \\,\\right \\rbrack\\,c_{pos} + \\sum_{i=1}^{k} \\left \\lbrack \\,\\sigma (\\mathbf{c_{{neg}_{i}}\\cdot w }) \\,\\right \\rbrack\\, \\mathbf{c_{{neg}_{i}}} \\,\\rbrack\\, \\right \\rbrack \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400a454",
   "metadata": {},
   "source": [
    "## Appendix A: Derivation of partial derivatives\n",
    "\n",
    "We start with the following reminder:  $\\dfrac{\\partial f}{\\partial \\mathbf{v}}$, where $v$ is an n-dimensional vector, is shorthand for \n",
    "$$\n",
    "\\left ( \\dfrac{\\partial f}{\\partial \\mathbf{v_{1}}},\\, \\dfrac{\\partial f}{\\partial \\mathbf{v_{2}}},\\,  \n",
    "\\dots \\dfrac{\\partial f}{\\partial \\mathbf{v_{n}}}\n",
    "\\right ) \n",
    "$$\n",
    "This is called the **gradient of f** and is written $\\nabla f$.  If $f$ is a function of more\n",
    "than one vector (as L is above) we write $\\nabla_{v} f$ to specifiy the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2e821",
   "metadata": {},
   "source": [
    "Our first target is $\\dfrac{\\partial L}{\\partial \\mathbf{c}}$, or $\\nabla_{c} L$.\n",
    "\n",
    "Let's consider a slightly simpler example first ($\\mathbf{w\\cdot c}$):\n",
    "\n",
    "$$\n",
    "\\begin{array}{lclr}\n",
    "\\text{Show } & & \\dfrac{\\partial (\\mathbf{w\\cdot c})}{\\partial \\mathbf{c}} = \\mathbf{w} & \\mathbf{Lemma \\, A} \\\\\n",
    " \\dfrac{\\partial (\\mathbf{w\\cdot c})}{\\partial \\mathbf{c}} & = & \n",
    "% Step 1\n",
    "%\\left \\lbrack \\begin{array}{c}\n",
    "%\\dfrac{\\partial f}{\\partial c_{1}} \\\\\n",
    "%\\dfrac{\\partial f}{\\partial c_{1}} \\\\\n",
    "%\\vdots\\\\\n",
    "%\\dfrac{\\partial f}{\\partial c_{n}} \\\\\n",
    "%\\end{array} \\right \\rbrack \n",
    "%=  \n",
    "% Step 2\n",
    "\\left \\lbrack \\begin{array}{c}\n",
    "\\dfrac{\\partial \\,\\sum_{i=1}^{n} w_{i}c_{i}}{\\partial \\,\\mathbf{c_{1}}} \\\\\n",
    "\\dfrac{\\partial\\, \\sum_{i=1}^{n} w_{i}c_{i}}{\\partial\\, \\mathbf{c_{2}}} \\\\\n",
    "\\vdots\\\\\n",
    "\\dfrac{\\partial \\, \\sum_{i=1}^{n} w_{i}c_{i}}{\\partial\\, \\mathbf{c_{n}}}\\\\\n",
    "\\end{array} \\right \\rbrack =\n",
    "% Step 3\n",
    "\\left \\lbrack \\begin{array}{c}\n",
    "%\\sum_{i=1}^{n} \\dfrac{\\partial w_{i}c_{i}}{\\partial c_{1}} \\\\\n",
    "{\\large\\sum_{i=1}^{n}} \\dfrac{\\partial \\,w_{i}c_{i}}{\\partial\\, c_{1}} \\\\\n",
    "{\\large \\sum_{i=1}^{n}} \\dfrac{\\partial\\, w_{i}c_{i}}{\\partial\\, c_{2}} \\\\\n",
    "\\vdots\\\\\n",
    "{\\large \\sum_{i=1}^{n}} \\dfrac{\\partial \\, w_{i}c_{i}}{\\partial\\, c_{n}}\\\\\n",
    "\\end{array} \\right \\rbrack =\n",
    "% Step 4\n",
    "\\left \\lbrack \\begin{array}{c}\n",
    "%\\sum_{i=1}^{n} \\dfrac{\\partial w_{i}c_{i}}{\\partial c_{1}} \\\\\n",
    "w_{1} + 0 + \\dots + 0\\\\\n",
    "0 + w_{2}+\\dots + 0 \\\\\n",
    "\\vdots\\\\\n",
    "0+0+ \\dots + w_{n}\\\\\n",
    "\\end{array} \\right \\rbrack =\n",
    "% Step QED -1\n",
    "\\left \\lbrack \\begin{array}{c}\n",
    " w_{1} \\\\\n",
    " w_{2} \\\\\n",
    "\\vdots\\\\\n",
    " w_{n}\\\\\n",
    "\\end{array} \\right \\rbrack =\n",
    "% QED step\n",
    "\\mathbf{w}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c7ce5",
   "metadata": {},
   "source": [
    "Recall that since $\\dfrac{d(\\mathbf{w\\cdot c})}{c_{i}}$ is a partial derivative, we treat all the $w_{i}$, \n",
    "and all the $c_{j}$, $j\\neq i$, like constants.  For example,\n",
    "$$\n",
    "\\dfrac{\\partial w_{1}c_{1}}{\\partial c_{1}} = w_{1},  \\quad \\dfrac{\\partial w_{2}c_{2}}{\\partial c_{1}} = 0\n",
    "$$\n",
    "As the derivation above shows,\n",
    "the derivative of the dot product follows a pattern analogous to that of\n",
    "the derivative of a scalar variable multiplied by a constant, \n",
    "$$\\dfrac{d(cx)}{dx} = c,$$\n",
    "even though dot product is an operation on vectors.\n",
    "This result is due to the fact that dot product is a sum of products,\n",
    "and to the fact that \n",
    "\n",
    "$$\n",
    "\\dfrac{d \\left ( \\sum_{i=1}^{n} f(c_{i},y) \\right )}{dy}  = \\sum_{i=i}^{n}\\dfrac{d (f(c_{i},y)) }{dy}.\n",
    "$$\n",
    "\n",
    "It will alse be helpful to know an alternative way of writing the sigmoid function:\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}} =  \\frac{e^{x}\\cdot 1}{e^{x}(1 + e^{-x})}  =  \\frac{e^{x}}{e^{x} + 1} \\quad \\mathbf{Lemma}\\,\\mathbf{B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c9d63",
   "metadata": {},
   "source": [
    "We turn to deriving the fact that\n",
    "\n",
    "$$\n",
    "\\dfrac{\\,\\partial\\, (\\text{L}(\\mathbf{w;\\,c_{pos},\\,c_{neg_{1}},\\,\\dots,c_{neg_{k}}})\\,)}{\\partial \\,\\mathbf{c_{pos}}}=\n",
    "\\lbrack\\, \\sigma(\\mathbf{w\\cdot c})- 1 \\,\\rbrack \\, \\cdot (\\mathbf{w}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b5303",
   "metadata": {},
   "source": [
    "Now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4774fad",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\dfrac{\\partial \\text{L}(\\mathbf{w;\\,c_{pos},\\,c_{neg_{1}},\\,\\dots,c_{neg_{k}}})}{\\partial \\mathbf{c_{pos}}} & =& -\\dfrac{\\partial \\log \\left \\lbrack \\,\\text{P}(+\\mid\\, \\mathbf {w,c_{pos}})\\prod_{i=1}^{k} \\text{P}(-\\mid\\,\\mathbf {w,c_{neg_{i}}})\\,\\right \\rbrack}{\\partial \\, c_{pos}}\\\\\n",
    "             &=&  -\\dfrac{\\partial \\left \\lbrack\\, \\log \\sigma (\\mathbf{w} \\cdot \\mathbf{c_{pos}}) + \\sum_\\limits{i}^{k} \\log (\\sigma (- \\mathbf{w} \\cdot \\mathbf{c_{neg_{i}}}))\\,\\right \\rbrack}{\\partial \\, c_{pos}}\\\\\n",
    "             &=&  \\dfrac{\\partial \\left \\lbrack\\, - \\log \\sigma (\\mathbf{w} \\cdot \\mathbf{c_{pos}}) \\,\\right \\rbrack}{\\partial \\, c_{pos}}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Working on the numerator of the  RHS:\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\log \\sigma (\\mathbf{w} \\cdot \\mathbf{c_{pos}})  & = & \\log \\frac{1}{1+e^{\\mathbf{-w\\cdot c}}}\\\\\n",
    "&=&  - \\log (1+e^{\\mathbf{-w\\cdot c}})\n",
    "\\end{array}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9c8ce",
   "metadata": {},
   "source": [
    "And so:\n",
    "\n",
    "$$\n",
    "\\begin{array}{llclr}\n",
    "(1)&  \\dfrac{\\partial \\left \\lbrack\\, - \\log \\sigma (\\mathbf{w} \\cdot \\mathbf{c_{pos}}) \\,\\right \\rbrack}{\\partial \\, c_{pos}} &=&  \\dfrac{ \\partial\\, (- -\\log 1+e^{\\mathbf{-w\\cdot c}})}{\\partial \\,c_{pos}}\\\\\n",
    "(3) &          &=&  \\frac{1}{1 + e^{\\mathbf{- w\\cdot c}}} \\dfrac{ \\partial\\, (1+e^{\\mathbf{-w\\cdot c}})}{\\partial \\,c_{pos}}\\\\\n",
    "(4)&            &=&  \\frac{1}{1 + e^{\\mathbf{- w\\cdot c}}} \\,\\dfrac{\\partial (-\\mathbf{w\\cdot c})}{\\partial{ c}} \\,e^{\\mathbf{-w\\cdot c}}\n",
    "          \\\\\n",
    "(6)&            &=&  \\frac{e^{\\mathbf{-w\\cdot c}}}{1 + e^{\\mathbf{- w\\cdot c}}} \\, (- \\mathbf{w}) && \\text{Using }\\mathbf{Lemma\\, A} \n",
    "          \\\\\n",
    "(7)&            &=&  \\sigma(\\mathbf{-w\\cdot c}) \\, \\cdot (- \\mathbf{w}) && \\text{Using }\\mathbf{Lemma\\, B} \n",
    "          \\\\\n",
    "(8)&            &=&  \\lbrack\\, 1 - \\sigma(\\mathbf{w\\cdot c})\\,\\rbrack \\, \\cdot (- \\mathbf{w}) \n",
    "          \\\\\n",
    "(8)&            &=&  \\lbrack\\, \\sigma(\\mathbf{w\\cdot c})- 1 \\,\\rbrack \\, \\cdot (\\mathbf{w}) \n",
    "          \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The derivations of the other partial derivatives of L with respect to te other vectors\n",
    "are all similar and ar eleft as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12938b3",
   "metadata": {},
   "source": [
    "Hence:\n",
    "$$\n",
    "\\dfrac{\\partial \\text{L}(\\mathbf{w;\\,c_{pos},\\,c_{neg_{1}},\\,\\dots,c_{neg_{k}}})}{\\partial \\mathbf{c_{pos}}} =\n",
    "\\lbrack\\, \\sigma(\\mathbf{w\\cdot c})- 1 \\,\\rbrack \\, \\cdot (\\mathbf{w}) \n",
    "$$\n",
    "Q. E. D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a183ef9",
   "metadata": {},
   "source": [
    "## Exploring word2vec models through gensim\n",
    "\n",
    "The easiest way to exploire some word2vec models (including training new model;s of your own is to install [`gensim`.](https://radimrehurek.com/gensim)\n",
    "\n",
    "The `gensim` implementation includes much of the functionality discussed in your text, including word vector visualizaton in 2D using tsne dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a4567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
