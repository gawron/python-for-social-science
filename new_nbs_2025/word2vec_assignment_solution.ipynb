{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to word2vec assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is an exploration of some of the information embodied in **continuous word embeddings**.  We wil work with high-quality pretrained vectors, so none of this work will touch on the concepts involved in training word embeddings, which have been covered in lecture.   For a visualization of word2vec training (including loss computations) have a look at this [cornell cs course animatioon](https://www.cs.cornell.edu/courses/cs4782/2026sp/demos/word2vec/) of training a toy corpus.\n",
    "\n",
    "This notebook assumes you have Radim Rehurek's `gensim` module installed.\n",
    "The notebook is self-contained and does not require prior knowledge of `gensim`, but if you do become\n",
    "intereste din some of the capabilities gensim offers, see [Rehurek's tutorials page.](https://radimrehurek.com/gensim/auto_examples/index.html#documentation) for some helpful tutorials.\n",
    "\n",
    "The cell below does the required installation, which works in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading pretrained vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a high-quality set of word vectors.  Loading the vectors will take about 10 minutes in Google Colab.  The size of the word vector set is nearly 1 GB.\n",
    "\n",
    "The training methods are described here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "@inproceedings{mikolov2018advances,\n",
    "  title=    {Advances in Pre-Training Distributed Word Representations},\n",
    "  author=   {Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, \n",
    "               Christian and Joulin, Armand},\n",
    "  booktitle={Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)},\n",
    "  year=     {2018}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectors about to be loaded are called **fasttext** vectors.  They contain subword information, which means the vectors encode information about the character sequences their words are spelled with.  This will affect some of the behaviors you observe, since it gives words with similar spellings (e.g., singular and plural nouns) more similar word vectors.\n",
    "\n",
    "The gensim description of the gensim-maintained version, including size info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_records                    999999\n",
      "file_size                      1005007116\n",
      "base_dataset                   Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)\n",
      "reader_code                    https://github.com/RaRe-Technologies/gensim-data/releases/download/fasttext-wiki-news-subwords-300/__init__.py\n",
      "license                        https://creativecommons.org/licenses/by-sa/3.0/\n",
      "parameters                     {'dimension': 300}\n",
      "description                    1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\n",
      "read_more                      ['https://fasttext.cc/docs/en/english-vectors.html', 'https://arxiv.org/abs/1712.09405', 'https://arxiv.org/abs/1607.01759']\n",
      "checksum                       de2bb3a20c46ce65c9c131e1ad9a77af\n",
      "file_name                      fasttext-wiki-news-subwords-300.gz\n",
      "parts                          1\n"
     ]
    }
   ],
   "source": [
    "# 1  GB\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "wordset = 'fasttext-wiki-news-subwords-300'\n",
    "for (k,v) in api.info(wordset).items():\n",
    "    print(f\"{k:<30} {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading the vectors with the gensim downloader\n",
    "\n",
    "Pretty much every body should do this the first time, whether working on google colab or on your home achine.\n",
    "\n",
    "Load the vectors with the gensim downloader (next code cell).  This is your **only** option in Google colab; On home or on Google, loading the vectors will take approximately 10 minutes, give or take.  If you execute the next cell on your home machine, gensim will place the vectors in your home directory under `gensim-data`. There is a progress bar telling you what percent of the vector file has been loaded, but note that when it completes, there are still several minutes of computing time remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f91e152d150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_vectors = api.load(wordset)\n",
    "model2 = fast_vectors\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this to confirm the vectors are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999999, 300)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  a vocab of 999,999  vector dimensionality 300\n",
    "wvecs = model2.vectors\n",
    "wvecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading the vectors from your local file system\n",
    "\n",
    "The following cell should be edited if you have downloaded a version of the vectors onto your local file system, for example using the gensim downloader.  We will refer to the directory where  you place the vectors as `data_dir` and the full path as `text_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the local file system options below assume you have downloaded a full set of 1 illion word vec word vectors \n",
    "into `data_dir` on your home machine,.  These are available on [wvec download page](https://fasttext.cc/docs/en/english-vectors.html) as \n",
    "**wiki-news-300d-1M-subword.vec.zip**, you don't want to use the gensim downloader.\n",
    "\n",
    "You will need to unzip them for everything below to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "import os.path\n",
    "data_dir = '/Users/gawron/gensim-data/fasttext-wiki-news-subwords-300'\n",
    "fn = 'fasttext-wiki-news-subwords-300'\n",
    "# Path for text version  of the full vector model (the default path)\n",
    "# Save the unzipped downloaded vectors here\n",
    "text_path = os.path.join(data_dir,fn)\n",
    "\n",
    "truncated_stem = \"_100K_vocab\"\n",
    "# Use truncated vectors (100K words) after the first time\n",
    "truncate = True\n",
    "truncated_text_path = text_path + truncated_stem\n",
    "\n",
    "## Only one or neither of the next two flags shd be true\n",
    "## Decide what version of the vectors you want to save first\n",
    "save_text_vecs = False\n",
    "save_binary_vecs = False\n",
    "\n",
    "if truncate:\n",
    "    binary_path = text_path + truncated_stem + \".bin\"\n",
    "else:\n",
    "    ## save untruncated binary vecs\n",
    "    binary_path = text_path + \".bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Option 1**: Load the full set of vectors from the model file you have saved on your disk.   Then you would do\n",
    "\n",
    "```python\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(text_path, binary=False) \n",
    "```\n",
    "\n",
    "from this notebook.  This is generally **not** the option you would take your first time through.  You would save the vecs locally with a gensim download first.  Then the second time do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Option 2a**:  Load a **truncated** subset (top 100K) of the vectors from the **full model** file (1 million vectors).\n",
    "\n",
    "Everything in this notebook will work fine with the truncated vocab, except  that your scores on the analogy task will be slightly lower because of 31 missing somewhat rare words. \n",
    "\n",
    "If you want reclaim some disk space, you can load the vectors from `text_path` as in the next cell, then turn around and save the vectors to `truncated_text_path` using `wv_from_text.save_word2vec_format` (illustrated in the comments). You can then delete the much larger `text_path` file from your hard drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding limit = 100_000 argument to load only the 100K most frequent words from the 1 GB file\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(text_path, limit=100_000, binary=False)  # C text format\n",
    "###############################################################\n",
    "if truncate and save_text_vecs:\n",
    "   ## save truncated text vecs\n",
    "   wv_from_text.save_word2vec_format(truncated_text_path,binary=False)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Option 2b:**   You have saved binary vectors (truncated or not, as illustrated in next cell) in some previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vecs in binary format for faster loading next time.\n",
    "# Have added 31 new vocab items to the original 100K vocab (for analogy test set coverage)\n",
    "# by working with a full vocab and using code later in the NB\n",
    "\n",
    "if save_binary_vecs:\n",
    "    wv_from_text.save_word2vec_format(binary_path,binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **if they have been made available**,  we load that binary version (very fast) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_from_text = KeyedVectors.load_word2vec_format(binary_path, binary=True)  # C text format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A look at the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlws = [k for k in wv_from_text.key_to_index if len(k)==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ion' in tlws, 'the' in tlws, 'and' in tlws, 'ham' in tlws, 'dog' in tlws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7276\n",
      "['GfK', 'KCC', 'мне', 'dur', 'oni', 'IOU', 'MIG', 'FGS', 'TER', 'EOP', 'SCL', 'bks', 'acc', 'PCH', 'leq', 'FMF', 'SPG', 'UWS', 'mei', 'NIJ', '30C', '90m', 'Al-', 'GTL', 'CBW', 'Abs', 'MVA', 'LCM', 'VfL', 'GPT', 'AGU', 'LPR', 'ona', 'hal', 'mem', 'SFM', 'CHE', \"'al\", 'N2O', 'SDO', 'DFO', 'Boz', 'GSN', 'IIs', 'كان', 'Mex', 'Sap', 'GCR', 'leu', 'lev']\n"
     ]
    }
   ],
   "source": [
    "print(len(tlws))\n",
    "print(tlws[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.011599 , -0.035565 ,  0.020809 ,  0.022919 ,  0.03974  ,\n",
       "       -0.010865 , -0.0029827, -0.13795  , -0.02587  ,  0.0027815,\n",
       "       -0.0091551,  0.050798 , -0.0075865, -0.044718 ,  0.027331 ,\n",
       "        0.033138 ,  0.062173 , -0.10651  ,  0.050687 , -0.038793 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(wv_from_text)\n",
    "wv_from_text.vectors[100_030,:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch a word vector and examine its first 30 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.089032 ,  0.0070157,  0.043966 ,  0.0095868, -0.0065863,\n",
       "        0.021975 ,  0.03802  , -0.11633  ,  0.086124 ,  0.043658 ,\n",
       "        0.068408 ,  0.016394 ,  0.044093 ,  0.0015541, -0.11214  ,\n",
       "       -0.014895 ,  0.044228 , -0.084028 ,  0.017321 ,  0.035936 ,\n",
       "       -0.020162 , -0.0071014, -0.069285 ,  0.081374 , -0.0078895,\n",
       "       -0.026504 ,  0.048517 ,  0.083375 ,  0.022454 , -0.044504 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2[\"woman\"][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A high-frequency smaller vocabulary\n",
    "\n",
    "Set up a small vocabulary of the 5K or so most frequent words.  This is **Optional**.  It is only essential if you want to write code to answer some of the questions below.  Answering those questions will involve search; nearest neighbor calculations while searching through the V vocabulary words will make your time quadratic on V, so creating a search space of 5K words instead of 100K (or even 1,000,000 words) is then important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5464 found\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_good_model_words (model,words=None,url=None):\n",
    "    \"\"\"\n",
    "    Use Frequency sorted BNC word list to get a list of frequent (well-modeled words)\n",
    "    and winnow it down to those we have vectors for.\n",
    "    \"\"\"\n",
    "    if url is None:\n",
    "        url = \"https://www.kilgarriff.co.uk/BNClists/lemma.num\"\n",
    "    df = pd.read_csv(url,sep = \" \",header=None,index_col=None,names=(\"rank freq word pos\".split()))\n",
    "    words = df[\"word\"].values\n",
    "    res = []\n",
    "    for wd in words:\n",
    "        if wd in res:\n",
    "            continue\n",
    "        else:\n",
    "            res.append(wd)\n",
    "    words = res\n",
    "    search_wds = [wd for wd in words if wd in model.key_to_index]\n",
    "    search_space = [model[wd] for wd in words if wd in search_wds]\n",
    "    print(f\"{len(search_wds)} found\")\n",
    "    return search_wds, search_space, words\n",
    "\n",
    "# First time in executing this cell provide value None\n",
    "words = None\n",
    "search_wds,search_space,words = find_good_model_words(model2,words,url=\"lemma.num.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic word similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75772464"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('woman', 'girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62647694"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('woman', 'boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67477584"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('man', 'boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6418483"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('man', 'girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8773635"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('boy', 'girl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8119809"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('man', 'woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the word vectors\n",
    "\n",
    "Reduce dimensionality to 2 (in 2 steps, as per recommendation of `sklearn` docs for using `tsne`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing PCA reduction\n",
      "PCA reduction done\n",
      "Doing TSNE reduction\n",
      "TSNE reduction done\n",
      "Final data shape: (5464, 2)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import decomposition, manifold\n",
    "import numpy as np\n",
    "\n",
    "#search_wds,search_space\n",
    "search_space = np.array(search_space)\n",
    "## PCA reduction\n",
    "red1 = decomposition.PCA(n_components=25)\n",
    "print(\"Doing PCA reduction\")\n",
    "search_space2 = red1.fit_transform(search_space)\n",
    "print(\"PCA reduction done\")\n",
    "\n",
    "# TSNE reduction\n",
    "print(\"Doing TSNE reduction\")\n",
    "red2 = manifold.TSNE(n_components=2)\n",
    "print(\"TSNE reduction done\")\n",
    "search_space3 = red2.fit_transform(search_space2)\n",
    "#(5464, 2)\n",
    "print(f\"Final data shape: {search_space3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the reduced vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1300x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "N = 50\n",
    "start = 200\n",
    "word_samp = search_wds[start:start+N]\n",
    "#word_samp = [wd for wd in word_samp if wd not in {\"start\",\"though\",\"include\",\"interest\"}]\n",
    "red_vecs_samp = search_space3[start:start+N]\n",
    "samp = [(wd, red_vecs_samp[i,0],red_vecs_samp[i,1]) for (i,wd) in enumerate(word_samp) \\\n",
    "            if wd not in {\"start\",\"though\",\"include\",\"interest\",\"move\"}]\n",
    "#x,y = red_vecs_samp[:,0],red_vecs_samp[:,1]\n",
    "\n",
    "\n",
    "(fig,ax) = plt.subplots(figsize=(13,8))\n",
    "wds,xs,ys = zip(*samp)\n",
    "plt.scatter(xs,ys,s=10)\n",
    "\n",
    "for (wd,x,y) in samp:\n",
    "    #print(wd)\n",
    "    plt.annotate(wd, xy=(x,y), xytext=(-1,4), textcoords=\"offset points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbors\n",
    "\n",
    "Nearest neighbor list for *woman* unrestricted vocabulary.  Some rare words show up, although they still make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.8119807243347168),\n",
       " ('woman--', 0.7959198951721191),\n",
       " ('lady', 0.7750157117843628),\n",
       " ('girl', 0.7577246427536011),\n",
       " ('woman-', 0.7568190097808838),\n",
       " ('womans', 0.7453511953353882),\n",
       " ('women', 0.7260429859161377),\n",
       " ('child-woman', 0.7223398089408875),\n",
       " ('trans-woman', 0.7164039015769958),\n",
       " ('woman-child', 0.7128437161445618)]"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['woman'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbor list for `woman` with restricted vocabulary. Not always a good idea to restrict the vocab, but it sometimes helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.8119807243347168),\n",
       " ('lady', 0.7750157117843628),\n",
       " ('girl', 0.7577246427536011),\n",
       " ('women', 0.7260429859161377),\n",
       " ('female', 0.7014045715332031),\n",
       " ('husband', 0.6878941655158997),\n",
       " ('person', 0.6830306649208069),\n",
       " ('mother', 0.6769816875457764),\n",
       " ('wife', 0.6661549806594849),\n",
       " ('male', 0.6632648706436157)]"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['woman'],topn=10,restrict_vocab=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computers', 0.8472652435302734),\n",
       " ('software', 0.7308359146118164),\n",
       " ('computing', 0.7130760550498962),\n",
       " ('laptop', 0.6961240172386169),\n",
       " ('machine', 0.6935686469078064),\n",
       " ('hardware', 0.6780312061309814),\n",
       " ('electronics', 0.663975179195404),\n",
       " ('technology', 0.6604807376861572),\n",
       " ('desktop', 0.6521348357200623),\n",
       " ('Computer', 0.6456718444824219)]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['computer'],topn=10,restrict_vocab=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computers', 0.8472652435302734),\n",
       " ('software', 0.7308359146118164),\n",
       " ('machine', 0.6935686469078064),\n",
       " ('hardware', 0.6780312061309814),\n",
       " ('technology', 0.6604807376861572),\n",
       " ('internet', 0.6444270610809326),\n",
       " ('electronic', 0.6268055438995361),\n",
       " ('PC', 0.6184285283088684),\n",
       " ('machines', 0.6025169491767883),\n",
       " ('digital', 0.5929277539253235)]"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['computer'],topn=10,restrict_vocab=5_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Twitter', 0.8208357095718384),\n",
       " ('Facebook', 0.6506764888763428),\n",
       " ('blog', 0.5960510969161987),\n",
       " ('blogs', 0.5761139988899231),\n",
       " ('YouTube', 0.5179937481880188),\n",
       " ('chat', 0.4908485412597656),\n",
       " ('news', 0.4890054166316986),\n",
       " ('web', 0.47877150774002075),\n",
       " ('website', 0.47871994972229004),\n",
       " ('email', 0.47649359703063965)]"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['twitter'],topn=10,restrict_vocab=10_000)\n",
    "#[(wd,sc) for (wd,sc) in model2.most_similar(positive=['twitter'],topn=100,restrict_vocab=10_000) \n",
    "#    if \"twitt\" not in wd.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Closer than calculations\n",
    "\n",
    "Along with the `most_similar` method, we have the `closer_than` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't that many words/countries (semantically) closer to Brazil than Argentina, but there are some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Portugal', 'Brasil', 'Brazils', 'Brazilia', 'Brazil.', 'Brazil-']"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.closer_than(\"Brazil\", \"Argentina\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More competition in the other direction.  Note the absence of *Spain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chile',\n",
       " 'Uruguay',\n",
       " 'Argentine',\n",
       " 'Bolivia',\n",
       " 'Paraguay',\n",
       " 'Argentinas',\n",
       " 'Argentinan',\n",
       " 'Argentinia',\n",
       " 'Argentina.',\n",
       " 'Brazil-Argentina']"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.closer_than(\"Argentina\", \"Brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that many words/names closer to Freud than Marx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nietzsche',\n",
       " 'psychoanalysis',\n",
       " 'Sigmund',\n",
       " 'Freudian',\n",
       " 'Lacan',\n",
       " 'Psychoanalysis',\n",
       " 'psychoanalysts',\n",
       " 'Nietzche',\n",
       " 'Freudians',\n",
       " 'Freudianism',\n",
       " 'Krafft-Ebing',\n",
       " 'Fliess',\n",
       " 'freud',\n",
       " 'Freuds',\n",
       " 'Freudenberger',\n",
       " 'Stekel',\n",
       " 'Freudiger',\n",
       " 'Freudberg']"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.closer_than(\"Freud\", \"Marx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short list.  One philosopher, and one of Plato's more famous works; interestingly Socrates is a main character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aristotle', 'Phaedo']"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.closer_than(\"Plato\", \"Socrates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And really no cities closer to Cleveland than Cincinnati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clevelands']"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.closer_than(\"Cleveland\", \"Cincinnati\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part One Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:**  Find the 5 nearest neighbor of *gorilla* if the vocabulary is unrestricted:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gorillas', 0.8310797214508057),\n",
       " ('chimpanzee', 0.7090175151824951),\n",
       " ('chimp', 0.705582857131958),\n",
       " ('orangutan', 0.703140377998352),\n",
       " ('gorilla-like', 0.6914221048355103)]"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['gorilla'],topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:**  The value of the `positive`-argument of `most_similar` can be a vector.\n",
    "Average the vectors of *gorilla* and *man* and find the 5 nearest neighbors\n",
    "to that average:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.8808894157409668),\n",
       " ('gorilla', 0.8068998456001282),\n",
       " ('woman', 0.7249176502227783),\n",
       " ('apeman', 0.7201209664344788),\n",
       " ('man-ape', 0.7170995473861694)]"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = (model2[\"man\"] + model2[\"gorilla\"])/2\n",
    "model2.most_similar(positive=avg,topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually a method for doing this which accepts a set of vectors, which is fun to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gorilla', 0.8459325432777405),\n",
       " ('man', 0.8459324240684509),\n",
       " ('ape', 0.7206934094429016),\n",
       " ('apeman', 0.7174420952796936),\n",
       " ('man-ape', 0.7141361832618713)]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg2 = model2.get_mean_vector([\"gorilla\",\"man\"])\n",
    "model2.most_similar(positive=avg2,topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('red', 0.9782130122184753),\n",
       " ('blue', 0.9782128930091858),\n",
       " ('yellow', 0.8905166983604431),\n",
       " ('purple', 0.8573741912841797),\n",
       " ('pink', 0.8360656499862671),\n",
       " ('green', 0.8251579999923706),\n",
       " ('orange', 0.8056360483169556)]"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg2 = model2.get_mean_vector([\"blue\",\"red\"])\n",
    "model2.most_similar(positive=avg2,topn=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('north', 0.9780260920524597),\n",
       " ('south', 0.9730840921401978),\n",
       " ('west', 0.9711037278175354),\n",
       " ('east', 0.968540608882904),\n",
       " ('southeast', 0.8879513740539551),\n",
       " ('southwest', 0.8878387212753296),\n",
       " ('northeast', 0.8818960189819336),\n",
       " ('northwest', 0.876802921295166)]"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg2 = model2.get_mean_vector([\"north\",\"south\",\"east\",\"west\"])\n",
    "model2.most_similar(positive=avg2,topn=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** There is a strong tendency for the nearest neighbor of a noun to be its standard plural.  As an illustration of just how strong this tendency is, consider *deer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deers', 0.8134419322013855),\n",
       " ('elk', 0.7754461765289307),\n",
       " ('moose', 0.752448558807373),\n",
       " ('elks', 0.7269112467765808),\n",
       " ('deer-hunting', 0.7168375849723816)]"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"deer\"],topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word *deers* is unusual and not the standard plural of *deer*.  Yet it occurs often enough in the 16 Billion- token training data to earn a word vector. One reason for this strong tendency is that in the fasttext model we are using, spelling contributes to vector similarity.  Yet there are already examples you have seen in this notebook where the nearest neighbor of a noun is not its plural.  Find 5 examples of nouns whose nearest neighbors are not their standard plurals, and you can use examples in this notebook for some of the 5. Hint: the examples in this notebook have a linguistic property that will help you find more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**  The linguistic property that helps (but is not necessary) is having irregular plurals, so that the plural form is not quite as close in spelling to the singular as regular plurals are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8119808435440063),\n",
       " ('man--', 0.732385516166687),\n",
       " ('man--and', 0.7230692505836487),\n",
       " ('person', 0.7203925848007202),\n",
       " ('mad-man', 0.7037577629089355),\n",
       " ('guy', 0.6992258429527283),\n",
       " ('god-man', 0.69350266456604),\n",
       " ('boy-man', 0.6925113797187805),\n",
       " ('man--the', 0.6904608607292175),\n",
       " ('man-love', 0.6874001622200012)]"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"man\"],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.8119807243347168),\n",
       " ('woman--', 0.7959198951721191),\n",
       " ('lady', 0.7750157117843628),\n",
       " ('girl', 0.7577246427536011),\n",
       " ('woman-', 0.7568190097808838),\n",
       " ('womans', 0.7453511953353882),\n",
       " ('women', 0.7260429859161377),\n",
       " ('child-woman', 0.7223398089408875),\n",
       " ('trans-woman', 0.7164039015769958),\n",
       " ('woman-child', 0.7128437161445618)]"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"woman\"],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('non-child', 0.7806164622306824),\n",
       " ('boy-child', 0.7771493196487427),\n",
       " ('infant', 0.7692996859550476),\n",
       " ('mother', 0.7654839754104614),\n",
       " ('child--', 0.7639940977096558),\n",
       " ('children', 0.7630216479301453),\n",
       " ('childen', 0.7588273882865906),\n",
       " ('parent', 0.746644139289856),\n",
       " ('childʼs', 0.7437947392463684),\n",
       " ('only-child', 0.7417019605636597)]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"child\"],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is like deer, the regular plural form muscles its way in, even though it is far less frequent\n",
    "than *mice*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mouses', 0.7705859541893005),\n",
       " ('mousing', 0.7554763555526733),\n",
       " ('mice', 0.7038449645042419),\n",
       " ('mouse-button', 0.7035195231437683),\n",
       " ('mouse-like', 0.6904830932617188),\n",
       " ('mousepad', 0.6862655878067017),\n",
       " ('mouse-click', 0.6830845475196838),\n",
       " ('mouse-based', 0.6790381669998169),\n",
       " ('mouse-clicking', 0.6651208996772766),\n",
       " ('moused', 0.6525858044624329)]"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"mouse\"],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bread', 0.7509481906890869),\n",
       " ('loafs', 0.7418695688247681),\n",
       " ('loaves', 0.659576416015625),\n",
       " ('butter', 0.6558520197868347),\n",
       " ('biscuit', 0.6432216763496399),\n",
       " ('baguette', 0.6394046545028687),\n",
       " ('scone', 0.6365483403205872),\n",
       " ('brioche', 0.635867714881897),\n",
       " ('wholemeal', 0.6191232800483704),\n",
       " ('meatloaf', 0.6027717590332031)]"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"loaf\"],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X-axis', 0.7045288681983948),\n",
       " ('Z-axis', 0.7040368318557739),\n",
       " ('z-axis', 0.7037435173988342),\n",
       " ('axis.', 0.7013909220695496),\n",
       " ('x-axis', 0.698753833770752),\n",
       " ('semi-axis', 0.6924705505371094),\n",
       " ('y-axis', 0.6903954148292542),\n",
       " ('long-axis', 0.6799377202987671),\n",
       " ('-axis', 0.6764941215515137),\n",
       " ('cross-axis', 0.6733323931694031)]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"axis\"],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mini-crisis', 0.8113057613372803),\n",
       " ('crises', 0.8089130520820618),\n",
       " ('crisis-', 0.8034021854400635),\n",
       " ('non-crisis', 0.7960949540138245),\n",
       " ('near-crisis', 0.7668130397796631),\n",
       " ('postcrisis', 0.7658597230911255),\n",
       " ('debt-crisis', 0.7403367757797241),\n",
       " ('turmoil', 0.7358798980712891),\n",
       " ('crisis.', 0.7320274710655212),\n",
       " ('financial-crisis', 0.7316805720329285)]"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"crisis\"],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:**  The vectors for the nouns *cheap* and *inexpensive* are mutual nearest neighbors (NNs) in the sense that the *cheap* vector is the nearest neighbor of the *inexpensive* vector and the *inexpensive* vector is the nearest neighbor of the *cheap* vector, as shown below.  It doesn't have to work out that way (as an example, consider prime numbers: 19  is the closest prime to 23, but 23 is not the closest prime to 19; 17 is).  Come up with three more examples of mutual NNs. Avoid related words like  nouns and their plurals or *act* and *action*.  As a very rough rule for determining two words are unrelated, they shouldn't share their first three letters.  Demonstrate the fact that your word pairs are mutual NNs by finding each word's NN as we have done for *cheap* and *inexpensive* below.  Hint:  Follow the pattern of *cheap* and *inexpensive* and try common adjectives that are strongly associated.  If you need help knowing what an adjective is, look at  [Adam Kilgariff's BNC frequnecy sorted word list](https://www.kilgarriff.co.uk/BNClists/lemma.num), and look for words whose part-of-speech is \"a\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('inexpensive', 0.8434295654296875)], [('cheap', 0.8434293270111084)])"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"cheap\"],topn=1), model2.most_similar(positive=[\"inexpensive\"],topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many of the words that qualify **aren't** synonyms.  They're just\n",
    "strongly associated words, for example, words that are often paired\n",
    "in discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('woman', 0.8119808435440063)], [('man', 0.8119807243347168)])"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"man\"],topn=1),model2.most_similar(positive=[\"woman\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('long', 0.7923822999000549)], [('short', 0.7923824787139893)])"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"short\"],topn=1),model2.most_similar(positive=[\"long\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('black', 0.9345934391021729)], [('white', 0.9345934987068176)])"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"white\"],topn=1), model2.most_similar(positive=[\"black\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('good', 0.8503089547157288)], [('bad', 0.8503088355064392)])"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"bad\"],topn=1),model2.most_similar(positive=[\"good\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('superb', 0.8295968174934387)], [('excellent', 0.8295969367027283)])"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"excellent\"],topn=1),model2.most_similar(positive=[\"superb\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('wet', 0.8566859364509583)], [('dry', 0.8566858768463135)])"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"dry\"],topn=1),model2.most_similar(positive=[\"wet\"],topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:**  Now find two unrelated words *a* and *b* such that *a* is the nearest neighbor of *b* but *b* is not the nearest neighbor of *a*, and whatever *b*'s nearest neighbor is, it isn't related to *b* (by the first three letters rule).    Demonstrate your answers by finding the nearest neighbors of *a* and *b* as in Question 3.  Option 1: you can code this up.  Use `search_wds` above to limit your search to a few thousand common words.  Or: Option 2 one place to look is in **sets** of strongly associated adjectives or adverbs, such as *fair, good, excellent* (except those don't work), *warm*, *lukewarm*, *cool* (and those don't work).\n",
    "\n",
    "Of course,  word pairs that answer this question don't have to be adjectives.  One example of the kind of *a* and *b* words you're looking for is *aunt* and *uncle*.  Here's the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('uncle', 0.8582535982131958)], [('nephew', 0.870086133480072)])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"aunt\"],topn=1),model2.most_similar(positive=[\"uncle\"],topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what you'll end up with is a triplet of semantically close words.   In this case they're all \n",
    "common **kinship terms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is my favorite, because it makes so much sense colorwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('blue', 0.8553687334060669)], [('red', 0.9138011932373047)])"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"purple\"],topn=1),model2.most_similar(positive=[\"blue\"],topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('tepid', 0.8382373452186584)], [('lukewarm', 0.8382373452186584)])"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"lukewarm\"],topn=1),model2.most_similar(positive=[\"tepid\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('red', 0.8753618001937866)], [('blue', 0.9138011932373047)])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"yellow\"],topn=1),model2.most_similar(positive=[\"red\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('regional', 0.8151846528053284)], [('national', 0.845012366771698)])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"local\"],topn=1),model2.most_similar(positive=[\"regional\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('vital', 0.8695250749588013)], [('crucial', 0.8794239163398743)])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"essential\"],topn=1),model2.most_similar(positive=[\"vital\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('scared', 0.7811442017555237)], [('frightened', 0.8641623258590698)])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"afraid\"],topn=1),model2.most_similar(positive=[\"scared\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('extraordinary', 0.8303589820861816)], [('remarkable', 0.8590794205665588)])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"exceptional\"],topn=1),model2.most_similar(positive=[\"extraordinary\"],topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding up the last two problems**\n",
    "\n",
    "Use the `search_wds` list computed above to stick to common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_wds,search_space\n",
    "# Keeping the mutual nns in two aligned lists\n",
    "partner_a,partner_b = [],[]\n",
    "# This will be a list of triples\n",
    "triplets = [ ]\n",
    "for word_1 in search_wds:\n",
    "    if len(word_1) <= 3:\n",
    "        continue\n",
    "    if word_1 in partner_b:\n",
    "        #  this word is already in  a mutual nn couple\n",
    "        continue\n",
    "    nn_1 = model2.most_similar(positive=[word_1],topn=1)[0][0]\n",
    "    if len(nn_1) <= 3 or nn_1 not in search_wds:\n",
    "        continue\n",
    "    if nn_1[:3] == word_1[:3]:\n",
    "        # related word probably\n",
    "        continue\n",
    "    nn_2 = model2.most_similar(positive=[nn_1],topn=1)[0][0]\n",
    "    if nn_2 == word_1:\n",
    "        partner_a.append(word_1)\n",
    "        partner_b.append(nn_1)\n",
    "    elif nn_2[:3] == nn_1[:3]:\n",
    "        # related word probably\n",
    "        continue\n",
    "    elif nn_2 not in search_wds:\n",
    "        # stay away from rarer words\n",
    "        continue\n",
    "    else:\n",
    "        triplets.append((word_1,nn_1,nn_2))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 193)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partner_a),len(partner_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would                      could                    \n",
      "into                       onto                     \n",
      "think                      believe                  \n",
      "more                       less                     \n",
      "last                       next                     \n",
      "should                     must                     \n",
      "these                      those                    \n",
      "after                      before                   \n",
      "something                  anything                 \n",
      "small                      large                    \n",
      "country                    nation                   \n",
      "really                     actually                 \n",
      "week                       month                    \n",
      "word                       phrase                   \n",
      "although                   though                   \n",
      "example                    instance                 \n",
      "long                       short                    \n",
      "often                      frequently               \n",
      "national                   regional                 \n",
      "perhaps                    maybe                    \n",
      "almost                     nearly                   \n",
      "early                      late                     \n",
      "public                     private                  \n",
      "particular                 specific                 \n",
      "sort                       kind                     \n",
      "mother                     father                   \n",
      "remember                   forget                   \n",
      "today                      yesterday                \n",
      "several                    numerous                 \n",
      "major                      minor                    \n",
      "agree                      disagree                 \n",
      "increase                   decrease                 \n",
      "therefore                  thus                     \n",
      "road                       highway                  \n",
      "real                       actual                   \n",
      "likely                     unlikely                 \n",
      "soon                       shortly                  \n",
      "particularly               especially               \n",
      "morning                    afternoon                \n",
      "city                       town                     \n",
      "black                      white                    \n",
      "strong                     weak                     \n",
      "whole                      entire                   \n",
      "usually                    typically                \n",
      "wife                       husband                  \n",
      "certainly                  undoubtedly              \n",
      "story                      tale                     \n",
      "method                     technique                \n",
      "simply                     merely                   \n",
      "reduce                     eliminate                \n",
      "achieve                    attain                   \n",
      "wide                       broad                    \n",
      "front                      rear                     \n",
      "ensure                     assure                   \n",
      "doctor                     physician                \n",
      "film                       movie                    \n",
      "modern                     contemporary             \n",
      "above                      below                    \n",
      "quickly                    swiftly                  \n",
      "previous                   prior                    \n",
      "maintain                   retain                   \n",
      "brother                    sister                   \n",
      "improve                    enhance                  \n",
      "summer                     winter                   \n",
      "determine                  ascertain                \n",
      "university                 college                  \n",
      "outside                    inside                   \n",
      "military                   civilian                 \n",
      "basic                      fundamental              \n",
      "okay                       alright                  \n",
      "aware                      unaware                  \n",
      "exactly                    precisely                \n",
      "president                  vice-president           \n",
      "encourage                  discourage               \n",
      "discover                   uncover                  \n",
      "useful                     helpful                  \n",
      "easily                     readily                  \n",
      "importance                 significance             \n",
      "direct                     indirect                 \n",
      "eventually                 ultimately               \n",
      "no-one                     nobody                   \n",
      "examine                    investigate              \n",
      "north                      south                    \n",
      "slightly                   somewhat                 \n",
      "hardly                     scarcely                 \n",
      "directly                   indirectly               \n",
      "completely                 totally                  \n",
      "obvious                    apparent                 \n",
      "positive                   negative                 \n",
      "male                       female                   \n",
      "slowly                     gradually                \n",
      "relatively                 comparatively            \n",
      "telephone                  phone                    \n",
      "primary                    secondary                \n",
      "apparently                 evidently                \n",
      "plus                       minus                    \n",
      "western                    eastern                  \n",
      "prison                     jail                     \n",
      "nevertheless               nonetheless              \n",
      "mainly                     mostly                   \n",
      "senior                     junior                   \n",
      "vary                       differ                   \n",
      "wood                       timber                   \n",
      "extremely                  incredibly               \n",
      "internal                   external                 \n",
      "strange                    weird                    \n",
      "excellent                  superb                   \n",
      "formal                     informal                 \n",
      "west                       east                     \n",
      "victory                    triumph                  \n",
      "assess                     evaluate                 \n",
      "limited                    restricted               \n",
      "sufficient                 adequate                 \n",
      "expensive                  costly                   \n",
      "properly                   appropriately            \n",
      "perfect                    ideal                    \n",
      "gold                       silver                   \n",
      "shout                      yell                     \n",
      "liberal                    conservative             \n",
      "vital                      crucial                  \n",
      "persuade                   convince                 \n",
      "capable                    incapable                \n",
      "beneath                    underneath               \n",
      "northern                   southern                 \n",
      "terrible                   horrible                 \n",
      "knee                       ankle                    \n",
      "unfortunately              fortunately              \n",
      "permanent                  temporary                \n",
      "inner                      outer                    \n",
      "virtually                  practically              \n",
      "inquiry                    enquiry                  \n",
      "badly                      poorly                   \n",
      "moreover                   furthermore              \n",
      "buyer                      seller                   \n",
      "yours                      ours                     \n",
      "enormous                   immense                  \n",
      "rarely                     seldom                   \n",
      "significantly              substantially            \n",
      "quietly                    silently                 \n",
      "long-term                  short-term               \n",
      "moral                      ethical                  \n",
      "distinguish                differentiate            \n",
      "gently                     softly                   \n",
      "incorporate                integrate                \n",
      "comfortable                uncomfortable            \n",
      "export                     import                   \n",
      "abroad                     overseas                 \n",
      "valuable                   invaluable               \n",
      "bread                      butter                   \n",
      "perspective                viewpoint                \n",
      "co-operation               cooperation              \n",
      "essentially                basically                \n",
      "bishop                     archbishop               \n",
      "conservation               preservation             \n",
      "remarkable                 extraordinary            \n",
      "rapid                      swift                    \n",
      "comprehensive              thorough                 \n",
      "maximum                    minimum                  \n",
      "concerning                 regarding                \n",
      "precise                    exact                    \n",
      "approximately              roughly                  \n",
      "ultimate                   eventual                 \n",
      "inspire                    motivate                 \n",
      "inadequate                 insufficient             \n",
      "condemn                    denounce                 \n",
      "acute                      chronic                  \n",
      "bike                       bicycle                  \n",
      "professor                  lecturer                 \n",
      "uncle                      nephew                   \n",
      "traditionally              historically             \n",
      "upstairs                   downstairs               \n",
      "reluctant                  unwilling                \n",
      "magnificent                splendid                 \n",
      "full-time                  part-time                \n",
      "capitalism                 socialism                \n",
      "explicit                   implicit                 \n",
      "amazing                    incredible               \n",
      "dull                       boring                   \n",
      "improved                   enhanced                 \n",
      "vertical                   horizontal               \n",
      "exclusively                solely                   \n",
      "accuracy                   precision                \n",
      "depict                     portray                  \n",
      "amend                      revise                   \n",
      "girlfriend                 boyfriend                \n",
      "temporarily                permanently              \n",
      "rage                       fury                     \n",
      "selected                   chosen                   \n",
      "cautious                   wary                     \n",
      "grim                       bleak                    \n",
      "outdoor                    indoor                   \n",
      "economically               financially              \n",
      "unusually                  exceptionally            \n"
     ]
    }
   ],
   "source": [
    "for (p1,p2) in zip(partner_a, partner_b):\n",
    "    print(f\"{p1:<25}  {p2:<25}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some                       many                      several                  \n",
      "year                       month                     week                     \n",
      "than                       less                      more                     \n",
      "other                      various                   numerous                 \n",
      "just                       simply                    merely                   \n",
      "only                       just                      simply                   \n",
      "very                       extremely                 incredibly               \n",
      "such                       certain                   specific                 \n",
      "even                       just                      simply                   \n",
      "many                       several                   numerous                 \n",
      "thing                      kind                      sort                     \n",
      "back                       down                      up                       \n",
      "still                      definitely                certainly                \n",
      "great                      tremendous                enormous                 \n",
      "might                      could                     would                    \n",
      "however                    though                    although                 \n",
      "never                      seldom                    rarely                   \n",
      "most                       many                      several                  \n",
      "local                      regional                  national                 \n",
      "rather                     less                      more                     \n",
      "social                     economic                  political                \n",
      "night                      evening                   afternoon                \n",
      "important                  crucial                   vital                    \n",
      "least                      only                      just                     \n",
      "probably                   certainly                 undoubtedly              \n",
      "ever                       never                     seldom                   \n",
      "main                       primary                   secondary                \n",
      "certain                    specific                  particular               \n",
      "sometimes                  often                     frequently               \n",
      "indeed                     certainly                 undoubtedly              \n",
      "various                    numerous                  several                  \n",
      "clearly                    obviously                 certainly                \n",
      "evening                    afternoon                 morning                  \n",
      "instead                    simply                    merely                   \n",
      "generally                  usually                   typically                \n",
      "obviously                  certainly                 undoubtedly              \n",
      "apart                      away                      off                      \n",
      "considerable               substantial               significant              \n",
      "highly                     extremely                 incredibly               \n",
      "concept                    idea                      notion                   \n",
      "green                      yellow                    red                      \n",
      "past                       previous                  prior                    \n",
      "fully                      completely                totally                  \n",
      "essential                  vital                     crucial                  \n",
      "normally                   usually                   typically                \n",
      "huge                       enormous                  immense                  \n",
      "largely                    mostly                    mainly                   \n",
      "entirely                   completely                totally                  \n",
      "author                     writer                    novelist                 \n",
      "unable                     unwilling                 reluctant                \n",
      "surely                     certainly                 undoubtedly              \n",
      "promote                    encourage                 discourage               \n",
      "ought                      should                    must                     \n",
      "afraid                     scared                    frightened               \n",
      "quick                      easy                      straightforward          \n",
      "spring                     summer                    winter                   \n",
      "tiny                       small                     large                    \n",
      "narrow                     broad                     wide                     \n",
      "ancient                    modern                    contemporary             \n",
      "vast                       huge                      enormous                 \n",
      "explore                    examine                   investigate              \n",
      "rapidly                    quickly                   swiftly                  \n",
      "somehow                    actually                  really                   \n",
      "massive                    huge                      enormous                 \n",
      "alter                      modify                    revise                   \n",
      "autumn                     summer                    winter                   \n",
      "regularly                  frequently                often                    \n",
      "subsequently               eventually                ultimately               \n",
      "brilliant                  superb                    excellent                \n",
      "anger                      rage                      fury                     \n",
      "presumably                 apparently                evidently                \n",
      "definitely                 certainly                 undoubtedly              \n",
      "primarily                  mainly                    mostly                   \n",
      "fewer                      less                      more                     \n",
      "reasonably                 fairly                    pretty                   \n",
      "outstanding                excellent                 superb                   \n",
      "awful                      horrible                  terrible                 \n",
      "pink                       purple                    blue                     \n",
      "impressive                 remarkable                extraordinary            \n",
      "considerably               significantly             substantially            \n",
      "sustain                    maintain                  retain                   \n",
      "strengthen                 enhance                   improve                  \n",
      "thereby                    thus                      therefore                \n",
      "evident                    apparent                  obvious                  \n",
      "purely                     solely                    exclusively              \n",
      "passion                    enthusiasm                excitement               \n",
      "underlying                 fundamental               basic                    \n",
      "cousin                     nephew                    uncle                    \n",
      "notably                    particularly              especially               \n",
      "purchaser                  buyer                     seller                   \n",
      "barely                     hardly                    scarcely                 \n",
      "modify                     revise                    amend                    \n",
      "wholly                     entirely                  completely               \n",
      "sole                       ultimate                  eventual                 \n",
      "tremendous                 enormous                  immense                  \n",
      "strictly                   purely                    solely                   \n",
      "lightly                    heavily                   strongly                 \n",
      "sadly                      unfortunately             fortunately              \n",
      "forth                      back                      down                     \n",
      "precious                   valuable                  invaluable               \n",
      "exceptional                extraordinary             remarkable               \n",
      "steadily                   slowly                    gradually                \n",
      "freely                     openly                    publicly                 \n",
      "invariably                 often                     frequently               \n",
      "orange                     yellow                    red                      \n",
      "aunt                       uncle                     nephew                   \n",
      "reassure                   assure                    ensure                   \n",
      "dreadful                   terrible                  horrible                 \n",
      "minimal                    substantial               significant              \n",
      "worthwhile                 useful                    helpful                  \n",
      "utterly                    totally                   completely               \n",
      "partially                  completely                totally                  \n",
      "seemingly                  apparently                evidently                \n",
      "respective                 their                     own                      \n",
      "adequately                 properly                  appropriately            \n",
      "purple                     blue                      red                      \n",
      "likewise                   thus                      therefore                \n",
      "glorious                   magnificent               splendid                 \n",
      "gradual                    rapid                     swift                    \n",
      "bizarre                    weird                     strange                  \n",
      "investigator               researcher                scientist                \n",
      "theirs                     ours                      yours                    \n",
      "uneasy                     uncomfortable             comfortable              \n",
      "duly                       promptly                  swiftly                  \n",
      "promptly                   swiftly                   quickly                  \n",
      "fundamentally              essentially               basically                \n",
      "vicious                    nasty                     unpleasant               \n"
     ]
    }
   ],
   "source": [
    "for (p1,p2,p3) in triplets:\n",
    "    print(f\"{p1:<25}  {p2:<25} {p3:<25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**:  Look up the 25 words most similar to *inteligence* and *lingusitics* (yes, those are  the spellings I mean), and describe an application of word vectors involving spelling correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**:  Maintain a  regular dictionary and morphological analyzer that works only with standard words.\n",
    "When a lookup fails (presumably because of a misspelling), turn to your word vector model (`wv`) and look up the misspelling using `wv.most_similar`. Choose the nearest neighbor that is in the standard dictionary.  You might also want to check that it shares a lot of letters with the misspelling and move on to the next best candidate if not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two:  The analogy test set\n",
    "\n",
    "Demonstrating state-of-the-art performance on the analogy test set was an early triumph of the word2vec model.  Some of the inflated claims made as a result of that performance have been justifiably criticized since, on the grounds that there are many kinds of analogies that humans are good at that this kind of word vector model is very bad at.  In retrospect, however, the strong performance on analogies, in particular, the kind of analogies the system was best at, can be seen an early harbinger of the power of language models.\n",
    "\n",
    "As you will see below, it demonstrates just how much real world knowwledge is packed into a robustly trained language model, forshadowing the spectular successes of later LLMs on tasks like question-answering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing an analogy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task for the system is to complete an analogy of the following form :  *Man is to woman as king is to ??*.\n",
    "\n",
    "Using word vectors, this is computed as follows.  \n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "v_{\\Delta} & =& v_{\\text{woman}} - v_{\\text{man}}\\\\\n",
    "v_{??}  & =& v_{\\text{king}} + v_{\\Delta}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We will call $v_{??}$ the $\\Delta$-point.  The $\\Delta$-point is displaced \n",
    "from *king* by the same amount and in the same direction\n",
    "as *woman* is from *man*.  The algorithm for  analogy completion with word vectors\n",
    "is to find the $\\Delta$-point and then find the closest word vector to\n",
    "$\\Delta$-point.  If all goes well, that vector will be *queen*.\n",
    "\n",
    "The algorithm is implemented in `gensim` with the `most_similar` method.  By default, the method returns\n",
    "a list of contenders ranked by how close they are to the $\\Delta$-point, where closeness is measured by\n",
    "cosine.  For the analogy above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.778674840927124),\n",
       " ('queen-mother', 0.7143871784210205),\n",
       " ('king-', 0.6981282830238342),\n",
       " ('queen-consort', 0.6724598407745361),\n",
       " ('monarch', 0.6667000651359558),\n",
       " ('child-king', 0.6663159132003784),\n",
       " ('boy-king', 0.660534679889679),\n",
       " ('princess', 0.653827428817749),\n",
       " ('ex-queen', 0.652145504951477),\n",
       " ('kings', 0.6497675776481628)]"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model got this one right because *queen* is the top-scoring vector. The cosine scores show that it wins\n",
    "by a significant margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the computation in code.  Not sure why my cosine value differs from gensim's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def my_cosine (v1, v2):\n",
    "    return v1.dot(v2)/(np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75703365"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_vec = model2['king'] + (model2['woman'] - model2['man'])\n",
    "my_cosine (model2['queen'], delta_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallelogram theory of analogy did not actually originate with the authors of the word2vec \n",
    "paper.  Here is the description of the original account as summarized in Peterson et al. (2020)\n",
    "\n",
    "> The parallelogram model of analogy, ... first proposed by Rumelhart and\n",
    "Abrahamson (1973), provides one solution to this problem for simple analogies based on relational\n",
    "similarity. In this model, entities are represented as points in a Euclidean space and relations\n",
    "between entities are represented as their difference vectors. Even though two pairs of points (A, B)\n",
    "and (D, C) may be far apart in the space (i.e., they are featurally dissimilar), they are considered\n",
    "relationally similar as long as their difference vectors (B − A) and (D − C) are similar. Rumelhart\n",
    "and Abrahamson found that this simple model worked well for a small domain of animal words,\n",
    "which are represented by vectors obtained using low-dimensional multidimensional scaling\n",
    "solutions.  -- Peterson et al. (2020):\n",
    "> Parallelograms revisited: Exploring the limitations of vector space models for simple analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell must be executed to complete the assignment.  It uploads the **Google Test Set** discussed in Mikolov et al (2013).  This is a file analogy tasks you will use to evaluate your word vectors.  The test items  are in `test_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def do_analogy(model,a,b,c, restrict_vocab=None,topn=1):\n",
    "    return model.most_similar(positive=[b,c], negative=[a],restrict_vocab=restrict_vocab,topn=topn)\n",
    "\n",
    "def get_content (url,verbose=False):\n",
    "    try:\n",
    "        # Open the URL and get the response\n",
    "        response = urllib.request.urlopen(url)\n",
    "\n",
    "        # Read the content from the response\n",
    "        content = response.read()\n",
    "\n",
    "        # Decode the bytes to a string (default is utf-8)\n",
    "        content = content.decode('utf-8')\n",
    "\n",
    "        if verbose:\n",
    "            # Print the content\n",
    "            print(content)\n",
    "    except urllib.error.HTTPError as e:\n",
    "        # Handle HTTP errors (e.g., 404 Not Found, 403 Forbidden)\n",
    "        print(f\"HTTP Error: {e.code} {e.reason}\")\n",
    "    except urllib.error.URLError as e:\n",
    "        # Handle other URL errors (e.g., network issues, invalid URL)\n",
    "        print(f\"URL Error: {e.reason}\")\n",
    "    return content\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/gawron/python-for-social-science/\"\\\n",
    "\"refs/heads/master/new_nbs_2025/questions-words.txt\"\n",
    "content = get_content (url)\n",
    "\n",
    "\n",
    "def make_analogies_dict (content):\n",
    "    test_dict = defaultdict(list)\n",
    "    lines = content.split(\"\\n\")\n",
    "    category = \"any\"\n",
    "    for line in lines:\n",
    "        if re.match(r\":\\s+\",line):\n",
    "            category = re.findall(r\":\\s+([\\w-]+)\",line)[0]\n",
    "            test_dict[category]\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                (a,b,c,d) = line.strip().split()\n",
    "            except ValueError:\n",
    "                continue\n",
    "            test_dict[category].append((a,b,c,d))\n",
    "    return test_dict\n",
    "\n",
    "test_dict = make_analogies_dict(content)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some test items.  The idea is for the model to be given the first three terms in each item \n",
    "and predict the fourth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Athens', 'Greece', 'Oslo', 'Norway'),\n",
       " ('Athens', 'Greece', 'Ottawa', 'Canada'),\n",
       " ('Athens', 'Greece', 'Paris', 'France'),\n",
       " ('Athens', 'Greece', 'Rome', 'Italy'),\n",
       " ('Athens', 'Greece', 'Stockholm', 'Sweden')]"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict['capital-common-countries'][15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `do_analogy` function, which calls the `most_similar` method  has been provided as a convenience.  The model completes the first analogy printed out above correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Norway', 0.7850077748298645)]"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_analogy(model2,\"Athens\",\"Greece\",\"Oslo\", restrict_vocab=None,topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the keyword value `topn=1` the `do_analogy` function prints out a singleton list containing the winning candidate for completing the analogy and the similarity score indicating how close the winner is to the $\\Delta$ point.\n",
    "\n",
    "Here is another sample of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hanoi', 'Vietnam', 'Berlin', 'Germany'),\n",
       " ('Hanoi', 'Vietnam', 'Bern', 'Switzerland'),\n",
       " ('Hanoi', 'Vietnam', 'Cairo', 'Egypt'),\n",
       " ('Hanoi', 'Vietnam', 'Canberra', 'Australia'),\n",
       " ('Havana', 'Cuba', 'Helsinki', 'Finland')]"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict['capital-common-countries'][194:199]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this time the model gets the first example printed out wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('West-Berlin', 0.6976140141487122)]"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_analogy(model2,\"Hanoi\",\"Vietnam\",\"Berlin\", restrict_vocab=None,topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a property of the character-sensitive word vectors that a vector $d$ displaced from vector $v$ can \n",
    "still be highly similar to words spelled like $v$.  It depends on the displacement of course,\n",
    "but in this case the displacement is semantic, and it may be that character-level properties are preserved\n",
    "with semantic displacements.\n",
    "\n",
    "As a consolation, the right answer does not lose by much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('West-Berlin', 0.6976140141487122),\n",
       " ('East-Berlin', 0.6797472238540649),\n",
       " ('Germany', 0.6623671054840088),\n",
       " ('Berlins', 0.635513424873352),\n",
       " ('Europe', 0.6308843493461609)]"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_analogy(model2,\"Hanoi\",\"Vietnam\",\"Berlin\", restrict_vocab=None,topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14 test categories each containing  a collecting of analogies involving a particular\n",
    "area of real world or linguistic information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['capital-common-countries', 'capital-world', 'currency', 'city-in-state', 'family', 'gram1-adjective-to-adverb', 'gram2-opposite', 'gram3-comparative', 'gram4-superlative', 'gram5-present-participle', 'gram6-nationality-adjective', 'gram7-past-tense', 'gram8-plural', 'gram9-plural-verbs'])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys in the `test_dict` dictionary are thus category names; the values returned\n",
    "are the associated test items.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dict['capital-common-countries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shows there are 506 test items for the categiry `capital-common-countries`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part two questions\n",
    "\n",
    "**Question 1A:**  Your first job is to compute the percentage of accuracy on each of the 14 categories in the Google analogy data loaded above.  Do it category by  category, to discover which categories are the hardest.  \n",
    "\n",
    "**Question 1B:** Given how you know the model is trained, and given how well it is doing in many categories, why do you think it is doing so poorly on the category for which it has the lowest score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 506 capital-common-countries items. Examples of individual items and how to use the model to complete them were given above.  As an example, your score on the `capital-common-countries` category should be over 98%\n",
    "(the model gets fewer than 10 items wrong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "capital-common-countries       98.62%  [499/506]\n",
      "capital-world                  95.47%  [4319/4524]\n",
      "currency                       37.76%  [327/866]\n",
      "city-in-state                  80.58%  [1988/2467]\n",
      "family                         85.18%  [431/506]\n",
      "gram1-adjective-to-adverb      69.76%  [692/992]\n",
      "gram2-opposite                 60.84%  [494/812]\n",
      "gram3-comparative              97.00%  [1292/1332]\n",
      "gram4-superlative              99.29%  [1114/1122]\n",
      "gram5-present-participle       97.82%  [1033/1056]\n",
      "gram6-nationality-adjective    92.81%  [1484/1599]\n",
      "gram7-past-tense               83.85%  [1308/1560]\n",
      "gram8-plural                   94.59%  [1260/1332]\n",
      "gram9-plural-verbs             95.29%  [829/870]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "capital-common-countries       98.62%  [499/506]\n",
    "capital-world                  95.47%  [4319/4524]\n",
    "currency                       37.76%  [327/866]\n",
    "city-in-state                  80.58%  [1988/2467]\n",
    "family                         85.18%  [431/506]\n",
    "gram1-adjective-to-adverb      69.76%  [692/992]\n",
    "gram2-opposite                 60.84%  [494/812]\n",
    "gram3-comparative              97.00%  [1292/1332]\n",
    "gram4-superlative              99.29%  [1114/1122]\n",
    "gram5-present-participle       97.82%  [1033/1056]\n",
    "gram6-nationality-adjective    92.81%  [1484/1599]\n",
    "gram7-past-tense               83.85%  [1308/1560]\n",
    "gram8-plural                   94.59%  [1260/1332]\n",
    "gram9-plural-verbs             95.29%  [829/870]\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my evaluation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries       98.62%  [499/506]\n",
      "capital-world                  95.47%  [4319/4524]\n",
      "currency                       37.76%  [327/866]\n",
      "city-in-state                  80.58%  [1988/2467]\n",
      "family                         85.18%  [431/506]\n",
      "gram1-adjective-to-adverb      69.76%  [692/992]\n",
      "gram2-opposite                 60.84%  [494/812]\n",
      "gram3-comparative              97.00%  [1292/1332]\n",
      "gram4-superlative              99.29%  [1114/1122]\n",
      "gram5-present-participle       97.82%  [1033/1056]\n",
      "gram6-nationality-adjective    92.81%  [1484/1599]\n",
      "gram7-past-tense               83.85%  [1308/1560]\n",
      "gram8-plural                   94.59%  [1260/1332]\n",
      "gram9-plural-verbs             95.29%  [829/870]\n",
      "\n",
      "905 words in test set.\n"
     ]
    }
   ],
   "source": [
    "def print_item (ranked,topn,a,b,c,d):\n",
    "    for (wd,sc) in ranked[:topn]:\n",
    "        print(f\"{a:<15} {b:<15} {c:<15} {d:<15} {wd:<15} {sc:.3f}\")\n",
    "    if topn > 1:\n",
    "        print()\n",
    "\n",
    "analogy_word_set = set()\n",
    "\n",
    "def eval_analogy_item (model, a,b,c,d,restrict_vocab=None,verbose=0, case=None,topn=1):\n",
    "    \"\"\"\n",
    "    For error-analysis: \n",
    "    \n",
    "    verbose = 1 prints out only wrong examples; \n",
    "    verbose = 2 prints out only correct examples (useful when there are more worng than right);\n",
    "    verbose = 3 prints out all of them.\n",
    "    \"\"\"\n",
    "    analogy_word_set.update((a,b,c,d))\n",
    "    ranked = do_analogy(model,a,b,c, restrict_vocab=restrict_vocab,topn=topn)\n",
    "    if d == ranked[0][0]:\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False \n",
    "    if (verbose == 3) or (verbose == 1 and not correct):\n",
    "        print_item (ranked,topn,a,b,c,d)\n",
    "    if verbose == 2 and correct:\n",
    "        print_item (ranked,topn,a,b,c,d)\n",
    "    return correct\n",
    "\n",
    "for category in test_dict:\n",
    "    ctr = 0\n",
    "    items = test_dict[category]\n",
    "    nitems = len(items)\n",
    "    for (a,b,c,d) in items:\n",
    "        ctr += eval_analogy_item (model2, a,b,c,d,verbose=0)\n",
    "    print(f\"{category:<30} {ctr/nitems:.2%}  [{ctr}/{nitems}]\")\n",
    "    \n",
    "print()\n",
    "print(f\"{len(analogy_word_set)} words in test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1B**  Why is the currency category so bad?  \n",
    "\n",
    "Currency words and nationality words do mostly fall into highly specific regions of the embedding space.  The nearest neighbors of countries generally include a lot of countries and the nearest neighbors of currencies generally include a lot of currencies.  So many of the $\\Delta$-vectors are pointed roughly in the right direction, from the country domain into the currency domain, as can be seen from the fact that many of the errors are currency terms, just not the right currency.  So how does the model ever get it right?  Well something like the following must be happening.  The $\\Delta$ point is in the currency domain (which involves, say, dimensions $i$, $j$, and $k$).  And the right currency is chosen because the  $\\Delta$ point is displaced into the currency domain from country $c$,  so it still retains many of $c$'s features (say, $l$, $m$, and $o$). This means that it will be more similar to the currency of country $c$ than to the currency of other countries, because the currency of country $c$ also shares some features with country $c$ (say, $l$, $m$, and $q$).  Notice that this formulation doesn't assume that currency $d$ and the country $c$ ever occur in the same sentence (although it wouldn't hurt!), just that they share significant numbers of contexts (they're both South American, they're both suffering from inflation, they both co-occur with Brazilian soccer players).\n",
    "\n",
    "Then here are some factors that might make things go wrong: (a) contexts establishing the\n",
    "connection between country $c$ and currency $d$ are not well enough supported in the data. Guess \n",
    "number one is that that's because currency $d$ is rare in the data. Guess number 2 is that some\n",
    "other currency is outcompeting  $d$ for country $c$ features; (b) currency $d$ is ambiguous as to country, like *peso*. (c) either currency is just ambiguous as to whether it's a currency.  The Brazilian real is a disaster, for example, because of the ambiguity of the word *real*. (d)  Sometimes features from currency $b$ persist through the $\\Delta$-ing.  Character level features seem to be a good example. For example, *dongs* is frequently chosen for $d$ when currency $b$ is *dong*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Algeria', 'dinar', 'Angola', 'kwanza')"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict['currency'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some nearest neighbors for currency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dinars', 0.8083240985870361),\n",
       " ('dinara', 0.6847990155220032),\n",
       " ('Dinar', 0.6501309871673584),\n",
       " ('dirham', 0.6494027376174927),\n",
       " ('rial', 0.6491531729698181),\n",
       " ('forint', 0.6173461079597473),\n",
       " ('manat', 0.6147133111953735),\n",
       " ('riyal', 0.6141151189804077),\n",
       " ('shekel', 0.5998964309692383),\n",
       " ('lira', 0.585889458656311)]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(\"dinar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pesos', 0.7524384260177612),\n",
       " ('bolívar', 0.7084741592407227),\n",
       " ('colón', 0.6957192420959473),\n",
       " ('peseta', 0.6849592924118042),\n",
       " ('Peso', 0.6739704012870789),\n",
       " ('piso', 0.6666857600212097),\n",
       " ('centavo', 0.6628603935241699),\n",
       " ('dollar', 0.6429269909858704),\n",
       " ('rupee', 0.6343357563018799),\n",
       " ('bolivar', 0.6318812370300293),\n",
       " ('rupiah', 0.6313176155090332),\n",
       " ('sospeso', 0.6304391622543335),\n",
       " ('bolívares', 0.6233600974082947),\n",
       " ('sucre', 0.623075008392334),\n",
       " ('lira', 0.6196767687797546),\n",
       " ('kwacha', 0.6147161722183228),\n",
       " ('peso-denominated', 0.6117200255393982),\n",
       " ('dollarization', 0.6037328243255615),\n",
       " ('rupia', 0.6014737486839294),\n",
       " ('bolívars', 0.6000157594680786)]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(\"peso\",topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely has currency features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kwanza', 0.7323664426803589),\n",
       " ('kwanzaa', 0.7269247174263),\n",
       " ('kwamba', 0.7164309620857239),\n",
       " ('kwacha', 0.7134572863578796),\n",
       " ('Kwacha', 0.6563941836357117),\n",
       " ('yayo', 0.6510071158409119),\n",
       " ('Ndonga', 0.6398398280143738),\n",
       " ('Kikongo', 0.6338241100311279),\n",
       " ('kwai', 0.6317110657691956),\n",
       " ('kongo', 0.6313470602035522)]"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kwacha is a currency, yayo seems to be a bitcoin\n",
    "# kwai is slang for  yuan\n",
    "model2.most_similar(\"kwanza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dinars', 0.5939924716949463),\n",
       " ('dinara', 0.5664173364639282),\n",
       " ('escudo', 0.5256189107894897),\n",
       " ('kwacha', 0.4998340904712677),\n",
       " ('forint', 0.4993775188922882),\n",
       " ('kyat', 0.4920961856842041),\n",
       " ('ruble', 0.4879476726055145),\n",
       " ('kuna', 0.4862690567970276),\n",
       " ('krone', 0.4822653532028198),\n",
       " ('birr', 0.48197510838508606),\n",
       " ('shekel', 0.4786297678947449),\n",
       " ('scudo', 0.47451627254486084),\n",
       " ('kroon', 0.47092241048812866),\n",
       " ('rial', 0.4677731692790985),\n",
       " ('gulden', 0.4659681022167206),\n",
       " ('naira', 0.46535149216651917),\n",
       " ('riyal', 0.46492430567741394),\n",
       " ('peso', 0.4633786082267761),\n",
       " ('rupee', 0.4610038697719574),\n",
       " ('Dinar', 0.45956841111183167),\n",
       " ('rouble', 0.4590199589729309),\n",
       " ('centavo', 0.4577377438545227),\n",
       " ('tolar', 0.4557463228702545),\n",
       " ('guilder', 0.4550864100456238),\n",
       " ('manat', 0.4482731223106384),\n",
       " ('lira', 0.4470963180065155),\n",
       " ('złoty', 0.4468900263309479),\n",
       " ('cedi', 0.4468514621257782),\n",
       " ('tenge', 0.4432205259799957),\n",
       " ('korun', 0.4416601359844208),\n",
       " ('rupiah', 0.441529244184494),\n",
       " ('gold-backed', 0.4411298632621765),\n",
       " ('koruna', 0.4411202669143677),\n",
       " ('litas', 0.43704453110694885),\n",
       " ('Angolan', 0.4363434910774231),\n",
       " ('shilling', 0.43618786334991455),\n",
       " ('hryvnia', 0.4359225630760193),\n",
       " ('escudos', 0.43544626235961914),\n",
       " ('denar', 0.43024885654449463),\n",
       " ('pula', 0.4294217526912689),\n",
       " ('baht', 0.42908477783203125),\n",
       " ('piastre', 0.4279710054397583),\n",
       " ('bolívar', 0.4267989695072174),\n",
       " ('pengő', 0.42664647102355957),\n",
       " ('dirham', 0.4259699583053589),\n",
       " ('toman', 0.42288216948509216),\n",
       " ('kopek', 0.42068445682525635),\n",
       " ('kwanza', 0.4199943244457245),\n",
       " ('Rupiah', 0.4196234941482544),\n",
       " ('Peso', 0.41939777135849)]"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# desired answer kwanza; a lot of currencies are beating it out,\n",
    "# suggesting low frequency in Angola-contexts\n",
    "do_analogy(model2, \"Algeria\", \"dinar\",\"Angola\",topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For doing some error-analysis: `verbose = 1` prints out only wrong examples; `verbose = 2` prints out\n",
    "out only correct examples; `verbose = 3` prints all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algeria         dinar           Angola          kwanza          dinars          0.594\n",
      "Algeria         dinar           Argentina       peso            dinara          0.580\n",
      "Algeria         dinar           Armenia         dram            dinars          0.547\n",
      "Algeria         dinar           Brazil          real            dinara          0.589\n",
      "Algeria         dinar           Bulgaria        lev             forint          0.551\n",
      "Algeria         dinar           Cambodia        riel            baht            0.536\n",
      "Algeria         dinar           Canada          dollar          dinara          0.489\n",
      "Algeria         dinar           Croatia         kuna            Croatian        0.582\n",
      "Algeria         dinar           Europe          euro            dinars          0.551\n",
      "Algeria         dinar           Japan           yen             dinara          0.564\n",
      "Algeria         dinar           Korea           won             dinara          0.535\n",
      "Algeria         dinar           Latvia          lats            Latvian         0.554\n",
      "Algeria         dinar           Macedonia       denar           dinara          0.551\n",
      "Algeria         dinar           Romania         leu             forint          0.602\n",
      "Algeria         dinar           Sweden          krona           krone           0.618\n",
      "Algeria         dinar           USA             dollar          dinara          0.500\n",
      "Algeria         dinar           Vietnam         dong            baht            0.512\n",
      "Angola          kwanza          Argentina       peso            uruguayo        0.567\n",
      "Angola          kwanza          Armenia         dram            Artsakh         0.531\n",
      "Angola          kwanza          Brazil          real            Brazilia        0.569\n",
      "Angola          kwanza          Bulgaria        lev             bulgaria        0.596\n",
      "Angola          kwanza          Cambodia        riel            cambodia        0.571\n",
      "Angola          kwanza          Canada          dollar          Canada.         0.576\n",
      "Angola          kwanza          Denmark         krone           Danmark         0.585\n",
      "Angola          kwanza          Europe          euro            europe          0.584\n",
      "Angola          kwanza          Hungary         forint          korona          0.639\n",
      "Angola          kwanza          India           rupee           diwali          0.630\n",
      "Angola          kwanza          Iran            rial            khomeini        0.577\n",
      "Angola          kwanza          Japan           yen             nihon           0.606\n",
      "Angola          kwanza          Korea           won             Korea.          0.659\n",
      "Angola          kwanza          Latvia          lats            Latvijas        0.577\n",
      "Angola          kwanza          Lithuania       litas           Lietuva         0.632\n",
      "Angola          kwanza          Macedonia       denar           macedonia       0.630\n",
      "Angola          kwanza          Malaysia        ringgit         1Malaysia       0.602\n",
      "Angola          kwanza          Mexico          peso            mexica          0.617\n",
      "Angola          kwanza          Nigeria         naira           yoruba          0.606\n",
      "Angola          kwanza          Poland          zloty           krakow          0.577\n",
      "Angola          kwanza          Romania         leu             romania         0.630\n",
      "Angola          kwanza          Russia          ruble           Russsia         0.544\n",
      "Angola          kwanza          Thailand        baht            Thai            0.596\n",
      "Angola          kwanza          Ukraine         hryvnia         Hryvnia         0.589\n",
      "Angola          kwanza          USA             dollar          -USA            0.565\n",
      "Angola          kwanza          Vietnam         dong            VietNam         0.586\n",
      "Angola          kwanza          Algeria         dinar           kwanzaa         0.559\n",
      "Argentina       peso            Armenia         dram            ruble           0.531\n",
      "Argentina       peso            Brazil          real            reais           0.613\n",
      "Argentina       peso            Bulgaria        lev             hryvnia         0.560\n",
      "Argentina       peso            Cambodia        riel            baht            0.593\n",
      "Argentina       peso            Europe          euro            dollar          0.581\n",
      "Argentina       peso            Korea           won             hwan            0.569\n",
      "Argentina       peso            Latvia          lats            hryvnia         0.607\n",
      "Argentina       peso            Macedonia       denar           Macedonian      0.537\n",
      "Argentina       peso            Vietnam         dong            đồng            0.585\n",
      "Argentina       peso            Algeria         dinar           franc           0.544\n",
      "Armenia         dram            Brazil          real            drams           0.493\n",
      "Armenia         dram            Bulgaria        lev             drams           0.559\n",
      "Armenia         dram            Cambodia        riel            drams           0.514\n",
      "Armenia         dram            Canada          dollar          drams           0.523\n",
      "Armenia         dram            Croatia         kuna            Croatian        0.545\n",
      "Armenia         dram            Denmark         krone           Danish          0.544\n",
      "Armenia         dram            Europe          euro            groat           0.541\n",
      "Armenia         dram            Hungary         forint          groat           0.554\n",
      "Armenia         dram            India           rupee           all-India       0.554\n",
      "Armenia         dram            Iran            rial            drams           0.555\n",
      "Armenia         dram            Japan           yen             Japanese        0.512\n",
      "Armenia         dram            Korea           won             Korean          0.553\n",
      "Armenia         dram            Latvia          lats            Latvian         0.535\n",
      "Armenia         dram            Lithuania       litas           drams           0.531\n",
      "Armenia         dram            Macedonia       denar           drams           0.530\n",
      "Armenia         dram            Malaysia        ringgit         Malaysian       0.551\n",
      "Armenia         dram            Mexico          peso            mescal          0.521\n",
      "Armenia         dram            Nigeria         naira           Nigerian        0.564\n",
      "Armenia         dram            Poland          zloty           groat           0.544\n",
      "Armenia         dram            Romania         leu             drams           0.562\n",
      "Armenia         dram            Russia          ruble           drams           0.575\n",
      "Armenia         dram            Sweden          krona           Swedish         0.531\n",
      "Armenia         dram            Thailand        baht            Thai            0.529\n",
      "Armenia         dram            Ukraine         hryvnia         drams           0.579\n",
      "Armenia         dram            USA             dollar          pint            0.492\n",
      "Armenia         dram            Vietnam         dong            post-Vietnam    0.491\n",
      "Armenia         dram            Algeria         dinar           drams           0.506\n",
      "Armenia         dram            Angola          kwanza          drams           0.502\n",
      "Armenia         dram            Argentina       peso            Argentine       0.567\n",
      "Brazil          real            Bulgaria        lev             actual          0.588\n",
      "Brazil          real            Cambodia        riel            actual          0.592\n",
      "Brazil          real            Canada          dollar          actual          0.605\n",
      "Brazil          real            Croatia         kuna            non-real        0.599\n",
      "Brazil          real            Denmark         krone           actual          0.598\n",
      "Brazil          real            Europe          euro            actual          0.620\n",
      "Brazil          real            Hungary         forint          actual          0.584\n",
      "Brazil          real            India           rupee           actual          0.643\n",
      "Brazil          real            Iran            rial            Iranian-related 0.591\n",
      "Brazil          real            Japan           yen             actual          0.623\n",
      "Brazil          real            Korea           won             actual          0.614\n",
      "Brazil          real            Latvia          lats            non-real        0.580\n",
      "Brazil          real            Lithuania       litas           non-real        0.590\n",
      "Brazil          real            Macedonia       denar           Macedonian      0.584\n",
      "Brazil          real            Malaysia        ringgit         genuine         0.600\n",
      "Brazil          real            Mexico          peso            non-real        0.628\n",
      "Brazil          real            Nigeria         naira           genuine         0.620\n",
      "Brazil          real            Poland          zloty           actual          0.622\n",
      "Brazil          real            Romania         leu             non-real        0.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brazil          real            Russia          ruble           non-real        0.611\n",
      "Brazil          real            Sweden          krona           actual          0.597\n",
      "Brazil          real            Thailand        baht            actual          0.602\n",
      "Brazil          real            Ukraine         hryvnia         actual          0.606\n",
      "Brazil          real            USA             dollar          actual          0.629\n",
      "Brazil          real            Vietnam         dong            Vietnam-like    0.580\n",
      "Brazil          real            Algeria         dinar           actual          0.575\n",
      "Brazil          real            Angola          kwanza          actual          0.654\n",
      "Brazil          real            Argentina       peso            non-real        0.657\n",
      "Brazil          real            Armenia         dram            Armenian        0.598\n",
      "Bulgaria        lev             Cambodia        riel            khmer           0.551\n",
      "Bulgaria        lev             Canada          dollar          canada          0.556\n",
      "Bulgaria        lev             Denmark         krone           Børsen          0.585\n",
      "Bulgaria        lev             Europe          euro            europe          0.531\n",
      "Bulgaria        lev             Japan           yen             Japans          0.563\n",
      "Bulgaria        lev             Korea           won             hwan            0.589\n",
      "Bulgaria        lev             Latvia          lats            Latvian         0.583\n",
      "Bulgaria        lev             Macedonia       denar           leva            0.534\n",
      "Bulgaria        lev             USA             dollar          berlin          0.469\n",
      "Bulgaria        lev             Vietnam         dong            vietnam         0.573\n",
      "Bulgaria        lev             Algeria         dinar           Algerian        0.529\n",
      "Bulgaria        lev             Angola          kwanza          Angolan         0.543\n",
      "Bulgaria        lev             Argentina       peso            Argentine       0.534\n",
      "Bulgaria        lev             Armenia         dram            manat           0.562\n",
      "Bulgaria        lev             Brazil          real            cruzeiro        0.571\n",
      "Cambodia        riel            Canada          dollar          Canadas         0.539\n",
      "Cambodia        riel            Denmark         krone           kroner          0.576\n",
      "Cambodia        riel            Hungary         forint          korona          0.566\n",
      "Cambodia        riel            India           rupee           paisa           0.545\n",
      "Cambodia        riel            Iran            rial            toman           0.583\n",
      "Cambodia        riel            Korea           won             hwan            0.613\n",
      "Cambodia        riel            Latvia          lats            litas           0.580\n",
      "Cambodia        riel            Macedonia       denar           liras           0.527\n",
      "Cambodia        riel            Poland          zloty           złoty           0.615\n",
      "Cambodia        riel            Russia          ruble           rubles          0.634\n",
      "Cambodia        riel            Sweden          krona           kronen          0.582\n",
      "Cambodia        riel            Ukraine         hryvnia         hryvnya         0.636\n",
      "Cambodia        riel            USA             dollar          eur             0.475\n",
      "Cambodia        riel            Vietnam         dong            riels           0.512\n",
      "Cambodia        riel            Algeria         dinar           rie             0.546\n",
      "Cambodia        riel            Angola          kwanza          Angolan         0.552\n",
      "Cambodia        riel            Argentina       peso            Argentine       0.594\n",
      "Cambodia        riel            Armenia         dram            liras           0.536\n",
      "Cambodia        riel            Brazil          real            reais           0.599\n",
      "Cambodia        riel            Bulgaria        lev             liras           0.568\n",
      "Canada          dollar          Croatia         kuna            one-euro        0.554\n",
      "Canada          dollar          Denmark         krone           kroner          0.582\n",
      "Canada          dollar          Europe          euro            euro-dollar     0.653\n",
      "Canada          dollar          Korea           won             dollar-yen      0.562\n",
      "Canada          dollar          Latvia          lats            ruble           0.606\n",
      "Canada          dollar          Lithuania       litas           ruble           0.570\n",
      "Canada          dollar          Macedonia       denar           one-euro        0.523\n",
      "Canada          dollar          Romania         leu             one-euro        0.580\n",
      "Canada          dollar          Ukraine         hryvnia         ruble           0.672\n",
      "Canada          dollar          Vietnam         dong            dollar-a-day    0.531\n",
      "Canada          dollar          Algeria         dinar           euro-dollar     0.536\n",
      "Canada          dollar          Angola          kwanza          dollar-value    0.525\n",
      "Canada          dollar          Armenia         dram            ruble           0.562\n",
      "Canada          dollar          Brazil          real            dolla           0.567\n",
      "Canada          dollar          Bulgaria        lev             ruble           0.553\n",
      "Canada          dollar          Cambodia        riel            rupiah          0.556\n",
      "Croatia         kuna            Denmark         krone           kroner          0.661\n",
      "Croatia         kuna            Europe          euro            dirham          0.572\n",
      "Croatia         kuna            Hungary         forint          korona          0.652\n",
      "Croatia         kuna            Iran            rial            rials           0.637\n",
      "Croatia         kuna            Japan           yen             ryo             0.651\n",
      "Croatia         kuna            Korea           won             hwan            0.702\n",
      "Croatia         kuna            Latvia          lats            kroon           0.617\n",
      "Croatia         kuna            Lithuania       litas           kunas           0.652\n",
      "Croatia         kuna            Macedonia       denar           kwacha          0.607\n",
      "Croatia         kuna            Mexico          peso            pesos           0.619\n",
      "Croatia         kuna            Poland          zloty           złoty           0.659\n",
      "Croatia         kuna            Russia          ruble           rubles          0.629\n",
      "Croatia         kuna            Ukraine         hryvnia         hryvnya         0.681\n",
      "Croatia         kuna            USA             dollar          usd             0.520\n",
      "Croatia         kuna            Vietnam         dong            đồng            0.613\n",
      "Croatia         kuna            Algeria         dinar           kwacha          0.597\n",
      "Croatia         kuna            Angola          kwanza          kwacha          0.685\n",
      "Croatia         kuna            Argentina       peso            kwacha          0.633\n",
      "Croatia         kuna            Armenia         dram            manat           0.594\n",
      "Croatia         kuna            Brazil          real            kwacha          0.667\n",
      "Croatia         kuna            Bulgaria        lev             kunas           0.611\n",
      "Croatia         kuna            Canada          dollar          kwacha          0.544\n",
      "Denmark         krone           Korea           won             yuan            0.593\n",
      "Denmark         krone           Latvia          lats            krona           0.664\n",
      "Denmark         krone           Lithuania       litas           zloty           0.676\n",
      "Denmark         krone           Macedonia       denar           lira            0.591\n",
      "Denmark         krone           Romania         leu             lira            0.611\n",
      "Denmark         krone           USA             dollar          USD             0.563\n",
      "Denmark         krone           Vietnam         dong            baht            0.568\n",
      "Denmark         krone           Algeria         dinar           lira            0.599\n",
      "Denmark         krone           Angola          kwanza          Angolan         0.584\n",
      "Denmark         krone           Armenia         dram            Armenian        0.595\n",
      "Denmark         krone           Brazil          real            reais           0.658\n",
      "Denmark         krone           Bulgaria        lev             liras           0.593\n",
      "Denmark         krone           Cambodia        riel            baht            0.602\n",
      "Denmark         krone           Canada          dollar          Canadian        0.540\n",
      "Denmark         krone           Croatia         kuna            Croatian        0.634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe          euro            Hungary         forint          koruna          0.615\n",
      "Europe          euro            Korea           won             yen             0.595\n",
      "Europe          euro            Latvia          lats            kroon           0.596\n",
      "Europe          euro            Lithuania       litas           zloty           0.637\n",
      "Europe          euro            Macedonia       denar           FYRO            0.606\n",
      "Europe          euro            Russia          ruble           hryvnya         0.679\n",
      "Europe          euro            Ukraine         hryvnia         hryvnya         0.701\n",
      "Europe          euro            USA             dollar          euro.           0.606\n",
      "Europe          euro            Vietnam         dong            baht            0.576\n",
      "Europe          euro            Algeria         dinar           Algerian        0.546\n",
      "Europe          euro            Angola          kwanza          kwacha          0.592\n",
      "Europe          euro            Armenia         dram            liras           0.543\n",
      "Europe          euro            Brazil          real            reais           0.598\n",
      "Europe          euro            Bulgaria        lev             Bulgarian       0.556\n",
      "Europe          euro            Cambodia        riel            baht            0.608\n",
      "Europe          euro            Canada          dollar          peso            0.542\n",
      "Hungary         forint          Korea           won             Korean          0.556\n",
      "Hungary         forint          Latvia          lats            litas           0.640\n",
      "Hungary         forint          Macedonia       denar           Macedonian      0.570\n",
      "Hungary         forint          Vietnam         dong            rupiah          0.547\n",
      "Hungary         forint          Algeria         dinar           Algerian        0.581\n",
      "Hungary         forint          Angola          kwanza          escudo          0.599\n",
      "Hungary         forint          Armenia         dram            manat           0.602\n",
      "Hungary         forint          Brazil          real            reais           0.661\n",
      "Hungary         forint          Cambodia        riel            rupiah          0.573\n",
      "Hungary         forint          Canada          dollar          canadian        0.561\n",
      "Hungary         forint          Croatia         kuna            forints         0.631\n",
      "India           rupee           Korea           won             peso            0.615\n",
      "India           rupee           Latvia          lats            krona           0.632\n",
      "India           rupee           Lithuania       litas           zloty           0.640\n",
      "India           rupee           Macedonia       denar           lira            0.565\n",
      "India           rupee           Vietnam         dong            peso            0.599\n",
      "India           rupee           Algeria         dinar           franc           0.604\n",
      "India           rupee           Angola          kwanza          kwacha          0.611\n",
      "India           rupee           Armenia         dram            ruble           0.596\n",
      "India           rupee           Brazil          real            peso            0.691\n",
      "India           rupee           Bulgaria        lev             lira            0.579\n",
      "India           rupee           Cambodia        riel            baht            0.607\n",
      "India           rupee           Canada          dollar          peso            0.606\n",
      "India           rupee           Denmark         krone           krona           0.701\n",
      "Iran            rial            Korea           won             hwan            0.559\n",
      "Iran            rial            Latvia          lats            kroon           0.614\n",
      "Iran            rial            Macedonia       denar           leu             0.530\n",
      "Iran            rial            USA             dollar          dólar           0.494\n",
      "Iran            rial            Vietnam         dong            đồng            0.572\n",
      "Iran            rial            Algeria         dinar           franc           0.568\n",
      "Iran            rial            Angola          kwanza          escudo          0.588\n",
      "Iran            rial            Armenia         dram            ruble           0.545\n",
      "Iran            rial            Brazil          real            escudo          0.590\n",
      "Iran            rial            Bulgaria        lev             leu             0.546\n",
      "Iran            rial            Cambodia        riel            baht            0.572\n",
      "Iran            rial            Canada          dollar          Canadian        0.496\n",
      "Japan           yen             Korea           won             yens            0.621\n",
      "Japan           yen             Latvia          lats            zloty           0.593\n",
      "Japan           yen             Lithuania       litas           zloty           0.641\n",
      "Japan           yen             Macedonia       denar           Macedonias      0.513\n",
      "Japan           yen             Russia          ruble           rubles          0.658\n",
      "Japan           yen             Vietnam         dong            baht            0.591\n",
      "Japan           yen             Algeria         dinar           franc           0.535\n",
      "Japan           yen             Angola          kwanza          kwacha          0.540\n",
      "Japan           yen             Armenia         dram            liras           0.525\n",
      "Japan           yen             Brazil          real            reais           0.617\n",
      "Japan           yen             Bulgaria        lev             liras           0.549\n",
      "Japan           yen             Cambodia        riel            baht            0.649\n",
      "Japan           yen             Canada          dollar          yens            0.529\n",
      "Japan           yen             Croatia         kuna            euro            0.546\n",
      "Japan           yen             Denmark         krone           kroner          0.672\n",
      "Japan           yen             India           rupee           rupees          0.704\n",
      "Japan           yen             Iran            rial            rials           0.560\n",
      "Korea           won             Latvia          lats            wone            0.555\n",
      "Korea           won             Lithuania       litas           wone            0.555\n",
      "Korea           won             Macedonia       denar           wone            0.583\n",
      "Korea           won             Malaysia        ringgit         wone            0.580\n",
      "Korea           won             Mexico          peso            wone            0.568\n",
      "Korea           won             Nigeria         naira           wone            0.583\n",
      "Korea           won             Poland          zloty           wone            0.592\n",
      "Korea           won             Romania         leu             wone            0.582\n",
      "Korea           won             Russia          ruble           wone            0.589\n",
      "Korea           won             Sweden          krona           wone            0.585\n",
      "Korea           won             Thailand        baht            wone            0.606\n",
      "Korea           won             Ukraine         hryvnia         wone            0.591\n",
      "Korea           won             USA             dollar          wone            0.623\n",
      "Korea           won             Vietnam         dong            wone            0.598\n",
      "Korea           won             Algeria         dinar           wone            0.544\n",
      "Korea           won             Angola          kwanza          wone            0.552\n",
      "Korea           won             Argentina       peso            wone            0.581\n",
      "Korea           won             Armenia         dram            wone            0.536\n",
      "Korea           won             Brazil          real            wone            0.593\n",
      "Korea           won             Bulgaria        lev             wone            0.574\n",
      "Korea           won             Cambodia        riel            wone            0.583\n",
      "Korea           won             Canada          dollar          wone            0.568\n",
      "Korea           won             Croatia         kuna            wone            0.586\n",
      "Korea           won             Denmark         krone           wone            0.595\n",
      "Korea           won             Europe          euro            wone            0.615\n",
      "Korea           won             Hungary         forint          wone            0.606\n",
      "Korea           won             India           rupee           wone            0.610\n",
      "Korea           won             Iran            rial            wone            0.585\n",
      "Korea           won             Japan           yen             wone            0.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latvia          lats            Lithuania       litas           latm            0.578\n",
      "Latvia          lats            Macedonia       denar           Macedonias      0.544\n",
      "Latvia          lats            Mexico          peso            Mexicos         0.534\n",
      "Latvia          lats            Nigeria         naira           nigeria         0.521\n",
      "Latvia          lats            Poland          zloty           Polands         0.532\n",
      "Latvia          lats            Romania         leu             latines         0.526\n",
      "Latvia          lats            Russia          ruble           rubles          0.540\n",
      "Latvia          lats            Sweden          krona           Swedens         0.505\n",
      "Latvia          lats            Thailand        baht            bahts           0.554\n",
      "Latvia          lats            Ukraine         hryvnia         Ukraines        0.564\n",
      "Latvia          lats            USA             dollar          latm            0.485\n",
      "Latvia          lats            Vietnam         dong            Vietnames       0.557\n",
      "Latvia          lats            Algeria         dinar           Algerians       0.547\n",
      "Latvia          lats            Angola          kwanza          Angolans        0.535\n",
      "Latvia          lats            Argentina       peso            Argentines      0.565\n",
      "Latvia          lats            Armenia         dram            Armenians       0.531\n",
      "Latvia          lats            Brazil          real            Brazils         0.566\n",
      "Latvia          lats            Bulgaria        lev             Bulgarians      0.517\n",
      "Latvia          lats            Cambodia        riel            Cambodians      0.540\n",
      "Latvia          lats            Canada          dollar          Canadas         0.517\n",
      "Latvia          lats            Croatia         kuna            Croatians       0.510\n",
      "Latvia          lats            Denmark         krone           Denmarks        0.520\n",
      "Latvia          lats            Europe          euro            Europes         0.533\n",
      "Latvia          lats            Hungary         forint          Budapest        0.512\n",
      "Latvia          lats            India           rupee           indias          0.518\n",
      "Latvia          lats            Iran            rial            Iranians        0.570\n",
      "Latvia          lats            Japan           yen             Japanes         0.565\n",
      "Latvia          lats            Korea           won             Korean          0.528\n",
      "Lithuania       litas           Macedonia       denar           drachmas        0.590\n",
      "Lithuania       litas           Russia          ruble           rubles          0.657\n",
      "Lithuania       litas           USA             dollar          centavo         0.508\n",
      "Lithuania       litas           Vietnam         dong            Vietnamese      0.568\n",
      "Lithuania       litas           Algeria         dinar           lire            0.552\n",
      "Lithuania       litas           Angola          kwanza          kwacha          0.590\n",
      "Lithuania       litas           Armenia         dram            lari            0.577\n",
      "Lithuania       litas           Brazil          real            reais           0.691\n",
      "Lithuania       litas           Bulgaria        lev             drachmas        0.585\n",
      "Lithuania       litas           Canada          dollar          bolívares       0.536\n",
      "Lithuania       litas           Denmark         krone           kroner          0.580\n",
      "Lithuania       litas           India           rupee           paise           0.629\n",
      "Lithuania       litas           Iran            rial            toman           0.611\n",
      "Lithuania       litas           Japan           yen             Japanese        0.557\n",
      "Lithuania       litas           Korea           won             Korean          0.584\n",
      "Lithuania       litas           Latvia          lats            leva            0.609\n",
      "Macedonia       denar           Malaysia        ringgit         Malaysian       0.571\n",
      "Macedonia       denar           Mexico          peso            Mexican         0.541\n",
      "Macedonia       denar           Nigeria         naira           denari          0.567\n",
      "Macedonia       denar           Poland          zloty           denars          0.554\n",
      "Macedonia       denar           Romania         leu             denari          0.626\n",
      "Macedonia       denar           Russia          ruble           denars          0.552\n",
      "Macedonia       denar           Sweden          krona           Swedish         0.573\n",
      "Macedonia       denar           Thailand        baht            Thai            0.552\n",
      "Macedonia       denar           Ukraine         hryvnia         denars          0.570\n",
      "Macedonia       denar           USA             dollar          denars          0.526\n",
      "Macedonia       denar           Vietnam         dong            post-Vietnam    0.539\n",
      "Macedonia       denar           Algeria         dinar           Algerien        0.579\n",
      "Macedonia       denar           Angola          kwanza          denari          0.581\n",
      "Macedonia       denar           Argentina       peso            denari          0.588\n",
      "Macedonia       denar           Armenia         dram            denars          0.567\n",
      "Macedonia       denar           Brazil          real            denari          0.567\n",
      "Macedonia       denar           Bulgaria        lev             denars          0.665\n",
      "Macedonia       denar           Cambodia        riel            Cambodian       0.564\n",
      "Macedonia       denar           Canada          dollar          Canadian        0.534\n",
      "Macedonia       denar           Croatia         kuna            denars          0.608\n",
      "Macedonia       denar           Denmark         krone           denmark         0.577\n",
      "Macedonia       denar           Europe          euro            denars          0.570\n",
      "Macedonia       denar           Hungary         forint          denari          0.572\n",
      "Macedonia       denar           India           rupee           India-West      0.552\n",
      "Macedonia       denar           Iran            rial            Iranian         0.563\n",
      "Macedonia       denar           Japan           yen             denari          0.567\n",
      "Macedonia       denar           Korea           won             chon            0.581\n",
      "Macedonia       denar           Latvia          lats            Latvian         0.568\n",
      "Macedonia       denar           Lithuania       litas           denars          0.577\n",
      "Malaysia        ringgit         Romania         leu             hryvnia         0.583\n",
      "Malaysia        ringgit         USA             dollar          milliard        0.542\n",
      "Malaysia        ringgit         Vietnam         dong            Sino-Vietnamese 0.556\n",
      "Malaysia        ringgit         Algeria         dinar           Algerian        0.559\n",
      "Malaysia        ringgit         Angola          kwanza          Angolan         0.581\n",
      "Malaysia        ringgit         Armenia         dram            Armenian        0.575\n",
      "Malaysia        ringgit         Brazil          real            reais           0.711\n",
      "Malaysia        ringgit         Cambodia        riel            baht            0.591\n",
      "Malaysia        ringgit         Denmark         krone           kroner          0.683\n",
      "Malaysia        ringgit         Iran            rial            toman           0.584\n",
      "Malaysia        ringgit         Korea           won             yen             0.571\n",
      "Malaysia        ringgit         Latvia          lats            litas           0.626\n",
      "Malaysia        ringgit         Macedonia       denar           Macedonias      0.581\n",
      "Mexico          peso            Vietnam         dong            đồng            0.577\n",
      "Mexico          peso            Algeria         dinar           franc           0.582\n",
      "Mexico          peso            Angola          kwanza          kwacha          0.609\n",
      "Mexico          peso            Armenia         dram            lira            0.568\n",
      "Mexico          peso            Brazil          real            kwacha          0.599\n",
      "Mexico          peso            Bulgaria        lev             lira            0.579\n",
      "Mexico          peso            Cambodia        riel            baht            0.603\n",
      "Mexico          peso            Korea           won             hwan            0.578\n",
      "Mexico          peso            Latvia          lats            ruble           0.605\n",
      "Mexico          peso            Lithuania       litas           zloty           0.624\n",
      "Mexico          peso            Macedonia       denar           lira            0.552\n",
      "Mexico          peso            Malaysia        ringgit         rupiah          0.699\n",
      "Nigeria         naira           Romania         leu             forint          0.633\n",
      "Nigeria         naira           Russia          ruble           rubles          0.722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nigeria         naira           USA             dollar          usd             0.533\n",
      "Nigeria         naira           Vietnam         dong            baht            0.587\n",
      "Nigeria         naira           Algeria         dinar           lire            0.603\n",
      "Nigeria         naira           Angola          kwanza          kwacha          0.635\n",
      "Nigeria         naira           Armenia         dram            manat           0.578\n",
      "Nigeria         naira           Brazil          real            reais           0.720\n",
      "Nigeria         naira           Bulgaria        lev             hryvnas         0.615\n",
      "Nigeria         naira           Cambodia        riel            baht            0.622\n",
      "Nigeria         naira           Canada          dollar          bolívares       0.533\n",
      "Nigeria         naira           Denmark         krone           kroner          0.679\n",
      "Nigeria         naira           India           rupee           rupees          0.708\n",
      "Nigeria         naira           Iran            rial            rials           0.676\n",
      "Nigeria         naira           Korea           won             hwan            0.626\n",
      "Nigeria         naira           Latvia          lats            litas           0.624\n",
      "Nigeria         naira           Macedonia       denar           drachmas        0.606\n",
      "Nigeria         naira           Mexico          peso            pesos           0.658\n",
      "Poland          zloty           USA             dollar          GBP             0.548\n",
      "Poland          zloty           Vietnam         dong            baht            0.630\n",
      "Poland          zloty           Algeria         dinar           franc           0.618\n",
      "Poland          zloty           Angola          kwanza          kwacha          0.623\n",
      "Poland          zloty           Armenia         dram            hryvnia         0.573\n",
      "Poland          zloty           Brazil          real            reais           0.685\n",
      "Poland          zloty           Bulgaria        lev             liras           0.599\n",
      "Poland          zloty           Cambodia        riel            baht            0.665\n",
      "Poland          zloty           Canada          dollar          Cdn.            0.541\n",
      "Poland          zloty           Iran            rial            rials           0.674\n",
      "Poland          zloty           Korea           won             yen             0.598\n",
      "Poland          zloty           Latvia          lats            hryvnia         0.628\n",
      "Poland          zloty           Lithuania       litas           zlotys          0.692\n",
      "Poland          zloty           Macedonia       denar           lira            0.567\n",
      "Romania         leu             USA             dollar          sucre           0.464\n",
      "Romania         leu             Vietnam         dong            đồng            0.570\n",
      "Romania         leu             Algeria         dinar           algérien        0.548\n",
      "Romania         leu             Angola          kwanza          kwacha          0.560\n",
      "Romania         leu             Armenia         dram            Karabakh        0.531\n",
      "Romania         leu             Brazil          real            baião           0.559\n",
      "Romania         leu             Canada          dollar          sucre           0.516\n",
      "Romania         leu             Denmark         krone           øre             0.544\n",
      "Romania         leu             Korea           won             hwan            0.619\n",
      "Romania         leu             Latvia          lats            kroon           0.588\n",
      "Romania         leu             Lithuania       litas           kroon           0.564\n",
      "Romania         leu             Macedonia       denar           kuruş           0.497\n",
      "Russia          ruble           Vietnam         dong            rupiah          0.577\n",
      "Russia          ruble           Algeria         dinar           franc           0.619\n",
      "Russia          ruble           Angola          kwanza          kwacha          0.610\n",
      "Russia          ruble           Armenia         dram            hryvnia         0.581\n",
      "Russia          ruble           Brazil          real            peso            0.658\n",
      "Russia          ruble           Bulgaria        lev             hryvnia         0.620\n",
      "Russia          ruble           Cambodia        riel            baht            0.608\n",
      "Russia          ruble           Croatia         kuna            dinar           0.601\n",
      "Russia          ruble           Korea           won             rupiah          0.595\n",
      "Russia          ruble           Latvia          lats            hryvnia         0.651\n",
      "Russia          ruble           Macedonia       denar           hryvnia         0.577\n",
      "Sweden          krona           USA             dollar          USD             0.556\n",
      "Sweden          krona           Vietnam         dong            baht            0.631\n",
      "Sweden          krona           Algeria         dinar           liras           0.594\n",
      "Sweden          krona           Angola          kwanza          kwacha          0.630\n",
      "Sweden          krona           Armenia         dram            lira            0.580\n",
      "Sweden          krona           Brazil          real            reais           0.650\n",
      "Sweden          krona           Bulgaria        lev             liras           0.589\n",
      "Sweden          krona           Cambodia        riel            baht            0.678\n",
      "Sweden          krona           Canada          dollar          peso            0.586\n",
      "Sweden          krona           Korea           won             yen             0.624\n",
      "Sweden          krona           Latvia          lats            krone           0.626\n",
      "Sweden          krona           Macedonia       denar           Macedonian      0.574\n",
      "Sweden          krona           Romania         leu             lira            0.617\n",
      "Thailand        baht            Ukraine         hryvnia         hryvna          0.774\n",
      "Thailand        baht            USA             dollar          usd             0.578\n",
      "Thailand        baht            Vietnam         dong            đồng            0.613\n",
      "Thailand        baht            Algeria         dinar           liras           0.582\n",
      "Thailand        baht            Angola          kwanza          kwacha          0.605\n",
      "Thailand        baht            Armenia         dram            liras           0.597\n",
      "Thailand        baht            Brazil          real            reais           0.733\n",
      "Thailand        baht            Bulgaria        lev             liras           0.619\n",
      "Thailand        baht            Cambodia        riel            bahts           0.624\n",
      "Thailand        baht            Canada          dollar          Cdn.            0.567\n",
      "Thailand        baht            Denmark         krone           kroner          0.764\n",
      "Thailand        baht            India           rupee           rupees          0.716\n",
      "Thailand        baht            Iran            rial            rials           0.658\n",
      "Thailand        baht            Korea           won             yen             0.623\n",
      "Thailand        baht            Latvia          lats            hryvnas         0.636\n",
      "Thailand        baht            Lithuania       litas           zlotys          0.689\n",
      "Thailand        baht            Macedonia       denar           liras           0.573\n",
      "Thailand        baht            Mexico          peso            pesos           0.715\n",
      "Thailand        baht            Russia          ruble           rubles          0.743\n",
      "Ukraine         hryvnia         USA             dollar          USD             0.586\n",
      "Ukraine         hryvnia         Vietnam         dong            đồng            0.616\n",
      "Ukraine         hryvnia         Algeria         dinar           franc           0.578\n",
      "Ukraine         hryvnia         Angola          kwanza          kwacha          0.617\n",
      "Ukraine         hryvnia         Armenia         dram            hryvnias        0.613\n",
      "Ukraine         hryvnia         Brazil          real            reais           0.669\n",
      "Ukraine         hryvnia         Bulgaria        lev             Hryvnia         0.628\n",
      "Ukraine         hryvnia         Cambodia        riel            baht            0.636\n",
      "Ukraine         hryvnia         Canada          dollar          bolívares       0.567\n",
      "Ukraine         hryvnia         Denmark         krone           krona           0.686\n",
      "Ukraine         hryvnia         Iran            rial            rials           0.701\n",
      "Ukraine         hryvnia         Korea           won             hwan            0.622\n",
      "Ukraine         hryvnia         Latvia          lats            krona           0.665\n",
      "Ukraine         hryvnia         Macedonia       denar           hryvnias        0.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA             dollar          Vietnam         dong            dollar-value    0.563\n",
      "USA             dollar          Algeria         dinar           dollar-value    0.543\n",
      "USA             dollar          Angola          kwanza          dollar-value    0.552\n",
      "USA             dollar          Armenia         dram            ruble           0.540\n",
      "USA             dollar          Brazil          real            peso            0.586\n",
      "USA             dollar          Bulgaria        lev             ruble           0.548\n",
      "USA             dollar          Cambodia        riel            rupee           0.548\n",
      "USA             dollar          Croatia         kuna            dollar-value    0.557\n",
      "USA             dollar          Europe          euro            euro-dollar     0.669\n",
      "USA             dollar          Korea           won             dollar-yen      0.614\n",
      "USA             dollar          Latvia          lats            ruble           0.610\n",
      "USA             dollar          Lithuania       litas           ruble           0.578\n",
      "USA             dollar          Macedonia       denar           dollar-euro     0.526\n",
      "USA             dollar          Romania         leu             one-euro        0.559\n",
      "USA             dollar          Ukraine         hryvnia         ruble           0.667\n",
      "Vietnam         dong            Algeria         dinar           dongs           0.514\n",
      "Vietnam         dong            Angola          kwanza          donga           0.561\n",
      "Vietnam         dong            Argentina       peso            Argentines      0.522\n",
      "Vietnam         dong            Armenia         dram            manat           0.499\n",
      "Vietnam         dong            Brazil          real            reais           0.541\n",
      "Vietnam         dong            Bulgaria        lev             bulgaria        0.542\n",
      "Vietnam         dong            Cambodia        riel            dongs           0.648\n",
      "Vietnam         dong            Canada          dollar          canada          0.533\n",
      "Vietnam         dong            Croatia         kuna            dongs           0.535\n",
      "Vietnam         dong            Denmark         krone           denmark         0.531\n",
      "Vietnam         dong            Europe          euro            dongs           0.542\n",
      "Vietnam         dong            Hungary         forint          hungary         0.535\n",
      "Vietnam         dong            India           rupee           dongs           0.551\n",
      "Vietnam         dong            Iran            rial            dongs           0.560\n",
      "Vietnam         dong            Japan           yen             dongs           0.578\n",
      "Vietnam         dong            Korea           won             dongs           0.655\n",
      "Vietnam         dong            Latvia          lats            latvia          0.553\n",
      "Vietnam         dong            Lithuania       litas           Lithuanians     0.570\n",
      "Vietnam         dong            Macedonia       denar           macedonia       0.537\n",
      "Vietnam         dong            Malaysia        ringgit         dongs           0.593\n",
      "Vietnam         dong            Mexico          peso            dongs           0.543\n",
      "Vietnam         dong            Poland          zloty           grodzki         0.541\n",
      "Vietnam         dong            Romania         leu             Romanians       0.525\n",
      "Vietnam         dong            Russia          ruble           Russsia         0.536\n",
      "Vietnam         dong            Sweden          krona           sweden          0.558\n",
      "Vietnam         dong            Thailand        baht            dongs           0.629\n",
      "Vietnam         dong            Ukraine         hryvnia         donbas          0.549\n",
      "Vietnam         dong            USA             dollar          donger          0.528\n",
      "currency                       37.76%  [327/866]\n"
     ]
    }
   ],
   "source": [
    "category = 'currency'\n",
    "\n",
    "ctr = 0\n",
    "items = test_dict[category]\n",
    "nitems = len(items)\n",
    "for (a,b,c,d) in items:\n",
    "    ctr += eval_analogy_item (model2, a,b,c,d,verbose=1)\n",
    "print(f\"{category:<30} {ctr/nitems:.2%}  [{ctr}/{nitems}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:**  Come up with a category of analogy the model is **bad** at.  Demonstrate by producing at least one example the model gets wrong.  Make sure your analogy is not one of the kinds in the test set and make sure your analogies are easy for humans.  There should be wide agreementon what the missing term is.  You don't have to do a rigorous study, but you might ask a few friends.\n",
    "\n",
    "Below is a kind of diary of my attempts at this.  Some of the things I tried worked (i. e., analogy completion failed).  In other cases the system surprised me and succeeded at some analogy type I thought it would be bad at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good hot heat warm warmth\n",
    "# Good long length wide width\n",
    "# Good hand finger foot toe\n",
    "# Good Everest mountain Nile river\n",
    "# Good oak tree tulip flower\n",
    "# Good oak tree jig dance\n",
    "# Good black white bad good\n",
    "# Good white black good bad\n",
    "# Good white good black bad [not explainable by using an NN of item c]\n",
    "# Good dancer dance boxer boxing\n",
    "# Good cat kitten dog puppy\n",
    "# Good cat kitten pig piglet\n",
    "\n",
    "###  The desired value for d (per me) is in square brackets.\n",
    "###  Sometimes there is more than one candidate\n",
    "# Bad tall height wide widest [width]\n",
    "# Bad arm hand leg one-leg [foot]\n",
    "# Bad fleet ship forest timberline [tree]\n",
    "# Bad old young happy delighted [sad]\n",
    "# Bad black white evil evil- [good; very rare choice]\n",
    "# Bad black white evil malevolent (restrict_vocab=50_000)\n",
    "# Bad cow herd bird birds [flock]\n",
    "# Bad wolf  pack bird  pack-up [flock: very rare choice]\n",
    "# Bad bird flock wolf wolves [pack]  (interesting case because arguably it's got something right)\n",
    "# Bad student school boxer boxing [gym/ring]\n",
    "# Bad shell peanut peel peanuts [fruit: apple ....]\n",
    "# Bad civilization barbarity intelligence inteligence [stupidity, NB restrict_vocab=30_000 gets this right]\n",
    "# Bad oak tree polka polkas [dance]\n",
    "# bad oak tree minuet minuets [dance]\n",
    "# bad oak tree waltz waltzing [dance]\n",
    "# bad dog puppy bear bears [cub]\n",
    "# bad cat kitten chicken chicks\n",
    "# bad dog puppy horse horses [foal/(colt/filly)]\n",
    "# bad dog puppy cow cows [calf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect the reason this one works better than \"puppy: (\"cub\" shoots up to number 7)\n",
    "is that using \"pup\" heightens the character similarity for the desired answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bears', 0.6735933423042297),\n",
       " ('bearing', 0.6022083759307861),\n",
       " ('bore', 0.5749645233154297),\n",
       " ('cubs', 0.5616635680198669),\n",
       " ('bear-', 0.5572898983955383),\n",
       " ('brunt', 0.5240294933319092),\n",
       " ('cub', 0.5148807764053345),\n",
       " ('beared', 0.5025845170021057),\n",
       " ('she-bear', 0.5020671486854553),\n",
       " ('pups', 0.5003380179405212)]"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_analogy(model2,\"dog\",\"pup\",\"bear\",topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the high score of \"pup\" amnd \"pups\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cubs', 0.8271422982215881),\n",
       " ('pup', 0.6810232996940613),\n",
       " ('pups', 0.615029513835907),\n",
       " ('lioness', 0.6094055771827698),\n",
       " ('panda', 0.5932631492614746),\n",
       " ('tiger', 0.5848243236541748),\n",
       " ('tigress', 0.5791497826576233),\n",
       " ('lion', 0.5652023553848267),\n",
       " ('zookeeper', 0.5598716735839844),\n",
       " ('kitten', 0.5436605215072632)]"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=[\"cub\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('puppy', 0.7904747128486633)]"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_analogy(model2,\"cat\",\"kitten\",\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horses', 0.6732252240180969)]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_analogy(model2,\"dog\",\"puppy\",\"horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cows', 0.6810647249221802),\n",
       " ('calf', 0.6178280711174011),\n",
       " ('goat', 0.5992587208747864),\n",
       " ('pig', 0.5905166864395142),\n",
       " ('milk', 0.5691573023796082)]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_analogy(model2,\"cat\",\"kitten\",\"cow\",topn=5,restrict_vocab=30_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the truncated vocab\n",
    "\n",
    "Optionally add the analogy test words that are missing from the truncated vocab vectors (`wv_from_text`)\n",
    "to the truncated vocab vectors, to facilitate using them for analogy experiments.\n",
    "\n",
    "Then save the updated model (called `wv_from_text`) to the truncated vocab file (see the beginning of the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 words to add\n",
      "31 words to add found in full model.\n",
      "Old truncated vocab size: 100000\n",
      "len(wv_from_text.key_to_index)=100031 len(wv_from_text.index_to_key)=100031\n",
      "31 new words added to truncated vocab. New vocab size: 100031\n"
     ]
    }
   ],
   "source": [
    "def add_test_words (wv_for_text,word_set,full_model,debug=False):\n",
    "    \"\"\"\n",
    "    wv_for_text is a truncated version of the full model (say, 1.0e5 words\n",
    "    out of 1.0e6 words).  We are adding whatever words are needed from\n",
    "    word set to the truncated model, if they can be found in the full model .\n",
    "    \n",
    "    Typically this is for purposes of a demonstration or an experiemnt,\n",
    "    \"\"\"\n",
    "    model2=full_model\n",
    "    # grab a vector (the first) to determine vector dimensionality\n",
    "    vec_dim = wv_from_text[0].shape[0]\n",
    "    words_to_add = set()\n",
    "    for wd in analogy_word_set:\n",
    "        if wd not in wv_from_text:\n",
    "            words_to_add.add(wd)\n",
    "    print(f\"{len(words_to_add)} words to add\")\n",
    "    words_to_add = [(wd,model2.key_to_index[wd]) for wd in words_to_add if wd in model2]\n",
    "    print(f\"{len(words_to_add)} words to add found in full model.\")\n",
    "    words_to_add.sort(key=lambda x: x[1])\n",
    "    words_ta,words_ta_idxs = zip(*words_to_add)\n",
    "    try:\n",
    "        del words_to_add_array\n",
    "    except NameError:\n",
    "        pass\n",
    "    words_to_add_array = np.zeros((len(words_ta),vec_dim))\n",
    "    print(f\"Old truncated vocab size: {len(wv_from_text.key_to_index)}\")\n",
    "    for (i,to_add) in enumerate(words_ta):\n",
    "        #print(to_add, model2[to_add].shape)\n",
    "        words_to_add_array[i,:] = model2[to_add]\n",
    "    wv_from_text.add_vectors(words_ta, words_to_add_array)\n",
    "    ##  This should be done in add_vectors.  It's one more place to maintain \n",
    "    ##  consistency after incrementing the vector set.\n",
    "    updated_count_array = np.arange(len(wv_from_text.index_to_key),0,-1)\n",
    "    wv_from_text.expandos['count'] = updated_count_array\n",
    "    if debug:\n",
    "        print(f\"{len(wv_from_text.key_to_index)=} {len(wv_from_text.index_to_key)=}\")\n",
    "    print(f\"{len(words_to_add)} new words added to truncated vocab.\"\n",
    "          f\" New vocab size: {len(wv_from_text.key_to_index)}\")\n",
    "    \n",
    "#####  analogy_word_set is defined much later in this NB. Circle back to execute this.  #############\n",
    "# Add the analogy test words that are missing from the truncated vocab vectors (`wv_from_text`)\n",
    "# to the truncated vocab vectors, to facilitate using them for analogy experiments.\n",
    "add_test_words (wv_from_text, analogy_word_set, model2, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
