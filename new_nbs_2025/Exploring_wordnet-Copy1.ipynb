{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f19797",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07504a11",
   "metadata": {},
   "source": [
    "Wordnet is blah blah blah.\n",
    "\n",
    "### Other resources hooked up to WordNet\n",
    "\n",
    "Let's use the following environment vars:\n",
    "\n",
    "```python\n",
    "CORPUS = /Users/gawron/ext/corpus/\n",
    "CODE = /Users/gawron/Desktop/src/sentiment_tagger/\n",
    "```\n",
    "\n",
    "1.  Sentiwordsnet: /Users/gawron/ext/corpus/sentiwordnet; access_wordnet_for_sentiwordnet.py contains code \n",
    "    for linking valence.\n",
    "2.  FrameNet.  XML format for frames.  Version 1.5.  `CORPUS`/framenet_plus/framenet\n",
    "    has the Framenet data; `CODE`/mt/framenet has python code for loading and reading the \n",
    "    XMl data (using the Python `xml` module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2eb4983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISRIStemmer', 'LancasterStemmer', 'PorterStemmer', 'RSLPStemmer', 'RegexpStemmer', 'SnowballStemmer', 'StemmerI']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stemmers = [nm for nm in dir(nltk) if \"temmer\" in nm]\n",
    "print(stemmers)\n",
    "stemmer = nltk.PorterStemmer()\n",
    "#stemmer.stem(\"sadness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31076568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "#from nltk import wordnet as wnl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb460abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ss = list(wn.all_synsets())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2479b",
   "metadata": {},
   "source": [
    "The parts of speech in wordnet: `s` is satellite (to be explained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5937382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'n': 82115, 'v': 13767, 's': 10693, 'a': 7463, 'r': 3621})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ctr = Counter(ss.pos() for ss in all_ss)\n",
    "ctr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9148ce9",
   "metadata": {},
   "source": [
    "What satellites all share, a synset they are all satellites of some **head**, linked via the `similar_to` relation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "08fad462",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1: 10693})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_satellites = sorted(ss.name() for ss in all_ss if ss.pos() == \"s\")\n",
    "print(len(all_satellites))\n",
    "Counter(len(wn.synset(ss).similar_tos()) for ss in all_satellites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ca6ea",
   "metadata": {},
   "source": [
    "For example, Consider the senses of \"bald\", all of which have pos \"s\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42784c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bald.s.01 with no effort to conceal\n",
      "bald.s.02 lacking hair on all or most of the scalp\n",
      "bald.s.03 without the natural or usual covering\n"
     ]
    }
   ],
   "source": [
    "baldies = wn.synsets(\"bald\",\"a\")\n",
    "for ss in baldies:\n",
    "    print(ss.name(),ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8dfe347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_head_and_satellites(head,satellites):\n",
    "    banner = f\"Head: {head.name()}\"\n",
    "    print(banner)\n",
    "    print(\"=\"*len(banner))\n",
    "    for sat in satellites:\n",
    "        print(f\"  {sat.name()}\")\n",
    "    \n",
    "def get_wheel (ss,verbose=False):\n",
    "    \"\"\"\n",
    "    ss is a satellite if some head (because it is pos s).\n",
    "    \n",
    "    Return the head and all satellites of the ehad (including ss)\n",
    "    \"\"\"\n",
    "    assert ss.pos() == \"s\", \"Only synsets with part of speech s have wheels\"\n",
    "    # The rule is that satellites have only one head linked by .similar_tos()\n",
    "    head = ss.similar_tos()[0]\n",
    "    satellites = get_satellites(head,verbose=verbose)\n",
    "    return head,satellites\n",
    "\n",
    "def get_satellites(head,verbose=False,include_head=False):\n",
    "    \"\"\"\n",
    "    Return all satellites of {head} \n",
    "    \"\"\"\n",
    "    satellites = head.similar_tos()\n",
    "    if verbose:\n",
    "        print_head_and_satellites(head,satellites)\n",
    "    return [head] + satellites\n",
    "\n",
    "def get_wheels_and_axle(ss,verbose=False,return_set=False):\n",
    "    head, satellites = get_wheel (ss,verbose=verbose)\n",
    "    # antonymy is an attribute of lemmas, not synsets.  This is confusing.\n",
    "    antonyms = [ant.synset() for lem in head.lemmas() for ant in lem.antonyms()]\n",
    "    if verbose:\n",
    "        print()\n",
    "    ant_wheels = [get_satellites (ant,verbose=verbose,include_head=True) for ant in antonyms] \n",
    "    if return_set:\n",
    "        res = set([head]).union(satellites)\n",
    "        for wheel in ant_wheels:\n",
    "            res.update(wheel)\n",
    "        return res\n",
    "    else:\n",
    "        return head, satellites, ant_wheels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c123f",
   "metadata": {},
   "source": [
    "Let's look at the head of the first sense the synset `bald.s.01`, and get all the `similar_tos()` of that head (all of that head's satellites)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8eeec7",
   "metadata": {},
   "source": [
    "The head connected to `bald.s.01` by `similar_tos()` is `overt.a.01`.  The 4 satellites of `overt.a.01`\n",
    "are the `similar_tos()` of `overt.a.01`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0e5defaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bald.s.01\n",
      "\n",
      "Head: overt.a.01\n",
      "================\n",
      "  naked.s.04\n",
      "  undisguised.s.01\n",
      "  bald.s.01\n",
      "  visible.s.02\n"
     ]
    }
   ],
   "source": [
    "ss = baldies[0]\n",
    "print(ss.name(),end=\"\\n\\n\")\n",
    "head, sats = get_wheel(ss,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd71ad",
   "metadata": {},
   "source": [
    "We call little subnetwork a **wheel**: `overt.a.01` is the hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ab6e6",
   "metadata": {},
   "source": [
    "This time we find the head and it satellites; then we find the sole antonym of the head `overt.a.01`, `covert.a.01`, which is another head, and find all of its satellites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "47400d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('backstair.s.01'),\n",
       " Synset('bald.s.01'),\n",
       " Synset('black.s.10'),\n",
       " Synset('clandestine.s.01'),\n",
       " Synset('cloaked.s.01'),\n",
       " Synset('collusive.s.01'),\n",
       " Synset('covert.a.01'),\n",
       " Synset('naked.s.04'),\n",
       " Synset('overt.a.01'),\n",
       " Synset('secret.s.04'),\n",
       " Synset('secret.s.09'),\n",
       " Synset('sub-rosa.s.01'),\n",
       " Synset('subterranean.s.02'),\n",
       " Synset('under_wraps.s.01'),\n",
       " Synset('undisclosed.s.01'),\n",
       " Synset('undisguised.s.01'),\n",
       " Synset('visible.s.02')}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_wheels_and_axle(ss,return_set=True)\n",
    "#wn.synset(\"overt.a.01\") in res\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6c611c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head: overt.a.01\n",
      "================\n",
      "  naked.s.04\n",
      "  undisguised.s.01\n",
      "  bald.s.01\n",
      "  visible.s.02\n",
      "\n",
      "Head: covert.a.01\n",
      "=================\n",
      "  secret.s.09\n",
      "  clandestine.s.01\n",
      "  backstair.s.01\n",
      "  cloaked.s.01\n",
      "  sub-rosa.s.01\n",
      "  under_wraps.s.01\n",
      "  collusive.s.01\n",
      "  undisclosed.s.01\n",
      "  subterranean.s.02\n",
      "  black.s.10\n",
      "  secret.s.04\n"
     ]
    }
   ],
   "source": [
    "head, satellites, ant_wheels = get_wheels_and_axle(ss,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173e3a9",
   "metadata": {},
   "source": [
    "Finding antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "401c845d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('unhappy.a.01.unhappy')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"happy\",\"a\")[0].lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30078a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(satellites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b2c9d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supperless.s.01\n",
      "Head: hungry.a.01\n",
      "=================\n",
      "  supperless.s.01\n",
      "  peckish.s.01\n",
      "  empty.s.03\n",
      "  famished.s.01\n",
      "\n",
      "Head: thirsty.a.02\n",
      "==================\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "deprecative.s.02\n",
      "Head: critical.a.01\n",
      "===================\n",
      "  captious.s.01\n",
      "  censorious.s.01\n",
      "  hypercritical.s.01\n",
      "  scathing.s.01\n",
      "  deprecative.s.02\n",
      "  searing.s.01\n",
      "\n",
      "Head: uncritical.a.02\n",
      "=====================\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "apostate.s.01\n",
      "Head: unfaithful.a.01\n",
      "=====================\n",
      "  punic.s.02\n",
      "  apostate.s.01\n",
      "  untrue.s.02\n",
      "\n",
      "Head: faithful.a.01\n",
      "===================\n",
      "  true.s.03\n",
      "  firm.s.10\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "oblanceolate.s.01\n",
      "Head: simple.a.06\n",
      "=================\n",
      "  apiculate.s.01\n",
      "  lanceolate.s.01\n",
      "  lyrate.s.01\n",
      "  oblanceolate.s.01\n",
      "  ovate.s.01\n",
      "  two-needled.s.01\n",
      "  acerate.s.01\n",
      "  peltate.s.01\n",
      "  cuneate.s.01\n",
      "  spatulate.s.01\n",
      "  acuminate.s.01\n",
      "  pandurate.s.01\n",
      "  dolabriform.s.01\n",
      "  reniform.s.01\n",
      "  oblong.s.01\n",
      "  obtuse.s.02\n",
      "  orbiculate.s.01\n",
      "  obovate.s.01\n",
      "  caudate.s.02\n",
      "  three-needled.s.01\n",
      "  needled.s.01\n",
      "  ensiform.s.01\n",
      "  five-needled.s.01\n",
      "  elliptic.s.01\n",
      "  perfoliate.s.01\n",
      "  unlobed.s.01\n",
      "  deltoid.s.01\n",
      "  sagittate.s.01\n",
      "  four-needled.s.01\n",
      "  hastate.s.01\n",
      "  linear.s.04\n",
      "  cordate.s.01\n",
      "\n",
      "Head: compound.a.01\n",
      "===================\n",
      "  pinnate.s.01\n",
      "  lobed.s.01\n",
      "  bipinnatifid.s.01\n",
      "  tripinnate.s.01\n",
      "  palmate.s.02\n",
      "  quinquefoliate.s.01\n",
      "  bipartite.s.01\n",
      "  pinnatisect.s.01\n",
      "  cleft.s.01\n",
      "  bilobate.s.01\n",
      "  conjugate.s.02\n",
      "  tripinnatifid.s.01\n",
      "  ternate.s.01\n",
      "  bipinnate.s.01\n",
      "  parted.s.01\n",
      "  incised.s.01\n",
      "  palmatifid.s.01\n",
      "  even-pinnate.s.01\n",
      "  binate.s.01\n",
      "  trifoliate.s.01\n",
      "  trilobate.s.01\n",
      "  radiate.s.02\n",
      "  pinnatifid.s.01\n",
      "  odd-pinnate.s.01\n",
      "  pedate.s.01\n",
      "  decompound.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "oppressive.s.02\n",
      "Head: domineering.a.01\n",
      "======================\n",
      "  oppressive.s.02\n",
      "  blustery.s.02\n",
      "  heavy-handed.s.02\n",
      "  authoritarian.s.02\n",
      "  cavalier.s.01\n",
      "  autocratic.s.01\n",
      "\n",
      "Head: submissive.a.01\n",
      "=====================\n",
      "  meek.s.03\n",
      "  dominated.s.02\n",
      "  abject.s.04\n",
      "  bowed.s.04\n",
      "  cringing.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "desperate.s.05\n",
      "Head: imperative.a.01\n",
      "=====================\n",
      "  adjuratory.s.02\n",
      "  clamant.s.02\n",
      "  peremptory.s.02\n",
      "  pressing.s.01\n",
      "  strident.s.03\n",
      "  desperate.s.05\n",
      "\n",
      "Head: beseeching.a.01\n",
      "=====================\n",
      "  importunate.s.01\n",
      "  suppliant.s.01\n",
      "  precatory.s.01\n",
      "  adjuratory.s.01\n",
      "  mendicant.s.01\n",
      "  petitionary.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "well-groomed.s.02\n",
      "Head: groomed.a.01\n",
      "==================\n",
      "  plastered.s.01\n",
      "  pomaded.s.01\n",
      "  brushed.s.02\n",
      "  sleek.s.01\n",
      "  well-groomed.s.01\n",
      "  well-groomed.s.02\n",
      "  kempt.s.01\n",
      "\n",
      "Head: ungroomed.a.01\n",
      "====================\n",
      "  bushy.s.01\n",
      "  ill-dressed.s.01\n",
      "  unbrushed.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "semipermeable.s.01\n",
      "Head: permeable.a.01\n",
      "====================\n",
      "  semipermeable.s.01\n",
      "  porous.s.01\n",
      "\n",
      "Head: impermeable.a.01\n",
      "======================\n",
      "  water-repellent.s.01\n",
      "  retentive.s.03\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "harmonious.s.02\n",
      "Head: balanced.a.01\n",
      "===================\n",
      "  stable.s.04\n",
      "  self-balancing.s.01\n",
      "  harmonious.s.02\n",
      "  counterbalanced.s.01\n",
      "  well-balanced.s.01\n",
      "  poised.s.01\n",
      "\n",
      "Head: unbalanced.a.01\n",
      "=====================\n",
      "  labile.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "red-coated.s.01\n",
      "Head: clothed.a.01\n",
      "==================\n",
      "  cassocked.s.01\n",
      "  red-coated.s.01\n",
      "  bundled-up.s.01\n",
      "  arrayed.s.01\n",
      "  vestmented.s.01\n",
      "  habited.s.01\n",
      "  appareled.s.01\n",
      "  turned_out.s.01\n",
      "  gowned.s.01\n",
      "  cowled.s.01\n",
      "  caparisoned.s.01\n",
      "  togged.s.01\n",
      "  underdressed.s.01\n",
      "  overdressed.s.01\n",
      "  dressed.s.04\n",
      "  surpliced.s.01\n",
      "  suited.s.02\n",
      "  dighted.s.01\n",
      "  tuxedoed.s.01\n",
      "  costumed.s.01\n",
      "  uniformed.s.01\n",
      "  heavy-coated.s.01\n",
      "  breeched.s.01\n",
      "  coated.s.02\n",
      "  petticoated.s.01\n",
      "\n",
      "Head: unclothed.a.01\n",
      "====================\n",
      "  en_deshabille.s.01\n",
      "  mother-naked.s.01\n",
      "  without_a_stitch.s.01\n",
      "  off-the-shoulder.s.01\n",
      "  seminude.s.01\n",
      "  unappareled.s.01\n",
      "  barelegged.s.01\n",
      "  half-clothed.s.01\n",
      "  bare-breasted.s.01\n",
      "  clothesless.s.01\n",
      "  stripped.s.03\n",
      "  bare-assed.s.01\n",
      "  exposed.s.02\n",
      "  starkers.s.01\n",
      "  bareheaded.s.01\n",
      "  bottomless.s.04\n",
      "  bare.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "bountied.s.01\n",
      "Head: rewarding.a.01\n",
      "====================\n",
      "  bountied.s.01\n",
      "  rewardful.s.01\n",
      "\n",
      "Head: unrewarding.a.01\n",
      "======================\n",
      "  thankless.s.02\n",
      "  profitless.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "sedentary.s.01\n",
      "Head: inactive.a.09\n",
      "===================\n",
      "  desk-bound.s.01\n",
      "  hypoactive.s.01\n",
      "  abeyant.s.01\n",
      "  inert.s.03\n",
      "  sedentary.s.01\n",
      "\n",
      "Head: active.a.05\n",
      "=================\n",
      "  hyperactive.s.01\n",
      "  on_the_go.s.01\n",
      "  acrobatic.s.01\n",
      "  about.s.01\n",
      "  agile.s.01\n",
      "  hot.s.21\n",
      "  sporty.s.03\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "one_hundred_seventy.s.01\n",
      "Head: cardinal.a.02\n",
      "===================\n",
      "  forty-eight.s.01\n",
      "  four.s.01\n",
      "  eighty-five.s.01\n",
      "  twenty-seven.s.01\n",
      "  fifty.s.01\n",
      "  one_hundred_eighty.s.01\n",
      "  non-zero.s.01\n",
      "  twenty-nine.s.01\n",
      "  forty-seven.s.01\n",
      "  thousand.s.01\n",
      "  one.s.01\n",
      "  ten.s.01\n",
      "  fifty-four.s.01\n",
      "  ninety-one.s.01\n",
      "  eighty.s.01\n",
      "  forty-one.s.01\n",
      "  one_hundred_ten.s.01\n",
      "  ninety-eight.s.01\n",
      "  nine.s.01\n",
      "  twenty-four.s.01\n",
      "  ninety.s.01\n",
      "  ninety-two.s.01\n",
      "  ten_thousand.s.01\n",
      "  three_hundred.s.01\n",
      "  forty-three.s.01\n",
      "  eighty-eight.s.01\n",
      "  zero.s.01\n",
      "  ninety-five.s.01\n",
      "  thirty-seven.s.01\n",
      "  twelve.s.01\n",
      "  thirty-one.s.01\n",
      "  three.s.01\n",
      "  seventy-seven.s.01\n",
      "  fifty-six.s.01\n",
      "  million.s.01\n",
      "  eighty-six.s.01\n",
      "  eighty-nine.s.01\n",
      "  seventy-three.s.01\n",
      "  one_hundred_seventy.s.01\n",
      "  seventy-six.s.01\n",
      "  one_hundred_five.s.01\n",
      "  seventeen.s.01\n",
      "  one_hundred_fifty.s.01\n",
      "  seventy-eight.s.01\n",
      "  seventy-two.s.01\n",
      "  hundred.s.01\n",
      "  one_hundred_thirty.s.01\n",
      "  thirty-nine.s.01\n",
      "  nineteen.s.01\n",
      "  hundred_thousand.s.01\n",
      "  thirty-six.s.01\n",
      "  twenty-eight.s.01\n",
      "  seventy-four.s.01\n",
      "  ninety-six.s.01\n",
      "  sixty-five.s.01\n",
      "  twenty-two.s.01\n",
      "  one_hundred_ninety.s.01\n",
      "  one_hundred_fifty-five.s.01\n",
      "  one_hundred_sixty.s.01\n",
      "  seventy-five.s.01\n",
      "  sixty-nine.s.01\n",
      "  eighty-four.s.01\n",
      "  twenty.s.01\n",
      "  sixty-six.s.01\n",
      "  forty-four.s.01\n",
      "  thirteen.s.01\n",
      "  zillion.s.01\n",
      "  eighty-two.s.01\n",
      "  forty.s.01\n",
      "  six.s.01\n",
      "  fifty-eight.s.01\n",
      "  two.s.01\n",
      "  fifty-one.s.01\n",
      "  fifty-three.s.01\n",
      "  sixty.s.01\n",
      "  one_hundred_seventy-five.s.01\n",
      "  sixty-seven.s.01\n",
      "  sixty-two.s.01\n",
      "  one_hundred_twenty-five.s.01\n",
      "  thirty-four.s.01\n",
      "  one_hundred_thirty-five.s.01\n",
      "  twenty-six.s.01\n",
      "  twenty-one.s.01\n",
      "  eighty-one.s.01\n",
      "  four_hundred.s.01\n",
      "  sixteen.s.01\n",
      "  one_hundred_fifteen.s.01\n",
      "  eight.s.01\n",
      "  fifteen.s.01\n",
      "  thirty.s.01\n",
      "  ninety-three.s.01\n",
      "  forty-nine.s.01\n",
      "  ninety-four.s.01\n",
      "  forty-six.s.01\n",
      "  twenty-five.s.01\n",
      "  thirty-two.s.01\n",
      "  trillion.s.02\n",
      "  fifty-nine.s.01\n",
      "  one_hundred_forty.s.01\n",
      "  one_hundred_twenty.s.01\n",
      "  sixty-eight.s.01\n",
      "  seventy-one.s.01\n",
      "  eleven.s.01\n",
      "  eighteen.s.01\n",
      "  thirty-five.s.01\n",
      "  seventy-nine.s.01\n",
      "  seven.s.01\n",
      "  hundred_and_one.s.01\n",
      "  fourteen.s.01\n",
      "  eighty-seven.s.01\n",
      "  five.s.01\n",
      "  forty-two.s.01\n",
      "  fifty-two.s.01\n",
      "  ninety-seven.s.01\n",
      "  twenty-three.s.01\n",
      "  sixty-one.s.01\n",
      "  thirty-three.s.01\n",
      "  ninety-nine.s.01\n",
      "  seventy.s.01\n",
      "  fifty-five.s.01\n",
      "  one_hundred_sixty-five.s.01\n",
      "  trillion.s.01\n",
      "  forty-five.s.01\n",
      "  sixty-four.s.01\n",
      "  one_hundred_forty-five.s.01\n",
      "  billion.s.02\n",
      "  sixty-three.s.01\n",
      "  thirty-eight.s.01\n",
      "  two_hundred.s.01\n",
      "  fifty-seven.s.01\n",
      "  billion.s.01\n",
      "  five_hundred.s.01\n",
      "  eighty-three.s.01\n",
      "\n",
      "Head: ordinal.a.02\n",
      "==================\n",
      "  eleventh.s.01\n",
      "  hundred-and-tenth.s.01\n",
      "  trillionth.s.01\n",
      "  hundred-and-fiftieth.s.01\n",
      "  thirty-sixth.s.01\n",
      "  four-hundredth.s.01\n",
      "  forty-ninth.s.01\n",
      "  forty-fifth.s.01\n",
      "  twenty-first.s.01\n",
      "  zeroth.s.01\n",
      "  thirty-fifth.s.01\n",
      "  forty-eighth.s.01\n",
      "  five-hundredth.s.01\n",
      "  twenty-fifth.s.01\n",
      "  fifty-fifth.s.01\n",
      "  hundred-and-sixty-fifth.s.01\n",
      "  sixty-fifth.s.01\n",
      "  second.s.01\n",
      "  hundred-and-fifty-fifth.s.01\n",
      "  thousandth.s.01\n",
      "  thirty-first.s.01\n",
      "  hundred-and-forty-fifth.s.01\n",
      "  eighteenth.s.01\n",
      "  thirty-seventh.s.01\n",
      "  hundred-and-twentieth.s.01\n",
      "  hundred-and-seventy-fifth.s.01\n",
      "  quadrillionth.s.01\n",
      "  hundred-and-fifteenth.s.01\n",
      "  seventeenth.s.01\n",
      "  fourth.s.01\n",
      "  tenth.s.01\n",
      "  twenty-second.s.01\n",
      "  ninetieth.s.01\n",
      "  twenty-ninth.s.01\n",
      "  twelfth.s.01\n",
      "  sixth.s.01\n",
      "  seventy-fifth.s.01\n",
      "  eightieth.s.01\n",
      "  thirty-third.s.01\n",
      "  hundred-and-eightieth.s.01\n",
      "  umpteenth.s.01\n",
      "  millionth.s.01\n",
      "  thirty-second.s.01\n",
      "  ninth.s.01\n",
      "  first.s.02\n",
      "  fifth.s.01\n",
      "  forty-third.s.01\n",
      "  forty-first.s.01\n",
      "  nineteenth.s.01\n",
      "  fortieth.s.01\n",
      "  twenty-sixth.s.01\n",
      "  fiftieth.s.01\n",
      "  forty-sixth.s.01\n",
      "  twenty-fourth.s.01\n",
      "  hundredth.s.01\n",
      "  hundred-and-first.s.01\n",
      "  hundred-and-thirtieth.s.01\n",
      "  seventh.s.01\n",
      "  thirteenth.s.01\n",
      "  twenty-seventh.s.01\n",
      "  thirty-eighth.s.01\n",
      "  thirty-ninth.s.01\n",
      "  sixtieth.s.01\n",
      "  ninety-fifth.s.01\n",
      "  nth.s.01\n",
      "  forty-second.s.01\n",
      "  seventieth.s.01\n",
      "  fifteenth.s.01\n",
      "  third.s.01\n",
      "  eighty-fifth.s.01\n",
      "  hundred-and-ninetieth.s.01\n",
      "  billionth.s.01\n",
      "  sixteenth.s.01\n",
      "  thirty-fourth.s.01\n",
      "  forty-seventh.s.01\n",
      "  hundred-and-fortieth.s.01\n",
      "  hundred-and-twenty-fifth.s.01\n",
      "  forty-fourth.s.01\n",
      "  zero.s.03\n",
      "  fourteenth.s.01\n",
      "  twenty-eighth.s.01\n",
      "  twentieth.s.01\n",
      "  two-hundredth.s.01\n",
      "  three-hundredth.s.01\n",
      "  twenty-third.s.01\n",
      "  eighth.s.01\n",
      "  quintillionth.s.01\n",
      "  thirtieth.s.01\n",
      "  sixty-fourth.s.01\n",
      "  hundred-and-thirty-fifth.s.01\n",
      "  hundred-and-seventieth.s.01\n",
      "  hundred-and-sixtieth.s.01\n",
      "  hundred-and-fifth.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "crazed.s.01\n",
      "Head: insane.a.01\n",
      "=================\n",
      "  brainsick.s.01\n",
      "  maniacal.s.01\n",
      "  paranoid.s.01\n",
      "  hebephrenic.s.01\n",
      "  screw-loose.s.01\n",
      "  amuck.s.01\n",
      "  balmy.s.01\n",
      "  certifiable.s.01\n",
      "  non_compos_mentis.s.01\n",
      "  crazed.s.01\n",
      "  mentally_ill.s.01\n",
      "  crackbrained.s.01\n",
      "  maniclike.s.01\n",
      "  psychopathic.s.01\n",
      "  lunatic.s.01\n",
      "  schizophrenic.s.01\n",
      "  fey.s.01\n",
      "  raving_mad.s.01\n",
      "  manic-depressive.s.01\n",
      "  psychotic.s.01\n",
      "\n",
      "Head: sane.a.01\n",
      "===============\n",
      "  in_his_right_mind.s.01\n",
      "  lucid.s.02\n",
      "  compos_mentis.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "prima_facie.s.01\n",
      "Head: clear.a.01\n",
      "================\n",
      "  broad.s.04\n",
      "  clear-cut.s.01\n",
      "  vivid.s.02\n",
      "  unmistakable.s.01\n",
      "  prima_facie.s.01\n",
      "  limpid.s.03\n",
      "\n",
      "Head: unclear.a.02\n",
      "==================\n",
      "  blurred.s.02\n",
      "  confusing.s.02\n",
      "  obscure.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "heart-healthy.s.01\n",
      "Head: wholesome.a.01\n",
      "====================\n",
      "  hearty.s.02\n",
      "  healthy.s.03\n",
      "  heart-healthy.s.01\n",
      "  salubrious.s.02\n",
      "  organic.s.04\n",
      "  alimentary.s.01\n",
      "\n",
      "Head: unwholesome.a.01\n",
      "======================\n",
      "  rich.s.09\n",
      "  morbid.s.01\n",
      "  insalubrious.s.01\n",
      "  nauseating.s.01\n",
      "  insubstantial.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "trillion.s.01\n",
      "Head: cardinal.a.02\n",
      "===================\n",
      "  forty-eight.s.01\n",
      "  four.s.01\n",
      "  eighty-five.s.01\n",
      "  twenty-seven.s.01\n",
      "  fifty.s.01\n",
      "  one_hundred_eighty.s.01\n",
      "  non-zero.s.01\n",
      "  twenty-nine.s.01\n",
      "  forty-seven.s.01\n",
      "  thousand.s.01\n",
      "  one.s.01\n",
      "  ten.s.01\n",
      "  fifty-four.s.01\n",
      "  ninety-one.s.01\n",
      "  eighty.s.01\n",
      "  forty-one.s.01\n",
      "  one_hundred_ten.s.01\n",
      "  ninety-eight.s.01\n",
      "  nine.s.01\n",
      "  twenty-four.s.01\n",
      "  ninety.s.01\n",
      "  ninety-two.s.01\n",
      "  ten_thousand.s.01\n",
      "  three_hundred.s.01\n",
      "  forty-three.s.01\n",
      "  eighty-eight.s.01\n",
      "  zero.s.01\n",
      "  ninety-five.s.01\n",
      "  thirty-seven.s.01\n",
      "  twelve.s.01\n",
      "  thirty-one.s.01\n",
      "  three.s.01\n",
      "  seventy-seven.s.01\n",
      "  fifty-six.s.01\n",
      "  million.s.01\n",
      "  eighty-six.s.01\n",
      "  eighty-nine.s.01\n",
      "  seventy-three.s.01\n",
      "  one_hundred_seventy.s.01\n",
      "  seventy-six.s.01\n",
      "  one_hundred_five.s.01\n",
      "  seventeen.s.01\n",
      "  one_hundred_fifty.s.01\n",
      "  seventy-eight.s.01\n",
      "  seventy-two.s.01\n",
      "  hundred.s.01\n",
      "  one_hundred_thirty.s.01\n",
      "  thirty-nine.s.01\n",
      "  nineteen.s.01\n",
      "  hundred_thousand.s.01\n",
      "  thirty-six.s.01\n",
      "  twenty-eight.s.01\n",
      "  seventy-four.s.01\n",
      "  ninety-six.s.01\n",
      "  sixty-five.s.01\n",
      "  twenty-two.s.01\n",
      "  one_hundred_ninety.s.01\n",
      "  one_hundred_fifty-five.s.01\n",
      "  one_hundred_sixty.s.01\n",
      "  seventy-five.s.01\n",
      "  sixty-nine.s.01\n",
      "  eighty-four.s.01\n",
      "  twenty.s.01\n",
      "  sixty-six.s.01\n",
      "  forty-four.s.01\n",
      "  thirteen.s.01\n",
      "  zillion.s.01\n",
      "  eighty-two.s.01\n",
      "  forty.s.01\n",
      "  six.s.01\n",
      "  fifty-eight.s.01\n",
      "  two.s.01\n",
      "  fifty-one.s.01\n",
      "  fifty-three.s.01\n",
      "  sixty.s.01\n",
      "  one_hundred_seventy-five.s.01\n",
      "  sixty-seven.s.01\n",
      "  sixty-two.s.01\n",
      "  one_hundred_twenty-five.s.01\n",
      "  thirty-four.s.01\n",
      "  one_hundred_thirty-five.s.01\n",
      "  twenty-six.s.01\n",
      "  twenty-one.s.01\n",
      "  eighty-one.s.01\n",
      "  four_hundred.s.01\n",
      "  sixteen.s.01\n",
      "  one_hundred_fifteen.s.01\n",
      "  eight.s.01\n",
      "  fifteen.s.01\n",
      "  thirty.s.01\n",
      "  ninety-three.s.01\n",
      "  forty-nine.s.01\n",
      "  ninety-four.s.01\n",
      "  forty-six.s.01\n",
      "  twenty-five.s.01\n",
      "  thirty-two.s.01\n",
      "  trillion.s.02\n",
      "  fifty-nine.s.01\n",
      "  one_hundred_forty.s.01\n",
      "  one_hundred_twenty.s.01\n",
      "  sixty-eight.s.01\n",
      "  seventy-one.s.01\n",
      "  eleven.s.01\n",
      "  eighteen.s.01\n",
      "  thirty-five.s.01\n",
      "  seventy-nine.s.01\n",
      "  seven.s.01\n",
      "  hundred_and_one.s.01\n",
      "  fourteen.s.01\n",
      "  eighty-seven.s.01\n",
      "  five.s.01\n",
      "  forty-two.s.01\n",
      "  fifty-two.s.01\n",
      "  ninety-seven.s.01\n",
      "  twenty-three.s.01\n",
      "  sixty-one.s.01\n",
      "  thirty-three.s.01\n",
      "  ninety-nine.s.01\n",
      "  seventy.s.01\n",
      "  fifty-five.s.01\n",
      "  one_hundred_sixty-five.s.01\n",
      "  trillion.s.01\n",
      "  forty-five.s.01\n",
      "  sixty-four.s.01\n",
      "  one_hundred_forty-five.s.01\n",
      "  billion.s.02\n",
      "  sixty-three.s.01\n",
      "  thirty-eight.s.01\n",
      "  two_hundred.s.01\n",
      "  fifty-seven.s.01\n",
      "  billion.s.01\n",
      "  five_hundred.s.01\n",
      "  eighty-three.s.01\n",
      "\n",
      "Head: ordinal.a.02\n",
      "==================\n",
      "  eleventh.s.01\n",
      "  hundred-and-tenth.s.01\n",
      "  trillionth.s.01\n",
      "  hundred-and-fiftieth.s.01\n",
      "  thirty-sixth.s.01\n",
      "  four-hundredth.s.01\n",
      "  forty-ninth.s.01\n",
      "  forty-fifth.s.01\n",
      "  twenty-first.s.01\n",
      "  zeroth.s.01\n",
      "  thirty-fifth.s.01\n",
      "  forty-eighth.s.01\n",
      "  five-hundredth.s.01\n",
      "  twenty-fifth.s.01\n",
      "  fifty-fifth.s.01\n",
      "  hundred-and-sixty-fifth.s.01\n",
      "  sixty-fifth.s.01\n",
      "  second.s.01\n",
      "  hundred-and-fifty-fifth.s.01\n",
      "  thousandth.s.01\n",
      "  thirty-first.s.01\n",
      "  hundred-and-forty-fifth.s.01\n",
      "  eighteenth.s.01\n",
      "  thirty-seventh.s.01\n",
      "  hundred-and-twentieth.s.01\n",
      "  hundred-and-seventy-fifth.s.01\n",
      "  quadrillionth.s.01\n",
      "  hundred-and-fifteenth.s.01\n",
      "  seventeenth.s.01\n",
      "  fourth.s.01\n",
      "  tenth.s.01\n",
      "  twenty-second.s.01\n",
      "  ninetieth.s.01\n",
      "  twenty-ninth.s.01\n",
      "  twelfth.s.01\n",
      "  sixth.s.01\n",
      "  seventy-fifth.s.01\n",
      "  eightieth.s.01\n",
      "  thirty-third.s.01\n",
      "  hundred-and-eightieth.s.01\n",
      "  umpteenth.s.01\n",
      "  millionth.s.01\n",
      "  thirty-second.s.01\n",
      "  ninth.s.01\n",
      "  first.s.02\n",
      "  fifth.s.01\n",
      "  forty-third.s.01\n",
      "  forty-first.s.01\n",
      "  nineteenth.s.01\n",
      "  fortieth.s.01\n",
      "  twenty-sixth.s.01\n",
      "  fiftieth.s.01\n",
      "  forty-sixth.s.01\n",
      "  twenty-fourth.s.01\n",
      "  hundredth.s.01\n",
      "  hundred-and-first.s.01\n",
      "  hundred-and-thirtieth.s.01\n",
      "  seventh.s.01\n",
      "  thirteenth.s.01\n",
      "  twenty-seventh.s.01\n",
      "  thirty-eighth.s.01\n",
      "  thirty-ninth.s.01\n",
      "  sixtieth.s.01\n",
      "  ninety-fifth.s.01\n",
      "  nth.s.01\n",
      "  forty-second.s.01\n",
      "  seventieth.s.01\n",
      "  fifteenth.s.01\n",
      "  third.s.01\n",
      "  eighty-fifth.s.01\n",
      "  hundred-and-ninetieth.s.01\n",
      "  billionth.s.01\n",
      "  sixteenth.s.01\n",
      "  thirty-fourth.s.01\n",
      "  forty-seventh.s.01\n",
      "  hundred-and-fortieth.s.01\n",
      "  hundred-and-twenty-fifth.s.01\n",
      "  forty-fourth.s.01\n",
      "  zero.s.03\n",
      "  fourteenth.s.01\n",
      "  twenty-eighth.s.01\n",
      "  twentieth.s.01\n",
      "  two-hundredth.s.01\n",
      "  three-hundredth.s.01\n",
      "  twenty-third.s.01\n",
      "  eighth.s.01\n",
      "  quintillionth.s.01\n",
      "  thirtieth.s.01\n",
      "  sixty-fourth.s.01\n",
      "  hundred-and-thirty-fifth.s.01\n",
      "  hundred-and-seventieth.s.01\n",
      "  hundred-and-sixtieth.s.01\n",
      "  hundred-and-fifth.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "canty.s.01\n",
      "Head: energetic.a.01\n",
      "====================\n",
      "  physical.s.05\n",
      "  vigorous.s.01\n",
      "  alert.s.02\n",
      "  canty.s.01\n",
      "  indefatigable.s.01\n",
      "  driving.s.02\n",
      "  strenuous.s.01\n",
      "  high-energy.s.02\n",
      "\n",
      "Head: lethargic.a.01\n",
      "====================\n",
      "  dazed.s.02\n",
      "  listless.s.01\n",
      "  dreamy.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "off.s.04\n",
      "Head: soured.a.01\n",
      "=================\n",
      "  off.s.04\n",
      "\n",
      "Head: unsoured.a.01\n",
      "===================\n",
      "  fresh.s.09\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "disbelieving.s.01\n",
      "Head: incredulous.a.01\n",
      "======================\n",
      "  disbelieving.s.01\n",
      "\n",
      "Head: credulous.a.01\n",
      "====================\n",
      "  overcredulous.s.01\n",
      "  unquestioning.s.01\n",
      "  credible.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "brassy.s.02\n",
      "Head: tasteless.a.02\n",
      "====================\n",
      "  brassy.s.02\n",
      "  brummagem.s.01\n",
      "  indelicate.s.01\n",
      "  camp.s.01\n",
      "  barbaric.s.02\n",
      "  ostentatious.s.02\n",
      "\n",
      "Head: tasteful.a.01\n",
      "===================\n",
      "  understated.s.01\n",
      "  aesthetic.s.03\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "handed-down.s.01\n",
      "Head: traditional.a.01\n",
      "======================\n",
      "  handed-down.s.01\n",
      "  conventional.s.06\n",
      "  traditionalistic.s.01\n",
      "\n",
      "Head: nontraditional.a.01\n",
      "=========================\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "convertible.s.03\n",
      "Head: commutable.a.01\n",
      "=====================\n",
      "  convertible.s.03\n",
      "  alterable.s.02\n",
      "\n",
      "Head: incommutable.a.01\n",
      "=======================\n",
      "  inconvertible.s.02\n",
      "  unalterable.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "pointy-toed.s.01\n",
      "Head: toed.a.01\n",
      "===============\n",
      "  pointy-toed.s.01\n",
      "  square-toed.s.02\n",
      "  two-toed.s.01\n",
      "\n",
      "Head: toeless.a.01\n",
      "==================\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "velvet.s.01\n",
      "Head: smooth.a.01\n",
      "=================\n",
      "  even-textured.s.01\n",
      "  velvet.s.01\n",
      "  fine-textured.s.01\n",
      "  creaseless.s.01\n",
      "  seamless.s.02\n",
      "  fast.s.04\n",
      "  streamlined.s.02\n",
      "  glassy.s.01\n",
      "\n",
      "Head: rough.a.01\n",
      "================\n",
      "  scabby.s.01\n",
      "  saw-like.s.01\n",
      "  squamulose.s.01\n",
      "  abrasive.s.01\n",
      "  crushed.s.01\n",
      "  bumpy.s.02\n",
      "  verrucose.s.01\n",
      "  pocked.s.01\n",
      "  broken.s.06\n",
      "  lined.s.02\n",
      "  lepidote.s.01\n",
      "  cragged.s.01\n",
      "  gravelly.s.01\n",
      "  homespun.s.01\n",
      "  rocky.s.01\n",
      "  roughish.s.01\n",
      "  textured.s.01\n",
      "  imbricate.s.01\n",
      "  sandpapery.s.01\n",
      "  bullate.s.01\n",
      "  shagged.s.01\n",
      "  chapped.s.01\n",
      "  alligatored.s.01\n",
      "  costate.s.01\n",
      "  rugose.s.01\n",
      "  barky.s.01\n",
      "  corded.s.01\n",
      "  rock-ribbed.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "incautious.s.02\n",
      "Head: careless.a.01\n",
      "===================\n",
      "  casual.s.05\n",
      "  offhand.s.02\n",
      "  heedless.s.02\n",
      "  haphazard.s.02\n",
      "  incautious.s.02\n",
      "\n",
      "Head: careful.a.01\n",
      "==================\n",
      "  certain.s.07\n",
      "  close.s.04\n",
      "  conscientious.s.01\n",
      "  particular.s.06\n",
      "  detailed.s.01\n",
      "  minute.s.02\n",
      "  blow-by-blow.s.01\n",
      "  overcareful.s.01\n",
      "  protective.s.03\n",
      "  thorough.s.01\n",
      "  studious.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "allowable.s.01\n",
      "Head: deductible.a.01\n",
      "=====================\n",
      "  allowable.s.01\n",
      "\n",
      "Head: nondeductible.a.01\n",
      "========================\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "palsied.s.01\n",
      "Head: ill.a.01\n",
      "==============\n",
      "  delirious.s.01\n",
      "  paralytic.s.02\n",
      "  afflicted.s.01\n",
      "  dyspeptic.s.01\n",
      "  scrofulous.s.01\n",
      "  gouty.s.01\n",
      "  milk-sick.s.01\n",
      "  dizzy.s.01\n",
      "  airsick.s.01\n",
      "  nauseated.s.01\n",
      "  paraplegic.s.01\n",
      "  tubercular.s.04\n",
      "  upset.s.04\n",
      "  bronchitic.s.01\n",
      "  laid_up.s.01\n",
      "  aguish.s.01\n",
      "  bedfast.s.01\n",
      "  diabetic.s.02\n",
      "  feverish.s.03\n",
      "  funny.s.04\n",
      "  laid_low.s.01\n",
      "  unhealed.s.01\n",
      "  palsied.s.01\n",
      "  spastic.s.02\n",
      "  autistic.s.01\n",
      "  convalescent.s.01\n",
      "  consumptive.s.02\n",
      "  rickety.s.02\n",
      "  sneezy.s.01\n",
      "  bilious.s.02\n",
      "  faint.s.04\n",
      "  green.s.04\n",
      "  ailing.s.01\n",
      "\n",
      "Head: well.a.01\n",
      "===============\n",
      "  cured.s.01\n",
      "  asymptomatic.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "bronzed.s.01\n",
      "Head: brunet.a.01\n",
      "=================\n",
      "  bronzed.s.01\n",
      "  brown.s.02\n",
      "  nutbrown.s.01\n",
      "  dark-skinned.s.02\n",
      "  grizzled.s.01\n",
      "  dark.s.03\n",
      "  dark-haired.s.01\n",
      "  adust.s.02\n",
      "\n",
      "Head: blond.a.01\n",
      "================\n",
      "  ash-blonde.s.01\n",
      "  flaxen.s.01\n",
      "  fair.s.10\n",
      "  nordic.s.03\n",
      "  redheaded.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "foliolate.s.01\n",
      "Head: leafy.a.01\n",
      "================\n",
      "  leafed.s.01\n",
      "  leaflike.s.01\n",
      "  foliaceous.s.02\n",
      "  two-leaved.s.01\n",
      "  large-leaved.s.01\n",
      "  ivied.s.01\n",
      "  bifoliate.s.01\n",
      "  pinnate-leaved.s.01\n",
      "  bowery.s.01\n",
      "  silky-leaved.s.01\n",
      "  fan-leaved.s.01\n",
      "  leather-leaved.s.01\n",
      "  silver-leaved.s.01\n",
      "  spiny-leaved.s.01\n",
      "  unifoliate.s.01\n",
      "  fine-leaved.s.01\n",
      "  foliolate.s.01\n",
      "  petallike.s.01\n",
      "  prickly-leaved.s.01\n",
      "  curly-leaved.s.01\n",
      "  grassy-leaved.s.01\n",
      "  foliate.s.02\n",
      "\n",
      "Head: leafless.a.01\n",
      "===================\n",
      "  scapose.s.01\n",
      "  aphyllous.s.01\n",
      "  defoliate.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "blase.s.01\n",
      "Head: sophisticated.a.01\n",
      "========================\n",
      "  blase.s.01\n",
      "  intelligent.s.02\n",
      "  polished.s.02\n",
      "  worldly-wise.s.01\n",
      "\n",
      "Head: naive.a.01\n",
      "================\n",
      "  fleeceable.s.01\n",
      "  credulous.s.02\n",
      "  simple-minded.s.01\n",
      "  childlike.s.02\n",
      "  unsophisticated.s.01\n",
      "  innocent.s.04\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "imprudent.s.02\n",
      "Head: indiscreet.a.01\n",
      "=====================\n",
      "  imprudent.s.02\n",
      "  bigmouthed.s.01\n",
      "\n",
      "Head: discreet.a.01\n",
      "===================\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "big-shouldered.s.01\n",
      "Head: robust.a.01\n",
      "=================\n",
      "  big-boned.s.01\n",
      "  vigorous.s.02\n",
      "  half-hardy.s.01\n",
      "  heavy-armed.s.01\n",
      "  big-shouldered.s.01\n",
      "  big-chested.s.01\n",
      "  hardy.s.02\n",
      "  square-built.s.01\n",
      "  cast-iron.s.01\n",
      "  beefy.s.01\n",
      "  hardy.s.01\n",
      "\n",
      "Head: frail.a.01\n",
      "================\n",
      "  light-boned.s.01\n",
      "  decrepit.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "first-string.s.01\n",
      "Head: regular.a.01\n",
      "==================\n",
      "  official.s.04\n",
      "  timed.s.01\n",
      "  weak.s.08\n",
      "  well-ordered.s.01\n",
      "  first-string.s.01\n",
      "  lawful.s.02\n",
      "  standard.s.05\n",
      "  uniform.s.04\n",
      "\n",
      "Head: irregular.a.01\n",
      "====================\n",
      "  randomized.s.01\n",
      "  asymmetrical.s.02\n",
      "  casual.s.06\n",
      "  strong.s.07\n",
      "  improper.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "constricting.s.01\n",
      "Head: narrow.a.01\n",
      "=================\n",
      "  slender.s.02\n",
      "  tapered.s.01\n",
      "  narrow-mouthed.s.01\n",
      "  narrowed.s.01\n",
      "  straplike.s.01\n",
      "  strait.s.01\n",
      "  constricting.s.01\n",
      "\n",
      "Head: wide.a.01\n",
      "===============\n",
      "  broad-brimmed.s.01\n",
      "  wide-screen.s.01\n",
      "  deep.s.09\n",
      "  fanlike.s.01\n",
      "  beamy.s.01\n",
      "  sweeping.s.01\n",
      "  bird's-eye.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "made.s.03\n",
      "Head: successful.a.01\n",
      "=====================\n",
      "  in.s.01\n",
      "  booming.s.01\n",
      "  triple-crown.s.02\n",
      "  boffo.s.01\n",
      "  no-hit.s.01\n",
      "  self-made.s.01\n",
      "  productive.s.03\n",
      "  made.s.03\n",
      "  triple-crown.s.01\n",
      "  sure-fire.s.01\n",
      "  victorious.s.01\n",
      "\n",
      "Head: unsuccessful.a.01\n",
      "=======================\n",
      "  unfulfilled.s.01\n",
      "  unplaced.s.01\n",
      "  winless.s.01\n",
      "  scoreless.s.01\n",
      "  hitless.s.01\n",
      "  self-defeating.s.01\n",
      "  done_for.s.02\n",
      "  defeated.s.02\n",
      "  no-win.s.01\n",
      "  out.s.04\n",
      "  down-and-out.s.01\n",
      "  attempted.s.01\n",
      "  empty-handed.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "available.s.02\n",
      "Head: free.a.01\n",
      "===============\n",
      "  out-of-school.s.01\n",
      "  at_large.s.01\n",
      "  unconstrained.s.01\n",
      "  autonomous.s.01\n",
      "  available.s.02\n",
      "  unhampered.s.02\n",
      "  unrestricted.s.02\n",
      "  footloose.s.01\n",
      "  aweigh.s.02\n",
      "  clear.s.05\n",
      "  emancipated.s.01\n",
      "  unconfined.s.02\n",
      "\n",
      "Head: unfree.a.02\n",
      "=================\n",
      "  captive.s.01\n",
      "  serflike.s.01\n",
      "  at_bay.s.01\n",
      "  entangled.s.03\n",
      "  nonautonomous.s.01\n",
      "  apprenticed.s.01\n",
      "  adscript.s.02\n",
      "  prisonlike.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "narrow.s.02\n",
      "Head: limited.a.01\n",
      "==================\n",
      "  minor.s.10\n",
      "  narrow.s.02\n",
      "\n",
      "Head: unlimited.a.01\n",
      "====================\n",
      "  bottomless.s.03\n",
      "  oceanic.s.02\n",
      "  untrammeled.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "husbandly.s.02\n",
      "Head: domestic.a.03\n",
      "===================\n",
      "  housewifely.s.01\n",
      "  home-loving.s.01\n",
      "  husbandly.s.02\n",
      "  home-style.s.01\n",
      "  domesticated.s.02\n",
      "\n",
      "Head: undomestic.a.01\n",
      "=====================\n",
      "  undomesticated.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "rough-spoken.s.01\n",
      "Head: unrefined.a.02\n",
      "====================\n",
      "  coarse.s.02\n",
      "  low.s.04\n",
      "  rough.s.02\n",
      "  crass.s.01\n",
      "  artless.s.04\n",
      "  boorish.s.01\n",
      "  agrestic.s.02\n",
      "  ungentlemanly.s.01\n",
      "  unladylike.s.01\n",
      "  robust.s.04\n",
      "  rough-spoken.s.01\n",
      "  ill-bred.s.01\n",
      "\n",
      "Head: refined.a.01\n",
      "==================\n",
      "  patrician.s.01\n",
      "  dainty.s.01\n",
      "  well-bred.s.01\n",
      "  civilized.s.02\n",
      "  ladylike.s.01\n",
      "  couth.s.01\n",
      "  gentlemanlike.s.01\n",
      "  finespun.s.01\n",
      "  overrefined.s.01\n",
      "  debonair.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "cold.s.05\n",
      "Head: perfect.a.01\n",
      "==================\n",
      "  idealized.s.01\n",
      "  idyllic.s.01\n",
      "  clear.s.13\n",
      "  perfectible.s.01\n",
      "  pluperfect.s.01\n",
      "  cold.s.05\n",
      "  faultless.s.01\n",
      "  ideal.s.01\n",
      "  clean.s.05\n",
      "  mint.s.01\n",
      "  uncorrupted.s.01\n",
      "  errorless.s.01\n",
      "  complete.s.02\n",
      "  down.s.05\n",
      "  flawless.s.01\n",
      "\n",
      "Head: imperfect.a.01\n",
      "====================\n",
      "  imperfectible.s.01\n",
      "  irregular.s.05\n",
      "  defective.s.01\n",
      "  corrupt.s.03\n",
      "  broken.s.07\n",
      "  blemished.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "catastrophic.s.01\n",
      "Head: harmful.a.01\n",
      "==================\n",
      "  bad.s.11\n",
      "  counterproductive.s.01\n",
      "  nocent.s.01\n",
      "  abusive.s.02\n",
      "  calumniatory.s.01\n",
      "  bruising.s.01\n",
      "  catastrophic.s.01\n",
      "  insidious.s.03\n",
      "  stabbing.s.01\n",
      "  deleterious.s.01\n",
      "  damaging.s.01\n",
      "  ill.s.02\n",
      "  mischievous.s.02\n",
      "\n",
      "Head: harmless.a.01\n",
      "===================\n",
      "  innocent.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "nonstick.s.01\n",
      "Head: slippery.a.01\n",
      "===================\n",
      "  slick.s.01\n",
      "  nonstick.s.01\n",
      "  slithery.s.01\n",
      "  lubricious.s.01\n",
      "  slipping.s.01\n",
      "  sliding.s.01\n",
      "  slimed.s.01\n",
      "\n",
      "Head: nonslippery.a.01\n",
      "======================\n",
      "  nonskid.s.01\n",
      "  nonslip.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "small.s.08\n",
      "Head: fine.a.05\n",
      "===============\n",
      "  close-grained.s.01\n",
      "  floury.s.01\n",
      "  nongranular.s.01\n",
      "  close.s.09\n",
      "  small.s.08\n",
      "  superfine.s.01\n",
      "  dustlike.s.01\n",
      "  powdered.s.01\n",
      "\n",
      "Head: coarse.a.01\n",
      "=================\n",
      "  coarse-grained.s.02\n",
      "  plushy.s.01\n",
      "  farinaceous.s.02\n",
      "  loose.s.09\n",
      "  granulated.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "in.s.01\n",
      "Head: successful.a.01\n",
      "=====================\n",
      "  in.s.01\n",
      "  booming.s.01\n",
      "  triple-crown.s.02\n",
      "  boffo.s.01\n",
      "  no-hit.s.01\n",
      "  self-made.s.01\n",
      "  productive.s.03\n",
      "  made.s.03\n",
      "  triple-crown.s.01\n",
      "  sure-fire.s.01\n",
      "  victorious.s.01\n",
      "\n",
      "Head: unsuccessful.a.01\n",
      "=======================\n",
      "  unfulfilled.s.01\n",
      "  unplaced.s.01\n",
      "  winless.s.01\n",
      "  scoreless.s.01\n",
      "  hitless.s.01\n",
      "  self-defeating.s.01\n",
      "  done_for.s.02\n",
      "  defeated.s.02\n",
      "  no-win.s.01\n",
      "  out.s.04\n",
      "  down-and-out.s.01\n",
      "  attempted.s.01\n",
      "  empty-handed.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "flash-frozen.s.01\n",
      "Head: preserved.a.01\n",
      "====================\n",
      "  smoked.s.01\n",
      "  potted.s.02\n",
      "  lyophilized.s.01\n",
      "  pickled.s.01\n",
      "  cured.s.04\n",
      "  freeze-dried.s.02\n",
      "  flash-frozen.s.01\n",
      "  sun-dried.s.01\n",
      "  corned.s.01\n",
      "  dried.s.02\n",
      "  salted.s.01\n",
      "  aged.s.05\n",
      "  canned.s.02\n",
      "  candied.s.02\n",
      "\n",
      "Head: fresh.a.05\n",
      "================\n",
      "  unprocessed.s.03\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "empty.s.02\n",
      "Head: meaningless.a.01\n",
      "======================\n",
      "  nonsense.s.01\n",
      "  empty.s.02\n",
      "  insignificant.s.02\n",
      "  mindless.s.01\n",
      "\n",
      "Head: meaningful.a.01\n",
      "=====================\n",
      "  purposeful.s.02\n",
      "  meaty.s.02\n",
      "  meaning.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "acrimonious.s.01\n",
      "Head: resentful.a.01\n",
      "====================\n",
      "  acrimonious.s.01\n",
      "  rancorous.s.01\n",
      "\n",
      "Head: unresentful.a.01\n",
      "======================\n",
      "  unbitter.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "many-lobed.s.01\n",
      "Head: multilateral.a.01\n",
      "=======================\n",
      "  tripartite.s.01\n",
      "  bipartite.s.02\n",
      "  eleven-sided.s.01\n",
      "  quadrilateral.s.01\n",
      "  palmately-lobed.s.01\n",
      "  deep-lobed.s.01\n",
      "  joint.s.03\n",
      "  six-sided.s.01\n",
      "  many-lobed.s.01\n",
      "  twelve-sided.s.01\n",
      "  multipartite.s.01\n",
      "  five-sided.s.01\n",
      "  ten-sided.s.01\n",
      "  bilateral.s.03\n",
      "  two-lobed.s.01\n",
      "  seven-sided.s.01\n",
      "  five-lobed.s.01\n",
      "  trilateral.s.02\n",
      "  eight-sided.s.01\n",
      "  tetramerous.s.01\n",
      "  three-cornered.s.02\n",
      "  three-lobed.s.02\n",
      "  nine-sided.s.01\n",
      "  quadripartite.s.01\n",
      "  four-lobed.s.01\n",
      "\n",
      "Head: unilateral.a.01\n",
      "=====================\n",
      "  one-party.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "wildcat.s.01\n",
      "Head: unsound.a.02\n",
      "==================\n",
      "  long.s.07\n",
      "  wildcat.s.01\n",
      "  bad.s.09\n",
      "\n",
      "Head: sound.a.01\n",
      "================\n",
      "  stable.s.02\n",
      "  healthy.s.02\n",
      "  solid.s.11\n",
      "  dependable.s.04\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "ironshod.s.01\n",
      "Head: shod.a.01\n",
      "===============\n",
      "  roughshod.s.01\n",
      "  ironshod.s.01\n",
      "  slippered.s.01\n",
      "  sandaled.s.01\n",
      "  booted.s.01\n",
      "\n",
      "Head: unshod.a.02\n",
      "=================\n",
      "  barefoot.s.01\n",
      "  stockinged.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "acerb.s.02\n",
      "Head: unpleasant.a.01\n",
      "=====================\n",
      "  embarrassing.s.02\n",
      "  acerb.s.02\n",
      "  ungrateful.s.02\n",
      "  unhappy.s.03\n",
      "  afflictive.s.01\n",
      "  dreadful.s.03\n",
      "  dour.s.02\n",
      "  rebarbative.s.01\n",
      "  beastly.s.01\n",
      "  hot.s.12\n",
      "  sharp.s.05\n",
      "  harsh.s.01\n",
      "  harsh.s.02\n",
      "\n",
      "Head: pleasant.a.01\n",
      "===================\n",
      "  enjoyable.s.01\n",
      "  grateful.s.02\n",
      "  idyllic.s.02\n",
      "  beautiful.s.02\n",
      "  dulcet.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "away.s.03\n",
      "Head: inaccurate.a.01\n",
      "=====================\n",
      "  away.s.03\n",
      "  wide.s.07\n",
      "  faulty.s.02\n",
      "  unfaithful.s.04\n",
      "\n",
      "Head: accurate.a.01\n",
      "===================\n",
      "  veracious.s.02\n",
      "  high-fidelity.s.01\n",
      "  true.s.02\n",
      "  straight.s.05\n",
      "  surgical.s.03\n",
      "  close.s.05\n",
      "  dead-on.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "smooth-bodied.s.01\n",
      "Head: bodied.a.01\n",
      "=================\n",
      "  short-bodied.s.01\n",
      "  oval-bodied.s.01\n",
      "  narrow-bodied.s.01\n",
      "  incarnate.s.02\n",
      "  long-bodied.s.01\n",
      "  silver-bodied.s.01\n",
      "  smooth-bodied.s.01\n",
      "  slim-bodied.s.01\n",
      "  thick-bodied.s.01\n",
      "  lithe-bodied.s.01\n",
      "\n",
      "Head: unbodied.a.01\n",
      "===================\n",
      "  bodiless.s.02\n",
      "  formless.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "absorbed.s.02\n",
      "Head: unreflected.a.01\n",
      "======================\n",
      "  absorbed.s.02\n",
      "\n",
      "Head: reflected.a.01\n",
      "====================\n",
      "  mirrored.s.01\n",
      "  echoic.s.02\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "male.s.02\n",
      "Head: masculine.a.02\n",
      "====================\n",
      "  male.s.02\n",
      "  mannish.s.02\n",
      "  butch.s.01\n",
      "\n",
      "Head: feminine.a.01\n",
      "===================\n",
      "  powder-puff.s.01\n",
      "  fair.s.06\n",
      "  female.s.02\n",
      "  maidenlike.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "fleeceable.s.01\n",
      "Head: naive.a.01\n",
      "================\n",
      "  fleeceable.s.01\n",
      "  credulous.s.02\n",
      "  simple-minded.s.01\n",
      "  childlike.s.02\n",
      "  unsophisticated.s.01\n",
      "  innocent.s.04\n",
      "\n",
      "Head: sophisticated.a.01\n",
      "========================\n",
      "  blase.s.01\n",
      "  intelligent.s.02\n",
      "  polished.s.02\n",
      "  worldly-wise.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "back.s.02\n",
      "Head: posterior.a.01\n",
      "====================\n",
      "  retral.s.02\n",
      "  back.s.02\n",
      "  caudal.s.03\n",
      "\n",
      "Head: anterior.a.01\n",
      "===================\n",
      "  prefrontal.s.01\n",
      "  frontal.s.01\n",
      "  frontal.s.04\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "neutral.s.07\n",
      "Head: uncharged.a.01\n",
      "====================\n",
      "  dead.s.16\n",
      "  neutral.s.07\n",
      "\n",
      "Head: charged.a.01\n",
      "==================\n",
      "  positive.s.10\n",
      "  hot.s.20\n",
      "  polar.s.01\n",
      "  negative.s.08\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "nibbed.s.01\n",
      "Head: pointed.a.01\n",
      "==================\n",
      "  acanthoid.s.01\n",
      "  barreled.s.02\n",
      "  six-pointed.s.01\n",
      "  peaked.s.02\n",
      "  bristle-pointed.s.01\n",
      "  spiked.s.01\n",
      "  nibbed.s.01\n",
      "  spikelike.s.01\n",
      "  five-pointed.s.01\n",
      "  acuate.s.01\n",
      "  fusiform.s.01\n",
      "  sharpened.s.01\n",
      "  pyramidal.s.01\n",
      "\n",
      "Head: pointless.a.01\n",
      "====================\n",
      "  blunt.s.01\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sat_samp = random.sample(all_satellites,60)\n",
    "for sat in sat_samp:\n",
    "    print(sat)\n",
    "    get_wheels_and_axle(wn.synset(sat),verbose=True)\n",
    "    print(end=\"\\n^^^^^^^^^^^^^^^^^^^^^^\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac3b26",
   "metadata": {},
   "source": [
    "## Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ea6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac0df32",
   "metadata": {},
   "source": [
    "Strategy find emotion nouns using hypernym relations.  Use stemmer to find related adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f4893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stemmer.stem(\"sadness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df219ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definitions (ss_set,verbose = False):\n",
    "    defs = [(ss.name(),ss.definition()) for ss in ss_set]\n",
    "    if verbose:\n",
    "        for (nm,df) in defs:\n",
    "            print(f\"{nm:>20}     {df}\")\n",
    "    return defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1a540f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('sad.a.01'), Synset('sad.s.02'), Synset('deplorable.s.01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad_synsets = [ss for ss in wn.synsets('sad')]\n",
    "sad_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94278a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sad.a.01     experiencing or showing sorrow or unhappiness; ; - Christina Rossetti\n",
      "            sad.s.02     of things that make you feel sad; ; ; ; - Christina Rossetti\n",
      "     deplorable.s.01     bad; unfortunate\n"
     ]
    }
   ],
   "source": [
    "defs = get_definitions(sad_synsets,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85cde40",
   "metadata": {},
   "source": [
    "Within the adjectives the hypernym structure has not been done.\n",
    "\n",
    "There's a semantic reason that has to do with a basic assumption/limitation of wn.  There are no\n",
    "abstract nodes.  And since there is no adjective meaning \"having an emotion\" no adjective\n",
    "can have a synset corresponding to the sense \"having an emotion\" as a synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f76400cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad_synset_0 = sad_synsets[0]\n",
    "sad_synset_0.hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7a0bf",
   "metadata": {},
   "source": [
    "###  Bingo!  Got one!\n",
    "\n",
    "Here's one intensity pair found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48784c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('anger.n.01'),\n",
       " Synset('anger.n.02'),\n",
       " Synset('wrath.n.02'),\n",
       " Synset('anger.v.01'),\n",
       " Synset('anger.v.02')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anger_synsets = [ss for ss in wn.synsets('anger')]\n",
    "anger_synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b751e",
   "metadata": {},
   "source": [
    "So these are the ones we ignore.  The basic level emotion words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d622b39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('emotion.n.01')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anger_hypernyms = anger_synsets[0].hypernyms()\n",
    "emotion_ss = anger_hypernyms[0]\n",
    "emotion_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72506191",
   "metadata": {},
   "source": [
    "All the senses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5907837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('fury.n.01'),\n",
       " Synset('rage.n.02'),\n",
       " Synset('rage.n.03'),\n",
       " Synset('rage.n.04'),\n",
       " Synset('fad.n.01')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rage_synsets = [ss for ss in wn.synsets('rage','n')]\n",
    "rage_synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105eddcb",
   "metadata": {},
   "source": [
    "Bingo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e04f624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('anger.n.01'),\n",
       " Synset('anger.n.02'),\n",
       " Synset('desire.n.03'),\n",
       " Synset('fashion.n.03'),\n",
       " Synset('violence.n.03')}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{hn for ss in rage_synsets for hn in ss.hypernyms()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "id": "7acc09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotional_state.n.01 the state of a person's emotions (especially with regard to pleasure or dejection)\n",
      "hate.n.01         the emotion of intense dislike; a feeling of dislike so strong that it demands action\n",
      "fear.n.03         a feeling of profound respect for someone or something\n",
      "joy.n.01          the emotion of great happiness\n",
      "love.n.01         a strong positive emotion of regard and affection\n",
      "anxiety.n.02      a vague unpleasant emotion that is experienced in anticipation of some (usually ill-defined) misfortune\n",
      "conditioned_emotional_response.n.01 an emotional response that has been acquired by conditioning\n",
      "anger.n.01        a strong emotion; a feeling that is oriented toward some real or supposed grievance\n",
      "fear.n.01         an emotion experienced in anticipation of some specific pain or danger (usually accompanied by a desire to flee or fight)\n"
     ]
    }
   ],
   "source": [
    "get_defs(emotion_ss.hyponyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a88b0",
   "metadata": {},
   "source": [
    "## Get emotion noun synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "69aaa90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  find all the emotion bnoun synsets in the obvious way\n",
    "anger_synsets = [ss for ss in wn.synsets('anger')]\n",
    "anger_hypernyms = anger_synsets[0].hypernyms()\n",
    "emotion_ss = anger_hypernyms[0]\n",
    "\n",
    "def get_hypos (ss_set):\n",
    "    return {hn for ss in ss_set for hn in ss.hyponyms()}\n",
    "\n",
    "def get_hypos_iter (root):\n",
    "    global accumulated\n",
    "    hl0 = root.hyponyms()\n",
    "    accumulated = set(hl0)\n",
    "    current = hl0\n",
    "    while current:\n",
    "        current = get_hypos(current)\n",
    "        accumulated.update(current)\n",
    "    return accumulated\n",
    "\n",
    "def get_lemmas_iter(root):\n",
    "    return {l for ss in get_hypos_iter(root) for l in ss.lemmas()}.union(root.lemmas())\n",
    "\n",
    "def get_emotion_nouns(root = emotion_ss,hn_list=None):\n",
    "    return get_hypos_iter (root)\n",
    "\n",
    "def get_defs (ss_seq):\n",
    "    for ss in ss_seq:\n",
    "        print(f\"{ss.name():<17} {ss.definition()}\")\n",
    "\n",
    "emotion_nouns = get_emotion_nouns()\n",
    "len(emotion_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88f1ac",
   "metadata": {},
   "source": [
    "The synset one up in the hierarchy (hypernym of \"emotion.n.01\") is actually what we\n",
    "want.  It's \"feeling.n.01\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73e6e7",
   "metadata": {},
   "source": [
    "## Cognition\n",
    "\n",
    "Basically everything under cognition is a complete mess. Better to find another way to\n",
    "mine this portion of lexicon.  Wordnet just throws in so much noise that a vast amount\n",
    "of human intervention would be needed to find the target words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "b63ebe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('perception.n.04') 3\n",
      "Synset('place.n.03') 1\n",
      "Synset('vocabulary.n.02') 0\n",
      "Synset('structure.n.03') 75\n",
      "Synset('lexis.n.01') 0\n",
      "Synset('information.n.02') 639\n",
      "Synset('episteme.n.01') 0\n",
      "Synset('mind.n.01') 5\n",
      "Synset('cognitive_factor.n.01') 47\n",
      "Synset('process.n.02') 573\n",
      "Synset('history.n.05') 0\n",
      "Synset('inability.n.01') 33\n",
      "Synset('equivalent.n.01') 8\n",
      "Synset('process.n.04') 18\n",
      "Synset('content.n.05') 1943\n",
      "Synset('public_knowledge.n.01') 4\n",
      "Synset('practice.n.05') 13\n",
      "Synset('attitude.n.01') 161\n",
      "Synset('ability.n.02') 370\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synset(\"cognition.n.01\").hyponyms():\n",
    "    print(ss,len(get_emotion_nouns(root = ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "67ea7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_nouns = get_emotion_nouns(root = wn.synset(\"feeling.n.01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50af01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_nouns2 = get_lemmas_iter(root = wn.synset(\"feeling.n.01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "701614b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feeling_nouns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "id": "46ad2182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordset = {l.name() for l in feeling_nouns2}\n",
    "len(wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "058d3286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feeling_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "87b415d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 weird nouns\n",
    "#perception_nouns = get_emotion_nouns(root = wn.synset(\"perception.n.04\"))\n",
    "# 161 words, most;y isms (e.g., agnosticism) some concept/attitude words irreverence, islamophobia, neoteny\n",
    "ism_nouns = get_hypos_iter(root = wn.synset(\"attitude.n.01\"))\n",
    "# 5 weird nouns\n",
    "#mind_nouns =  get_emotion_nouns(root = wn.synset('mind.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "d9bdec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost all medical words but occasionally not (sunset, variance, nuisance, noon,midnight)\n",
    "information_nouns = get_hypos_iter(root = wn.synset(\"information.n.02\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428ea1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "bb359d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(573, 639, 5, 161)"
      ]
     },
     "execution_count": 1073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(process_nouns),len(information_nouns),len(mind_nouns),len(ism_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "a74121e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discipline names, some isms,\n",
    "content_nouns = get_hypos_iter(root = wn.synset(\"content.n.05\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "fac2059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitive_factor_nouns = get_hypos_iter(root = wn.synset(\"cognitive_factor.n.01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "id": "615f97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a terrible name for this lexical set  which includes idyll, harmonic_motion, aircraft_landing,  \n",
    "## and channel.n\n",
    "psychological_feature_nouns = list(get_hypos_iter(root = wn.synset('psychological_feature.n.01')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "id": "d6a66c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orthoepy.n.02     a term formerly used for the part of phonology that dealt with the `correct' pronunciation of words and its relation to `correct' orthography\n",
      "abscess.n.01      symptom consisting of a localized collection of pus surrounded by inflamed tissue\n",
      "contempt_of_court.n.01 disrespect for the rules of a court of law\n",
      "apnea.n.01        transient cessation of respiration\n",
      "channel.n.05      (often plural) a means of communication or access\n",
      "superiority.n.03  displaying a sense of being better than others\n",
      "harmonic_motion.n.01 a periodic motion in which the displacement is either symmetrical about a point or is the sum of such motions\n",
      "tetralogy.n.01    a series of four related works (plays or operas or novels)\n",
      "scalage.n.01      estimation of the amount of lumber in a log\n",
      "stare.n.01        a fixed look with eyes open wide\n",
      "gripe.n.01        informal terms for objecting\n",
      "copying.n.01      an act of copying\n",
      "hydropathy.n.01   the internal and external use of water in the treatment of disease\n",
      "lavage.n.01       washing out a hollow organ (especially the stomach) by flushing with water\n",
      "rub.n.02          the act of rubbing or wiping\n",
      "pretense.n.03     imaginative intellectual play\n",
      "step_dancing.n.01 dancing in which the steps are more important than gestures or postures\n",
      "battle_damage.n.01 loss of military equipment in battle\n",
      "aircraft_landing.n.01 landing an aircraft\n",
      "killing.n.01      an event that causes someone to die\n",
      "indoctrination.n.01 teaching someone to accept doctrines uncritically\n",
      "manhunt.n.01      an organized search (by police) for a person (charged with a crime)\n",
      "cocooning.n.01    retreating to the seclusion of your home (as for privacy or escape)\n",
      "foul.n.01         an act that violates the rules of a sport\n",
      "neutralism.n.01   a policy of neutrality or nonalignment in international affairs\n",
      "neurology.n.02    (neurology) the branch of medicine that deals with the nervous system and its disorders\n",
      "hasidism.n.02     beliefs and practices of a sect of Orthodox Jews\n",
      "quantum_field_theory.n.01 the branch of quantum physics that is concerned with the theory of fields; it was motivated by the question of how an atom radiates light as its electrons jump from excited states\n",
      "aquaculture.n.01  rearing aquatic animals or cultivating aquatic plants for food\n",
      "urban_renewal.n.01 the clearing and rebuilding and redevelopment of urban slums\n",
      "order.n.13        a request for something to be made, supplied, or served\n",
      "wicca.n.02        the polytheistic nature religion of modern witchcraft whose central deity is a mother goddess; claims origins in pre-Christian pagan religions of western Europe\n",
      "ability.n.02      possession of the qualities (especially mental qualities) required to do something or get something done\n",
      "arthralgia.n.01   pain in a joint or joints\n",
      "idyll.n.01        an episode of such pastoral or romantic charm as to qualify as the subject of a poetic idyll\n",
      "comedown.n.01     decline to a lower status or level\n",
      "memory.n.02       the cognitive processes whereby past experience is remembered\n",
      "cultivation.n.01  socialization through training and education to develop one's mind or manners\n",
      "childbirth-preparation_class.n.01 a course that teaches pregnant women to use breathing and concentration and exercise techniques to use during labor\n",
      "spoonfeeding.n.02 teaching in an overly simplified way that discourages independent thought\n",
      "compilation.n.02  the act of compiling (as into a single book or file or list)\n",
      "clawback.n.01     finding a way to take money back from people that they were given in another way\n",
      "acupuncture.n.01  treatment of pain or disease by inserting the tips of needles at specific points on the skin\n",
      "femoral_pulse.n.01 pulse of the femoral artery (felt in the groin)\n",
      "pursuit.n.02      a search for an alternative that meets cognitive criteria\n",
      "smash.n.02        a serious collision (especially of motor vehicles)\n",
      "malacology.n.01   the branch of zoology that studies the structure and behavior of mollusks\n",
      "bell_ringer.n.03  something that exactly succeeds in achieving its goal\n",
      "prophylaxis.n.01  the prevention of disease\n",
      "drip.n.02         the sound of a liquid falling drop by drop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "get_defs (psychological_feature_nouns[340:390])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "b943aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temptation.n.01     something that seduces or has the quality to seduce\n",
      "clincher.n.02       a point or fact or remark that settles something conclusively\n",
      "straitjacket.n.01   anything immaterial that severely hinders or confines\n",
      "trouble.n.01        a source of difficulty\n",
      "lifeline.n.02       support that enables people to survive or to continue doing something (often by providing an essential connection)\n",
      "forbidden_fruit.n.01   originally an apple from the tree of knowledge of good and evil in the Garden of Eden; it is now used to refer to anything that is tempting but dangerous (as sexuality)\n",
      "influence.n.03      a cognitive factor that tends to have an effect on what you do\n",
      "barrier.n.02        any condition that makes it difficult to make progress or to achieve an objective\n",
      "imponderable.n.01   a factor whose effects cannot be accurately assessed\n",
      "bait.n.01           anything that serves as an enticement\n",
      "difficulty.n.02     a factor causing trouble in achieving a positive result or tending to produce a negative result\n",
      "diriment_impediment.n.01   (canon law) an impediment that invalidates a marriage (such as the existence of a prior marriage)\n",
      "allurement.n.01     attractiveness\n",
      "morale_builder.n.01   something or someone who influences by building or strengthening morale\n",
      "albatross.n.01      (figurative) something that hinders or handicaps\n",
      "can_of_worms.n.01   a source of unpredictable trouble and complexity\n",
      "leaven.n.02         an influence that works subtly to lighten or modify something\n",
      "hang-up.n.02        an unforeseen obstacle\n",
      "kink.n.05           a difficulty or flaw in a plan or operation\n",
      "divine_guidance.n.01   (theology) a special influence of a divinity on the minds of human beings\n",
      "matter.n.04         a problem\n",
      "bind.n.01           something that hinders as if with bonds\n",
      "bamboo_curtain.n.01   an ideological barrier around communist China especially in the 1950s and 1960s\n",
      "deep_water.n.01     serious trouble\n",
      "hurdle.n.02         an obstacle that you are expected to overcome\n",
      "snorter.n.02        something outstandingly difficult\n",
      "stymie.n.02         a thwarting and distressing situation\n",
      "growing_pains.n.03   problems that arise in enlarging an enterprise (especially in the early stages)\n",
      "ideological_barrier.n.01   a barrier to cooperation or interaction resulting from conflicting ideologies\n",
      "anchor.n.02         a central cohesive source of support and stability\n",
      "killer.n.03         a difficulty that is hard to deal with\n",
      "support.n.03        something providing immaterial assistance to a person or cause or interest\n",
      "iron_curtain.n.01   an impenetrable barrier to communication or information especially as imposed by rigid censorship and secrecy; used by Winston Churchill in 1946 to describe the demarcation between democratic and communist countries\n",
      "hindrance.n.01      something immaterial that interferes with or delays action or progress\n",
      "color_bar.n.01      barrier preventing blacks from participating in various activities with whites\n",
      "imprint.n.01        a distinctive influence\n",
      "pestilence.n.03     a pernicious and malign influence that is hard to get rid of\n",
      "wrinkle.n.02        a minor difficulty\n",
      "pisser.n.02         a very disagreeable difficulty\n",
      "facer.n.01          (a dated Briticism) a serious difficulty with which one is suddenly faced\n",
      "hydra.n.03          trouble that cannot be overcome by a single effort because of its many aspects or its persistent and pervasive quality\n",
      "pressure_point.n.02   where problems or difficulties are likely to occur\n",
      "determinant.n.01    a determining or causal element or factor\n",
      "pitfall.n.01        an unforeseen or unexpected or surprising difficulty\n",
      "language_barrier.n.01   barrier to communication resulting from speaking different languages\n",
      "drag.n.02           something that slows or delays progress\n",
      "obstacle.n.01       something immaterial that stands in the way and must be circumvented or surmounted\n"
     ]
    }
   ],
   "source": [
    "for ss in cognitive_factor_nouns:\n",
    "    print(f\"{ss.name():<17}   {ss.definition()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "7757e654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('boringness.n.01'),\n",
       " Synset('drag.n.03'),\n",
       " Synset('dullness.n.02'),\n",
       " Synset('helplessness.n.01'),\n",
       " Synset('ineffectiveness.n.01'),\n",
       " Synset('inefficacy.n.01'),\n",
       " Synset('jejunity.n.01'),\n",
       " Synset('paper_tiger.n.01'),\n",
       " Synset('ponderousness.n.01'),\n",
       " Synset('tediousness.n.01'),\n",
       " Synset('uninterestingness.n.01'),\n",
       " Synset('unpersuasiveness.n.01'),\n",
       " Synset('voicelessness.n.03')}"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerlessness_ss = wn.synset(\"drag.n.03\").hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0]\n",
    "powerlessness_nouns = get_emotion_nouns(root = powerlessness_ss)\n",
    "powerlessness_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "83592ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('drag.n.01') the phenomenon of resistance to motion through a fluid\n",
      "Synset('drag.n.02') something that slows or delays progress\n",
      "Synset('drag.n.03') something tedious and boring\n",
      "Synset('drag.n.04') clothing that is conventionally worn by the opposite sex (especially women's clothing when worn by a man)\n",
      "Synset('puff.n.07') a slow inhalation (as of tobacco smoke)\n",
      "Synset('drag.n.06') the act of dragging (pulling with force)\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets(\"drag\",\"n\"):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "4d999812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('anticipation.n.01') {Synset('feeling.n.01'), Synset('expectation.n.03'), Synset('attribute.n.02'), Synset('state.n.02'), Synset('abstraction.n.06'), Synset('entity.n.01')}\n",
      "\n",
      "Synset('anticipation.n.02') {Synset('psychological_feature.n.01'), Synset('expectation.n.01'), Synset('cognition.n.01'), Synset('abstraction.n.06'), Synset('entity.n.01'), Synset('content.n.05'), Synset('belief.n.01')}\n",
      "\n",
      "Synset('prediction.n.01') {Synset('higher_cognitive_process.n.01'), Synset('psychological_feature.n.01'), Synset('entity.n.01'), Synset('reasoning.n.01'), Synset('abstraction.n.06'), Synset('cognition.n.01'), Synset('process.n.02'), Synset('thinking.n.01')}\n",
      "\n",
      "Synset('anticipation.n.04') {Synset('attribute.n.02'), Synset('state.n.02'), Synset('abstraction.n.06'), Synset('entity.n.01'), Synset('condition.n.01'), Synset('hopefulness.n.01')}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets(\"anticipation\",\"n\"):\n",
    "    print(ss, get_hypers_iter (ss))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "d4aa3a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anticipation', 'expectancy']"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('anticipation.n.02').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "2eeb8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are almost all mnames for religious doctrines but just to be confusing anticipation.n.02 is in there\n",
    "# as is conviction, decuisuion\n",
    "belief_nouns = sorted(ss.name() for ss in list(get_hypos_iter(root = wn.synset('belief.n.01'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "d3258df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_nouns2 = list(get_hypos_iter(root = wn.synset('belief.n.02')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb85168",
   "metadata": {},
   "source": [
    "A little known fact about the `wn.synset()` function: the key `\"belief.n.02\"` retrieves the second synset\n",
    "associated with the noun *belief*, whether or not  the official name of that synset is `\"belief.n.02\"`.\n",
    "In fact, the \"official\" name for the second sense of \"belief\" is \"impression.n.01\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "id": "53b0281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'impression.n.01'"
      ]
     },
     "execution_count": 1122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('belief.n.02').name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b3dde",
   "metadata": {},
   "source": [
    "The objects returned for both keys are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "id": "44f737ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('belief.n.02') == wn.synset('impression.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd78bb34",
   "metadata": {},
   "source": [
    "Moreover the associated lemmas are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "id": "347a4832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('belief.n.02.belief') == wn.lemma('impression.n.01.belief')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7291c",
   "metadata": {},
   "source": [
    "It is an error however to ask for the nth synset when the number of senses for the\n",
    "for the form,pos pair is fewer than n.  Since `belief.n` has only two definitions, \n",
    "the following raises both a \n",
    "\n",
    "```python\n",
    "WordNetError: Lemma 'belief' with part of speech 'n' only has 2 senses\n",
    "```\n",
    "\n",
    "and an `IndexError`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "id": "81db7d0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "WordNetError",
     "evalue": "Lemma 'belief' with part of speech 'n' only has 2 senses",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/p312/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1514\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synset\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1514\u001b[0m     offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lemma_pos_offset_map[lemma][pos][synset_index]\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wn\u001b[38;5;241m.\u001b[39msynset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbelief.n.03\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/p312/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1519\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synset\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1518\u001b[0m     n_senses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lemma_pos_offset_map[lemma][pos])\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WordNetError(\n\u001b[1;32m   1520\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLemma \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlemma\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m with part of speech \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpos\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_senses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msense\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mn_senses\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msenses\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1522\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# load synset information from the appropriate file\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m synset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynset_from_pos_and_offset(pos, offset)\n",
      "\u001b[0;31mWordNetError\u001b[0m: Lemma 'belief' with part of speech 'n' only has 2 senses"
     ]
    }
   ],
   "source": [
    "wn.synset('belief.n.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "5d5b7d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Lemma('impression.n.01.belief'),\n",
       " Lemma('heart.n.01.bosom'),\n",
       " Lemma('effect.n.03.effect'),\n",
       " Lemma('impression.n.01.feeling'),\n",
       " Lemma('first_blush.n.01.first_blush'),\n",
       " Lemma('heart.n.01.heart'),\n",
       " Lemma('intuition.n.02.hunch'),\n",
       " Lemma('impression.n.01.impression'),\n",
       " Lemma('intuition.n.02.intuition'),\n",
       " Lemma('impression.n.01.notion'),\n",
       " Lemma('impression.n.01.opinion'),\n",
       " Lemma('presence.n.04.presence'),\n",
       " Lemma('sound_effect.n.01.sound_effect'),\n",
       " Lemma('special_effect.n.01.special_effect'),\n",
       " Lemma('stage_effect.n.01.stage_effect'),\n",
       " Lemma('intuition.n.02.suspicion')}"
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lemmas_iter(wn.synset('belief.n.02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "edcd46f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('impression.n.01.impression'),\n",
       " Lemma('impression.n.01.feeling'),\n",
       " Lemma('impression.n.01.belief'),\n",
       " Lemma('impression.n.01.notion'),\n",
       " Lemma('impression.n.01.opinion')]"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('belief.n.02').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "6033054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belief.n.01       any cognitive content held as true\n",
      "impression.n.01   a vague idea in which some confidence is placed\n"
     ]
    }
   ],
   "source": [
    "get_defs(wn.synsets(\"belief\",\"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "0ab68056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('stage_effect.n.01'),\n",
       " Synset('presence.n.04'),\n",
       " Synset('special_effect.n.01'),\n",
       " Synset('sound_effect.n.01'),\n",
       " Synset('intuition.n.02'),\n",
       " Synset('first_blush.n.01'),\n",
       " Synset('effect.n.03'),\n",
       " Synset('heart.n.01')]"
      ]
     },
     "execution_count": 1101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belief_nouns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "a27b329e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abolitionism.n.01',\n",
       " 'absolutism.n.04',\n",
       " 'aditya.n.01',\n",
       " 'adonis.n.03',\n",
       " 'adventism.n.01',\n",
       " 'aesir.n.01',\n",
       " 'aesthetic.n.01',\n",
       " 'aether.n.01',\n",
       " 'aglaia.n.01',\n",
       " 'ahimsa.n.01',\n",
       " 'ahura.n.01',\n",
       " 'albigensianism.n.01',\n",
       " 'amateurism.n.01',\n",
       " 'amen.n.01',\n",
       " 'amoralism.n.01',\n",
       " 'anabaptism.n.01',\n",
       " 'andvari.n.01',\n",
       " 'angel.n.01',\n",
       " 'anglicanism.n.01',\n",
       " 'anglo-catholicism.n.01',\n",
       " 'anglo-saxon_deity.n.01',\n",
       " 'animalism.n.01',\n",
       " 'animism.n.01',\n",
       " 'anticipation.n.02',\n",
       " 'antiestablishmentarianism.n.01',\n",
       " 'antinomianism.n.01',\n",
       " 'anunnaki.n.01',\n",
       " 'apophatism.n.01',\n",
       " 'apparition.n.01',\n",
       " 'apprehension.n.03',\n",
       " 'archangel.n.01',\n",
       " 'arianism.n.01',\n",
       " 'aristotelianism.n.01',\n",
       " 'arminianism.n.01',\n",
       " 'article_of_faith.n.01',\n",
       " 'asceticism.n.01',\n",
       " 'asvins.n.01',\n",
       " 'athanasian_creed.n.01',\n",
       " 'athanasianism.n.01',\n",
       " 'autotelism.n.01',\n",
       " 'avatar.n.02',\n",
       " 'bad_fairy.n.01',\n",
       " 'bahaism.n.01',\n",
       " 'banshee.n.01',\n",
       " 'baptistic_doctrine.n.01',\n",
       " 'boehmenism.n.01',\n",
       " 'bogey.n.01',\n",
       " 'brahmanism.n.02',\n",
       " 'british_empiricism.n.01',\n",
       " 'buddhism.n.02',\n",
       " 'cacodemon.n.01',\n",
       " 'calvinism.n.01',\n",
       " 'calypso.n.02',\n",
       " 'cargo_cult.n.02',\n",
       " 'cataphatism.n.01',\n",
       " 'catholicism.n.01',\n",
       " 'celtic_deity.n.01',\n",
       " 'chabad.n.02',\n",
       " 'cherub.n.02',\n",
       " 'chinese_deity.n.01',\n",
       " 'christian_science.n.02',\n",
       " 'christianity.n.01',\n",
       " 'christology.n.01',\n",
       " 'comtism.n.01',\n",
       " 'conceptualism.n.01',\n",
       " 'confession.n.05',\n",
       " 'confucianism.n.01',\n",
       " 'congregationalism.n.01',\n",
       " 'conjuring.n.01',\n",
       " 'conservative_judaism.n.02',\n",
       " 'consubstantiation.n.01',\n",
       " 'contextualism.n.01',\n",
       " 'control.n.10',\n",
       " 'conviction.n.01',\n",
       " 'creation_science.n.01',\n",
       " 'creationism.n.01',\n",
       " 'creed.n.01',\n",
       " 'cult.n.04',\n",
       " 'cult.n.05',\n",
       " 'daemon.n.02',\n",
       " 'daphne.n.02',\n",
       " 'darsana.n.01',\n",
       " 'decision.n.02',\n",
       " 'deconstruction.n.01',\n",
       " 'deism.n.01',\n",
       " 'deity.n.01',\n",
       " 'demiurge.n.01',\n",
       " 'descriptivism.n.01',\n",
       " 'descriptivism.n.02',\n",
       " 'determinism.n.01',\n",
       " 'devil.n.02',\n",
       " 'dharma.n.01',\n",
       " 'diabolism.n.01',\n",
       " 'dialectical_materialism.n.01',\n",
       " 'divine_messenger.n.01',\n",
       " 'divine_right.n.01',\n",
       " 'docetism.n.01',\n",
       " 'doctrine.n.01',\n",
       " 'doctrine_of_analogy.n.01',\n",
       " 'dogma.n.01',\n",
       " 'dogma.n.02',\n",
       " 'donatism.n.01',\n",
       " 'druidism.n.01',\n",
       " 'dryad.n.01',\n",
       " 'dualism.n.01',\n",
       " 'dybbuk.n.01',\n",
       " 'dynamism.n.01',\n",
       " 'earth-god.n.01',\n",
       " 'earth-goddess.n.01',\n",
       " 'earth_mother.n.01',\n",
       " 'eastern_catholicism.n.01',\n",
       " 'eblis.n.01',\n",
       " 'ecclesiasticism.n.02',\n",
       " 'echo.n.02',\n",
       " 'ecumenism.n.02',\n",
       " 'egalitarianism.n.01',\n",
       " 'egoism.n.01',\n",
       " 'egyptian_deity.n.01',\n",
       " 'election.n.04',\n",
       " 'elf.n.01',\n",
       " 'empiricism.n.01',\n",
       " 'enchantment.n.03',\n",
       " 'environmentalism.n.01',\n",
       " 'eon.n.03',\n",
       " 'epicureanism.n.01',\n",
       " 'episcopalianism.n.01',\n",
       " 'erastianism.n.01',\n",
       " 'establishmentarianism.n.01',\n",
       " 'ethicism.n.01',\n",
       " 'eudemon.n.01',\n",
       " 'euphrosyne.n.01',\n",
       " 'evangelicalism.n.01',\n",
       " 'evil_spirit.n.01',\n",
       " 'evocation.n.02',\n",
       " 'existentialism.n.01',\n",
       " 'exorcism.n.01',\n",
       " 'expansionism.n.01',\n",
       " 'expectation.n.01',\n",
       " 'experimentalism.n.01',\n",
       " 'eyes.n.01',\n",
       " 'fairy.n.01',\n",
       " 'fairy_godmother.n.02',\n",
       " 'faith.n.02',\n",
       " 'familiar.n.03',\n",
       " 'fatalism.n.02',\n",
       " 'faun.n.01',\n",
       " 'feminism.n.01',\n",
       " 'fetishism.n.01',\n",
       " 'flying_dutchman.n.01',\n",
       " 'fomor.n.01',\n",
       " 'foretaste.n.01',\n",
       " 'formalism.n.01',\n",
       " 'formalism.n.02',\n",
       " 'functionalism.n.02',\n",
       " 'fundamentalism.n.01',\n",
       " 'gabriel.n.01',\n",
       " 'garuda.n.01',\n",
       " 'geneticism.n.01',\n",
       " 'genie.n.01',\n",
       " 'genius_loci.n.02',\n",
       " 'ghoul.n.02',\n",
       " 'girondism.n.01',\n",
       " 'gnome.n.01',\n",
       " 'gnosticism.n.01',\n",
       " 'goblin.n.01',\n",
       " 'goddess.n.01',\n",
       " 'golden_rule.n.02',\n",
       " 'gospel.n.05',\n",
       " 'grace.n.05',\n",
       " 'greco-roman_deity.n.01',\n",
       " 'greek_deity.n.01',\n",
       " 'guardian_spirit.n.01',\n",
       " 'gymnosophy.n.01',\n",
       " 'hamadryad.n.01',\n",
       " 'hasidism.n.02',\n",
       " 'hereditarianism.n.01',\n",
       " 'hesperides.n.01',\n",
       " 'hinayana.n.02',\n",
       " 'hinayanism.n.01',\n",
       " 'hindu_deity.n.01',\n",
       " 'hinduism.n.02',\n",
       " 'hoodoo.n.02',\n",
       " 'humanism.n.02',\n",
       " 'humanitarianism.n.01',\n",
       " 'hyades.n.01',\n",
       " 'idea.n.03',\n",
       " 'idealism.n.01',\n",
       " 'imitation.n.01',\n",
       " 'immaculate_conception.n.02',\n",
       " 'incarnation.n.02',\n",
       " 'incubus.n.01',\n",
       " 'individualism.n.02',\n",
       " 'individualism.n.03',\n",
       " 'instrumentalism.n.01',\n",
       " 'internationalism.n.01',\n",
       " 'intuitionism.n.01',\n",
       " 'irredentism.n.01',\n",
       " 'islam.n.02',\n",
       " 'ismailism.n.01',\n",
       " 'jainism.n.02',\n",
       " 'jansenism.n.01',\n",
       " 'japanese_deity.n.01',\n",
       " 'judaism.n.02',\n",
       " 'judgment.n.01',\n",
       " 'juju.n.01',\n",
       " 'kabbalism.n.01',\n",
       " 'kachina.n.02',\n",
       " 'kelpy.n.01',\n",
       " 'kingdom_of_god.n.01',\n",
       " 'krishnaism.n.01',\n",
       " 'lamaism.n.01',\n",
       " 'leprechaun.n.01',\n",
       " 'leto.n.01',\n",
       " 'life_expectancy.n.01',\n",
       " 'lilith.n.01',\n",
       " 'lir.n.01',\n",
       " 'literalism.n.01',\n",
       " 'llew_llaw_gyffes.n.01',\n",
       " 'logicism.n.01',\n",
       " 'lutheranism.n.01',\n",
       " 'macumba.n.03',\n",
       " 'magic.n.01',\n",
       " 'mahayana.n.02',\n",
       " 'mahayanism.n.01',\n",
       " 'mahdism.n.01',\n",
       " 'mainstream.n.01',\n",
       " 'majority_rule.n.01',\n",
       " 'mandaeanism.n.01',\n",
       " 'manichaeism.n.01',\n",
       " 'marcionism.n.01',\n",
       " 'marut.n.01',\n",
       " 'materialism.n.02',\n",
       " 'mechanism.n.04',\n",
       " 'meliorism.n.01',\n",
       " 'mennonitism.n.01',\n",
       " 'mentalism.n.01',\n",
       " 'methodism.n.01',\n",
       " 'michael.n.01',\n",
       " 'millenarianism.n.01',\n",
       " 'millennium.n.02',\n",
       " 'mimamsa.n.01',\n",
       " 'mimesis.n.01',\n",
       " 'mithraism.n.01',\n",
       " 'mitzvah.n.01',\n",
       " 'moirai.n.01',\n",
       " 'mojo.n.01',\n",
       " 'monism.n.01',\n",
       " 'monophysitism.n.01',\n",
       " 'monotheism.n.01',\n",
       " 'monothelitism.n.01',\n",
       " 'morgan_le_fay.n.01',\n",
       " 'mormonism.n.01',\n",
       " 'multiculturalism.n.01',\n",
       " 'muse.n.01',\n",
       " 'mysticism.n.01',\n",
       " 'naiad.n.02',\n",
       " 'nanna.n.02',\n",
       " 'nationalism.n.02',\n",
       " 'nationalism.n.04',\n",
       " 'nativism.n.02',\n",
       " 'naturalism.n.01',\n",
       " 'nature_worship.n.01',\n",
       " 'neoplatonism.n.01',\n",
       " 'nereid.n.01',\n",
       " 'nestorianism.n.01',\n",
       " 'nibelung.n.02',\n",
       " 'nicene_creed.n.01',\n",
       " 'nihilism.n.01',\n",
       " 'nominalism.n.01',\n",
       " 'norn.n.01',\n",
       " 'norse_deity.n.01',\n",
       " 'nuclear_deterrence.n.01',\n",
       " 'nullification.n.01',\n",
       " 'numen.n.01',\n",
       " 'nymph.n.01',\n",
       " 'obeah.n.02',\n",
       " 'oberson.n.01',\n",
       " 'obiism.n.01',\n",
       " 'occultism.n.02',\n",
       " 'oceanid.n.01',\n",
       " 'one-way_street.n.01',\n",
       " 'operationalism.n.01',\n",
       " 'opinion.n.01',\n",
       " 'oread.n.01',\n",
       " 'original_sin.n.01',\n",
       " 'originalism.n.01',\n",
       " 'orthodox_judaism.n.02',\n",
       " 'pacifism.n.01',\n",
       " 'pacifism.n.02',\n",
       " 'paganism.n.01',\n",
       " 'pantheism.n.01',\n",
       " 'pantheism.n.02',\n",
       " 'parcae.n.01',\n",
       " 'parsiism.n.01',\n",
       " 'patchwork.n.01',\n",
       " 'patron_saint.n.01',\n",
       " 'pelagianism.n.01',\n",
       " 'pentecostalism.n.01',\n",
       " 'peri.n.02',\n",
       " 'persian_deity.n.01',\n",
       " 'phenomenology.n.01',\n",
       " 'philosophical_doctrine.n.01',\n",
       " 'philosophy.n.03',\n",
       " 'phrygian_deity.n.01',\n",
       " 'platonism.n.01',\n",
       " 'pleiades.n.01',\n",
       " 'pluralism.n.02',\n",
       " 'pole.n.03',\n",
       " 'politics.n.04',\n",
       " 'polytheism.n.01',\n",
       " 'pontus.n.01',\n",
       " 'populism.n.01',\n",
       " 'positivism.n.01',\n",
       " 'possibility.n.01',\n",
       " 'pragmatism.n.01',\n",
       " 'preconception.n.01',\n",
       " 'predestinarianism.n.01',\n",
       " 'predestination.n.02',\n",
       " 'predetermination.n.02',\n",
       " 'presbyterianism.n.01',\n",
       " 'prescriptivism.n.01',\n",
       " 'prescriptivism.n.02',\n",
       " 'presence.n.03',\n",
       " 'presentism.n.01',\n",
       " 'probabilism.n.02',\n",
       " 'promise.n.02',\n",
       " 'protestantism.n.01',\n",
       " 'public_opinion.n.01',\n",
       " 'puck.n.01',\n",
       " 'puritanism.n.01',\n",
       " 'python.n.02',\n",
       " 'quakerism.n.01',\n",
       " 'quietism.n.01',\n",
       " 'rainbow.n.02',\n",
       " 'raphael.n.02',\n",
       " 'rastafarianism.n.01',\n",
       " 'rationalism.n.01',\n",
       " 'rationalism.n.02',\n",
       " 'rationalism.n.03',\n",
       " 'real_presence.n.01',\n",
       " 'realism.n.03',\n",
       " 'reform_judaism.n.02',\n",
       " 'reformism.n.01',\n",
       " 'reincarnation.n.03',\n",
       " 'reincarnationism.n.01',\n",
       " 'relativism.n.01',\n",
       " 'religion.n.01',\n",
       " 'religious_doctrine.n.01',\n",
       " 'revealed_religion.n.01',\n",
       " 'revivalism.n.01',\n",
       " 'revolutionism.n.01',\n",
       " 'rhadamanthus.n.01',\n",
       " 'ribhus.n.01',\n",
       " 'roman_deity.n.01',\n",
       " 'romanism.n.01',\n",
       " 'rosicrucianism.n.01',\n",
       " 'rugged_individualism.n.01',\n",
       " 'sacerdotalism.n.01',\n",
       " 'saint.n.01',\n",
       " 'salafism.n.01',\n",
       " 'salmacis.n.01',\n",
       " 'sandman.n.01',\n",
       " 'satyr.n.02',\n",
       " 'scholasticism.n.01',\n",
       " 'sea_god.n.01',\n",
       " 'sea_nymph.n.01',\n",
       " 'secessionism.n.01',\n",
       " 'secularism.n.01',\n",
       " 'semiotics.n.01',\n",
       " 'semitic_deity.n.01',\n",
       " 'sensualism.n.02',\n",
       " 'seraph.n.01',\n",
       " 'seventh-day_adventism.n.01',\n",
       " 'shaitan.n.01',\n",
       " 'shaktism.n.02',\n",
       " 'shamanism.n.01',\n",
       " 'shamanism.n.02',\n",
       " 'shiism.n.01',\n",
       " 'shingon.n.01',\n",
       " 'shinto.n.02',\n",
       " 'shivaism.n.02',\n",
       " 'sigyn.n.01',\n",
       " 'sikhism.n.01',\n",
       " 'silenus.n.01',\n",
       " 'siren.n.01',\n",
       " 'solipsism.n.01',\n",
       " 'soma.n.02',\n",
       " 'sorcery.n.01',\n",
       " 'spirit.n.04',\n",
       " 'spiritual_being.n.01',\n",
       " 'spiritual_world.n.01',\n",
       " 'spiritualism.n.01',\n",
       " 'spiritualism.n.02',\n",
       " \"states'_rights.n.01\",\n",
       " 'sterope.n.01',\n",
       " 'stoicism.n.02',\n",
       " 'subjectivism.n.01',\n",
       " 'succubus.n.01',\n",
       " 'suffragism.n.01',\n",
       " 'sufism.n.01',\n",
       " 'sun_god.n.01',\n",
       " 'supernaturalism.n.01',\n",
       " 'superstition.n.01',\n",
       " 'supremacism.n.01',\n",
       " 'sylvan.n.01',\n",
       " 'synergism.n.02',\n",
       " 'tantra.n.02',\n",
       " 'taoism.n.03',\n",
       " 'taoism.n.04',\n",
       " 'teaching.n.02',\n",
       " 'teleology.n.01',\n",
       " 'testament.n.01',\n",
       " 'teutonic_deity.n.01',\n",
       " 'thalia.n.02',\n",
       " 'theanthropism.n.01',\n",
       " 'theism.n.01',\n",
       " 'theological_doctrine.n.01',\n",
       " 'theory.n.03',\n",
       " 'theosophism.n.01',\n",
       " 'theravada.n.01',\n",
       " 'thetis.n.01',\n",
       " 'theurgy.n.02',\n",
       " 'thomism.n.01',\n",
       " 'thought.n.03',\n",
       " 'thunderbird.n.01',\n",
       " 'titania.n.02',\n",
       " 'tooth_fairy.n.01',\n",
       " 'total_depravity.n.01',\n",
       " 'totemism.n.01',\n",
       " 'tractarianism.n.01',\n",
       " 'traditionalism.n.03',\n",
       " 'transubstantiation.n.01',\n",
       " 'tribalism.n.02',\n",
       " 'trickster.n.03',\n",
       " 'trinitarianism.n.01',\n",
       " 'tritheism.n.01',\n",
       " 'tuatha_de_danann.n.01',\n",
       " 'ull.n.01',\n",
       " 'undine.n.01',\n",
       " 'unilateralism.n.01',\n",
       " 'unitarianism.n.01',\n",
       " 'universalism.n.01',\n",
       " 'utilitarianism.n.01',\n",
       " 'vaishnavism.n.02',\n",
       " 'vajra.n.01',\n",
       " 'vali.n.01',\n",
       " 'values.n.01',\n",
       " 'vampire.n.01',\n",
       " 'vampirism.n.01',\n",
       " 'vanir.n.01',\n",
       " 'vedanta.n.01',\n",
       " 'vedism.n.01',\n",
       " 'virgin_birth.n.02',\n",
       " 'vitalism.n.01',\n",
       " 'vitharr.n.01',\n",
       " 'voodoo.n.03',\n",
       " 'wahhabism.n.01',\n",
       " 'war_god.n.01',\n",
       " 'water_nymph.n.03',\n",
       " 'water_sprite.n.02',\n",
       " 'wesleyanism.n.01',\n",
       " 'white_magic.n.01',\n",
       " 'wicca.n.02',\n",
       " 'witchcraft.n.01',\n",
       " 'wyrd.n.01',\n",
       " 'yoga.n.01',\n",
       " 'yogacara.n.01',\n",
       " 'zen.n.02',\n",
       " 'zombi.n.01',\n",
       " 'zombi.n.02',\n",
       " 'zoroastrianism.n.01',\n",
       " 'zurvanism.n.02']"
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belief_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a2a09ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('abashment.n.01'),\n",
       " Synset('abhorrence.n.01'),\n",
       " Synset('acquired_taste.n.01'),\n",
       " Synset('addiction.n.02'),\n",
       " Synset('admiration.n.01'),\n",
       " Synset('affect.n.01'),\n",
       " Synset('affection.n.01'),\n",
       " Synset('afterglow.n.02'),\n",
       " Synset('agape.n.01'),\n",
       " Synset('agape.n.02'),\n",
       " Synset('aggravation.n.01'),\n",
       " Synset('aggression.n.02'),\n",
       " Synset('agitation.n.03'),\n",
       " Synset('agony.n.01'),\n",
       " Synset('alarm.n.01'),\n",
       " Synset('algolagnia.n.01'),\n",
       " Synset('alienation.n.01'),\n",
       " Synset('ambition.n.01'),\n",
       " Synset('ambivalence.n.01'),\n",
       " Synset('american_dream.n.01'),\n",
       " Synset('amicability.n.01'),\n",
       " Synset('amorousness.n.01'),\n",
       " Synset('amorousness.n.02'),\n",
       " Synset('amour_propre.n.01'),\n",
       " Synset('amusement.n.01'),\n",
       " Synset('anaphrodisia.n.01'),\n",
       " Synset('anger.n.01'),\n",
       " Synset('anglophilia.n.01'),\n",
       " Synset('anglophobia.n.01'),\n",
       " Synset('angst.n.01'),\n",
       " Synset('anguish.n.01'),\n",
       " Synset('animosity.n.01'),\n",
       " Synset('annoyance.n.02'),\n",
       " Synset('antagonism.n.03'),\n",
       " Synset('anticipation.n.01'),\n",
       " Synset('antipathy.n.01'),\n",
       " Synset('anxiety.n.02'),\n",
       " Synset('anxiousness.n.02'),\n",
       " Synset('apathy.n.01'),\n",
       " Synset('aphrodisia.n.01'),\n",
       " Synset('appetite.n.01'),\n",
       " Synset('apprehension.n.01'),\n",
       " Synset('approbation.n.01'),\n",
       " Synset('approval.n.02'),\n",
       " Synset('ardor.n.01'),\n",
       " Synset('ardor.n.02'),\n",
       " Synset('ardor.n.03'),\n",
       " Synset('astonishment.n.01'),\n",
       " Synset('attachment.n.01'),\n",
       " Synset('attrition.n.03'),\n",
       " Synset('awe.n.01'),\n",
       " Synset('bad_temper.n.01'),\n",
       " Synset('bang.n.04'),\n",
       " Synset('belligerence.n.01'),\n",
       " Synset('belonging.n.01'),\n",
       " Synset('beneficence.n.01'),\n",
       " Synset('benevolence.n.01'),\n",
       " Synset('blahs.n.01'),\n",
       " Synset('blessedness.n.01'),\n",
       " Synset('bloodlust.n.01'),\n",
       " Synset('bonheur.n.01'),\n",
       " Synset('boredom.n.01'),\n",
       " Synset('broken_heart.n.01'),\n",
       " Synset('brotherhood.n.03'),\n",
       " Synset('buck_fever.n.01'),\n",
       " Synset('buoyancy.n.01'),\n",
       " Synset('calmness.n.03'),\n",
       " Synset('caprice.n.01'),\n",
       " Synset('captivation.n.02'),\n",
       " Synset('carefreeness.n.01'),\n",
       " Synset('chagrin.n.01'),\n",
       " Synset('cheerfulness.n.02'),\n",
       " Synset('cheerlessness.n.01'),\n",
       " Synset('chill.n.04'),\n",
       " Synset('civic_pride.n.01'),\n",
       " Synset('class_feeling.n.01'),\n",
       " Synset('closeness.n.01'),\n",
       " Synset('cold_comfort.n.01'),\n",
       " Synset('cold_feet.n.01'),\n",
       " Synset('comfort.n.02'),\n",
       " Synset('comfort.n.05'),\n",
       " Synset('comfortableness.n.02'),\n",
       " Synset('commiseration.n.01'),\n",
       " Synset('compassion.n.01'),\n",
       " Synset('compatibility.n.01'),\n",
       " Synset('complacency.n.01'),\n",
       " Synset('complex.n.03'),\n",
       " Synset('compunction.n.01'),\n",
       " Synset('concern.n.02'),\n",
       " Synset('concern.n.03'),\n",
       " Synset('conditioned_emotional_response.n.01'),\n",
       " Synset('confidence.n.02'),\n",
       " Synset('conflict.n.02'),\n",
       " Synset('confusion.n.03'),\n",
       " Synset('conscience.n.03'),\n",
       " Synset('consolation.n.01'),\n",
       " Synset('contempt.n.01'),\n",
       " Synset('contentment.n.01'),\n",
       " Synset('coolness.n.01'),\n",
       " Synset('covetousness.n.01'),\n",
       " Synset('craving.n.01'),\n",
       " Synset('creeps.n.02'),\n",
       " Synset('creepy-crawlies.n.01'),\n",
       " Synset('cruelty.n.02'),\n",
       " Synset('cynicism.n.01'),\n",
       " Synset('dander.n.02'),\n",
       " Synset('daze.n.01'),\n",
       " Synset('defeatism.n.01'),\n",
       " Synset('delight.n.01'),\n",
       " Synset('demoralization.n.03'),\n",
       " Synset('depression.n.04'),\n",
       " Synset('desire.n.01'),\n",
       " Synset('despair.n.02'),\n",
       " Synset('despisal.n.01'),\n",
       " Synset('despondency.n.01'),\n",
       " Synset('devastation.n.02'),\n",
       " Synset('devotion.n.01'),\n",
       " Synset('diffidence.n.01'),\n",
       " Synset('dignity.n.01'),\n",
       " Synset('disappointment.n.01'),\n",
       " Synset('disapproval.n.01'),\n",
       " Synset('discomfiture.n.01'),\n",
       " Synset('discomfort.n.02'),\n",
       " Synset('discontentment.n.01'),\n",
       " Synset('discouragement.n.01'),\n",
       " Synset('disgruntlement.n.01'),\n",
       " Synset('disgust.n.01'),\n",
       " Synset('disinclination.n.01'),\n",
       " Synset('dislike.n.02'),\n",
       " Synset('displeasure.n.01'),\n",
       " Synset('dissatisfaction.n.01'),\n",
       " Synset('distance.n.04'),\n",
       " Synset('distress.n.01'),\n",
       " Synset('dolefulness.n.01'),\n",
       " Synset('dolor.n.01'),\n",
       " Synset('downheartedness.n.01'),\n",
       " Synset('dudgeon.n.01'),\n",
       " Synset('dysphoria.n.01'),\n",
       " Synset('eagerness.n.01'),\n",
       " Synset('earnestness.n.01'),\n",
       " Synset('easiness.n.01'),\n",
       " Synset('ecstasy.n.01'),\n",
       " Synset('edginess.n.01'),\n",
       " Synset('ego.n.01'),\n",
       " Synset('elation.n.02'),\n",
       " Synset('electra_complex.n.01'),\n",
       " Synset('electricity.n.03'),\n",
       " Synset('embarrassment.n.01'),\n",
       " Synset('embarrassment.n.02'),\n",
       " Synset('embitterment.n.01'),\n",
       " Synset('emotion.n.01'),\n",
       " Synset('emotional_state.n.01'),\n",
       " Synset('emotionlessness.n.01'),\n",
       " Synset('empathy.n.01'),\n",
       " Synset('emulation.n.01'),\n",
       " Synset('encouragement.n.03'),\n",
       " Synset('enjoyment.n.01'),\n",
       " Synset('enthusiasm.n.01'),\n",
       " Synset('entrancement.n.01'),\n",
       " Synset('envy.n.01'),\n",
       " Synset('euphoria.n.01'),\n",
       " Synset('exhilaration.n.01'),\n",
       " Synset('expectation.n.03'),\n",
       " Synset('exuberance.n.01'),\n",
       " Synset('exultation.n.01'),\n",
       " Synset('faintness.n.01'),\n",
       " Synset('fatigue.n.03'),\n",
       " Synset('favor.n.04'),\n",
       " Synset('fear.n.01'),\n",
       " Synset('fear.n.03'),\n",
       " Synset('fearlessness.n.01'),\n",
       " Synset('feelings.n.01'),\n",
       " Synset('fetish.n.01'),\n",
       " Synset('fever.n.02'),\n",
       " Synset('fidget.n.01'),\n",
       " Synset('filial_love.n.01'),\n",
       " Synset('fit.n.01'),\n",
       " Synset('fondness.n.01'),\n",
       " Synset('foreboding.n.01'),\n",
       " Synset('forgiveness.n.01'),\n",
       " Synset('forlornness.n.01'),\n",
       " Synset('friendliness.n.01'),\n",
       " Synset('frisson.n.01'),\n",
       " Synset('frustration.n.01'),\n",
       " Synset('frustration.n.03'),\n",
       " Synset('fulfillment.n.01'),\n",
       " Synset('fury.n.01'),\n",
       " Synset('gaiety.n.01'),\n",
       " Synset('gaiety.n.02'),\n",
       " Synset('gladness.n.01'),\n",
       " Synset('gloat.n.01'),\n",
       " Synset('gloom.n.02'),\n",
       " Synset('glow.n.04'),\n",
       " Synset('gold_fever.n.01'),\n",
       " Synset('good_humor.n.01'),\n",
       " Synset('good_will.n.03'),\n",
       " Synset('gratefulness.n.01'),\n",
       " Synset('gratification.n.01'),\n",
       " Synset('gratitude.n.01'),\n",
       " Synset('gravity.n.03'),\n",
       " Synset('grief.n.01'),\n",
       " Synset('growing_pains.n.02'),\n",
       " Synset('grudge.n.01'),\n",
       " Synset('guilt.n.02'),\n",
       " Synset('guilt_pang.n.01'),\n",
       " Synset('gusto.n.01'),\n",
       " Synset('hankering.n.01'),\n",
       " Synset('happiness.n.01'),\n",
       " Synset('happiness.n.02'),\n",
       " Synset('harassment.n.01'),\n",
       " Synset('hate.n.01'),\n",
       " Synset('heartburning.n.01'),\n",
       " Synset('heartlessness.n.01'),\n",
       " Synset('heartstrings.n.01'),\n",
       " Synset('heaviness.n.02'),\n",
       " Synset('heavyheartedness.n.01'),\n",
       " Synset('helplessness.n.03'),\n",
       " Synset('hero_worship.n.01'),\n",
       " Synset('hesitance.n.01'),\n",
       " Synset('hilarity.n.01'),\n",
       " Synset('homesickness.n.01'),\n",
       " Synset('hope.n.01'),\n",
       " Synset('hope.n.02'),\n",
       " Synset('hopefulness.n.02'),\n",
       " Synset('hopelessness.n.01'),\n",
       " Synset('horror.n.01'),\n",
       " Synset('hostility.n.03'),\n",
       " Synset('huffiness.n.01'),\n",
       " Synset('humility.n.02'),\n",
       " Synset('hysteria.n.02'),\n",
       " Synset('ill_humor.n.01'),\n",
       " Synset('impatience.n.02'),\n",
       " Synset('inclination.n.05'),\n",
       " Synset('indifference.n.01'),\n",
       " Synset('indignation.n.01'),\n",
       " Synset('infatuation.n.01'),\n",
       " Synset('inferiority_complex.n.01'),\n",
       " Synset('infuriation.n.01'),\n",
       " Synset('ingratitude.n.01'),\n",
       " Synset('insecurity.n.02'),\n",
       " Synset('insight.n.02'),\n",
       " Synset('intimidation.n.02'),\n",
       " Synset('intimidation.n.03'),\n",
       " Synset('intoxication.n.03'),\n",
       " Synset('irascibility.n.01'),\n",
       " Synset('irritability.n.01'),\n",
       " Synset('isolation.n.02'),\n",
       " Synset('jealousy.n.01'),\n",
       " Synset('jitteriness.n.01'),\n",
       " Synset('jocundity.n.01'),\n",
       " Synset('joie_de_vivre.n.01'),\n",
       " Synset('jollity.n.01'),\n",
       " Synset('joy.n.01'),\n",
       " Synset('joylessness.n.01'),\n",
       " Synset('kindheartedness.n.01'),\n",
       " Synset('languor.n.01'),\n",
       " Synset('languor.n.02'),\n",
       " Synset('leaning.n.01'),\n",
       " Synset('lecherousness.n.01'),\n",
       " Synset('levity.n.01'),\n",
       " Synset('libido.n.01'),\n",
       " Synset('liking.n.01'),\n",
       " Synset('lividity.n.01'),\n",
       " Synset('longing.n.01'),\n",
       " Synset('love.n.01'),\n",
       " Synset('love.n.04'),\n",
       " Synset('lovesickness.n.01'),\n",
       " Synset('lovingness.n.01'),\n",
       " Synset('loyalty.n.02'),\n",
       " Synset('maleficence.n.01'),\n",
       " Synset('malevolence.n.01'),\n",
       " Synset('malice.n.01'),\n",
       " Synset('masochism.n.01'),\n",
       " Synset('mawkishness.n.01'),\n",
       " Synset('meekness.n.01'),\n",
       " Synset('melancholy.n.01'),\n",
       " Synset('mellowness.n.01'),\n",
       " Synset('mental_anguish.n.01'),\n",
       " Synset('mercifulness.n.01'),\n",
       " Synset('misanthropy.n.01'),\n",
       " Synset('misery.n.02'),\n",
       " Synset('misocainea.n.01'),\n",
       " Synset('misogamy.n.01'),\n",
       " Synset('misogyny.n.01'),\n",
       " Synset('misology.n.01'),\n",
       " Synset('misoneism.n.01'),\n",
       " Synset('misopedia.n.01'),\n",
       " Synset('moodiness.n.01'),\n",
       " Synset('moroseness.n.01'),\n",
       " Synset('mournfulness.n.01'),\n",
       " Synset('mourning.n.01'),\n",
       " Synset('murderousness.n.01'),\n",
       " Synset('mysophilia.n.01'),\n",
       " Synset('nationalism.n.03'),\n",
       " Synset('nausea.n.02'),\n",
       " Synset('nirvana.n.01'),\n",
       " Synset('nostalgia.n.01'),\n",
       " Synset('nymphomania.n.01'),\n",
       " Synset('oedipus_complex.n.01'),\n",
       " Synset('oppression.n.03'),\n",
       " Synset('optimism.n.01'),\n",
       " Synset('oversensitiveness.n.01'),\n",
       " Synset('pain.n.02'),\n",
       " Synset('pang.n.01'),\n",
       " Synset('panic.n.01'),\n",
       " Synset('passion.n.01'),\n",
       " Synset('passion.n.05'),\n",
       " Synset('peace.n.03'),\n",
       " Synset('peeve.n.01'),\n",
       " Synset('penis_envy.n.01'),\n",
       " Synset('pensiveness.n.01'),\n",
       " Synset('pessimism.n.01'),\n",
       " Synset('pet.n.03'),\n",
       " Synset('philhellenism.n.01'),\n",
       " Synset('philogyny.n.01'),\n",
       " Synset('pining.n.01'),\n",
       " Synset('pique.n.02'),\n",
       " Synset('placidity.n.01'),\n",
       " Synset('plaintiveness.n.01'),\n",
       " Synset('pleasantness.n.01'),\n",
       " Synset('pleasure.n.01'),\n",
       " Synset('poignance.n.01'),\n",
       " Synset('preference.n.01'),\n",
       " Synset('presage.n.01'),\n",
       " Synset('pride.n.01'),\n",
       " Synset('pride.n.02'),\n",
       " Synset('protectiveness.n.01'),\n",
       " Synset('prurience.n.01'),\n",
       " Synset('puppy_love.n.01'),\n",
       " Synset('quality_of_life.n.01'),\n",
       " Synset('radiance.n.03'),\n",
       " Synset('razbliuto.n.01'),\n",
       " Synset('regard.n.06'),\n",
       " Synset('rejoicing.n.01'),\n",
       " Synset('relief.n.01'),\n",
       " Synset('repentance.n.01'),\n",
       " Synset('repugnance.n.01'),\n",
       " Synset('resentment.n.01'),\n",
       " Synset('resignation.n.01'),\n",
       " Synset('sadism.n.01'),\n",
       " Synset('sadness.n.01'),\n",
       " Synset('sadness.n.02'),\n",
       " Synset('sadomasochism.n.01'),\n",
       " Synset('sanguinity.n.01'),\n",
       " Synset('satisfaction.n.01'),\n",
       " Synset('satyriasis.n.01'),\n",
       " Synset('scare.n.02'),\n",
       " Synset('schadenfreude.n.01'),\n",
       " Synset('scruple.n.02'),\n",
       " Synset('scunner.n.01'),\n",
       " Synset('security.n.03'),\n",
       " Synset('self-consciousness.n.01'),\n",
       " Synset('self-depreciation.n.01'),\n",
       " Synset('self-disgust.n.01'),\n",
       " Synset('self-esteem.n.01'),\n",
       " Synset('self-pity.n.01'),\n",
       " Synset('self-torture.n.01'),\n",
       " Synset('sensation.n.03'),\n",
       " Synset('sensibility.n.02'),\n",
       " Synset('sensitivity.n.03'),\n",
       " Synset('sensuality.n.01'),\n",
       " Synset('sensuousness.n.01'),\n",
       " Synset('sentiment.n.01'),\n",
       " Synset('sentimentality.n.02'),\n",
       " Synset('sex.n.03'),\n",
       " Synset('sexual_desire.n.01'),\n",
       " Synset('sexual_pleasure.n.01'),\n",
       " Synset('shadow.n.04'),\n",
       " Synset('shame.n.01'),\n",
       " Synset('shamefacedness.n.01'),\n",
       " Synset('shyness.n.01'),\n",
       " Synset('silver_lining.n.01'),\n",
       " Synset('sinking.n.03'),\n",
       " Synset('smugness.n.01'),\n",
       " Synset('soft_spot.n.02'),\n",
       " Synset('softheartedness.n.01'),\n",
       " Synset('solicitude.n.01'),\n",
       " Synset('sorrow.n.01'),\n",
       " Synset('sorrow.n.02'),\n",
       " Synset('soul.n.03'),\n",
       " Synset('stage_fright.n.01'),\n",
       " Synset('state.n.06'),\n",
       " Synset('stewing.n.01'),\n",
       " Synset('stir.n.02'),\n",
       " Synset('stomach.n.03'),\n",
       " Synset('stomach.n.04'),\n",
       " Synset('storminess.n.02'),\n",
       " Synset('stupefaction.n.01'),\n",
       " Synset('suffering.n.04'),\n",
       " Synset('sulk.n.01'),\n",
       " Synset('sulkiness.n.02'),\n",
       " Synset('surprise.n.01'),\n",
       " Synset('survivor_guilt.n.01'),\n",
       " Synset('suspense.n.01'),\n",
       " Synset('suspense.n.03'),\n",
       " Synset('sweet_tooth.n.01'),\n",
       " Synset('swivet.n.01'),\n",
       " Synset('sympathy.n.02'),\n",
       " Synset('technophilia.n.01'),\n",
       " Synset('technophobia.n.01'),\n",
       " Synset('temper.n.02'),\n",
       " Synset('temptation.n.02'),\n",
       " Synset('tenderness.n.03'),\n",
       " Synset('testiness.n.01'),\n",
       " Synset('the_hots.n.01'),\n",
       " Synset('thing.n.11'),\n",
       " Synset('throes.n.01'),\n",
       " Synset('timidity.n.01'),\n",
       " Synset('titillation.n.01'),\n",
       " Synset('togetherness.n.01'),\n",
       " Synset('tranquillity.n.02'),\n",
       " Synset('trepidation.n.01'),\n",
       " Synset('triumph.n.02'),\n",
       " Synset('tsoris.n.01'),\n",
       " Synset('tumult.n.02'),\n",
       " Synset('umbrage.n.01'),\n",
       " Synset('unassertiveness.n.01'),\n",
       " Synset('unconcern.n.02'),\n",
       " Synset('undertow.n.01'),\n",
       " Synset('unfriendliness.n.01'),\n",
       " Synset('unhappiness.n.02'),\n",
       " Synset('unpleasantness.n.01'),\n",
       " Synset('unrest.n.02'),\n",
       " Synset('urge.n.02'),\n",
       " Synset('velleity.n.01'),\n",
       " Synset('vindictiveness.n.01'),\n",
       " Synset('warmheartedness.n.01'),\n",
       " Synset('warpath.n.01'),\n",
       " Synset('weakness.n.05'),\n",
       " Synset('weepiness.n.01'),\n",
       " Synset('weight.n.05'),\n",
       " Synset('wildness.n.01'),\n",
       " Synset('willies.n.01'),\n",
       " Synset('wish.n.01'),\n",
       " Synset('wishfulness.n.01'),\n",
       " Synset('wistfulness.n.01'),\n",
       " Synset('withdrawal.n.04'),\n",
       " Synset('woe.n.02'),\n",
       " Synset('wonder.n.01'),\n",
       " Synset('world-weariness.n.01'),\n",
       " Synset('worry.n.02'),\n",
       " Synset('worship.n.02'),\n",
       " Synset('wound.n.03'),\n",
       " Synset('wrath.n.01'),\n",
       " Synset('zeal.n.02')}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feeling_nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc46283",
   "metadata": {},
   "source": [
    "## searching for intensity pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b95c3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_hypers (ss_set):\n",
    "    return {hn for ss in ss_set for hn in ss.hypernyms()}\n",
    "\n",
    "def get_hypers_iter (root):\n",
    "    global accumulated\n",
    "    hl0 = root.hypernyms()\n",
    "    accumulated = set(hl0)\n",
    "    current = hl0\n",
    "    while current:\n",
    "        current = get_hypers(current)\n",
    "        accumulated.update(current)\n",
    "    return accumulated\n",
    "\n",
    "def ss_set_to_word_set (ss_set):\n",
    "    return sorted(list(set([nm for ss in ss_set for nm in ss.lemma_names()])))\n",
    "\n",
    "def expand_intensity_pairs (ips):\n",
    "    \"\"\"\n",
    "    ips is a dict of teh form ss => ss_list\n",
    "    find all the words related to ss_w and all the words ss_rel_w related the ss_list members\n",
    "    construnct a word to word_liust dict\n",
    "    \"\"\"\n",
    "    new_dict = defaultdict(list)\n",
    "    for ss,ss_list in ips.items():\n",
    "        for ss_w in ss.lemma_names():\n",
    "            for ss_rel_w in ss_set_to_word_set (ss_list):\n",
    "                new_dict[ss_w].append(ss_rel_w)\n",
    "    return new_dict\n",
    "\n",
    "def output_intensity_word_dict_to_file(intensity_word_dict,fn):\n",
    "    keywords = sorted(list(intensity_word_dict.keys()))\n",
    "    with open(fn,\"w\") as ofh:\n",
    "        for k in keywords:\n",
    "            word_list = \" \".join(sorted(intensity_word_dict[k]))\n",
    "            print(f\"{k:<30}\\t{word_list}\",file=ofh)\n",
    "            \n",
    "def output_intensity_pairs_to_file(intensity_pairs,fn):\n",
    "    keywords = sorted(list(intensity_pairs.keys()))\n",
    "    get_name = lambda x:getattr(x,\"name\")()\n",
    "    with open(fn,\"w\") as ofh:\n",
    "        for k in keywords:\n",
    "            word_list = \" \".join(sorted(map(get_name,intensity_pairs[k])))\n",
    "            print(f\"{k.name():<30}\\t{word_list}\",file=ofh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e3a24026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'ardor': ['passion',\n",
       "              'passionateness',\n",
       "              'avidity',\n",
       "              'avidness',\n",
       "              'eagerness',\n",
       "              'keenness',\n",
       "              'love'],\n",
       "             'ardour': ['passion',\n",
       "              'passionateness',\n",
       "              'avidity',\n",
       "              'avidness',\n",
       "              'eagerness',\n",
       "              'keenness',\n",
       "              'love'],\n",
       "             'fervor': ['passion', 'passionateness'],\n",
       "             'fervour': ['passion', 'passionateness'],\n",
       "             'fervency': ['passion', 'passionateness'],\n",
       "             'fire': ['passion', 'passionateness'],\n",
       "             'fervidness': ['passion', 'passionateness'],\n",
       "             'worry': ['anxiety'],\n",
       "             'trouble': ['anxiety'],\n",
       "             'shamefacedness': ['embarrassment'],\n",
       "             'sheepishness': ['embarrassment'],\n",
       "             'heaviness': ['sadness', 'unhappiness'],\n",
       "             'gaiety': ['happiness', 'levity'],\n",
       "             'merriment': ['happiness'],\n",
       "             'benevolence': ['love'],\n",
       "             'scunner': ['dislike'],\n",
       "             'stewing': ['agitation'],\n",
       "             'suffering': ['pain', 'painfulness', 'pain', 'painfulness'],\n",
       "             'hurt': ['pain', 'painfulness', 'pain', 'painfulness'],\n",
       "             'plaintiveness': ['mournfulness', 'ruthfulness', 'sorrowfulness'],\n",
       "             'tumult': ['agitation'],\n",
       "             'turmoil': ['agitation'],\n",
       "             'fit': ['bad_temper', 'ill_temper'],\n",
       "             'tantrum': ['bad_temper', 'ill_temper'],\n",
       "             'scene': ['bad_temper', 'ill_temper'],\n",
       "             'conniption': ['bad_temper', 'ill_temper'],\n",
       "             'comfort': ['gratification',\n",
       "              'satisfaction',\n",
       "              'pleasance',\n",
       "              'pleasure'],\n",
       "             'anger': ['emotion'],\n",
       "             'choler': ['emotion', 'distemper', 'ill_humor', 'ill_humour'],\n",
       "             'ire': ['emotion'],\n",
       "             'stir': ['agitation'],\n",
       "             'pique': ['annoyance', 'chafe', 'vexation'],\n",
       "             'temper': ['annoyance', 'chafe', 'vexation'],\n",
       "             'irritation': ['annoyance',\n",
       "              'chafe',\n",
       "              'vexation',\n",
       "              'hurt',\n",
       "              'suffering'],\n",
       "             'defeatism': ['resignation', 'surrender'],\n",
       "             'edginess': ['anxiety'],\n",
       "             'uneasiness': ['anxiety', 'embarrassment'],\n",
       "             'inquietude': ['anxiety'],\n",
       "             'disquietude': ['anxiety'],\n",
       "             'animosity': ['enmity', 'hostility', 'ill_will'],\n",
       "             'animus': ['enmity', 'hostility', 'ill_will'],\n",
       "             'bad_blood': ['enmity', 'hostility', 'ill_will'],\n",
       "             'good_will': ['friendliness'],\n",
       "             'goodwill': ['friendliness'],\n",
       "             'agape': ['love', 'love'],\n",
       "             'gloom': ['apprehension',\n",
       "              'apprehensiveness',\n",
       "              'dread',\n",
       "              'melancholy'],\n",
       "             'gloominess': ['apprehension',\n",
       "              'apprehensiveness',\n",
       "              'dread',\n",
       "              'melancholy'],\n",
       "             'somberness': ['apprehension',\n",
       "              'apprehensiveness',\n",
       "              'dread',\n",
       "              'melancholy'],\n",
       "             'sombreness': ['apprehension',\n",
       "              'apprehensiveness',\n",
       "              'dread',\n",
       "              'melancholy'],\n",
       "             'fever': ['anticipation', 'expectancy'],\n",
       "             'belligerence': ['enmity', 'hostility', 'ill_will'],\n",
       "             'belligerency': ['enmity', 'hostility', 'ill_will'],\n",
       "             'tenderness': ['compassion', 'compassionateness', 'concern'],\n",
       "             'tenderheartedness': ['compassion', 'compassionateness'],\n",
       "             'kindheartedness': ['fellow_feeling', 'sympathy'],\n",
       "             'kind-heartedness': ['fellow_feeling', 'sympathy'],\n",
       "             'cheerlessness': ['sadness', 'unhappiness'],\n",
       "             'uncheerfulness': ['sadness', 'unhappiness'],\n",
       "             'dysphoria': ['depression',\n",
       "              'discontent',\n",
       "              'discontentedness',\n",
       "              'discontentment'],\n",
       "             'sexual_pleasure': ['pleasance', 'pleasure'],\n",
       "             'protectiveness': ['affection',\n",
       "              'affectionateness',\n",
       "              'fondness',\n",
       "              'heart',\n",
       "              'philia',\n",
       "              'tenderness',\n",
       "              'warmheartedness',\n",
       "              'warmness'],\n",
       "             'frustration': ['disappointment',\n",
       "              'letdown',\n",
       "              'annoyance',\n",
       "              'chafe',\n",
       "              'vexation'],\n",
       "             'defeat': ['disappointment', 'letdown'],\n",
       "             'stage_fright': ['fear', 'fearfulness', 'fright'],\n",
       "             'appetite': ['craving'],\n",
       "             'appetency': ['craving'],\n",
       "             'appetence': ['craving'],\n",
       "             'comfortableness': ['belonging'],\n",
       "             'annoyance': ['anger', 'choler', 'ire'],\n",
       "             'chafe': ['anger', 'choler', 'ire'],\n",
       "             'vexation': ['anger', 'choler', 'ire'],\n",
       "             'unhappiness': ['emotional_state', 'spirit'],\n",
       "             'earnestness': ['gravity', 'solemnity'],\n",
       "             'seriousness': ['gravity', 'solemnity'],\n",
       "             'sincerity': ['gravity', 'solemnity'],\n",
       "             'relief': ['comfort'],\n",
       "             'alleviation': ['comfort'],\n",
       "             'assuagement': ['comfort'],\n",
       "             'cruelty': ['coldheartedness',\n",
       "              'hardheartedness',\n",
       "              'heartlessness'],\n",
       "             'mercilessness': ['coldheartedness',\n",
       "              'hardheartedness',\n",
       "              'heartlessness'],\n",
       "             'pitilessness': ['coldheartedness',\n",
       "              'hardheartedness',\n",
       "              'heartlessness'],\n",
       "             'ruthlessness': ['coldheartedness',\n",
       "              'hardheartedness',\n",
       "              'heartlessness'],\n",
       "             'longing': ['desire'],\n",
       "             'yearning': ['desire'],\n",
       "             'hungriness': ['desire'],\n",
       "             'wonder': ['amazement', 'astonishment'],\n",
       "             'wonderment': ['amazement', 'astonishment'],\n",
       "             'admiration': ['amazement', 'astonishment', 'liking'],\n",
       "             'misogyny': ['hate', 'hatred'],\n",
       "             'misogynism': ['hate', 'hatred'],\n",
       "             'stupefaction': ['amazement', 'astonishment'],\n",
       "             'algolagnia': ['sexual_pleasure'],\n",
       "             'algophilia': ['sexual_pleasure'],\n",
       "             'anxiety': ['emotion'],\n",
       "             'fear': ['emotion', 'emotion', 'anxiety'],\n",
       "             'reverence': ['emotion'],\n",
       "             'awe': ['emotion', 'admiration', 'wonder', 'wonderment'],\n",
       "             'veneration': ['emotion'],\n",
       "             'dissatisfaction': ['discontent',\n",
       "              'discontentedness',\n",
       "              'discontentment'],\n",
       "             'unpleasantness': ['pain', 'painfulness'],\n",
       "             'belonging': ['happiness'],\n",
       "             'euphoria': ['elation', 'high_spirits', 'lightness'],\n",
       "             'euphory': ['elation', 'high_spirits', 'lightness'],\n",
       "             'guilt_pang': ['pang', 'stab', 'twinge'],\n",
       "             'dolor': ['brokenheartedness',\n",
       "              'grief',\n",
       "              'heartache',\n",
       "              'heartbreak'],\n",
       "             'dolour': ['brokenheartedness',\n",
       "              'grief',\n",
       "              'heartache',\n",
       "              'heartbreak'],\n",
       "             'shadow': ['boding', 'foreboding', 'premonition', 'presentiment'],\n",
       "             'sulk': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'sulkiness': ['humor',\n",
       "              'humour',\n",
       "              'mood',\n",
       "              'temper',\n",
       "              'bitterness',\n",
       "              'gall',\n",
       "              'rancor',\n",
       "              'rancour',\n",
       "              'resentment'],\n",
       "             'solicitude': ['concern'],\n",
       "             'solicitousness': ['concern'],\n",
       "             'hysteria': ['fear', 'fearfulness', 'fright'],\n",
       "             'penis_envy': ['enviousness', 'envy'],\n",
       "             'civic_pride': ['pride'],\n",
       "             'civic_spirit': ['pride'],\n",
       "             'urge': ['desire'],\n",
       "             'itch': ['desire'],\n",
       "             'optimism': ['hope'],\n",
       "             'intoxication': ['excitement', 'exhilaration'],\n",
       "             'security': ['bravery', 'fearlessness'],\n",
       "             'despondency': ['depression'],\n",
       "             'despondence': ['depression'],\n",
       "             'heartsickness': ['depression'],\n",
       "             'disconsolateness': ['depression'],\n",
       "             'wish': ['desire'],\n",
       "             'wishing': ['desire'],\n",
       "             'want': ['desire'],\n",
       "             'entrancement': ['delectation', 'delight'],\n",
       "             'ravishment': ['delectation', 'delight'],\n",
       "             'favor': ['approval'],\n",
       "             'favour': ['approval'],\n",
       "             'compunction': ['regret', 'rue', 'ruefulness', 'sorrow'],\n",
       "             'remorse': ['regret', 'rue', 'ruefulness', 'sorrow'],\n",
       "             'self-reproach': ['regret', 'rue', 'ruefulness', 'sorrow'],\n",
       "             'misanthropy': ['hate', 'hatred'],\n",
       "             'joy': ['emotion'],\n",
       "             'joyousness': ['emotion'],\n",
       "             'joyfulness': ['emotion'],\n",
       "             'masochism': ['sexual_pleasure'],\n",
       "             'amicability': ['friendliness'],\n",
       "             'amicableness': ['friendliness'],\n",
       "             'forlornness': ['sadness', 'unhappiness'],\n",
       "             'loneliness': ['sadness', 'unhappiness'],\n",
       "             'desolation': ['sadness', 'unhappiness'],\n",
       "             'sensation': ['stir'],\n",
       "             'horror': ['fear', 'fearfulness', 'fright', 'disgust'],\n",
       "             'gratification': ['emotional_state', 'spirit'],\n",
       "             'satisfaction': ['emotional_state', 'spirit', 'contentment'],\n",
       "             'pride': ['satisfaction'],\n",
       "             'lovesickness': ['pining'],\n",
       "             'encouragement': ['hope'],\n",
       "             'testiness': ['choler',\n",
       "              'crossness',\n",
       "              'fretfulness',\n",
       "              'fussiness',\n",
       "              'irritability',\n",
       "              'peevishness',\n",
       "              'petulance'],\n",
       "             'touchiness': ['choler',\n",
       "              'crossness',\n",
       "              'fretfulness',\n",
       "              'fussiness',\n",
       "              'irritability',\n",
       "              'peevishness',\n",
       "              'petulance'],\n",
       "             'tetchiness': ['choler',\n",
       "              'crossness',\n",
       "              'fretfulness',\n",
       "              'fussiness',\n",
       "              'irritability',\n",
       "              'peevishness',\n",
       "              'petulance'],\n",
       "             'oppression': ['depression'],\n",
       "             'oppressiveness': ['depression'],\n",
       "             'pensiveness': ['melancholy'],\n",
       "             'brooding': ['melancholy'],\n",
       "             'gloat': ['satisfaction'],\n",
       "             'gloating': ['satisfaction'],\n",
       "             'glee': ['satisfaction', 'gaiety', 'merriment'],\n",
       "             'nirvana': ['beatification', 'beatitude', 'blessedness'],\n",
       "             'enlightenment': ['beatification', 'beatitude', 'blessedness'],\n",
       "             'broken_heart': ['sorrow'],\n",
       "             'empathy': ['fellow_feeling', 'sympathy'],\n",
       "             'titillation': ['excitement', 'exhilaration'],\n",
       "             'complacency': ['satisfaction'],\n",
       "             'complacence': ['satisfaction'],\n",
       "             'self-complacency': ['satisfaction'],\n",
       "             'self-satisfaction': ['satisfaction'],\n",
       "             'sexual_desire': ['desire'],\n",
       "             'eros': ['desire'],\n",
       "             'concupiscence': ['desire'],\n",
       "             'physical_attraction': ['desire'],\n",
       "             'frisson': ['fear', 'fearfulness', 'fright'],\n",
       "             'shiver': ['fear', 'fearfulness', 'fright'],\n",
       "             'chill': ['fear',\n",
       "              'fearfulness',\n",
       "              'fright',\n",
       "              'apprehension',\n",
       "              'apprehensiveness',\n",
       "              'dread'],\n",
       "             'quiver': ['fear', 'fearfulness', 'fright'],\n",
       "             'shudder': ['fear', 'fearfulness', 'fright'],\n",
       "             'thrill': ['fear',\n",
       "              'fearfulness',\n",
       "              'fright',\n",
       "              'excitement',\n",
       "              'exhilaration'],\n",
       "             'tingle': ['fear', 'fearfulness', 'fright'],\n",
       "             'huffishness': ['bitterness',\n",
       "              'gall',\n",
       "              'rancor',\n",
       "              'rancour',\n",
       "              'resentment'],\n",
       "             'surprise': ['amazement', 'astonishment'],\n",
       "             'bang': ['excitement', 'exhilaration'],\n",
       "             'boot': ['excitement', 'exhilaration'],\n",
       "             'charge': ['excitement', 'exhilaration'],\n",
       "             'rush': ['excitement', 'exhilaration'],\n",
       "             'flush': ['excitement', 'exhilaration'],\n",
       "             'kick': ['excitement', 'exhilaration'],\n",
       "             'apprehension': ['fear', 'fearfulness', 'fright'],\n",
       "             'apprehensiveness': ['fear', 'fearfulness', 'fright'],\n",
       "             'dread': ['fear', 'fearfulness', 'fright'],\n",
       "             'state': ['emotional_state', 'spirit'],\n",
       "             'sensuousness': ['sensibility'],\n",
       "             'mercifulness': ['compassion', 'compassionateness'],\n",
       "             'mercy': ['compassion', 'compassionateness'],\n",
       "             'fondness': ['liking'],\n",
       "             'fancy': ['liking'],\n",
       "             'partiality': ['liking'],\n",
       "             'hesitance': ['diffidence', 'self-distrust', 'self-doubt'],\n",
       "             'hesitancy': ['diffidence', 'self-distrust', 'self-doubt'],\n",
       "             'misology': ['hate', 'hatred'],\n",
       "             'wildness': ['passion', 'passionateness'],\n",
       "             'abandon': ['passion', 'passionateness'],\n",
       "             'jocundity': ['gaiety', 'merriment'],\n",
       "             'jocularity': ['gaiety', 'merriment'],\n",
       "             'nostalgia': ['hungriness', 'longing', 'yearning'],\n",
       "             'hero_worship': ['admiration', 'esteem'],\n",
       "             'willies': ['disquietude',\n",
       "              'edginess',\n",
       "              'inquietude',\n",
       "              'uneasiness'],\n",
       "             'survivor_guilt': ['guilt',\n",
       "              'guilt_feelings',\n",
       "              'guilt_trip',\n",
       "              'guilty_conscience'],\n",
       "             'American_Dream': ['ambition', 'aspiration', 'dream'],\n",
       "             'triumph': ['exultation', 'jubilance', 'jubilancy', 'jubilation'],\n",
       "             'sanguinity': ['optimism'],\n",
       "             'sanguineness': ['optimism'],\n",
       "             'anxiousness': ['anxiety'],\n",
       "             'disquiet': ['anxiety'],\n",
       "             'foreboding': ['apprehension', 'apprehensiveness', 'dread'],\n",
       "             'premonition': ['apprehension', 'apprehensiveness', 'dread'],\n",
       "             'presentiment': ['apprehension', 'apprehensiveness', 'dread'],\n",
       "             'boding': ['apprehension', 'apprehensiveness', 'dread'],\n",
       "             'intimidation': ['discouragement',\n",
       "              'disheartenment',\n",
       "              'dismay',\n",
       "              'fear',\n",
       "              'fearfulness',\n",
       "              'fright'],\n",
       "             'dolefulness': ['sadness', 'unhappiness'],\n",
       "             'sentimentality': ['sentiment'],\n",
       "             'Electra_complex': ['complex'],\n",
       "             'oversensitiveness': ['sensitiveness', 'sensitivity'],\n",
       "             'hankering': ['hungriness', 'longing', 'yearning'],\n",
       "             'yen': ['hungriness', 'longing', 'yearning'],\n",
       "             'exhilaration': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'excitement': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'approbation': ['approval'],\n",
       "             'world-weariness': ['melancholy'],\n",
       "             'Weltschmerz': ['melancholy'],\n",
       "             'disinclination': ['dislike'],\n",
       "             'mellowness': ['kind-heartedness', 'kindheartedness'],\n",
       "             'bloodlust': ['desire'],\n",
       "             'sorrow': ['sadness',\n",
       "              'unhappiness',\n",
       "              'unhappiness',\n",
       "              'sadness',\n",
       "              'unhappiness'],\n",
       "             'angst': ['anxiety'],\n",
       "             'anguish': ['distress', 'hurt', 'suffering'],\n",
       "             'torment': ['distress',\n",
       "              'hurt',\n",
       "              'suffering',\n",
       "              'hurt',\n",
       "              'suffering',\n",
       "              'annoyance',\n",
       "              'chafe',\n",
       "              'vexation'],\n",
       "             'torture': ['distress', 'hurt', 'suffering', 'hurt', 'suffering'],\n",
       "             'caprice': ['desire'],\n",
       "             'impulse': ['desire'],\n",
       "             'whim': ['desire'],\n",
       "             'undertow': ['inclination'],\n",
       "             'joylessness': ['cheerlessness', 'uncheerfulness'],\n",
       "             'embitterment': ['unhappiness'],\n",
       "             'devotion': ['love'],\n",
       "             'devotedness': ['love'],\n",
       "             'meekness': ['humbleness', 'humility'],\n",
       "             'submission': ['humbleness', 'humility'],\n",
       "             'mourning': ['sadness', 'sorrow', 'sorrowfulness'],\n",
       "             'bereavement': ['sadness', 'sorrow', 'sorrowfulness'],\n",
       "             'amusement': ['delectation', 'delight'],\n",
       "             'infuriation': ['anger', 'choler', 'ire'],\n",
       "             'enragement': ['anger', 'choler', 'ire'],\n",
       "             'downheartedness': ['sadness', 'unhappiness'],\n",
       "             'dejectedness': ['sadness', 'unhappiness'],\n",
       "             'low-spiritedness': ['sadness', 'unhappiness'],\n",
       "             'lowness': ['sadness', 'unhappiness'],\n",
       "             'dispiritedness': ['sadness', 'unhappiness'],\n",
       "             'electricity': ['stir'],\n",
       "             'heartstrings': ['compassion', 'compassionateness', 'love'],\n",
       "             'sensuality': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'sensualness': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'sensualism': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'fatigue': ['boredom', 'ennui', 'tedium'],\n",
       "             'maleficence': ['malevolence', 'malignity'],\n",
       "             'growing_pains': ['pain', 'painfulness'],\n",
       "             'covetousness': ['enviousness', 'envy'],\n",
       "             'discomfiture': ['anxiety', 'embarrassment'],\n",
       "             'discomposure': ['anxiety', 'embarrassment'],\n",
       "             'disconcertion': ['anxiety', 'embarrassment'],\n",
       "             'disconcertment': ['anxiety', 'embarrassment'],\n",
       "             'pessimism': ['despair'],\n",
       "             'attrition': ['regret', 'rue', 'ruefulness', 'sorrow'],\n",
       "             'contrition': ['regret', 'rue', 'ruefulness', 'sorrow'],\n",
       "             'contriteness': ['regret', 'rue', 'ruefulness', 'sorrow'],\n",
       "             'misoneism': ['hate', 'hatred'],\n",
       "             'diffidence': ['timidity', 'timidness', 'timorousness'],\n",
       "             'self-doubt': ['timidity', 'timidness', 'timorousness'],\n",
       "             'self-distrust': ['timidity', 'timidness', 'timorousness'],\n",
       "             'self-esteem': ['pride', 'pridefulness'],\n",
       "             'self-pride': ['pride', 'pridefulness'],\n",
       "             'grudge': ['bitterness',\n",
       "              'gall',\n",
       "              'rancor',\n",
       "              'rancour',\n",
       "              'resentment'],\n",
       "             'score': ['bitterness',\n",
       "              'gall',\n",
       "              'rancor',\n",
       "              'rancour',\n",
       "              'resentment'],\n",
       "             'grievance': ['bitterness',\n",
       "              'gall',\n",
       "              'rancor',\n",
       "              'rancour',\n",
       "              'resentment'],\n",
       "             'guilt': ['compunction', 'remorse', 'self-reproach'],\n",
       "             'guilty_conscience': ['compunction', 'remorse', 'self-reproach'],\n",
       "             'guilt_feelings': ['compunction', 'remorse', 'self-reproach'],\n",
       "             'guilt_trip': ['compunction', 'remorse', 'self-reproach'],\n",
       "             'love': ['emotion',\n",
       "              'concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'depression': ['sadness', 'unhappiness'],\n",
       "             'sadism': ['sexual_pleasure'],\n",
       "             'umbrage': ['anger', 'choler', 'ire'],\n",
       "             'offense': ['anger', 'choler', 'ire'],\n",
       "             'offence': ['anger', 'choler', 'ire'],\n",
       "             'vindictiveness': ['malevolence', 'malignity'],\n",
       "             'vengefulness': ['malevolence', 'malignity'],\n",
       "             'Anglophobia': ['dislike'],\n",
       "             'razbliuto': ['sentiment'],\n",
       "             'discomfort': ['hurt', 'suffering'],\n",
       "             'soreness': ['hurt', 'suffering'],\n",
       "             'chagrin': ['embarrassment'],\n",
       "             'humiliation': ['embarrassment'],\n",
       "             'mortification': ['embarrassment'],\n",
       "             'mental_anguish': ['pain', 'painfulness'],\n",
       "             'repugnance': ['disgust'],\n",
       "             'repulsion': ['disgust'],\n",
       "             'revulsion': ['disgust'],\n",
       "             'antagonism': ['dislike', 'enmity', 'hostility', 'ill_will'],\n",
       "             'stomach': ['inclination', 'appetence', 'appetency', 'appetite'],\n",
       "             'antipathy': ['dislike'],\n",
       "             'aversion': ['dislike'],\n",
       "             'distaste': ['dislike'],\n",
       "             'unassertiveness': ['diffidence', 'self-distrust', 'self-doubt'],\n",
       "             'pall': ['apprehension', 'apprehensiveness', 'dread'],\n",
       "             'eagerness': ['enthusiasm'],\n",
       "             'avidity': ['enthusiasm'],\n",
       "             'avidness': ['enthusiasm'],\n",
       "             'keenness': ['enthusiasm'],\n",
       "             'leaning': ['inclination'],\n",
       "             'propensity': ['inclination'],\n",
       "             'tendency': ['inclination'],\n",
       "             'passion': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'filial_love': ['love'],\n",
       "             'insecurity': ['anxiety'],\n",
       "             'Anglophilia': ['admiration', 'esteem'],\n",
       "             'misery': ['sadness', 'unhappiness'],\n",
       "             'philhellenism': ['admiration', 'esteem'],\n",
       "             'abhorrence': ['disgust', 'hate', 'hatred'],\n",
       "             'abomination': ['disgust', 'hate', 'hatred'],\n",
       "             'detestation': ['disgust', 'hate', 'hatred'],\n",
       "             'execration': ['disgust', 'hate', 'hatred'],\n",
       "             'loathing': ['disgust', 'hate', 'hatred'],\n",
       "             'odium': ['disgust', 'hate', 'hatred'],\n",
       "             'resentment': ['enmity', 'hostility', 'ill_will'],\n",
       "             'bitterness': ['enmity', 'hostility', 'ill_will'],\n",
       "             'gall': ['enmity', 'hostility', 'ill_will'],\n",
       "             'rancor': ['enmity', 'hostility', 'ill_will'],\n",
       "             'rancour': ['enmity', 'hostility', 'ill_will'],\n",
       "             'blessedness': ['felicity', 'happiness'],\n",
       "             'beatitude': ['felicity', 'happiness'],\n",
       "             'beatification': ['felicity', 'happiness'],\n",
       "             'pet': ['choler',\n",
       "              'crossness',\n",
       "              'fretfulness',\n",
       "              'fussiness',\n",
       "              'irritability',\n",
       "              'peevishness',\n",
       "              'petulance'],\n",
       "             'bonheur': ['happiness'],\n",
       "             'helplessness': ['depression'],\n",
       "             'tsoris': ['distress', 'hurt', 'suffering'],\n",
       "             'cheerfulness': ['happiness'],\n",
       "             'blitheness': ['happiness'],\n",
       "             'bad_temper': ['anger', 'choler', 'ire'],\n",
       "             'ill_temper': ['anger', 'choler', 'ire'],\n",
       "             'self-torture': ['distress', 'hurt', 'suffering'],\n",
       "             'self-torment': ['distress', 'hurt', 'suffering'],\n",
       "             'mysophilia': ['liking'],\n",
       "             'puppy_love': ['love'],\n",
       "             'calf_love': ['love'],\n",
       "             'crush': ['love'],\n",
       "             'infatuation': ['love', 'passion', 'passionateness'],\n",
       "             'confusion': ['embarrassment'],\n",
       "             'discombobulation': ['embarrassment'],\n",
       "             'velleity': ['want', 'wish', 'wishing'],\n",
       "             'esteem': ['liking'],\n",
       "             'Oedipus_complex': ['complex'],\n",
       "             'Oedipal_complex': ['complex'],\n",
       "             'buoyancy': ['blitheness', 'cheerfulness'],\n",
       "             'perkiness': ['blitheness', 'cheerfulness'],\n",
       "             'peace': ['quietness', 'quietude', 'tranquility', 'tranquillity'],\n",
       "             'peacefulness': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'peace_of_mind': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'repose': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'serenity': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'heartsease': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'ataraxis': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'amour_propre': ['pride', 'pridefulness'],\n",
       "             'conceit': ['pride', 'pridefulness'],\n",
       "             'self-love': ['pride', 'pridefulness'],\n",
       "             'vanity': ['pride', 'pridefulness'],\n",
       "             'scruple': ['anxiety'],\n",
       "             'qualm': ['anxiety'],\n",
       "             'misgiving': ['anxiety'],\n",
       "             'hostility': ['hate', 'hatred'],\n",
       "             'enmity': ['hate', 'hatred'],\n",
       "             'ill_will': ['hate', 'hatred'],\n",
       "             'technophobia': ['dislike'],\n",
       "             'despisal': ['hate', 'hatred'],\n",
       "             'despising': ['hate', 'hatred'],\n",
       "             'inclination': ['liking'],\n",
       "             'embarrassment': ['emotional_state', 'spirit', 'shame'],\n",
       "             'heartburning': ['bitterness',\n",
       "              'gall',\n",
       "              'rancor',\n",
       "              'rancour',\n",
       "              'resentment'],\n",
       "             'attachment': ['affection',\n",
       "              'affectionateness',\n",
       "              'fondness',\n",
       "              'heart',\n",
       "              'philia',\n",
       "              'tenderness',\n",
       "              'warmheartedness',\n",
       "              'warmness'],\n",
       "             'fond_regard': ['affection',\n",
       "              'affectionateness',\n",
       "              'fondness',\n",
       "              'heart',\n",
       "              'philia',\n",
       "              'tenderness',\n",
       "              'warmheartedness',\n",
       "              'warmness'],\n",
       "             'approval': ['liking'],\n",
       "             'distance': ['indifference'],\n",
       "             'aloofness': ['indifference'],\n",
       "             'suspense': ['anticipation',\n",
       "              'expectancy',\n",
       "              'apprehension',\n",
       "              'apprehensiveness',\n",
       "              'dread'],\n",
       "             'feelings': ['sensitiveness', 'sensitivity'],\n",
       "             'good_humor': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'good_humour': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'good_temper': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'amiability': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'soft_spot': ['affection',\n",
       "              'affectionateness',\n",
       "              'fondness',\n",
       "              'heart',\n",
       "              'philia',\n",
       "              'tenderness',\n",
       "              'warmheartedness',\n",
       "              'warmness'],\n",
       "             'distress': ['pain', 'painfulness'],\n",
       "             'consolation': ['comfort'],\n",
       "             'solace': ['comfort'],\n",
       "             'solacement': ['comfort'],\n",
       "             'resignation': ['despair'],\n",
       "             'surrender': ['despair'],\n",
       "             'regard': ['affection',\n",
       "              'affectionateness',\n",
       "              'fondness',\n",
       "              'heart',\n",
       "              'philia',\n",
       "              'tenderness',\n",
       "              'warmheartedness',\n",
       "              'warmness'],\n",
       "             'respect': ['affection',\n",
       "              'affectionateness',\n",
       "              'fondness',\n",
       "              'heart',\n",
       "              'philia',\n",
       "              'tenderness',\n",
       "              'warmheartedness',\n",
       "              'warmness'],\n",
       "             'unrest': ['agitation'],\n",
       "             'daze': ['stupefaction'],\n",
       "             'shock': ['stupefaction'],\n",
       "             'stupor': ['stupefaction'],\n",
       "             'prurience': ['amativeness',\n",
       "              'amorousness',\n",
       "              'eroticism',\n",
       "              'erotism',\n",
       "              'sexiness'],\n",
       "             'pruriency': ['amativeness',\n",
       "              'amorousness',\n",
       "              'eroticism',\n",
       "              'erotism',\n",
       "              'sexiness'],\n",
       "             'lasciviousness': ['amativeness',\n",
       "              'amorousness',\n",
       "              'eroticism',\n",
       "              'erotism',\n",
       "              'sexiness'],\n",
       "             'carnality': ['amativeness',\n",
       "              'amorousness',\n",
       "              'eroticism',\n",
       "              'erotism',\n",
       "              'sexiness'],\n",
       "             'lubricity': ['amativeness',\n",
       "              'amorousness',\n",
       "              'eroticism',\n",
       "              'erotism',\n",
       "              'sexiness'],\n",
       "             'huffiness': ['anger', 'choler', 'ire'],\n",
       "             'satyriasis': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'ego': ['pride', 'pridefulness'],\n",
       "             'egotism': ['pride', 'pridefulness'],\n",
       "             'self-importance': ['pride', 'pridefulness'],\n",
       "             'mournfulness': ['sorrow'],\n",
       "             'sorrowfulness': ['sorrow', 'unhappiness'],\n",
       "             'ruthfulness': ['sorrow'],\n",
       "             'amorousness': ['love',\n",
       "              'concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'enamoredness': ['love'],\n",
       "             'buck_fever': ['fever'],\n",
       "             'Schadenfreude': ['delectation', 'delight'],\n",
       "             'exultation': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'jubilance': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'jubilancy': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'jubilation': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'weight': ['oppression', 'oppressiveness'],\n",
       "             'discouragement': ['despair'],\n",
       "             'disheartenment': ['despair'],\n",
       "             'dismay': ['despair', 'fear', 'fearfulness', 'fright'],\n",
       "             'sadness': ['unhappiness'],\n",
       "             'cold_comfort': ['consolation', 'solace', 'solacement'],\n",
       "             'libido': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'addiction': ['craving'],\n",
       "             'unfriendliness': ['dislike'],\n",
       "             'weakness': ['penchant', 'predilection', 'preference', 'taste'],\n",
       "             'wistfulness': ['hungriness', 'longing', 'yearning'],\n",
       "             'anaphrodisia': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'misogamy': ['hate', 'hatred'],\n",
       "             'demoralization': ['depression'],\n",
       "             'demoralisation': ['depression'],\n",
       "             'compassion': ['fellow_feeling', 'sympathy'],\n",
       "             'compassionateness': ['fellow_feeling', 'sympathy'],\n",
       "             'self-pity': ['sorrow'],\n",
       "             'emulation': ['ambition', 'aspiration', 'dream'],\n",
       "             'moroseness': ['moodiness'],\n",
       "             'glumness': ['moodiness'],\n",
       "             'sullenness': ['moodiness'],\n",
       "             'gusto': ['enjoyment', 'enthusiasm'],\n",
       "             'relish': ['enjoyment', 'enthusiasm'],\n",
       "             'zest': ['enjoyment', 'enthusiasm'],\n",
       "             'zestfulness': ['enjoyment', 'enthusiasm'],\n",
       "             'regret': ['sadness', 'unhappiness'],\n",
       "             'rue': ['sadness', 'unhappiness'],\n",
       "             'ruefulness': ['sadness', 'unhappiness'],\n",
       "             'disgust': ['dislike'],\n",
       "             'lecherousness': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'lust': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'lustfulness': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'sexual_love': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'erotic_love': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'nausea': ['disgust'],\n",
       "             'philogyny': ['admiration', 'esteem'],\n",
       "             'pleasantness': ['pleasance', 'pleasure'],\n",
       "             'lovingness': ['love'],\n",
       "             'caring': ['love'],\n",
       "             'tranquillity': ['calmness'],\n",
       "             'tranquility': ['calmness'],\n",
       "             'quietness': ['calmness'],\n",
       "             'quietude': ['calmness'],\n",
       "             'elation': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'high_spirits': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'lightness': ['joy', 'joyfulness', 'joyousness'],\n",
       "             'peeve': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'smugness': ['complacence',\n",
       "              'complacency',\n",
       "              'self-complacency',\n",
       "              'self-satisfaction'],\n",
       "             'hopelessness': ['despair'],\n",
       "             'inferiority_complex': ['complex'],\n",
       "             'impatience': ['fidget', 'fidgetiness', 'restlessness'],\n",
       "             'gratefulness': ['gratitude'],\n",
       "             'thankfulness': ['gratitude'],\n",
       "             'appreciativeness': ['gratitude'],\n",
       "             'poignance': ['sadness', 'sorrow', 'sorrowfulness'],\n",
       "             'poignancy': ['sadness', 'sorrow', 'sorrowfulness'],\n",
       "             'boredom': ['dissatisfaction'],\n",
       "             'ennui': ['dissatisfaction'],\n",
       "             'tedium': ['dissatisfaction'],\n",
       "             'sadomasochism': ['masochism', 'sadism'],\n",
       "             'concern': ['fellow_feeling', 'sympathy', 'anxiety'],\n",
       "             'class_feeling': ['enmity', 'hostility', 'ill_will'],\n",
       "             'worship': ['love'],\n",
       "             'adoration': ['love'],\n",
       "             'conscience': ['shame'],\n",
       "             'hopefulness': ['hope'],\n",
       "             'rejoicing': ['happiness'],\n",
       "             'shyness': ['timidity', 'timidness', 'timorousness'],\n",
       "             'indignation': ['anger', 'choler', 'ire'],\n",
       "             'outrage': ['anger', 'choler', 'ire'],\n",
       "             'carefreeness': ['blitheness', 'cheerfulness'],\n",
       "             'insouciance': ['blitheness', 'cheerfulness'],\n",
       "             'lightheartedness': ['blitheness', 'cheerfulness'],\n",
       "             'lightsomeness': ['blitheness', 'cheerfulness'],\n",
       "             'agony': ['hurt', 'suffering'],\n",
       "             'temptation': ['desire'],\n",
       "             'anticipation': ['expectation'],\n",
       "             'expectancy': ['expectation'],\n",
       "             'creeps': ['fear', 'fearfulness', 'fright'],\n",
       "             'self-depreciation': ['humbleness', 'humility'],\n",
       "             'moodiness': ['distemper', 'ill_humor', 'ill_humour'],\n",
       "             'envy': ['bitterness', 'gall', 'rancor', 'rancour', 'resentment'],\n",
       "             'enviousness': ['bitterness',\n",
       "              'gall',\n",
       "              'rancor',\n",
       "              'rancour',\n",
       "              'resentment'],\n",
       "             'happiness': ['emotional_state', 'spirit'],\n",
       "             'felicity': ['emotional_state', 'spirit'],\n",
       "             'pining': ['hungriness', 'longing', 'yearning'],\n",
       "             'elan': ['avidity', 'avidness', 'eagerness', 'keenness'],\n",
       "             'zeal': ['avidity',\n",
       "              'avidness',\n",
       "              'eagerness',\n",
       "              'keenness',\n",
       "              'ardor',\n",
       "              'ardour',\n",
       "              'fervency',\n",
       "              'fervidness',\n",
       "              'fervor',\n",
       "              'fervour',\n",
       "              'fire'],\n",
       "             'fearfulness': ['emotion'],\n",
       "             'fright': ['emotion'],\n",
       "             'hope': ['anticipation', 'expectancy'],\n",
       "             'timidity': ['fear', 'fearfulness', 'fright'],\n",
       "             'timidness': ['fear', 'fearfulness', 'fright'],\n",
       "             'timorousness': ['fear', 'fearfulness', 'fright'],\n",
       "             'acquired_taste': ['penchant',\n",
       "              'predilection',\n",
       "              'preference',\n",
       "              'taste'],\n",
       "             'technophilia': ['enthusiasm'],\n",
       "             'fidget': ['agitation'],\n",
       "             'fidgetiness': ['agitation'],\n",
       "             'restlessness': ['agitation'],\n",
       "             'agape_love': ['love'],\n",
       "             'homesickness': ['nostalgia'],\n",
       "             'disappointment': ['dissatisfaction'],\n",
       "             'letdown': ['dissatisfaction'],\n",
       "             'self-consciousness': ['embarrassment'],\n",
       "             'uncomfortableness': ['embarrassment'],\n",
       "             'withdrawal': ['indifference'],\n",
       "             'detachment': ['indifference'],\n",
       "             'storminess': ['passion', 'passionateness'],\n",
       "             'brotherhood': ['friendliness'],\n",
       "             'fury': ['anger', 'choler', 'ire'],\n",
       "             'rage': ['anger', 'choler', 'ire'],\n",
       "             'madness': ['anger', 'choler', 'ire'],\n",
       "             'displeasure': ['annoyance',\n",
       "              'chafe',\n",
       "              'dissatisfaction',\n",
       "              'vexation'],\n",
       "             'confidence': ['security'],\n",
       "             'wrath': ['fury', 'madness', 'rage'],\n",
       "             'swivet': ['affright', 'panic', 'terror'],\n",
       "             'misocainea': ['misoneism'],\n",
       "             'quality_of_life': ['gratification', 'satisfaction'],\n",
       "             'gladness': ['happiness'],\n",
       "             'gladfulness': ['happiness'],\n",
       "             'gladsomeness': ['happiness'],\n",
       "             'emotionlessness': ['apathy'],\n",
       "             'impassivity': ['apathy'],\n",
       "             'impassiveness': ['apathy'],\n",
       "             'phlegm': ['apathy'],\n",
       "             'indifference': ['apathy', 'unconcern'],\n",
       "             'stolidity': ['apathy'],\n",
       "             'unemotionality': ['apathy'],\n",
       "             'nationalism': ['ambition', 'aspiration', 'dream'],\n",
       "             'the_hots': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'jollity': ['amiability',\n",
       "              'gaiety',\n",
       "              'good_humor',\n",
       "              'good_humour',\n",
       "              'good_temper',\n",
       "              'merriment'],\n",
       "             'jolliness': ['amiability',\n",
       "              'gaiety',\n",
       "              'good_humor',\n",
       "              'good_humour',\n",
       "              'good_temper',\n",
       "              'merriment'],\n",
       "             'joviality': ['amiability',\n",
       "              'gaiety',\n",
       "              'good_humor',\n",
       "              'good_humour',\n",
       "              'good_temper',\n",
       "              'merriment'],\n",
       "             'aphrodisia': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'languor': ['apathy', 'easiness', 'relaxation'],\n",
       "             'lassitude': ['apathy'],\n",
       "             'listlessness': ['apathy'],\n",
       "             'jitteriness': ['anxiety'],\n",
       "             'jumpiness': ['anxiety'],\n",
       "             'nervousness': ['anxiety'],\n",
       "             'restiveness': ['anxiety'],\n",
       "             'ecstasy': ['emotional_state', 'spirit'],\n",
       "             'rapture': ['emotional_state', 'spirit'],\n",
       "             'transport': ['emotional_state', 'spirit'],\n",
       "             'exaltation': ['emotional_state', 'spirit'],\n",
       "             'raptus': ['emotional_state', 'spirit'],\n",
       "             'nymphomania': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'closeness': ['belonging'],\n",
       "             'intimacy': ['belonging'],\n",
       "             'contempt': ['dislike'],\n",
       "             'disdain': ['dislike'],\n",
       "             'scorn': ['dislike'],\n",
       "             'despite': ['dislike'],\n",
       "             'mawkishness': ['sentimentality'],\n",
       "             'bathos': ['sentimentality'],\n",
       "             'exuberance': ['enthusiasm', 'joy', 'joyfulness', 'joyousness'],\n",
       "             'disgruntlement': ['discontent',\n",
       "              'discontentedness',\n",
       "              'discontentment'],\n",
       "             'alienation': ['dislike'],\n",
       "             'disaffection': ['dislike'],\n",
       "             'estrangement': ['dislike'],\n",
       "             'captivation': ['liking'],\n",
       "             'enchantment': ['liking'],\n",
       "             'enthrallment': ['liking'],\n",
       "             'fascination': ['liking'],\n",
       "             'aggravation': ['annoyance', 'chafe', 'vexation'],\n",
       "             'exasperation': ['annoyance', 'chafe', 'vexation'],\n",
       "             'softheartedness': ['concern'],\n",
       "             'scare': ['fear', 'fearfulness', 'fright'],\n",
       "             'panic_attack': ['fear', 'fearfulness', 'fright'],\n",
       "             'irritability': ['distemper', 'ill_humor', 'ill_humour'],\n",
       "             'crossness': ['distemper', 'ill_humor', 'ill_humour'],\n",
       "             'fretfulness': ['distemper', 'ill_humor', 'ill_humour'],\n",
       "             'fussiness': ['distemper', 'ill_humor', 'ill_humour'],\n",
       "             'peevishness': ['distemper', 'ill_humor', 'ill_humour'],\n",
       "             'petulance': ['distemper', 'ill_humor', 'ill_humour'],\n",
       "             'sweet_tooth': ['appetence', 'appetency', 'appetite'],\n",
       "             'misopedia': ['hate', 'hatred'],\n",
       "             'aggression': ['enmity', 'hostility', 'ill_will'],\n",
       "             'aggressiveness': ['enmity', 'hostility', 'ill_will'],\n",
       "             'ambition': ['desire'],\n",
       "             'aspiration': ['desire'],\n",
       "             'dream': ['desire'],\n",
       "             'woe': ['mournfulness', 'ruthfulness', 'sorrowfulness'],\n",
       "             'woefulness': ['mournfulness', 'ruthfulness', 'sorrowfulness'],\n",
       "             'warmheartedness': ['caring', 'lovingness'],\n",
       "             'warmth': ['caring', 'lovingness'],\n",
       "             'contentment': ['happiness'],\n",
       "             'conflict': ['ambivalence', 'ambivalency'],\n",
       "             'abashment': ['embarrassment'],\n",
       "             'bashfulness': ['embarrassment'],\n",
       "             'grief': ['sorrow'],\n",
       "             'heartache': ['sorrow'],\n",
       "             'heartbreak': ['sorrow'],\n",
       "             'brokenheartedness': ['sorrow'],\n",
       "             'hilarity': ['gaiety', 'merriment'],\n",
       "             'mirth': ['gaiety', 'merriment'],\n",
       "             'mirthfulness': ['gaiety', 'merriment'],\n",
       "             'gleefulness': ['gaiety', 'merriment'],\n",
       "             'repentance': ['compunction', 'remorse', 'self-reproach'],\n",
       "             'penitence': ['compunction', 'remorse', 'self-reproach'],\n",
       "             'penance': ['compunction', 'remorse', 'self-reproach'],\n",
       "             'panic': ['fear', 'fearfulness', 'fright'],\n",
       "             'terror': ['fear', 'fearfulness', 'fright'],\n",
       "             'affright': ['fear', 'fearfulness', 'fright'],\n",
       "             'eroticism': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'erotism': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'sexiness': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'amativeness': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'afterglow': ['pleasantness'],\n",
       "             'delight': ['pleasance', 'pleasure'],\n",
       "             'delectation': ['pleasance', 'pleasure'],\n",
       "             'insight': ['sensibility'],\n",
       "             'perceptiveness': ['sensibility'],\n",
       "             'perceptivity': ['sensibility'],\n",
       "             'wound': ['distress', 'hurt', 'suffering'],\n",
       "             'friendliness': ['liking'],\n",
       "             'placidity': ['calmness'],\n",
       "             'placidness': ['calmness'],\n",
       "             'joie_de_vivre': ['enjoyment'],\n",
       "             'playfulness': ['levity'],\n",
       "             'sinking': ['anxiety'],\n",
       "             'sinking_feeling': ['anxiety'],\n",
       "             'melancholy': ['sadness', 'unhappiness'],\n",
       "             'care': ['anxiety'],\n",
       "             'weepiness': ['sadness', 'unhappiness'],\n",
       "             'tearfulness': ['sadness', 'unhappiness'],\n",
       "             'loyalty': ['love'],\n",
       "             'dander': ['anger', 'choler', 'ire'],\n",
       "             'hackles': ['anger', 'choler', 'ire'],\n",
       "             'commiseration': ['fellow_feeling', 'sympathy'],\n",
       "             'pity': ['fellow_feeling', 'sympathy'],\n",
       "             'ruth': ['fellow_feeling', 'sympathy'],\n",
       "             'pathos': ['fellow_feeling', 'sympathy'],\n",
       "             'dudgeon': ['indignation', 'outrage'],\n",
       "             'high_dudgeon': ['indignation', 'outrage'],\n",
       "             'jealousy': ['enviousness', 'envy'],\n",
       "             'green-eyed_monster': ['enviousness', 'envy'],\n",
       "             'murderousness': ['hate', 'hatred'],\n",
       "             'isolation': ['alienation', 'disaffection', 'estrangement'],\n",
       "             'enjoyment': ['pleasance', 'pleasure'],\n",
       "             'silver_lining': ['consolation', 'solace', 'solacement'],\n",
       "             'bright_side': ['consolation', 'solace', 'solacement'],\n",
       "             'throes': ['hurt', 'suffering'],\n",
       "             'creepy-crawlies': ['dislike'],\n",
       "             'conditioned_emotional_response': ['emotion'],\n",
       "             'CER': ['emotion'],\n",
       "             'conditioned_emotion': ['emotion'],\n",
       "             'disapproval': ['dislike'],\n",
       "             'wishfulness': ['hungriness', 'longing', 'yearning'],\n",
       "             'malevolence': ['hate', 'hatred'],\n",
       "             'malignity': ['hate', 'hatred'],\n",
       "             'heartlessness': ['unconcern'],\n",
       "             'coldheartedness': ['unconcern'],\n",
       "             'hardheartedness': ['unconcern'],\n",
       "             'irascibility': ['bad_temper', 'ill_temper'],\n",
       "             'short_temper': ['bad_temper', 'ill_temper'],\n",
       "             'spleen': ['bad_temper', 'ill_temper'],\n",
       "             'quick_temper': ['bad_temper', 'ill_temper'],\n",
       "             'compatibility': ['fellow_feeling', 'sympathy'],\n",
       "             'alarm': ['fear', 'fearfulness', 'fright'],\n",
       "             'consternation': ['fear', 'fearfulness', 'fright'],\n",
       "             'gold_fever': ['fever'],\n",
       "             'malice': ['malevolence', 'malignity'],\n",
       "             'maliciousness': ['malevolence', 'malignity'],\n",
       "             'spite': ['malevolence', 'malignity'],\n",
       "             'spitefulness': ['malevolence', 'malignity'],\n",
       "             'venom': ['malevolence', 'malignity'],\n",
       "             'fulfillment': ['satisfaction'],\n",
       "             'fulfilment': ['satisfaction'],\n",
       "             'ill_humor': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'ill_humour': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'distemper': ['humor', 'humour', 'mood', 'temper'],\n",
       "             'beneficence': ['benevolence'],\n",
       "             'lividity': ['fury', 'madness', 'rage'],\n",
       "             'coolness': ['calmness'],\n",
       "             'imperturbability': ['calmness'],\n",
       "             'imperturbableness': ['calmness'],\n",
       "             'sensibility': ['sensitiveness', 'sensitivity'],\n",
       "             'cynicism': ['pessimism'],\n",
       "             'preference': ['liking'],\n",
       "             'penchant': ['liking'],\n",
       "             'predilection': ['liking'],\n",
       "             'taste': ['liking'],\n",
       "             'dreaminess': ['easiness', 'relaxation'],\n",
       "             'trepidation': ['apprehension', 'apprehensiveness', 'dread'],\n",
       "             'blahs': ['boredom', 'ennui', 'tedium'],\n",
       "             'togetherness': ['closeness', 'intimacy'],\n",
       "             'hate': ['emotion'],\n",
       "             'hatred': ['emotion'],\n",
       "             'heavyheartedness': ['melancholy'],\n",
       "             'forgiveness': ['mercifulness', 'mercy'],\n",
       "             'presage': ['boding',\n",
       "              'foreboding',\n",
       "              'premonition',\n",
       "              'presentiment'],\n",
       "             'self-disgust': ['shame'],\n",
       "             'self-hatred': ['shame'],\n",
       "             'craving': ['desire'],\n",
       "             'easiness': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'relaxation': ['quietness',\n",
       "              'quietude',\n",
       "              'tranquility',\n",
       "              'tranquillity'],\n",
       "             'dignity': ['pride', 'pridefulness'],\n",
       "             'self-respect': ['pride', 'pridefulness'],\n",
       "             'self-regard': ['pride', 'pridefulness'],\n",
       "             'self-worth': ['pride', 'pridefulness'],\n",
       "             'radiance': ['felicity', 'happiness'],\n",
       "             'discontentment': ['hungriness', 'longing', 'yearning'],\n",
       "             'discontent': ['hungriness', 'longing', 'yearning'],\n",
       "             'discontentedness': ['hungriness', 'longing', 'yearning'],\n",
       "             'warpath': ['belligerence', 'belligerency'],\n",
       "             'fetish': ['concupiscence',\n",
       "              'eros',\n",
       "              'physical_attraction',\n",
       "              'sexual_desire'],\n",
       "             'harassment': ['annoyance', 'chafe', 'vexation'],\n",
       "             'cold_feet': ['timidity', 'timidness', 'timorousness'],\n",
       "             'emotional_state': ['emotion'],\n",
       "             'spirit': ['emotion']})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dict = dict()\n",
    "feeling_root = wn.synset(\"feeling.n.01\")\n",
    "intensity_pairs = {n_ss:[ss for ss in n_ss.hypernyms() if feeling_root in get_hypers_iter(ss)] \n",
    "                         for n_ss in feeling_nouns} \n",
    "intensity_word_dict =  expand_intensity_pairs (intensity_pairs)\n",
    "output_intensity_word_dict_to_file(intensity_word_dict,\"intensity_pairs.txt\")\n",
    "intensity_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3800216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('ferocious.s.01'), Synset('angered.s.01'), Synset('angry.s.02')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"furious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fef644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('angry.a.01'), Synset('angry.s.02'), Synset('angry.s.03')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"angry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6eeb5cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_intensity_pairs_to_file(intensity_pairs,\"intensity_synsets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3445af0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odium n = ss_s =>\n",
      "[Synset('shame.n.02'), Synset('hate.n.01'), Synset('disgust.n.01')]\n",
      "[Synset('dishonor.n.01'), Synset('emotion.n.01'), Synset('dislike.n.02')]\n",
      "[Synset('standing.n.01'), Synset('feeling.n.01'), Synset('feeling.n.01')]\n"
     ]
    }
   ],
   "source": [
    "def get_h (wd,pos=\"n\"):\n",
    "    return [h for ss in wn.synsets(wd, pos) for h in ss.hypernyms()]\n",
    "\n",
    "print(\"odium n = ss_s =>\")\n",
    "L = get_h(\"odium\",\"n\")\n",
    "print(L)\n",
    "M = [h for ss in L for h in ss.hypernyms()]\n",
    "print(M)\n",
    "N = [h for ss in M for h in ss.hypernyms()]\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bd9c157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disgust.n.01', 'hate.n.01', 'shame.n.02']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name = lambda x:getattr(x,\"name\")()\n",
    "sorted(map(get_name,L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232615c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ambition.n.01', 'a cherished desire'),\n",
       " ('ambition.n.02', 'a strong drive for success')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambition_ss_s = wn.synsets(\"ambition\",\"n\")\n",
    "get_definitions(ambition_ss_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809608c7",
   "metadata": {},
   "source": [
    "In Wordnet *ambition* is not an emotion.  It's a feeling.\n",
    "\n",
    "```\n",
    "ambition -> desire -> feeling\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac1abe",
   "metadata": {},
   "source": [
    "The disctinction between feeling and emotion is made, for example. in the field of clinical counseling.  The [Wake Forest Page Counseling Blog Page on feelings and emotions](https://counseling.online.wfu.edu/blog/difference-feelings-emotions/#:~:text=A%20fundamental%20difference%20between%20feelings,the%20depths%20of%20their%20emotions.) says:\n",
    "\n",
    ">Many people use the terms feeling and emotion as synonyms, but they are not interchangeable. While they have similar elements, there is a marked difference between feelings and emotions.\n",
    "\n",
    ">**Feelings**. Both emotional experiences and physical sensations  such as hunger or pain  bring about feelings, according to Psychology Today. Feelings are a conscious experience, although not every conscious experience, such as seeing or believing, is a feeling, as explained in the article.\n",
    "\n",
    ">**Emotions**. According to Psychology Today, an emotion can only ever be feltthrough the emotional experiences it gives rise to, even though it might be discovered through its associated thoughts, beliefs, desires, and actions. Emotions are not conscious but instead manifest in the unconscious mind. These emotions can be brought to the surface of the conscious state through extended psychotherapy.\n",
    "\n",
    ">A fundamental difference between feelings and emotions is that feelings are experienced consciously, while emotions manifest either consciously or subconsciously. Some people may spend years, or even a lifetime, not understanding the depths of their emotions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e33551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('feeling.n.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambition_ss.hypernyms()[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47eb21",
   "metadata": {},
   "source": [
    "## hierarchy exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4494d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypos (ss_set):\n",
    "    return {hn for ss in ss_set for hn in ss.hyponyms()}\n",
    "\n",
    "\n",
    "\n",
    "def get_hypers_list (ss_set):\n",
    "    return [hn for ss in ss_set for hn in ss.hypernyms()]\n",
    "\n",
    "def get_hypers_iter_list (root):\n",
    "    global accumulated\n",
    "    hl0 = root.hypernyms()\n",
    "    accumulated = hl0\n",
    "    current = hl0\n",
    "    while current:\n",
    "        current = get_hypers_list(current)\n",
    "        accumulated.extend(current)\n",
    "    return accumulated\n",
    "\n",
    "def get_hypers (ss_set):\n",
    "    return {hn for ss in ss_set for hn in ss.hypernyms()}\n",
    "\n",
    "def get_hypers_iter (root):\n",
    "    global accumulated\n",
    "    hl0 = root.hypernyms()\n",
    "    accumulated = set(hl0)\n",
    "    current = hl0\n",
    "    while current:\n",
    "        current = get_hypers(current)\n",
    "        accumulated.update(current)\n",
    "    return accumulated\n",
    "\n",
    "def get_hypos_iter (root):\n",
    "    global accumulated2\n",
    "    hl0 = root.hyponyms()\n",
    "    accumulated2 = set(hl0)\n",
    "    current = hl0\n",
    "    while current:\n",
    "        current = get_hypos(current)\n",
    "        accumulated2.update(current)\n",
    "    return accumulated2\n",
    "\n",
    "def get_hypos_gen (root):\n",
    "    hl0 = root.hyponyms()\n",
    "    accumulated2 = set(hl0)\n",
    "    current = hl0\n",
    "    while current:\n",
    "        current = get_hypos(current)\n",
    "        for hn in current:\n",
    "            yield current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61a9f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_ss = wn.all_eng_synsets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa753b",
   "metadata": {},
   "source": [
    "Let's find out how deep \"emotion.n.01\" is and what its hhypernyms are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be9926",
   "metadata": {},
   "source": [
    "Finding the root of the wn hoierarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5230b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('thing.n.01')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing_list = [ss for ss in all_ss if \"thing.n.01\" == ss.name()]\n",
    "thing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7351a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('abstraction.n.06'),\n",
       " Synset('attribute.n.02'),\n",
       " Synset('entity.n.01'),\n",
       " Synset('situation.n.01'),\n",
       " Synset('state.n.02')}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_root = thing_list[0]\n",
    "search_res = get_hypers_iter (search_root)\n",
    "search_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cf6e3d",
   "metadata": {},
   "source": [
    "Unnecessary but perhaps a useful code model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0f0324a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261 2261 501\n"
     ]
    }
   ],
   "source": [
    "#root = wn.synset(\"entity.n.01\")\n",
    "##print(root.name())\n",
    "#ctr = 0\n",
    "#accum = [(ctr,root)]\n",
    "#accum0 = [root]\n",
    "#for ss_set in get_hypos_gen (root):\n",
    "#    for ss in ss_set:\n",
    "#        if ss not in accum0:\n",
    "#            accum.append((ctr,ss))\n",
    "#            accum0.append(ss)\n",
    "#    ctr += 1\n",
    "#    if ctr > 500:\n",
    "#        break\n",
    "#print(len(accum),len(accum0), ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df3c33",
   "metadata": {},
   "source": [
    "Here are the hypernyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bb3adc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01'),\n",
       " Synset('state.n.02'),\n",
       " Synset('abstraction.n.06'),\n",
       " Synset('feeling.n.01'),\n",
       " Synset('attribute.n.02')]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = list(get_hypers_iter(emotion_ss))\n",
    "# not in any use ful order\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f4d99",
   "metadata": {},
   "source": [
    "The tree order from the root down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0           1              2          3         4          5\n",
    "#entity -> abstraction -> attribute -> state -> feeling -> emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a1c97547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Synset('entity.n.01')}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# depth = 5\n",
    "get_hypers(get_hypers(get_hypers(get_hypers(get_hypers ({emotion_ss})))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7804878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafca8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d6aa15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Tree\n",
    "\n",
    "def extend_tree(t,start=0,max_dtrs=5,pass_max_dtrs=False):\n",
    "    \"\"\"\n",
    "    Extends tree from frontier down\n",
    "    Supports the convention that nltk node labels\n",
    "    wll be names of synset instances (strings) rather than synset\n",
    "    instances.\n",
    "    \n",
    "    Note that the recursive call to extend_tree does\n",
    "    not by default pass max_dtrs values.  This is because\n",
    "    in most cases the deeper parts of teh Wordnet tree\n",
    "    do not have large numbers of daughters.  When\n",
    "    inspecting the exceptions, the relevant mother\n",
    "    node can be navigated to directly.\n",
    "    \"\"\"\n",
    "    for (i,t0) in enumerate(t):\n",
    "        if isinstance(t0,Tree):\n",
    "            if pass_max_dtrs:\n",
    "                extend_tree(t0,max_dtrs=max_dtrs)\n",
    "            else:\n",
    "                extend_tree(t0)\n",
    "        else:\n",
    "            t[i] = Tree(t0,convert_dtrs(wn.synset(t0).hyponyms()[start:start+max_dtrs]))\n",
    "\n",
    "def convert_dtrs (dtrs):\n",
    "    \"\"\"\n",
    "    ss_list to string_ist\n",
    "    \"\"\"\n",
    "    return [n.name() for n in dtrs]\n",
    "\n",
    "\n",
    "def make_trees(root_name,last=0,inc=5):\n",
    "    \"\"\"\n",
    "    Return a list of non overlapping subtrees of the \n",
    "    tree rooted at rootname, each tree containing a subsequence \n",
    "    of inc of the dtrs of root_name.\n",
    "    So if inc=5 the first subtree contains the first\n",
    "    5 daughters, the next the next 5, and so on.\n",
    "    \"\"\"\n",
    "    dtrs = wn.synset(root_name).hyponyms()\n",
    "    trees = []\n",
    "    for n in range(last, len(dtrs), inc):\n",
    "        these_dtrs = dtrs[last:last+inc]\n",
    "        trees.append(Tree(root_name,convert_dtrs(these_dtrs)))\n",
    "        last += inc\n",
    "    return trees\n",
    "\n",
    "def make_tree(root_name):\n",
    "    \"\"\"\n",
    "    Complete Wordnet tree starting at root_name.\n",
    "    \n",
    "    Note: the leaves will be trees with empty dtr lists.\n",
    "    \"\"\"\n",
    "    #last,inc = 0,5\n",
    "    dtrs_list = []\n",
    "    tree = Tree(root_name, dtrs_list)\n",
    "    dtrs = wn.synset(root_name).hyponyms()\n",
    "    for n in range(len(dtrs)):\n",
    "        this_dtr = dtrs[n].name()\n",
    "        tree.append(make_tree(this_dtr))\n",
    "    return tree\n",
    "\n",
    "def sub_tree(tree0,start=0,end=None):\n",
    "    \"\"\"\n",
    "    Just a convenience function for displaying\n",
    "    part of tree0: show only the subtrees for\n",
    "    dtrs at indices start up to end.\n",
    "    \n",
    "    Used for slicing & displaying \n",
    "    trees with many dtrs (e.g., \"feeling.n.01\").\n",
    "    \n",
    "    Note that tree[start:end] returns a list of\n",
    "    trees, which then don't display nicely.\n",
    "    This is a bandaid for that problem.\n",
    "    \"\"\"\n",
    "    return Tree(tree0.label(), tree0[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "de2eb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_tree = make_tree(\"feeling.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c480ad5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('confusion.n.03', []), Tree('discomfiture.n.01', [])]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_tree[4,2][2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "96d1d56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('ardor.n.03', [Tree('zeal.n.02', [])]), Tree('wildness.n.01', [])]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_tree[3][2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "dfa27073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,216.0,120.0\" width=\"216px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">passion.n.01</text></svg><svg width=\"44.4444%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ardor.n.03</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">zeal.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.2222%\" y1=\"20px\" y2=\"48px\" /><svg width=\"55.5556%\" x=\"44.4444%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">wildness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.2222%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('passion.n.01', [Tree('ardor.n.03', [Tree('zeal.n.02', [])]), Tree('wildness.n.01', [])])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_tree(big_tree[3],2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7517c802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1584.0,120.0\" width=\"1584px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">feeling.n.1</text></svg><svg width=\"25.2525%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">calmness.n.03</text></svg><svg width=\"30%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">coolness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"15%\" y1=\"20px\" y2=\"48px\" /><svg width=\"38%\" x=\"30%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">tranquillity.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"49%\" y1=\"20px\" y2=\"48px\" /><svg width=\"32%\" x=\"68%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">placidity.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"84%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.6263%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.09091%\" x=\"25.2525%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ingratitude.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.798%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.06061%\" x=\"34.3434%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">thing.n.11</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.3737%\" y1=\"20px\" y2=\"48px\" /><svg width=\"31.3131%\" x=\"40.404%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">passion.n.01</text></svg><svg width=\"29.0323%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">infatuation.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.5161%\" y1=\"20px\" y2=\"48px\" /><svg width=\"27.4194%\" x=\"29.0323%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">storminess.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.7419%\" y1=\"20px\" y2=\"48px\" /><svg width=\"19.3548%\" x=\"56.4516%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ardor.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.129%\" y1=\"20px\" y2=\"48px\" /><svg width=\"24.1935%\" x=\"75.8065%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">wildness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.9032%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.0606%\" y1=\"20px\" y2=\"48px\" /><svg width=\"28.2828%\" x=\"71.7172%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">shame.n.01</text></svg><svg width=\"30.3571%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">conscience.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.1786%\" y1=\"20px\" y2=\"48px\" /><svg width=\"33.9286%\" x=\"30.3571%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">self-disgust.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.3214%\" y1=\"20px\" y2=\"48px\" /><svg width=\"35.7143%\" x=\"64.2857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embarrassment.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1429%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.8586%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('feeling.n.1', [Tree('calmness.n.03', ['coolness.n.01', 'tranquillity.n.02', 'placidity.n.01']), Tree('ingratitude.n.01', []), Tree('thing.n.11', []), Tree('passion.n.01', ['infatuation.n.01', 'storminess.n.02', 'ardor.n.03', 'wildness.n.01']), Tree('shame.n.01', ['conscience.n.03', 'self-disgust.n.01', 'embarrassment.n.01'])])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t1_start = feelings[:20]\n",
    "#t2_start = feelings[21:]\n",
    "\n",
    "#trees[0]\n",
    "#t1,t2 = dict(),dict()\n",
    "#41 hyponyms\n",
    "root_name = \"feeling.n.1\"\n",
    "trees = make_trees(root_name)\n",
    "for t0 in trees:\n",
    "    extend_tree(t0)\n",
    "trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2b6d41f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1912.0,120.0\" width=\"1912px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">feeling.n.1</text></svg><svg width=\"7.53138%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">devastation.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.76569%\" y1=\"20px\" y2=\"48px\" /><svg width=\"34.3096%\" x=\"7.53138%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sadness.n.01</text></svg><svg width=\"20.7317%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">depression.n.04</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.3659%\" y1=\"20px\" y2=\"48px\" /><svg width=\"19.5122%\" x=\"20.7317%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">heaviness.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.4878%\" y1=\"20px\" y2=\"48px\" /><svg width=\"21.9512%\" x=\"40.2439%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">forlornness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"51.2195%\" y1=\"20px\" y2=\"48px\" /><svg width=\"21.9512%\" x=\"62.1951%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">dolefulness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.1707%\" y1=\"20px\" y2=\"48px\" /><svg width=\"15.8537%\" x=\"84.1463%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sorrow.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.0732%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"24.6862%\" y1=\"20px\" y2=\"48px\" /><svg width=\"15.4812%\" x=\"41.841%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sentiment.n.01</text></svg><svg width=\"43.2432%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">razbliuto.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.6216%\" y1=\"20px\" y2=\"48px\" /><svg width=\"56.7568%\" x=\"43.2432%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sentimentality.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.6216%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"49.5816%\" y1=\"20px\" y2=\"48px\" /><svg width=\"35.5649%\" x=\"57.3222%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">pleasure.n.01</text></svg><svg width=\"16.4706%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">comfort.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.23529%\" y1=\"20px\" y2=\"48px\" /><svg width=\"18.8235%\" x=\"16.4706%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">enjoyment.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"25.8824%\" y1=\"20px\" y2=\"48px\" /><svg width=\"25.8824%\" x=\"35.2941%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sexual_pleasure.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.2353%\" y1=\"20px\" y2=\"48px\" /><svg width=\"22.3529%\" x=\"61.1765%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">pleasantness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.3529%\" y1=\"20px\" y2=\"48px\" /><svg width=\"16.4706%\" x=\"83.5294%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">delight.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.7647%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75.1046%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.11297%\" x=\"92.887%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">pang.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">guilt_pang.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.4435%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('feeling.n.1', [Tree('devastation.n.02', []), Tree('sadness.n.01', ['depression.n.04', 'heaviness.n.02', 'forlornness.n.01', 'dolefulness.n.01', 'sorrow.n.01']), Tree('sentiment.n.01', ['razbliuto.n.01', 'sentimentality.n.02']), Tree('pleasure.n.01', ['comfort.n.02', 'enjoyment.n.01', 'sexual_pleasure.n.01', 'pleasantness.n.01', 'delight.n.01']), Tree('pang.n.01', ['guilt_pang.n.01'])])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bfbd049c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,3712.0,168.0\" width=\"3712px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">feeling.n.1</text></svg><svg width=\"3.87931%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">devastation.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"1.93966%\" y1=\"20px\" y2=\"48px\" /><svg width=\"45.0431%\" x=\"3.87931%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sadness.n.01</text></svg><svg width=\"43.5407%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">depression.n.04</text></svg><svg width=\"18.6813%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">oppression.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.34066%\" y1=\"20px\" y2=\"48px\" /><svg width=\"23.0769%\" x=\"18.6813%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">demoralization.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.2198%\" y1=\"20px\" y2=\"48px\" /><svg width=\"17.5824%\" x=\"41.7582%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">dysphoria.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50.5495%\" y1=\"20px\" y2=\"48px\" /><svg width=\"20.8791%\" x=\"59.3407%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">helplessness.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.7802%\" y1=\"20px\" y2=\"48px\" /><svg width=\"19.7802%\" x=\"80.2198%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">despondency.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.1099%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.7703%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.6555%\" x=\"43.5407%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">heaviness.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.3684%\" y1=\"20px\" y2=\"48px\" /><svg width=\"8.61244%\" x=\"51.1962%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">forlornness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.5024%\" y1=\"20px\" y2=\"48px\" /><svg width=\"8.61244%\" x=\"59.8086%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">dolefulness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.1148%\" y1=\"20px\" y2=\"48px\" /><svg width=\"31.5789%\" x=\"68.4211%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sorrow.n.01</text></svg><svg width=\"28.7879%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">broken_heart.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.3939%\" y1=\"20px\" y2=\"48px\" /><svg width=\"28.7879%\" x=\"28.7879%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">mournfulness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"43.1818%\" y1=\"20px\" y2=\"48px\" /><svg width=\"24.2424%\" x=\"57.5758%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">self-pity.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.697%\" y1=\"20px\" y2=\"48px\" /><svg width=\"18.1818%\" x=\"81.8182%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">grief.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.9091%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.2105%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.4009%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.97414%\" x=\"48.9224%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sentiment.n.01</text></svg><svg width=\"43.2432%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">razbliuto.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.6216%\" y1=\"20px\" y2=\"48px\" /><svg width=\"56.7568%\" x=\"43.2432%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sentimentality.n.02</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">mawkishness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.6216%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.9095%\" y1=\"20px\" y2=\"48px\" /><svg width=\"39.4397%\" x=\"56.8966%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">pleasure.n.01</text></svg><svg width=\"16.9399%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">comfort.n.02</text></svg><svg width=\"58.0645%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">consolation.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.0323%\" y1=\"20px\" y2=\"48px\" /><svg width=\"41.9355%\" x=\"58.0645%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">relief.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.0323%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.46995%\" y1=\"20px\" y2=\"48px\" /><svg width=\"17.4863%\" x=\"16.9399%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">enjoyment.n.01</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">joie_de_vivre.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"20px\" y2=\"48px\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">gusto.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25.6831%\" y1=\"20px\" y2=\"48px\" /><svg width=\"25.1366%\" x=\"34.4262%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sexual_pleasure.n.01</text></svg><svg width=\"28.2609%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sadism.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.1304%\" y1=\"20px\" y2=\"48px\" /><svg width=\"34.7826%\" x=\"28.2609%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">masochism.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"45.6522%\" y1=\"20px\" y2=\"48px\" /><svg width=\"36.9565%\" x=\"63.0435%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">algolagnia.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.5217%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.9945%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10.3825%\" x=\"59.5628%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">pleasantness.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">afterglow.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7541%\" y1=\"20px\" y2=\"48px\" /><svg width=\"30.0546%\" x=\"69.9454%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">delight.n.01</text></svg><svg width=\"36.3636%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">schadenfreude.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1818%\" y1=\"20px\" y2=\"48px\" /><svg width=\"29.0909%\" x=\"36.3636%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">amusement.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50.9091%\" y1=\"20px\" y2=\"48px\" /><svg width=\"34.5455%\" x=\"65.4545%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">entrancement.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.7273%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.9727%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.6164%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.66379%\" x=\"96.3362%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">pang.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">guilt_pang.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.1681%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('feeling.n.1', [Tree('devastation.n.02', []), Tree('sadness.n.01', [Tree('depression.n.04', ['oppression.n.03', 'demoralization.n.03', 'dysphoria.n.01', 'helplessness.n.03', 'despondency.n.01']), Tree('heaviness.n.02', []), Tree('forlornness.n.01', []), Tree('dolefulness.n.01', []), Tree('sorrow.n.01', ['broken_heart.n.01', 'mournfulness.n.01', 'self-pity.n.01', 'grief.n.01'])]), Tree('sentiment.n.01', [Tree('razbliuto.n.01', []), Tree('sentimentality.n.02', ['mawkishness.n.01'])]), Tree('pleasure.n.01', [Tree('comfort.n.02', ['consolation.n.01', 'relief.n.01']), Tree('enjoyment.n.01', ['joie_de_vivre.n.01', 'gusto.n.01']), Tree('sexual_pleasure.n.01', ['sadism.n.01', 'masochism.n.01', 'algolagnia.n.01']), Tree('pleasantness.n.01', ['afterglow.n.02']), Tree('delight.n.01', ['schadenfreude.n.01', 'amusement.n.01', 'entrancement.n.01'])]), Tree('pang.n.01', [Tree('guilt_pang.n.01', [])])])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_tree(trees[1])\n",
    "trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f2c5a07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'meekness.n.01'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(l[3])\n",
    "trees[2][l[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e6e0dba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,4376.0,168.0\" width=\"4376px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">feeling.n.1</text></svg><svg width=\"7.1298%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">humility.n.02</text></svg><svg width=\"61.5385%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">self-depreciation.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.7692%\" y1=\"20px\" y2=\"48px\" /><svg width=\"38.4615%\" x=\"61.5385%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">meekness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"80.7692%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.5649%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.47349%\" x=\"7.1298%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">fearlessness.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">security.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.86654%\" y1=\"20px\" y2=\"48px\" /><svg width=\"17.0018%\" x=\"10.6033%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sympathy.n.02</text></svg><svg width=\"21.5054%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">commiseration.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.7527%\" y1=\"20px\" y2=\"48px\" /><svg width=\"21.5054%\" x=\"21.5054%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">compatibility.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.2581%\" y1=\"20px\" y2=\"48px\" /><svg width=\"18.2796%\" x=\"43.0108%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">compassion.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.1505%\" y1=\"20px\" y2=\"48px\" /><svg width=\"23.6559%\" x=\"61.2903%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">kindheartedness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.1183%\" y1=\"20px\" y2=\"48px\" /><svg width=\"15.0538%\" x=\"84.9462%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">concern.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.4731%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.1042%\" y1=\"20px\" y2=\"48px\" /><svg width=\"59.5978%\" x=\"27.6051%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotion.n.01</text></svg><svg width=\"26.3804%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotional_state.n.01</text></svg><svg width=\"20.9302%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">unhappiness.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.4651%\" y1=\"20px\" y2=\"48px\" /><svg width=\"23.2558%\" x=\"20.9302%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">gratification.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.5581%\" y1=\"20px\" y2=\"48px\" /><svg width=\"13.9535%\" x=\"44.186%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">state.n.06</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"51.1628%\" y1=\"20px\" y2=\"48px\" /><svg width=\"23.2558%\" x=\"58.1395%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embarrassment.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.7674%\" y1=\"20px\" y2=\"48px\" /><svg width=\"18.6047%\" x=\"81.3953%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">happiness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.6977%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.1902%\" y1=\"20px\" y2=\"48px\" /><svg width=\"25.7669%\" x=\"26.3804%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">hate.n.01</text></svg><svg width=\"17.8571%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">despisal.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.92857%\" y1=\"20px\" y2=\"48px\" /><svg width=\"17.8571%\" x=\"17.8571%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">misogamy.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.7857%\" y1=\"20px\" y2=\"48px\" /><svg width=\"21.4286%\" x=\"35.7143%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">misanthropy.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.4286%\" y1=\"20px\" y2=\"48px\" /><svg width=\"19.0476%\" x=\"57.1429%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">hostility.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"20px\" y2=\"48px\" /><svg width=\"23.8095%\" x=\"76.1905%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">murderousness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.0952%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"39.2638%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.37423%\" x=\"52.1472%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">fear.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.8344%\" y1=\"20px\" y2=\"48px\" /><svg width=\"20.5521%\" x=\"55.5215%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">joy.n.01</text></svg><svg width=\"25.3731%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">exultation.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.6866%\" y1=\"20px\" y2=\"48px\" /><svg width=\"28.3582%\" x=\"25.3731%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">exhilaration.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"39.5522%\" y1=\"20px\" y2=\"48px\" /><svg width=\"20.8955%\" x=\"53.7313%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">elation.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.1791%\" y1=\"20px\" y2=\"48px\" /><svg width=\"25.3731%\" x=\"74.6269%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">exuberance.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.3134%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.7975%\" y1=\"20px\" y2=\"48px\" /><svg width=\"23.9264%\" x=\"76.0736%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">love.n.01</text></svg><svg width=\"23.0769%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">filial_love.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.5385%\" y1=\"20px\" y2=\"48px\" /><svg width=\"15.3846%\" x=\"23.0769%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">agape.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.7692%\" y1=\"20px\" y2=\"48px\" /><svg width=\"15.3846%\" x=\"38.4615%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ardor.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.1538%\" y1=\"20px\" y2=\"48px\" /><svg width=\"21.7949%\" x=\"53.8462%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">puppy_love.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7436%\" y1=\"20px\" y2=\"48px\" /><svg width=\"24.359%\" x=\"75.641%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">heartstrings.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.8205%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.0368%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.404%\" y1=\"20px\" y2=\"48px\" /><svg width=\"12.7971%\" x=\"87.2029%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">complex.n.03</text></svg><svg width=\"31.4286%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">oedipus_complex.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.7143%\" y1=\"20px\" y2=\"48px\" /><svg width=\"37.1429%\" x=\"31.4286%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">inferiority_complex.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /><svg width=\"31.4286%\" x=\"68.5714%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">electra_complex.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.2857%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"93.6015%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('feeling.n.1', [Tree('humility.n.02', ['self-depreciation.n.01', 'meekness.n.01']), Tree('fearlessness.n.01', ['security.n.03']), Tree('sympathy.n.02', ['commiseration.n.01', 'compatibility.n.01', 'compassion.n.01', 'kindheartedness.n.01', 'concern.n.03']), Tree('emotion.n.01', [Tree('emotional_state.n.01', ['unhappiness.n.02', 'gratification.n.01', 'state.n.06', 'embarrassment.n.02', 'happiness.n.01']), Tree('hate.n.01', ['despisal.n.01', 'misogamy.n.01', 'misanthropy.n.01', 'hostility.n.03', 'murderousness.n.01']), Tree('fear.n.03', []), Tree('joy.n.01', ['exultation.n.01', 'exhilaration.n.01', 'elation.n.02', 'exuberance.n.01']), Tree('love.n.01', ['filial_love.n.01', 'agape.n.01', 'ardor.n.02', 'puppy_love.n.01', 'heartstrings.n.01'])]), Tree('complex.n.03', ['oedipus_complex.n.01', 'inferiority_complex.n.01', 'electra_complex.n.01'])])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6b1b15c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('emotional_state.n.01'),\n",
       " Synset('hate.n.01'),\n",
       " Synset('fear.n.03'),\n",
       " Synset('joy.n.01'),\n",
       " Synset('love.n.01'),\n",
       " Synset('anxiety.n.02'),\n",
       " Synset('conditioned_emotional_response.n.01'),\n",
       " Synset('anger.n.01'),\n",
       " Synset('fear.n.01')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset(\"emotion.n.01\").hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a4a8f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_trees = make_trees(\"emotion.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f11c3f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"72px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,520.0,72.0\" width=\"520px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotion.n.01</text></svg><svg width=\"33.8462%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotional_state.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.9231%\" y1=\"20px\" y2=\"48px\" /><svg width=\"16.9231%\" x=\"33.8462%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">hate.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.3077%\" y1=\"20px\" y2=\"48px\" /><svg width=\"16.9231%\" x=\"50.7692%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">fear.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.2308%\" y1=\"20px\" y2=\"48px\" /><svg width=\"15.3846%\" x=\"67.6923%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">joy.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"75.3846%\" y1=\"20px\" y2=\"48px\" /><svg width=\"16.9231%\" x=\"83.0769%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">love.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.5385%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('emotion.n.01', ['emotional_state.n.01', 'hate.n.01', 'fear.n.03', 'joy.n.01', 'love.n.01'])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1b07e7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"72px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,592.0,72.0\" width=\"592px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotion.n.01</text></svg><svg width=\"18.9189%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">anxiety.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.45946%\" y1=\"20px\" y2=\"48px\" /><svg width=\"50%\" x=\"18.9189%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">conditioned_emotional_response.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"43.9189%\" y1=\"20px\" y2=\"48px\" /><svg width=\"16.2162%\" x=\"68.9189%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">anger.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.027%\" y1=\"20px\" y2=\"48px\" /><svg width=\"14.8649%\" x=\"85.1351%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">fear.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.5676%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('emotion.n.01', ['anxiety.n.02', 'conditioned_emotional_response.n.01', 'anger.n.01', 'fear.n.01'])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "12c479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_state = em_tree[0]\n",
    "#dir(em_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2e53c300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"72px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,800.0,72.0\" width=\"800px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotional_state.n.01</text></svg><svg width=\"18%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">unhappiness.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"9%\" y1=\"20px\" y2=\"48px\" /><svg width=\"20%\" x=\"18%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">gratification.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"28%\" y1=\"20px\" y2=\"48px\" /><svg width=\"12%\" x=\"38%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">state.n.06</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"44%\" y1=\"20px\" y2=\"48px\" /><svg width=\"20%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embarrassment.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"60%\" y1=\"20px\" y2=\"48px\" /><svg width=\"16%\" x=\"70%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">happiness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"78%\" y1=\"20px\" y2=\"48px\" /><svg width=\"14%\" x=\"86%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ecstasy.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"93%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('emotional_state.n.01', ['unhappiness.n.02', 'gratification.n.01', 'state.n.06', 'embarrassment.n.02', 'happiness.n.01', 'ecstasy.n.01'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "em_state_trees = make_trees(em_state.label(),inc=6)\n",
    "for t in em_state_trees:\n",
    "    display(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5b5e0693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1184.0,120.0\" width=\"1184px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotional_state.n.01</text></svg><svg width=\"22.2973%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">unhappiness.n.02</text></svg><svg width=\"57.5758%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embitterment.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.7879%\" y1=\"20px\" y2=\"48px\" /><svg width=\"42.4242%\" x=\"57.5758%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sadness.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.7879%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.1486%\" y1=\"20px\" y2=\"48px\" /><svg width=\"24.3243%\" x=\"22.2973%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">gratification.n.01</text></svg><svg width=\"61.1111%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">quality_of_life.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.5556%\" y1=\"20px\" y2=\"48px\" /><svg width=\"38.8889%\" x=\"61.1111%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">comfort.n.05</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"80.5556%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.4595%\" y1=\"20px\" y2=\"48px\" /><svg width=\"8.10811%\" x=\"46.6216%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">state.n.06</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50.6757%\" y1=\"20px\" y2=\"48px\" /><svg width=\"13.5135%\" x=\"54.7297%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embarrassment.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.4865%\" y1=\"20px\" y2=\"48px\" /><svg width=\"22.2973%\" x=\"68.2432%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">happiness.n.01</text></svg><svg width=\"54.5455%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">blessedness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.2727%\" y1=\"20px\" y2=\"48px\" /><svg width=\"45.4545%\" x=\"54.5455%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">radiance.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.2727%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.3919%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.45946%\" x=\"90.5405%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ecstasy.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"95.2703%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('emotional_state.n.01', [Tree('unhappiness.n.02', ['embitterment.n.01', 'sadness.n.02']), Tree('gratification.n.01', ['quality_of_life.n.01', 'comfort.n.05']), Tree('state.n.06', []), Tree('embarrassment.n.02', []), Tree('happiness.n.01', ['blessedness.n.01', 'radiance.n.03']), Tree('ecstasy.n.01', [])])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_tree(em_state_trees[0])\n",
    "em_state_trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ce37f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1320.0,168.0\" width=\"1320px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">emotional_state.n.01</text></svg><svg width=\"30.303%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">unhappiness.n.02</text></svg><svg width=\"38%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embitterment.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"19%\" y1=\"20px\" y2=\"48px\" /><svg width=\"62%\" x=\"38%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sadness.n.02</text></svg><svg width=\"51.6129%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">poignance.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"25.8065%\" y1=\"20px\" y2=\"48px\" /><svg width=\"48.3871%\" x=\"51.6129%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">mourning.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"75.8065%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.1515%\" y1=\"20px\" y2=\"48px\" /><svg width=\"21.8182%\" x=\"30.303%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">gratification.n.01</text></svg><svg width=\"61.1111%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">quality_of_life.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.5556%\" y1=\"20px\" y2=\"48px\" /><svg width=\"38.8889%\" x=\"61.1111%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">comfort.n.05</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"80.5556%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.2121%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.27273%\" x=\"52.1212%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">state.n.06</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.7576%\" y1=\"20px\" y2=\"48px\" /><svg width=\"12.1212%\" x=\"59.3939%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embarrassment.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.4545%\" y1=\"20px\" y2=\"48px\" /><svg width=\"20%\" x=\"71.5152%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">happiness.n.01</text></svg><svg width=\"54.5455%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">blessedness.n.01</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">nirvana.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.2727%\" y1=\"20px\" y2=\"48px\" /><svg width=\"45.4545%\" x=\"54.5455%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">radiance.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.2727%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.5152%\" y1=\"20px\" y2=\"48px\" /><svg width=\"8.48485%\" x=\"91.5152%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ecstasy.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"95.7576%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('emotional_state.n.01', [Tree('unhappiness.n.02', [Tree('embitterment.n.01', []), Tree('sadness.n.02', ['poignance.n.01', 'mourning.n.01'])]), Tree('gratification.n.01', [Tree('quality_of_life.n.01', []), Tree('comfort.n.05', [])]), Tree('state.n.06', []), Tree('embarrassment.n.02', []), Tree('happiness.n.01', [Tree('blessedness.n.01', ['nirvana.n.01']), Tree('radiance.n.03', [])]), Tree('ecstasy.n.01', [])])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_tree(em_state_trees[0])\n",
    "em_state_trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4e886426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1584.0,120.0\" width=\"1584px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">feeling.n.1</text></svg><svg width=\"25.2525%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">calmness.n.03</text></svg><svg width=\"30%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">coolness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"15%\" y1=\"20px\" y2=\"48px\" /><svg width=\"38%\" x=\"30%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">tranquillity.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"49%\" y1=\"20px\" y2=\"48px\" /><svg width=\"32%\" x=\"68%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">placidity.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"84%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.6263%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.09091%\" x=\"25.2525%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ingratitude.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.798%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.06061%\" x=\"34.3434%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">thing.n.11</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.3737%\" y1=\"20px\" y2=\"48px\" /><svg width=\"31.3131%\" x=\"40.404%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">passion.n.01</text></svg><svg width=\"29.0323%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">infatuation.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.5161%\" y1=\"20px\" y2=\"48px\" /><svg width=\"27.4194%\" x=\"29.0323%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">storminess.n.02</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.7419%\" y1=\"20px\" y2=\"48px\" /><svg width=\"19.3548%\" x=\"56.4516%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ardor.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.129%\" y1=\"20px\" y2=\"48px\" /><svg width=\"24.1935%\" x=\"75.8065%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">wildness.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.9032%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.0606%\" y1=\"20px\" y2=\"48px\" /><svg width=\"28.2828%\" x=\"71.7172%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">shame.n.01</text></svg><svg width=\"30.3571%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">conscience.n.03</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.1786%\" y1=\"20px\" y2=\"48px\" /><svg width=\"33.9286%\" x=\"30.3571%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">self-disgust.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.3214%\" y1=\"20px\" y2=\"48px\" /><svg width=\"35.7143%\" x=\"64.2857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">embarrassment.n.01</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1429%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.8586%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('feeling.n.1', [Tree('calmness.n.03', ['coolness.n.01', 'tranquillity.n.02', 'placidity.n.01']), Tree('ingratitude.n.01', []), Tree('thing.n.11', []), Tree('passion.n.01', ['infatuation.n.01', 'storminess.n.02', 'ardor.n.03', 'wildness.n.01']), Tree('shame.n.01', ['conscience.n.03', 'self-disgust.n.01', 'embarrassment.n.01'])])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd59c9",
   "metadata": {},
   "source": [
    "## The non-NLTK Python wrapper for wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3fb92",
   "metadata": {},
   "source": [
    "For comparison with [wn (non NLTK Python wrapper for Wordnet).](https://wn.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255be0d",
   "metadata": {},
   "source": [
    "It looks like there are two paths to the root, the second beginning right after the first occurrence of the root `entity.n.01`.  This despite the fact that tracing hypernyms from one sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0759aba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('domestic_animal.n.01'),\n",
       " Synset('canine.n.02'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('carnivore.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('placental.n.01'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('mammal.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('vertebrate.n.01'),\n",
       " Synset('object.n.01'),\n",
       " Synset('chordate.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('entity.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hypers_iter_list(wn.synsets(\"dog\",\"n\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abb861",
   "metadata": {},
   "source": [
    "## from the nouns to the other parts of speech (a and v)\n",
    "\n",
    "We use the stemmer to get to synsets that are morphologically related to emotionm nouns\n",
    "and are adjectives.  Highly porous but a start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf96214",
   "metadata": {},
   "source": [
    "nltk stemmers\n",
    "\n",
    "1. ISRIStemmer: For Arabic\n",
    "2. Lancaster stemmer:  agressive, recursive curious,curiousity,curio -> cury\n",
    "3. Porter stemmer: popular Does work. curious,curiousity,curio -> cury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f80f5ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ISRIStemmer',\n",
       " 'LancasterStemmer',\n",
       " 'PorterStemmer',\n",
       " 'RSLPStemmer',\n",
       " 'RegexpStemmer',\n",
       " 'SnowballStemmer',\n",
       " 'StemmerI']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cd40c",
   "metadata": {},
   "source": [
    "The code below really doesnt work well since it assumes the output of the stemmer is a word,\n",
    "which it often isn't.  A better approach follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0b33eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos=\"v\"\n",
    "#pos = \"a\"\n",
    "\n",
    "stemmers = [nm for nm in dir(nltk) if \"temmer\" in nm]\n",
    "#stemmer = nltk.PorterStemmer()\n",
    "stemmer = nltk.LancasterStemmer()\n",
    "# This needs a regexp that defines endings to be stripped\n",
    "# but knows diddly aboiut English spelling rules\n",
    "# so given \"ed$\" and \"jarred\" it will return \"jarr\"\n",
    "#stemmer = nltk.RegexpStemmer()\n",
    "# RThese both seem to be lingusitcially cuatious stemmers.\n",
    "# Not approrpriate for this wild and wooly application.\n",
    "#from nltk.stem import WordNetLemmatizer as wnl\n",
    "#wnlstemmer = wnl()\n",
    "\n",
    "def get_derivationally_related_words(ss_set, stemmer, pos=\"a\"):\n",
    "    new_pos_ss_set = []\n",
    "    for ss1 in ss_set:\n",
    "        #for ss2 in wn.synsets(stemmer.stem(ss1.name()),\"a\"):\n",
    "        for l in ss1.lemmas():\n",
    "            #[l.name() for l in sadness_ss.lemmas()]\n",
    "            for ss_res in wn.synsets(stemmer.stem(l.name()),pos):\n",
    "                new_pos_ss_set.append(ss_res)\n",
    "    return new_pos_ss_set\n",
    "\n",
    "def ss_set_to_word_set (ss_set):\n",
    "    return sorted(list(set([nm for ss in ss_set for nm in ss.lemma_names()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d150636",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_adjectives_ss_set = get_derivationally_related_words(feeling_nouns, stemmer, pos=\"a\")\n",
    "\n",
    "emotion_verbs_ss_set = get_derivationally_related_words(feeling_nouns, stemmer, pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "15eaa849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    }
   ],
   "source": [
    "print(len(emotion_adjectives_ss_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "23b6a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_noun_words = ss_set_to_word_set(feeling_nouns)\n",
    "emotion_adjective_words = ss_set_to_word_set(emotion_adjectives_ss_set)\n",
    "emotion_verb_words = ss_set_to_word_set(emotion_verbs_ss_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bcf65245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804, 529, 985)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emotion_noun_words), len(emotion_adjective_words), len(emotion_verb_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d5cdb",
   "metadata": {},
   "source": [
    "Observation: a lot of these verbs are of the \"cause to have emotion\" variety, like \"aggravate\".  Some are noise (\"abandon\").  Many are just puzzling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "45d45016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abase',\n",
       " 'abash',\n",
       " 'abide',\n",
       " 'abide_by',\n",
       " 'accommodate',\n",
       " 'accomplish',\n",
       " 'accost',\n",
       " 'acerbate',\n",
       " 'ache',\n",
       " 'act',\n",
       " 'act_as',\n",
       " 'action',\n",
       " 'addict',\n",
       " 'adjourn',\n",
       " 'affect',\n",
       " 'affirm',\n",
       " 'affright',\n",
       " 'aggress',\n",
       " 'agitate',\n",
       " 'agree',\n",
       " 'ail',\n",
       " 'alarm',\n",
       " 'alert',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alight',\n",
       " 'allege',\n",
       " 'amaze',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'anguish',\n",
       " 'animate',\n",
       " 'anneal',\n",
       " 'annoy',\n",
       " 'anticipate',\n",
       " 'appal',\n",
       " 'appall',\n",
       " 'apprehend',\n",
       " 'arouse',\n",
       " 'ask',\n",
       " 'assault',\n",
       " 'assert',\n",
       " 'astonish',\n",
       " 'astound',\n",
       " 'atone',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attaint',\n",
       " 'augur',\n",
       " 'auspicate',\n",
       " 'aver',\n",
       " 'avow',\n",
       " 'await',\n",
       " 'awe',\n",
       " 'back_away',\n",
       " 'back_out',\n",
       " 'badmouth',\n",
       " 'baffle',\n",
       " 'ball_over',\n",
       " 'bang',\n",
       " 'barrack',\n",
       " 'bash',\n",
       " 'bask',\n",
       " 'be',\n",
       " 'be_given',\n",
       " 'be_intimate',\n",
       " 'be_on_cloud_nine',\n",
       " 'beam',\n",
       " 'bear',\n",
       " 'bear_on',\n",
       " 'bear_upon',\n",
       " 'beat',\n",
       " 'beat_out',\n",
       " 'beatify',\n",
       " 'becalm',\n",
       " 'becharm',\n",
       " 'become_flat',\n",
       " 'bed',\n",
       " 'bedaze',\n",
       " 'bedazzle',\n",
       " 'bedevil',\n",
       " 'beg',\n",
       " 'begrudge',\n",
       " 'beguile',\n",
       " 'belong',\n",
       " 'belong_to',\n",
       " 'belt_along',\n",
       " 'beset',\n",
       " 'bet',\n",
       " 'betoken',\n",
       " 'bewitch',\n",
       " 'bid',\n",
       " 'bilk',\n",
       " 'bind',\n",
       " 'bitter',\n",
       " 'bless',\n",
       " 'block',\n",
       " 'blockade',\n",
       " 'blow_out_of_the_water',\n",
       " 'blush',\n",
       " 'bode',\n",
       " 'bond',\n",
       " 'bonk',\n",
       " 'boot',\n",
       " 'bop',\n",
       " 'bother',\n",
       " 'bow_out',\n",
       " 'break_down',\n",
       " 'bring',\n",
       " 'bring_up',\n",
       " 'brood',\n",
       " 'brook',\n",
       " 'bruise',\n",
       " 'buck',\n",
       " 'bucket_along',\n",
       " 'budge',\n",
       " 'bulk_large',\n",
       " 'bump_off',\n",
       " 'burden',\n",
       " 'burn',\n",
       " 'burn_down',\n",
       " 'burthen',\n",
       " 'bury',\n",
       " 'bust',\n",
       " 'call_back',\n",
       " 'call_down',\n",
       " 'call_forth',\n",
       " 'call_in',\n",
       " 'calm',\n",
       " 'calm_down',\n",
       " 'can',\n",
       " 'cannonball_along',\n",
       " 'captivate',\n",
       " 'capture',\n",
       " 'care',\n",
       " 'cark',\n",
       " 'carry',\n",
       " 'carry_out',\n",
       " 'carry_through',\n",
       " 'cast_down',\n",
       " 'catch',\n",
       " 'chafe',\n",
       " 'chagrin',\n",
       " 'channel',\n",
       " 'channelise',\n",
       " 'channelize',\n",
       " 'charge',\n",
       " 'charm',\n",
       " 'chasten',\n",
       " 'check',\n",
       " 'cheer',\n",
       " 'cheer_up',\n",
       " 'chevvy',\n",
       " 'chevy',\n",
       " 'chill',\n",
       " 'chill_out',\n",
       " 'chirk_up',\n",
       " 'chivvy',\n",
       " 'chivy',\n",
       " 'choke',\n",
       " 'choose',\n",
       " 'churn_up',\n",
       " 'circumnavigate',\n",
       " 'clear',\n",
       " 'clear_up',\n",
       " 'close',\n",
       " 'close_down',\n",
       " 'close_up',\n",
       " 'cloy',\n",
       " 'come_away',\n",
       " 'come_off',\n",
       " 'come_to',\n",
       " 'come_together',\n",
       " 'comfort',\n",
       " 'commit',\n",
       " 'compass',\n",
       " 'complain',\n",
       " 'comprehend',\n",
       " 'comprise',\n",
       " 'concern',\n",
       " 'conclude',\n",
       " 'confiscate',\n",
       " 'conflict',\n",
       " 'conform_to',\n",
       " 'confuse',\n",
       " 'congratulate',\n",
       " 'conjure',\n",
       " 'conjure_up',\n",
       " 'conk',\n",
       " 'consecrate',\n",
       " 'consider',\n",
       " 'console',\n",
       " 'constitute',\n",
       " 'contemn',\n",
       " 'contend',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'contravene',\n",
       " 'cool',\n",
       " 'cool_down',\n",
       " 'cool_it',\n",
       " 'cool_off',\n",
       " 'correspond',\n",
       " 'cost',\n",
       " 'court',\n",
       " 'cover',\n",
       " 'covet',\n",
       " 'cower',\n",
       " 'crave',\n",
       " 'crawfish',\n",
       " 'crawfish_out',\n",
       " 'crawl',\n",
       " 'creep',\n",
       " 'crimson',\n",
       " 'cringe',\n",
       " 'cross',\n",
       " 'crossbreed',\n",
       " 'crow',\n",
       " 'crucify',\n",
       " 'crush',\n",
       " 'crystalise',\n",
       " 'crystalize',\n",
       " 'crystallise',\n",
       " 'crystallize',\n",
       " 'curve',\n",
       " 'cut_across',\n",
       " 'cut_through',\n",
       " 'dally',\n",
       " 'dash',\n",
       " 'daunt',\n",
       " 'daydream',\n",
       " 'daze',\n",
       " 'dazzle',\n",
       " 'deal',\n",
       " 'decompress',\n",
       " 'dedicate',\n",
       " 'defeat',\n",
       " 'deject',\n",
       " 'delight',\n",
       " 'demolish',\n",
       " 'demoralise',\n",
       " 'demoralize',\n",
       " 'deplumate',\n",
       " 'deplume',\n",
       " 'depress',\n",
       " 'desert',\n",
       " 'desire',\n",
       " 'desolate',\n",
       " 'despair',\n",
       " 'despise',\n",
       " 'despond',\n",
       " 'detach',\n",
       " 'detest',\n",
       " 'devil',\n",
       " 'devote',\n",
       " 'diddle',\n",
       " 'die',\n",
       " 'dig',\n",
       " 'digest',\n",
       " 'dip',\n",
       " 'disaffect',\n",
       " 'disappoint',\n",
       " 'discharge',\n",
       " 'discomfit',\n",
       " 'discompose',\n",
       " 'disconcert',\n",
       " 'discontent',\n",
       " 'disdain',\n",
       " 'disengage',\n",
       " 'disgrace',\n",
       " 'disgust',\n",
       " 'dishearten',\n",
       " 'dishonor',\n",
       " 'dishonour',\n",
       " 'dismay',\n",
       " 'dismiss',\n",
       " 'dismount',\n",
       " 'disorder',\n",
       " 'dispatch',\n",
       " 'dispirit',\n",
       " 'displace',\n",
       " 'displume',\n",
       " 'disquiet',\n",
       " 'dissemble',\n",
       " 'distract',\n",
       " 'distress',\n",
       " 'do_it',\n",
       " 'drag_through_the_mud',\n",
       " 'draw',\n",
       " 'draw_back',\n",
       " 'draw_off',\n",
       " 'dread',\n",
       " 'dream',\n",
       " 'drop',\n",
       " 'drop_down',\n",
       " 'dull',\n",
       " 'dun',\n",
       " 'dwarf',\n",
       " 'dwell',\n",
       " 'ease',\n",
       " 'eat_away',\n",
       " 'eat_into',\n",
       " 'edify',\n",
       " 'eff',\n",
       " 'elicit',\n",
       " 'elucidate',\n",
       " 'embarrass',\n",
       " 'embitter',\n",
       " 'embody',\n",
       " 'embolden',\n",
       " 'empty',\n",
       " 'enamor',\n",
       " 'enamour',\n",
       " 'enchant',\n",
       " 'encounter',\n",
       " 'endure',\n",
       " 'enjoy',\n",
       " 'enkindle',\n",
       " 'enlighten',\n",
       " 'enliven',\n",
       " 'enquire',\n",
       " 'enrapture',\n",
       " 'enthral',\n",
       " 'enthrall',\n",
       " 'entrance',\n",
       " 'envenom',\n",
       " 'equal',\n",
       " 'equip',\n",
       " 'erode',\n",
       " 'esteem',\n",
       " 'estrange',\n",
       " 'even',\n",
       " 'even_out',\n",
       " 'evoke',\n",
       " 'exalt',\n",
       " 'excite',\n",
       " 'excoriate',\n",
       " 'excruciate',\n",
       " 'execute',\n",
       " 'exhilarate',\n",
       " 'exhort',\n",
       " 'exist',\n",
       " 'expect',\n",
       " 'experience',\n",
       " 'express',\n",
       " 'extol',\n",
       " 'exuberate',\n",
       " 'exult',\n",
       " 'faint',\n",
       " 'fall',\n",
       " 'fall_off',\n",
       " 'fascinate',\n",
       " 'fatigue',\n",
       " 'favor',\n",
       " 'favour',\n",
       " 'fawn',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'feign',\n",
       " 'festinate',\n",
       " 'fiddle',\n",
       " 'fidget',\n",
       " 'fill',\n",
       " 'fill_up',\n",
       " 'find',\n",
       " 'finger',\n",
       " 'fire',\n",
       " 'fire_up',\n",
       " 'fit',\n",
       " 'fit_out',\n",
       " 'flicker',\n",
       " 'flirt',\n",
       " 'flitter',\n",
       " 'floor',\n",
       " 'flurry',\n",
       " 'flush',\n",
       " 'flutter',\n",
       " 'foil',\n",
       " 'fold',\n",
       " 'follow',\n",
       " 'force_out',\n",
       " 'forecast',\n",
       " 'foreshadow',\n",
       " 'foretell',\n",
       " 'forsake',\n",
       " 'fray',\n",
       " 'free',\n",
       " 'freeze_off',\n",
       " 'fret',\n",
       " 'fright',\n",
       " 'frighten',\n",
       " 'frighten_away',\n",
       " 'frighten_off',\n",
       " 'frustrate',\n",
       " 'fuck',\n",
       " 'fuel',\n",
       " 'fulfil',\n",
       " 'fulfill',\n",
       " 'fuss',\n",
       " 'gag',\n",
       " 'gall',\n",
       " 'gestate',\n",
       " 'get',\n",
       " 'get_across',\n",
       " 'get_at',\n",
       " 'get_down',\n",
       " 'get_it_on',\n",
       " 'get_laid',\n",
       " 'get_off',\n",
       " 'get_over',\n",
       " 'get_the_better_of',\n",
       " 'get_the_picture',\n",
       " 'get_to',\n",
       " 'gibe',\n",
       " 'give',\n",
       " 'give_care',\n",
       " 'give_notice',\n",
       " 'give_thanks',\n",
       " 'give_the_axe',\n",
       " 'give_the_sack',\n",
       " 'give_up',\n",
       " 'gladden',\n",
       " 'glamour',\n",
       " 'gloat',\n",
       " 'glorify',\n",
       " 'glow',\n",
       " 'go',\n",
       " 'go_down',\n",
       " 'go_for',\n",
       " 'go_off',\n",
       " 'go_under',\n",
       " 'grade',\n",
       " 'grasp',\n",
       " 'grate',\n",
       " 'gravel',\n",
       " 'grieve',\n",
       " 'grind',\n",
       " 'grizzle',\n",
       " 'grok',\n",
       " 'gross_out',\n",
       " 'grovel',\n",
       " 'grudge',\n",
       " 'hallow',\n",
       " 'handle',\n",
       " 'hanker',\n",
       " 'harass',\n",
       " 'harden',\n",
       " 'harry',\n",
       " 'hassle',\n",
       " 'hasten',\n",
       " 'hatch',\n",
       " 'hate',\n",
       " 'have',\n",
       " 'have-to_doe_with',\n",
       " 'have_a_bun_in_the_oven',\n",
       " 'have_a_go_at_it',\n",
       " 'have_intercourse',\n",
       " 'have_it_away',\n",
       " 'have_it_off',\n",
       " 'have_sex',\n",
       " 'hearten',\n",
       " 'hero-worship',\n",
       " 'hex',\n",
       " 'hie',\n",
       " 'hinder',\n",
       " 'hit',\n",
       " 'hoist',\n",
       " 'honor',\n",
       " 'honour',\n",
       " 'hook',\n",
       " 'hope',\n",
       " 'horrify',\n",
       " 'hotfoot',\n",
       " 'hover',\n",
       " 'humble',\n",
       " 'humiliate',\n",
       " 'humor',\n",
       " 'humour',\n",
       " 'hump',\n",
       " 'hunger',\n",
       " 'hurry',\n",
       " 'hurt',\n",
       " 'hush',\n",
       " 'hybridise',\n",
       " 'hybridize',\n",
       " 'idolise',\n",
       " 'idolize',\n",
       " 'ignite',\n",
       " 'illume',\n",
       " 'illuminate',\n",
       " 'illumine',\n",
       " 'impact',\n",
       " 'impound',\n",
       " 'impress',\n",
       " 'incline',\n",
       " 'incubate',\n",
       " 'induce',\n",
       " 'inebriate',\n",
       " 'infringe',\n",
       " 'injure',\n",
       " 'inquire',\n",
       " 'inspire',\n",
       " 'inspirit',\n",
       " 'interbreed',\n",
       " 'interest',\n",
       " 'intersect',\n",
       " 'invigorate',\n",
       " 'invoke',\n",
       " 'involve',\n",
       " 'irk',\n",
       " 'irradiate',\n",
       " 'irritate',\n",
       " 'itch',\n",
       " 'jab',\n",
       " 'jade',\n",
       " 'jam',\n",
       " 'jazz',\n",
       " 'jibe',\n",
       " 'jinx',\n",
       " 'jolly_along',\n",
       " 'jolly_up',\n",
       " 'joy',\n",
       " 'jubilate',\n",
       " 'jump_for_joy',\n",
       " 'keen',\n",
       " 'kick',\n",
       " 'kick_back',\n",
       " 'kill',\n",
       " 'kindle',\n",
       " 'knife',\n",
       " 'know',\n",
       " 'kvetch',\n",
       " 'lament',\n",
       " 'languish',\n",
       " 'lapse',\n",
       " 'laud',\n",
       " 'lean',\n",
       " 'leave_office',\n",
       " 'let_down',\n",
       " 'level',\n",
       " 'lie_with',\n",
       " 'lift',\n",
       " 'light',\n",
       " 'light_up',\n",
       " 'like',\n",
       " 'list',\n",
       " 'live',\n",
       " 'live_up_to',\n",
       " 'long',\n",
       " 'look',\n",
       " 'look_on',\n",
       " 'look_sharp',\n",
       " 'look_upon',\n",
       " 'loom',\n",
       " 'loose',\n",
       " 'loosen',\n",
       " 'loosen_up',\n",
       " 'lose',\n",
       " 'love',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lull',\n",
       " 'lust',\n",
       " 'make',\n",
       " 'make_for',\n",
       " 'make_love',\n",
       " 'make_out',\n",
       " 'make_relaxed',\n",
       " 'make_up',\n",
       " 'malign',\n",
       " 'manage',\n",
       " 'mangle',\n",
       " 'mark',\n",
       " 'marvel',\n",
       " 'mash',\n",
       " 'match',\n",
       " 'meander',\n",
       " 'meet',\n",
       " 'mellow',\n",
       " 'mellow_out',\n",
       " 'melt',\n",
       " 'moderate',\n",
       " 'molest',\n",
       " 'mollify',\n",
       " 'moo',\n",
       " 'mortify',\n",
       " 'mourn',\n",
       " 'mouse',\n",
       " 'move',\n",
       " 'move_back',\n",
       " 'murder',\n",
       " 'mutilate',\n",
       " 'nark',\n",
       " 'nauseate',\n",
       " 'need',\n",
       " 'nettle',\n",
       " 'niggle',\n",
       " 'nock',\n",
       " 'normalize',\n",
       " 'nose',\n",
       " 'observe',\n",
       " 'obstruct',\n",
       " 'occupy',\n",
       " 'off',\n",
       " 'offend',\n",
       " 'offer',\n",
       " 'omen',\n",
       " 'open_fire',\n",
       " 'oppress',\n",
       " 'opt',\n",
       " 'outfit',\n",
       " 'outrage',\n",
       " 'overcome',\n",
       " 'overshadow',\n",
       " 'pain',\n",
       " 'pall',\n",
       " 'palpate',\n",
       " 'palpitate',\n",
       " 'panic',\n",
       " 'pass',\n",
       " 'pass_out',\n",
       " 'pass_over',\n",
       " 'pay',\n",
       " 'pelt_along',\n",
       " 'pep_up',\n",
       " 'perch',\n",
       " 'persecute',\n",
       " 'personify',\n",
       " 'pertain',\n",
       " 'perturb',\n",
       " 'pet',\n",
       " 'pine',\n",
       " 'pipe_down',\n",
       " 'plague',\n",
       " 'plain',\n",
       " 'play',\n",
       " 'playact',\n",
       " 'please',\n",
       " 'pluck',\n",
       " 'plume',\n",
       " 'poke',\n",
       " 'polish_off',\n",
       " 'pooh-pooh',\n",
       " 'portend',\n",
       " 'posit',\n",
       " 'pout',\n",
       " 'predict',\n",
       " 'prefer',\n",
       " 'prefigure',\n",
       " 'presage',\n",
       " 'press_down',\n",
       " 'pretend',\n",
       " 'prevail',\n",
       " 'pride',\n",
       " 'prise',\n",
       " 'privilege',\n",
       " 'prize',\n",
       " 'proclaim',\n",
       " 'prod',\n",
       " 'prognosticate',\n",
       " 'protect',\n",
       " 'provoke',\n",
       " 'pull',\n",
       " 'pull_away',\n",
       " 'pull_back',\n",
       " \"pull_in_one's_horns\",\n",
       " 'pulsate',\n",
       " 'purge',\n",
       " 'pussyfoot',\n",
       " 'put_forward',\n",
       " 'put_off',\n",
       " 'put_up',\n",
       " 'quake',\n",
       " 'queer',\n",
       " 'question',\n",
       " 'quetch',\n",
       " 'quiesce',\n",
       " 'quiet',\n",
       " 'quiet_down',\n",
       " 'quieten',\n",
       " 'quit',\n",
       " 'quiver',\n",
       " 'race',\n",
       " 'rack',\n",
       " 'rack_up',\n",
       " 'radiate',\n",
       " 'rag',\n",
       " 'rage',\n",
       " 'raise',\n",
       " 'ramp',\n",
       " 'rankle',\n",
       " 'rape',\n",
       " 'ravish',\n",
       " 'reboot',\n",
       " 'recall',\n",
       " 'recede',\n",
       " 'reckon',\n",
       " 'recoil',\n",
       " 'reconcile',\n",
       " 'recreate',\n",
       " 'redden',\n",
       " 'refer',\n",
       " 'regard',\n",
       " 'regard_as',\n",
       " 'regret',\n",
       " 'reject',\n",
       " 'rejoice',\n",
       " 'relate',\n",
       " 'relax',\n",
       " 'release',\n",
       " 'relinquish',\n",
       " 'relish',\n",
       " 'remove',\n",
       " 'renounce',\n",
       " 'repel',\n",
       " 'repent',\n",
       " 'represent',\n",
       " 'repugn',\n",
       " 'repute',\n",
       " 'require',\n",
       " 'resent',\n",
       " 'resign',\n",
       " 'respect',\n",
       " 'retire',\n",
       " 'retreat',\n",
       " 'revel',\n",
       " 'revere',\n",
       " 'reverence',\n",
       " 'revolt',\n",
       " 'rile',\n",
       " 'roleplay',\n",
       " 'roll',\n",
       " 'roll_in_the_hay',\n",
       " 'romance',\n",
       " 'root_on',\n",
       " 'rub',\n",
       " 'rue',\n",
       " 'run',\n",
       " 'run_afoul',\n",
       " 'rupture',\n",
       " 'rush',\n",
       " 'rush_along',\n",
       " 'sack',\n",
       " 'sanctify',\n",
       " 'satisfy',\n",
       " 'savor',\n",
       " 'savour',\n",
       " 'savvy',\n",
       " 'say',\n",
       " 'scandalise',\n",
       " 'scandalize',\n",
       " 'scare',\n",
       " 'scare_away',\n",
       " 'scare_off',\n",
       " 'scent',\n",
       " 'score',\n",
       " 'scorn',\n",
       " 'scotch',\n",
       " 'scour',\n",
       " 'scrape',\n",
       " 'scratch',\n",
       " 'screw',\n",
       " 'season',\n",
       " 'seclude',\n",
       " 'sedate',\n",
       " 'seduce',\n",
       " 'see',\n",
       " 'see_red',\n",
       " 'seize',\n",
       " 'send',\n",
       " 'send_away',\n",
       " 'sense',\n",
       " 'sequester',\n",
       " 'sequestrate',\n",
       " 'settle',\n",
       " 'settle_down',\n",
       " 'sex',\n",
       " 'shade',\n",
       " 'shade_off',\n",
       " 'shadow',\n",
       " 'shake',\n",
       " 'shake_up',\n",
       " 'sham',\n",
       " 'shame',\n",
       " 'shed_light_on',\n",
       " 'shell',\n",
       " 'shift',\n",
       " 'shine',\n",
       " 'ship',\n",
       " 'shiver',\n",
       " 'shock',\n",
       " 'shoot',\n",
       " 'shoot_down',\n",
       " 'shudder',\n",
       " 'shut',\n",
       " 'shut_down',\n",
       " 'sicken',\n",
       " 'sign',\n",
       " 'simmer_down',\n",
       " 'sink',\n",
       " 'slack',\n",
       " 'slack_up',\n",
       " 'slacken',\n",
       " 'slam',\n",
       " 'slant',\n",
       " 'slay',\n",
       " 'sleep_together',\n",
       " 'sleep_with',\n",
       " 'slide_down',\n",
       " 'slow_down',\n",
       " 'sluice',\n",
       " 'slump',\n",
       " 'smart',\n",
       " 'smash',\n",
       " 'snap',\n",
       " 'sneak',\n",
       " 'sock',\n",
       " 'solace',\n",
       " 'solicit',\n",
       " 'soothe',\n",
       " 'sorrow',\n",
       " 'sort_out',\n",
       " 'sound_off',\n",
       " 'span',\n",
       " 'spang',\n",
       " 'speed',\n",
       " 'spice',\n",
       " 'spice_up',\n",
       " 'spiel',\n",
       " 'spirit',\n",
       " 'spirit_up',\n",
       " 'spite',\n",
       " 'spoil',\n",
       " 'spurn',\n",
       " 'squash',\n",
       " 'squeeze',\n",
       " 'squelch',\n",
       " 'stab',\n",
       " 'stand',\n",
       " 'stargaze',\n",
       " 'starve',\n",
       " 'state',\n",
       " 'steady',\n",
       " 'step_down',\n",
       " 'step_on_it',\n",
       " 'stew',\n",
       " 'stick_out',\n",
       " 'still',\n",
       " 'stimulate',\n",
       " 'stir',\n",
       " 'stomach',\n",
       " 'storm',\n",
       " 'straighten_out',\n",
       " 'straiten',\n",
       " 'strike',\n",
       " 'stun',\n",
       " 'stymie',\n",
       " 'stymy',\n",
       " 'submit',\n",
       " 'subside',\n",
       " 'suffer',\n",
       " 'suit',\n",
       " 'sulk',\n",
       " 'support',\n",
       " 'suppress',\n",
       " 'sustain',\n",
       " 'swallow',\n",
       " 'swan',\n",
       " 'swear',\n",
       " 'sweep',\n",
       " 'swoon',\n",
       " 'take',\n",
       " 'take_aback',\n",
       " 'take_away',\n",
       " 'take_back',\n",
       " 'take_on',\n",
       " 'take_out',\n",
       " 'take_to_be',\n",
       " 'tally',\n",
       " 'tap',\n",
       " 'tear',\n",
       " 'tell',\n",
       " 'temper',\n",
       " 'tend',\n",
       " 'tender',\n",
       " 'tenderise',\n",
       " 'tenderize',\n",
       " 'terminate',\n",
       " 'thank',\n",
       " 'think_of',\n",
       " 'thirst',\n",
       " 'thread',\n",
       " 'thrill',\n",
       " 'throb',\n",
       " 'thwart',\n",
       " 'tickle',\n",
       " 'tickle_pink',\n",
       " 'tie',\n",
       " 'tilt',\n",
       " 'tip',\n",
       " 'tire',\n",
       " 'tolerate',\n",
       " 'torment',\n",
       " 'torture',\n",
       " 'touch',\n",
       " 'touch_on',\n",
       " 'toy',\n",
       " 'track',\n",
       " 'traduce',\n",
       " 'trance',\n",
       " 'tranquilize',\n",
       " 'tranquillise',\n",
       " 'tranquillize',\n",
       " 'transfer',\n",
       " 'transmit',\n",
       " 'transport',\n",
       " 'traumatise',\n",
       " 'traumatize',\n",
       " 'traverse',\n",
       " 'trifle',\n",
       " 'triumph',\n",
       " 'trouble',\n",
       " 'trounce',\n",
       " 'trust',\n",
       " 'turn_down',\n",
       " 'turn_on',\n",
       " 'twine',\n",
       " 'twist',\n",
       " 'unbend',\n",
       " 'unhinge',\n",
       " 'unhorse',\n",
       " 'unlax',\n",
       " 'unsay',\n",
       " 'unstrain',\n",
       " 'untune',\n",
       " 'unwind',\n",
       " 'upset',\n",
       " 'urge',\n",
       " 'urge_on',\n",
       " 'vacate',\n",
       " 'value',\n",
       " 'vanquish',\n",
       " 'venerate',\n",
       " 'verify',\n",
       " 'vex',\n",
       " 'vibrate',\n",
       " 'view',\n",
       " 'violate',\n",
       " 'vote_down',\n",
       " 'vote_out',\n",
       " 'wager',\n",
       " 'wait',\n",
       " 'walk_on_air',\n",
       " 'wallow',\n",
       " 'wander',\n",
       " 'want',\n",
       " 'warm',\n",
       " 'warm_up',\n",
       " 'waver',\n",
       " 'weary',\n",
       " 'weave',\n",
       " 'weight',\n",
       " 'weight_down',\n",
       " 'whap',\n",
       " 'whop',\n",
       " 'wind',\n",
       " 'wind_up',\n",
       " 'wish',\n",
       " 'wish_well',\n",
       " 'witch',\n",
       " 'withdraw',\n",
       " 'wonder',\n",
       " 'woo',\n",
       " 'woolgather',\n",
       " 'work',\n",
       " 'worry',\n",
       " 'worship',\n",
       " 'wound',\n",
       " 'wrap',\n",
       " 'wreak',\n",
       " 'wreathe',\n",
       " 'yearn',\n",
       " 'yen',\n",
       " 'zest']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_verb_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875551e8",
   "metadata": {},
   "source": [
    "## Experiment with using wheels and axles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6198bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_satellites = [a for a in emotion_adjectives_ss_set if a.pos()==\"s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3d46e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "head, satellites, ant_wheels\n",
    "\n",
    "extended_emotion_satellites = set()\n",
    "for ss in emotion_satellites:\n",
    "    (h,sats, ants) = get_wheels_and_axle(ss)\n",
    "    extended_emotion_satellites.add(h)\n",
    "    extended_emotion_satellites.update(sats)\n",
    "    extended_emotion_satellites.update(elem for sxl in ants for elem in sxl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2f93027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    }
   ],
   "source": [
    "print(len(emotion_adjectives_ss_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3cf94493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(len(emotion_satellites))\n",
    "print(len(extended_emotion_satellites))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179ed5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e6cbb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3466\n"
     ]
    }
   ],
   "source": [
    "extended_emotion_adjective_words = ss_set_to_word_set(extended_emotion_satellites)\n",
    "print(len(extended_emotion_adjective_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a19f2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extended_emotion_adjective_words = sorted(list(extended_emotion_adjective_words))\n",
    "with open(\"expressive_corpora/extended_emotion_adjectives_wn.txt\",\"w\") as ofh:\n",
    "    for adj in extended_emotion_adjective_words:\n",
    "        print(adj,file=ofh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5485e0b",
   "metadata": {},
   "source": [
    "## Stemmers redux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b459d49",
   "metadata": {},
   "source": [
    "A more realistic picture of what the stemmers do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "a2f2070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word             Port             Snow            Lanc            \n",
      "===================================================================\n",
      "destruction     destruct         destruct        destruct       \n",
      "destroy         destroy          destroy         destroy        \n",
      "destructible    destruct         destruct        destruct       \n",
      "indestructible  indestruct       indestruct      indestruct     \n",
      "curiousity      curious          curious         cury           \n",
      "curious         curiou           curious         cury           \n",
      "emblematic      emblemat         emblemat        emblem         \n",
      "emblem          emblem           emblem          emblem         \n",
      "orientation     orient           orient          ory            \n",
      "orient          orient           orient          ory            \n",
      "furious         furiou           furious         fury           \n",
      "fury            furi             furi            fury           \n",
      "abstemious      abstemi          abstemi         abstemy        \n",
      "abstain         abstain          abstain         abstain        \n",
      "fleece          fleec            fleec           fleec          \n",
      "undoable        undoabl          undoabl         undo           \n",
      "government      govern           govern          govern         \n",
      "govern          govern           govern          govern         \n",
      "aviate          aviat            aviat           avy            \n",
      "aviation        aviat            aviat           avy            \n"
     ]
    }
   ],
   "source": [
    "examples = (\"destruction destroy destructible indestructible curiousity curious emblematic\" +\\\n",
    "            \" emblem orientation orient furious fury abstemious abstain\" +\\\n",
    "            \" fleece undoable government govern aviate aviation\").split()\n",
    "port,snow,lanc = nltk.PorterStemmer(),nltk.SnowballStemmer(\"english\"),nltk.LancasterStemmer()\n",
    "banner = f\" {'Word':<15}  {'Port':<15}  {'Snow':<15} {'Lanc':<15} \"\n",
    "print(banner)\n",
    "print(\"=\"*len(banner))\n",
    "for wd in examples:\n",
    "    #print(wd)\n",
    "    print(f\"{wd:<15} {port.stem(wd):<15}  {snow.stem(wd):<15} {lanc.stem(wd):<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "15a4beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "stem_dict = defaultdict(set)\n",
    "#stemmer = nltk.PorterStemmer()\n",
    "#stemmer = nltk.LancasterStemmer()\n",
    "\n",
    "def update_stem_dict (ss_container):\n",
    "    for ss in ss_container:\n",
    "        for lname in ss.lemma_names():\n",
    "            stem_name = stemmer.stem(lname)\n",
    "            stem_dict[stem_name].add(lname)\n",
    "            \n",
    "            \n",
    "def update_stem_dict_all_pos ():\n",
    "    wn_nouns = wn.all_synsets('n')\n",
    "    update_stem_dict (wn_nouns)\n",
    "    wn_verbs = wn.all_synsets('v')\n",
    "    update_stem_dict (wn_verbs)\n",
    "    wn_adjectives = wn.all_synsets('a')\n",
    "    update_stem_dict (wn_adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ca58c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_stem_dict_all_pos ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8425bc9",
   "metadata": {},
   "source": [
    "Overstemming examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "fd023f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el'"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"elation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "id": "a48ae3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EL',\n",
       " 'ELA',\n",
       " 'Elagatis',\n",
       " 'Elia',\n",
       " 'Elul',\n",
       " 'el',\n",
       " 'elan',\n",
       " 'elate',\n",
       " 'elated',\n",
       " 'elater',\n",
       " 'elating',\n",
       " 'elation',\n",
       " 'element',\n",
       " 'elemental',\n",
       " 'elementary',\n",
       " 'elements',\n",
       " 'ell'}"
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_dict[\"el\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "76fe99e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"elation\",\"n\")[0] in wn_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "62ac9d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ER',\n",
       " 'ERA',\n",
       " 'Er',\n",
       " 'Ericales',\n",
       " 'Eris',\n",
       " 'Erivan',\n",
       " 'era',\n",
       " 'eristic',\n",
       " 'eristical',\n",
       " 'err',\n",
       " 'errancy',\n",
       " 'errant',\n",
       " 'erratic',\n",
       " 'erring',\n",
       " 'error'}"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_dict[\"er\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "55c2d9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract   10  abstractedness abstractness abstractionism abstract abstracted abstraction abstracter abstractor abstractionist abstractive\n",
      "object     10  objectionable objector objection objectify object objectification objective objectionableness objectivity objectiveness\n",
      "person     16  personable personation personification persona personalise personify personableness personalize personality person personate personage personalised personhood personal personalized\n",
      "individ    11  individualization individualised individuality individualistic individualise individualized individualisation individual individualist individualism individualize\n",
      "plant       8  planted Plantation plantar plantation planting plant plantal planter\n",
      "subst       9  substrate substantival substantial substantiality substantive substance substation substring substantialness\n",
      "artic      10  article articulated articulary articled articulation articulate articulateness articulative articulator articulatory\n",
      "process    10  processor processing processional processed proceeding process procession proceed proceeds proceedings\n",
      "commun     28  community communion communication communicant Communion Communist communal communicative communicable communicate communications communise communize communistic communalise communalism communization communicativeness communisation communicator communique communicational communism communicatory communist communicating communalize commune\n",
      "quant      14  quantify quantifiability quantisation quantum quantized quantification quantize quantic quantity quantization quantise quantifiable quantal quantifier\n",
      "apply       8  applied applicative applicator application applier applicatory appliance apply\n",
      "exploit     7  exploitive exploited exploitative exploitation exploitatory exploit exploiter\n",
      "reciproc    7  reciprocal reciprocality reciprocatory reciprocate reciprocation reciprocative reciprocity\n",
      "penet       7  penetrating penetration penetrability penetrative penetrator penetrable penetrate\n",
      "break       8  breaking break breakability breakers breakable breaker breakableness breakage\n",
      "consum     10  consumptive consummate consumption consumer consumerism consumable consummated consummation consume consuming\n",
      "fruit       7  fruition fruitage fruiting fruit fruiterer fruitfulness fruitful\n",
      "success    10  success succeeding successful succeed succeeder succession successiveness successive successfulness successor\n",
      "capit      14  capital capitulary Capital capitalisation capitalise capitalistic capitalism capitalist capitalization capitate capitulation capitation capitulate capitalize\n",
      "revert      8  reversive reversioner reversionist revertible reversion revert reversionary reverting\n",
      "round       8  rounding round roundedness rounded rounders roundish rounder roundness\n",
      "contract    8  contracture contracting contractable contracted contraction contract contractor contractual\n",
      "acceiv     11  acceptance acceptable acceptive acceptant acceptor acceptability acceptableness accept accepted accepting acceptation\n",
      "posit      12  positioning positivist positionable positivistic positivism position positive positivity positioner positional positiveness posit\n",
      "adopt       7  adopted adoptee adopt adoptable adopter adoptive adoption\n",
      "intern     23  internationality internationalism International international internationalisation internist internalisation internationalise internship internality interne Internationale internee internal internationalistic intern internment internationalization internalise internationalize internationalist internalization internalize\n",
      "impress    11  impressiveness impressive impressible impressionist impressionistic impression impressed Impressionism impressment impressionable impress\n",
      "subsid     11  subsidizer subsidisation subsiding subsidize subsidized subsidise subsidised subsidence subsidization subsidiser subside\n",
      "subject     7  subjectiveness subjectivity subjectivist subject subjectivism subjective subjection\n",
      "receiv     12  receptor receivables receptiveness receive reception receptionist received receptivity receivable receivership receiver receptive\n",
      "absolv      9  absolute absolutism absolve absoluteness absolver absolutistic absolutist absolution absolved\n",
      "convert     7  convertor converted convert converter convertible convertibility conversion\n",
      "reform     12  Reformation reformable reformulate reformist reformer reformatory reformation Reformed reform reformed reformism reformative\n",
      "instru      7  instrumental instrumentation instrumentality instrumentalism instrumentate instrumentalist instrument\n",
      "execut     10  executing execute executability executor executant execution executioner executable executive executed\n",
      "extemp      7  extemporaneous extemporization extempore extemporize extemporary extemporisation extemporise\n",
      "improv     10  improvise improvize improver improvised improvement improve improvisation improved improving improvable\n",
      "interpret   8  interpreted interpret interpretive interpreter interpretable interpretation interpretative interpreting\n",
      "autom       9  automatism automat automation automatize automatic automatise Automeris automate automated\n",
      "comput      9  computerize computation computable computerise computerization computational compute computing computer\n",
      "depress    10  depressing depression depressive depressurise Depression depress depressed depressor depressant depressurize\n",
      "press       7  pressing pressurise pressure press pressurize pressed pressor\n",
      "tract       9  tractive Tractarian tractability tractable Tractarianism traction tract tractableness tractor\n",
      "expect     11  expectorant expectedness expectable expectant expectorator expectorate expectoration expect expectancy expectation expected\n",
      "bound       8  bounden bounder bounderish bound boundedness bounds bounded boundary\n",
      "bount       7  bouncer bouncy bounciness bouncing bounce bounteous bounteousness\n",
      "transmit    8  transmitter transmittal transmitting transmittable transmitted transmittance transmit transmission\n",
      "manip       7  manipulable Manipur manipulator manipulability manipulation manipulative manipulate\n",
      "connect     9  connect connective connectedness connecter connexion connectivity connector connection connected\n",
      "detect      7  detector detected detect detection detective detecting detectable\n",
      "determin   13  determination determiner deterministic determinant determinateness determinist determinate determining determinable determinative determine determinism determined\n",
      "design      7  designate designed designative designing designation designer design\n",
      "resolv      8  resolved resolvent resolve resolving resolute resolution resolvable resoluteness\n",
      "valid       8  validatory validity validate validating validated validness validation valid\n",
      "monet       8  monetisation monetarism Monet monetize monetarist monetise monetary monetization\n",
      "induc      12  induced inductance inducer induct inducive inducing inductee inductive induction inducement inductor induce\n",
      "hypnot      9  hypnotic hypnotise hypnotist hypnotized hypnotiser hypnotism hypnotizer hypnotize hypnotised\n",
      "corrupt     8  corrupting corrupt corrupted corruption corruptive corruptibility corruptible corruptness\n",
      "adult      10  adulterator adulterating adulterated adulterate adult adulterous adulthood adulteration adulterer adulterant\n",
      "assign      8  assignation assign assignment assignee assigned assignable assignor assigning\n",
      "nomin      10  nominalism nominalistic nominator nominal nominee nominate nominative nominated nomination nominalist\n",
      "elect      15  electrification election electoral electioneer electorate elect electioneering Elector elector electrical elective elected electric electricity electrician\n",
      "chang      11  Chang changeability changed changing change Changan changer changefulness changeful changeableness changeable\n",
      "reduc      11  reduced reduction reductant reduce reducing reductive reductionist reducer reducible reductivism reductionism\n",
      "simpl       8  simplicity simple simplism simplistic simplification simpleness simplify simplified\n",
      "econom      9  economizer economic economize economise economy economics economist economiser economical\n",
      "adapt      11  adaptable adaptational adapt adapter adaptation adaptative adaptability adaptive adapted adaption adaptor\n",
      "domest      7  domesticity domesticise domestication domestic domesticize domesticated domesticate\n",
      "decim       7  decimalisation decimate decimalise decimation decimalization decimal decimalize\n",
      "commut      9  commutation commute commutability commutate commutator commuter commutable commutative commuting\n",
      "suppl      10  supplementary supplanting supplicant supplanter supple supplemental suppleness supplement supplant supplementation\n",
      "adjust      7  adjuster adjustive adjustable adjusted adjust adjustment adjustor\n",
      "transit    10  transition transit transitoriness transitivity transitivize transitional transitive transitory transitivise transitiveness\n",
      "fossil      9  fossilization fossil fossilisation fossilist fossilised fossilize fossilise fossiliferous fossilized\n",
      "transf      7  transfer transferability transferor transferable transferee transferer transference\n",
      "resist      8  resistive resister resistor resistible resist resistivity resistance resistant\n",
      "react      11  reactivate react reactionism reaction reactance reactionist reactionary reactivity reactor reactant reactive\n",
      "anathem     7  anathematize anathematisation anathemize anathematization anathematise anathemise anathema\n",
      "termin      8  terminate termination terminable terminal terminative terminated terminator terminus\n",
      "immun       8  immunity immunization immunized immunisation immunise immunised immunize immune\n",
      "dissolv     9  dissolve dissolute dissolvable dissolvent dissolution dissolver dissolving dissolved dissoluteness\n",
      "liquid     10  liquidise liquidity liquidator liquidate liquid liquidness liquidize liquidation liquidizer liquidiser\n",
      "settl       7  settle settlement settling settlings settlor settled settler\n",
      "extinct     7  extinct extinction extinguisher extinguished extinguish extinguishing extinguishable\n",
      "access      8  accessory accessional accessible accessibility access accessary accessorial accession\n",
      "constitut  10  constitutionalist constitutive constituted constitution Constitution constitutionalism constitutional constitute constitutionalise constitutionalize\n",
      "institut    7  institutionalised institutionalize institutional institution institute institutionalized institutionalise\n",
      "origin      8  origination originality originator originative originate origin originalism original\n",
      "brown       8  Browning Browne browning brownish brown browned brownness Brown\n",
      "season      7  season seasonableness seasonable seasoner seasoned seasonal seasoning\n",
      "sweet       8  sweetening sweet sweetened sweeten sweetness Sweet sweetener sweetish\n",
      "steril     11  sterilization sterilise sterilized sterilizer sterileness steriliser sterilised sterilisation sterilize sterile sterility\n",
      "sanit      10  sanitize sanitisation sanitary sanitization sanitized sanitation sanitate sanitariness sanitise sanitised\n",
      "correct     8  correct correctional correction correctness corrections corrected corrective correctable\n",
      "optim       9  optimisation optimise optimism optimist optimal optimistic optimize optimization optimum\n",
      "perfect    10  perfecta perfective perfectibility perfection perfectionism perfectible perfect perfecter perfectionist perfected\n",
      "modern     14  modernized modernisation modernness moderne modernism modernist modernize modernise modernised Modern modern modernity modernistic modernization\n",
      "bastard     8  bastardised bastardize bastardized bastardisation bastardly bastardization bastardise bastard\n",
      "popul      10  popularity popularization popularisation popularise popular Populus populariser popularize popularism popularizer\n",
      "light      10  lightship light lightness lighting Light lightening lighten lighted lighter lighterage\n",
      "black       8  blacking Black blackening blacken blackness blackish blackened black\n",
      "moist       8  moisturize moisturise moist moistening moistness moisten moisture moistener\n",
      "march       8  Marchantiales Marche march March marching Marches marcher MArch\n",
      "travel      8  traveler traveller travelable travelling traveling traveled travelled travel\n",
      "convey      8  conveyance convey conveyancing conveyor conveyer conveying conveyancer conveyable\n",
      "instil      7  instilment instillment instillator instilling instill instil instillation\n",
      "ascend     15  ascendent ascending ascendancy ascendant ascendence ascendency ascensive ascension ascensional ascendance Ascension ascendible ascender ascend ascendable\n",
      "abduc       7  abduction abducent abducens abduce abduct abductor abducting\n",
      "adduc       9  adduct adductive adductor adduction adducent adduce adducing adducer adducting\n",
      "right       9  righteous right rightness rightful rightish rightist rightism rightfulness righteousness\n",
      "allevy      7  alleviative alleviatory alleviator alleviated alleviate alleviant alleviation\n",
      "minim      11  minimum minim minimized minimalism minimisation minimalist minimization minimus minimize minimal minimise\n",
      "compress    7  compression compressed compressibility compressing compress compressible compressor\n",
      "express    10  express expressed expressionism expressionistic expression expressive expressionist expressiveness expressible expressage\n",
      "short      10  shortish shortener shortia short shorten shortness shortage shortened shortening shorts\n",
      "apprecy     7  appreciable appreciation appreciativeness appreciator appreciative appreciate appreciated\n",
      "fluorid     7  fluoridize fluoridization fluoridisation fluoridise fluoridation fluoridate fluoride\n",
      "expand     10  expansionism expandable expansion expandible expansiveness expansive expanded expansivity expansionist expand\n",
      "maxim      12  maximal maximum maxim maximisation maximization Maximian maximizing Maxim maximize maximise maximation maximising\n",
      "extend      8  extendible extension extendable extensional extended extensiveness extend extensive\n",
      "diffus      8  diffused diffusion diffuse diffusor diffuser diffuseness diffusive diffusing\n",
      "intens      7  intensity intensification intensifying intensifier intensified intense intensify\n",
      "ignit       7  igniter ignitible ignited ignite ignitable ignition ignitor\n",
      "inflam      7  inflamed inflaming inflame inflammatory inflammable inflammability inflammation\n",
      "combin      9  combinatorial combining combined combination combine combinative combinational combinatory combinable\n",
      "homog      11  homogeneous homogeneousness homogenise homogenisation homogenization homogenized homogenous homogenize homogenate homogenised homogeneity\n",
      "concret     7  concretism concreteness concretistic concretion concrete concretise concretize\n",
      "divid       7  divided divisive divider division divisional divide dividable\n",
      "quart       7  quartic quartering quartan quarter quarterly quart quarters\n",
      "syllab     10  syllabication syllabize syllabification syllabic syllabary syllabicity syllabicate syllabify syllabus syllabise\n",
      "bowdl       8  bowdlerise Bowdler bowdleriser bowdlerize bowdlerisation bowdlerizer bowdlerization Bowdlerism\n",
      "refresh     7  refreshing refreshful refresher refresh refreshed refreshen refreshment\n",
      "pract      10  practice practised practicability practicable practicality practicableness practician practiced practical practise\n",
      "symbol     13  symbolism symbolisation symbolize symbolist symbolizing symbolizer symboliser symbol symbolic symbolising symbolise symbolical symbolization\n",
      "habit      10  habitant habited habitus habitation habitable habit habitability habitat habitual habitableness\n",
      "irrit       8  irritation irritant irritability irritable irritated irritative irritate irritating\n",
      "victim      9  victimiser victimization victimized victimisation victim victimise victimizer victimised victimize\n",
      "repress     7  repressive repressor represser repression repress repressing repressed\n",
      "inhum       7  inhume inhumation inhumed inhumane inhumaneness inhumanity inhuman\n",
      "colon      15  colon colonisation colonialist colonialism Colon colonizer colonial colonist colonise colonization colonized coloniser colonised colonize colonic\n",
      "celebr      8  celebration celebrate celebratory celebrator celebrity celebrater celebrated celebrant\n",
      "battl       7  battledore battlemented battlement battler battleful battleship battle\n",
      "marbl      12  marbleised marbleise marbles marbleisation marbleising marbleization marble marbling marbleizing marbleize marbleized marbled\n",
      "bacch       8  bacchante bacchic bacchantic bacchanal Baccharis Bacchus bacchanalian bacchant\n",
      "exhibit     7  exhibitionism exhibitioner exhibitionistic exhibitionist exhibition exhibitor exhibit\n",
      "demonst     8  demonstrated demonstrative demonstrativeness demonstration demonstrator demonstrability demonstrate demonstrable\n",
      "produc      7  production productive product produce producer productiveness productivity\n",
      "carol       7  caroling caroller Carolus caroler Carolean carol Carolingian\n",
      "excit      11  excitableness excitation excitant excitable excitement excited exciting excitatory excitative excite excitability\n",
      "obstruct    8  obstructive obstructer obstruct obstructionist obstructionism obstructed obstructor obstruction\n",
      "spirit     17  spiritual spirited spiritualisation spiritism spiritualistic spiritualism spirit spirits spiritualization spiritize spiritualist spiritise spiritous spiritualise spiritualize spirituality spiritedness\n",
      "academ      7  academe academic academicianship academicism academia academician academism\n",
      "account     7  accountantship accountancy accounting accountability account accountant accountable\n",
      "assocy     10  associative associationism associability association associable associatory associateship associational associate associableness\n",
      "command     7  commandment commandership commandeer command commanding commandant commander\n",
      "counsel     7  counsellorship counsellor counseling counselorship counsel counselor counselling\n",
      "direct     14  directorship directorate directional directed directness directing direct directivity directive directiveness director directory directionality direction\n",
      "govern      9  govern governorship governing governable governmental government governor governance governed\n",
      "instruct    7  instructions instructive instruct instructor instructional instruction instructorship\n",
      "legisl      7  legislatorship legislation legislator legislative legislate legislating legislature\n",
      "presid      7  President presidium presidency presidential president presidentship preside\n",
      "profess    13  professionalism professionalization professed professorial profess professor professionalise professionalize professionalisation professional profession professorship professing\n",
      "protect    11  protectiveness protection protectionist protector protectorship protective protecting protect protectionism protected protectorate\n",
      "resid       7  resid reside residual residency residence residential resident\n",
      "secret     14  secretive secretary secretor secretariate secretarial secretory secretariat secrete secretiveness secretion secret secreter secretaryship Secretariat\n",
      "trust      10  trustor trustingness trusting trustee trusted trust trustfulness trusteeship truster trustful\n",
      "plumb       7  plumb plumbing plumbable plumbous plumbism plumbic plumber\n",
      "polit       8  politeness politicise politics politician politicize polite politic political\n",
      "theolog     8  theologiser theological theologize theologist theologian theologise theologizer theology\n",
      "condit      7  conditioner conditions conditionality conditional conditioned conditioning condition\n",
      "consult     7  consultive consultancy consult consultatory consultation consultant consultative\n",
      "analys     10  analyser analysis analytic analyzed analyze analyticity analytical analyzer analyzable analyse\n",
      "expery      9  experimenter experimental experienced experimentalism experient experiential experience experimentation experiment\n",
      "analog      8  analogical analogous analog analogise analogy analogist analogue analogize\n",
      "hospit      8  hospitalize hospitality hospitalise hospital hospitable hospitableness hospitalisation hospitalization\n",
      "digit      14  digitizer digitalis digital digitate digitalize digit digitiser digitalisation digitization digitisation digitise digitize digitalise digitalization\n",
      "plast      11  plasterer plasticizer plasticise plastered plastic plastique plastering plasticity plaster plasticize plasticiser\n",
      "funct       7  functionary functionalist function functioning functional functionalism functionality\n",
      "commit     10  committed commissioning commissioned commissioner committal commitment commit commission committedness committee\n",
      "famili     10  familiarisation familiarising familiarizing familiarity familiarise familiar familiarized familiarised familiarize familiarization\n",
      "slack       7  slackening slacker slackness slacken slacks slacking slack\n",
      "plagi      11  plagiarizer plagiarism plagiaristic plagiarised plagiarise plagiariser plagiarize plagiarized plagiarisation plagiarist plagiarization\n",
      "affect     10  affectionateness affect affection affectional affectionate affectedness affective affecting affectation affected\n",
      "chant       7  chanting chanted chance chant chanter chancy chanceful\n",
      "regul       7  Regulus regularity regularization regularise regularisation regularize regular\n",
      "synchron   16  synchronized synchronal synchronism synchroneity synchronize synchronization synchronic synchronised synchronicity synchronous synchronisation synchroniser synchronizer synchronizing synchronise synchronising\n",
      "preserv     8  preserves preserved preserver preserve preservation preservationist preservable preservative\n",
      "conserv    13  conservative conservatism conserve conservatory conservationist conservation conservancy conserves conservativism conserved conservativist Conservative conservator\n",
      "vaccin     11  vaccinated vaccinate vaccinee vaccinator vaccination vaccina vaccinum vaccine vaccinia vaccinating Vaccinium\n",
      "sensit     13  sensitivity sensitisation sensitive sensitise sensitization sensitized sensitizing sensitiser sensitising sensitize sensitised sensitizer sensitiveness\n",
      "inspir      7  inspirational inspired inspiring inspiratory inspiration inspirer inspire\n",
      "aspir       7  aspirator aspirant aspirer aspirate aspiration aspiring aspire\n",
      "conceiv    17  conceivability conceptual conception conceptualization conceptualise conceptional conceptive conceptuality conceivableness conceptualize conceive conceivable conceptualistic concept conceiver conceptualisation conceptualism\n",
      "pleas      10  pleasing pleasance pleasurable please pleasantness pleasingness pleaser pleased pleasure pleasant\n",
      "integr      9  integrity integral integrative integrating integrated integrate integration integrator integrality\n",
      "construct   7  constructive constructiveness constructivist construction constructor constructivism construct\n",
      "perceiv    10  perceiver perceivable perceptive perceptual perceptivity perception percept perceived perceptiveness perceive\n",
      "observ     10  observational observed observance observation observer observing observant observe observable observatory\n",
      "class      16  class classification classicist classicalism classic classicistic classificatory classicize classifiable classicism classify classical classifier classics classified classicise\n",
      "indust      9  industrialization industrialize industrialist industrial industrialisation industrialised industrialism industrialized industrialise\n",
      "lamin       7  laminar Laminariales lamina lamination laminal laminate laminator\n",
      "novel       7  novel novelist novelize novelty novelisation novelization novelise\n",
      "extern      7  externality externalize external extern externalisation externalization externalise\n",
      "sculpt      8  sculpted Sculptor sculpturer sculptured sculpt sculptor sculptural sculpture\n",
      "commerc    10  commercialization commercialised commercialisation commercialise commercialize commercial Commerce commercialism commerce commercialized\n",
      "revolv      9  revolutionise revolve revolutionist revolutionize revolved revolutionary revolution revolutionism revolver\n",
      "spoil       7  spoilage spoilable spoiled spoilation spoiling spoiler spoil\n",
      "standard    9  standard standardizer standardize standardized standardised standardiser standardise standardisation standardization\n",
      "random      8  randomise randomized randomization randomisation randomised randomize random randomness\n",
      "system     16  systematize systematisation systematism systemize systematization system systemizer systemiser systematist systematics systematizer systematise systematiser systemise systemic systematic\n",
      "alphabet   11  alphabetic alphabet alphabetization alphabetical alphabetiser alphabetisation alphabetized alphabetise alphabetised alphabetize alphabetizer\n",
      "categ      10  categorisation categorise categorised categorical categorial category categorized categorization categoric categorize\n",
      "compart    10  compartmentalisation compartmentalized compartmented compartmentalize compartmental compartmentalise compartmentalised compartmentalization compart compartment\n",
      "collect    17  collectivized collectivist collecting collected collectivization collector collect collectivised collectible collectivism collectivise collectable collectivistic collection collectivisation collectivize collective\n",
      "territ      7  territory territorialization territoriality territorial territorialize territorialisation territorialise\n",
      "continu    11  continuous continuity continuousness continue continuation continuative continuum continuing continued continuant continuance\n",
      "confirm     7  confirm confirmatory confirmation confirmed confirming confirmative confirmable\n",
      "sanct       9  sanction sanctionative sanctity sanctified sanctioning sanctioned sanctum sanctification sanctify\n",
      "canon      10  canonise canonist canonize canonical canonization canon canonisation canonized canonic canonised\n",
      "supply      7  supply supplication supplier supplying suppliant supplicate supplicatory\n",
      "revit       8  revitalizing revitalised revitalisation revitalise revitalize revitalising revitalization revitalized\n",
      "provid     11  providence provision provisioner provisional provider provisions provide provident Providence provisionary providential\n",
      "stock       7  stock stocker stocks stockinged stocked stocking stockist\n",
      "hesit       8  hesitater hesitance hesitancy hesitant hesitating hesitator hesitation hesitate\n",
      "veget       9  vegetarian vegetation vegetate vegetational vegetal vegetarianism vegetive vegetative vegetable\n",
      "chast       7  chastity chastise chasten chastening chastisement chasteness chaste\n",
      "suppress    7  suppressive suppression suppressor suppressant suppresser suppress suppressed\n",
      "luxury      7  luxurious luxuriate luxuriousness luxuriant luxuriation luxuriance luxury\n",
      "comply     11  complicated compliment compliancy complimentary complication compliments complicate compliant comply complicatedness compliance\n",
      "distribut   8  distributive distributer distributed distributor distributional distribution distribute distributary\n",
      "dispens     8  dispensability dispensed dispenser dispensable dispensation dispensary dispense dispensableness\n",
      "arbit      14  arbitrage arbiter arbitrary arbitration arbitrement arbitrate arbitral arbitrariness arbitrager arbitrable arbitrational arbitrative arbitrator arbitrageur\n",
      "patron      9  patronage patronised patronising patronized patron patronize patronise patronne patronizing\n",
      "advert     14  advertent advertizement advertizing advertency advertize advertence advertorial advertizer advertiser advertise advertised advert advertising advertisement\n",
      "republ      7  republican republication Republican republishing republic republish republicanism\n",
      "secul       7  secularism secularize secularise secularist secularisation secularization secular\n",
      "import      8  importance importing imported import important importation importer importee\n",
      "crimin     11  criminatory criminalize criminalism criminalization criminalise criminative criminality criminate criminalness criminalisation criminal\n",
      "domin      18  dominus Dominique dominion Dominican dominance domineeringness dominee Dominic domineer dominating dominant Dominion dominated domination domine dominical domineering dominate\n",
      "monopol     8  monopolisation monopolist monopolization monopolise monopolistic monopolize monopoliser monopolizer\n",
      "oblig      10  obligingness oblige obliging obligation obligatory obligated obligational obliged obligate obliger\n",
      "respect     9  respected respectfulness respectful respective respectable respecter respect respectability respects\n",
      "conduc      9  conductance conducive conduction conduce conduct conductivity conductor conducting conductive\n",
      "superv      7  supervised supervisory supervene supervising supervisor supervise supervention\n",
      "immobl      7  immobilizing immobile immobility immobilization immobilise immobilisation immobilize\n",
      "contain     8  container containerize contain contained containership containerful containment containerise\n",
      "discrimin   7  discriminable discriminative discrimination discriminatory discriminator discriminating discriminate\n",
      "milit      15  military militia militaristic militant militarize militancy militarization militarisation militarism militarist militance militarized militarised militate militarise\n",
      "stabl      15  stabilisation stabilizing stabilising stabilization stableness stabilise stabile stabilised stabilize stabling stabilized stable stabilizer stabiliser stability\n",
      "lapid       8  lapidify lapidarist lapidate lapidation lapidarian lapidist lapidary lapidator\n",
      "contest     7  contestable contestant contestation contest contestee contester contested\n",
      "affirm      8  affirmative affirm affirmation affirmer affirmatory affirmativeness affirmable Affirmed\n",
      "legitim     7  legitimate legitimatize legitimize legitimatise legitimacy legitimise legitimation\n",
      "conform     8  conformable conformity conformation conform conformist conforming conformism conformance\n",
      "comfort     7  comforting comforts comfortable comforter comfort comforted comfortableness\n",
      "admir       8  admirability admirableness admirable admiration admired admiral admire admirer\n",
      "senty      14  sentiment sentimentise sentimental sentimentalisation sentimentalise sentience sentimentalization sentimentalist sentimentality sentimentalize sentimentize sentimentalism sentiency sentient\n",
      "stigm       8  stigma stigmatize stigmatist stigmatise stigmatization stigmatism stigmatisation stigmatic\n",
      "scand      10  scandalousness scandal scandalisation scansion scandalization scandalous scandent scandium scandalize scandalise\n",
      "civil       9  civilization civilize civilise civilisation civility civilised civilized civil civilian\n",
      "court       7  courteous courtship courtliness Court court courtly courting\n",
      "congreg     8  congregational Congregationalism Congregationalist congregant congregation congregate congregating Congregational\n",
      "attend      7  attended attendant attendance attendee attender attend attending\n",
      "democr      9  democratization democrat democratise Democratic democratisation democracy democratic Democrat democratize\n",
      "invalid     9  invalidation invalidating invalidator invalidism invalidity invalidated invalid invalidness invalidate\n",
      "harmon     13  harmonization harmonics harmoniser harmonisation harmonised harmonizer harmonized harmonizable harmonize harmonic harmonise harmonium harmonical\n",
      "actin       8  actinium actinal actinic Actinia actinian actinism actinia actin\n",
      "stern       7  sternness sternal stern sternum Sterna Sterne Stern\n",
      "genet       7  genetic geneticist geneticism genet Genet genetics genetical\n",
      "monochrom   8  monochromacy monochromous monochromatism monochromic monochromatic monochromat monochromia monochrome\n",
      "carbon     12  carbonic carboniferous carbonated carbonate carbonation carbonize carbonization carbon Carboniferous carbonise carbonisation carbonous\n",
      "chart       7  chartered Chartist chart Chartres chartist charter Chartism\n",
      "coron       7  coronal coronate coronion corona coroner coronation coronary\n",
      "digest      7  digestibleness digestive digest digestion digestible digestibility digester\n",
      "refract     8  refractivity refractory refractoriness refract refraction refractive refracture refractiveness\n",
      "green       9  greening greenish greenness greens greenhood Green green greenishness Greene\n",
      "magnet     10  magnetism magnetize magnetise magnetic magnetisation magnetics magnetised magnetization magnetized magnet\n",
      "marin       7  Marines marine Marini marina marinate Marine mariner\n",
      "illumin     7  illuminant illuminance illuminate illuminating illumine illumination illuminated\n",
      "narcot      7  narcotized narcotize narcotised narcotising narcotic narcotizing narcotise\n",
      "precipit   10  precipitant precipitator precipitating precipitateness precipitance precipitate precipitation precipitousness precipitancy precipitous\n",
      "reflect    12  reflected reflexion reflectiveness reflectorize reflectorise reflect reflective reflector reflection reflectivity reflectance reflecting\n",
      "therm       7  thermionics thermion thermionic therm thermic thermal thermistor\n",
      "tranquil   13  tranquillising tranquillize tranquillizing tranquilising tranquillise tranquil tranquillity tranquillizer tranquilliser tranquilizing tranquilize tranquilizer tranquility\n",
      "univers     9  universe universalise university universality universalism universalize universal universalist universalistic\n",
      "obsess      7  obsessed obsess obsessional obsessiveness obsessive obsessivity obsession\n",
      "volatil     8  volatile volatilized volatilisable volatilizable volatilised volatilize volatilise volatility\n",
      "viril       7  virile virilization virilise virility virilize virilisation virilism\n",
      "depend      9  dependence dependable dependability dependableness dependent dependency depend dependant dependance\n",
      "solid       9  solidify solidifying solidness solid solidification solidity solidified solidus solidarity\n",
      "effect     11  effecter effect effector effected effectual effectivity effectualness effects effectiveness effective effectuality\n",
      "attract     7  attractor attractable attraction attractiveness attractive attract attracter\n",
      "distinct    8  distinctiveness distinguishable distinct distinctive distinction distinctness distinguished distinguish\n",
      "const       9  constancy constringe Constance Constable construal constant constable constatation constantan\n",
      "margin      7  margin marginal marginality marginalization marginalize marginalisation marginalise\n",
      "unlik       7  unlike unlikelihood unlikeable unlikeness unlikeliness unlikable unlikely\n",
      "particul   10  particularised particularization particularity particularistic particular particularize particularisation particularized particularise particularism\n",
      "common      7  common commonness Commons commonage commons commonality commoner\n",
      "cathol      7  catholicity Catholicism Catholic Catholicity catholic catholicise catholicize\n",
      "inform     12  informatory informality informing informative informal informatics informant inform informational informed informer information\n",
      "supern      7  supernal supernaturalness supernaturalist supernatant supernatural supernaturalism supernaturalistic\n",
      "refin       8  refined refiner refinance refining refine refinisher refinish refinement\n",
      "diplom      7  diplomate diplomatical diploma diplomat diplomatic diplomatist diplomacy\n",
      "malign      7  malign malignance malignancy malignant malignity maligner malignment\n",
      "defend      7  defensive defendable defend defensiveness defender defending defendant\n",
      "contin      7  continency Continental Continent continental continence continent continual\n",
      "absorb     13  absorbed absorb absorbing absorptance absorbent absorption absorptive absorbance absorbency absorbable absorptivity absorber absorbate\n",
      "achrom      9  achromatous achromic achromia achromatize achromatic achromaticity achromatise achromatism achromous\n",
      "appet       9  appetizingness appetizer appetising appetisingness appetency appetence appetiser appetizing appetent\n",
      "contemp     7  contemporary contemporise contemporaries contemporaneous contemporaneity contemporaneousness contemporize\n",
      "fertil      9  fertilization fertilize fertiliser fertilise fertilizer fertilisation fertile fertilizable fertility\n",
      "assert      8  assertiveness asserted asserting assertion assertive asserter assertable assert\n",
      "occid       8  Occidentalism Occidental occidental Occident occident occidentalism occidentalize occidentalise\n",
      "confid      8  confident confide confiding confidant confidante confidential confidence confidentiality\n",
      "inquisit    8  Inquisitor inquisitiveness inquisitory inquisition inquisitorial Inquisition inquisitor inquisitive\n",
      "assimil     7  assimilative assimilation assimilating assimilate assimilator assimilable assimilatory\n",
      "crystal     7  crystallise crystallized crystallised crystallize crystallisation crystallization crystallizing\n",
      "anticip     7  anticipation anticipated anticipatory anticipant anticipate anticipator anticipative\n",
      "syllog      7  syllogistic syllogiser syllogist syllogizer syllogism syllogise syllogize\n",
      "convers     8  conversant conversational conversancy conversation conversationalist conversationist conversance converse\n",
      "describ     7  describe description descriptive described descriptor describable descriptivism\n",
      "philosoph   9  philosophical philosophizing philosophic philosophize philosophise philosophy philosophizer philosopher philosophiser\n",
      "predestin   7  predestinarianism predestine predestinarian predestinationist predestination predestined predestinate\n",
      "demon       7  demon demonic demonisation demonize demonization demonism demonise\n",
      "sceiv       7  sceptre scepter sceptred sceptic sceptered scepticism sceptical\n",
      "mytholog    8  mythologist mythological mythologization mythologisation mythologize mythology mythologise mythologic\n",
      "polem       9  polemical polemicize polemicist polemist polemise polemize polemic polemics polemicise\n",
      "transcend   7  transcend transcendence transcendentalism transcendent transcendentalist transcendency transcendental\n",
      "evangel     9  evangel evangelistic evangelist evangelicalism evangelism Evangelist evangelise evangelize evangelical\n",
      "latin       8  latinate Latinism Latinise Latinize latinise Latin Latinist latinize\n",
      "accus       9  accusative accusing accuser accusatory accusation accusal accuse accusatorial accused\n",
      "alleg      11  allege allegement allegoric alleged allegorical allegory allegation allegorize allegoriser allegorizer allegorise\n",
      "angel       7  angel angelique angelus angelical angelic Angel Angelus\n",
      "western     7  westernize Western western Westernisation westerner Westernization westernise\n",
      "attest      7  attestant attester attestor attestation attested attest attestator\n",
      "europ       9  Europeanise Europa Europe European Europan Europeanisation Europeanize Europeanization europium\n",
      "archa       8  archaean archaise archaize archaic archaism archaist archaistic archaicism\n",
      "inculp      7  inculpability inculpable inculpableness inculpation inculpatory inculpative inculpate\n",
      "suburb      7  suburbanise suburbia suburbanized suburbanised suburb suburban suburbanize\n",
      "stalin      7  Stalinism Stalinisation Stalinization Stalinist stalinise Stalin stalinize\n",
      "alchem      7  alchemise alchemistical alchemize alchemical alchemic alchemistic alchemist\n",
      "recogn      8  recognized recognizance recognisable recognised recognize recognisance recognizable recognise\n",
      "acetyl      8  acetylise acetyl acetylene acetylenic acetylate acetylic acetylation acetylize\n",
      "syncret     7  syncretize syncretistic syncretistical syncretise syncretical syncretism syncretic\n",
      "alumin      8  aluminous aluminium aluminise aluminate aluminum alumina aluminize aluminiferous\n"
     ]
    }
   ],
   "source": [
    "for (k,v) in stem_dict.items():\n",
    "    if len(v) > 6 and len(k) > 4:\n",
    "        print(f\"{k:<10} {len(v):>2}  {\" \".join(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b8b2c",
   "metadata": {},
   "source": [
    "Next step: filter results back to word, pos pairs known in WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "613e6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_poses = (\"a\",\"v\", \"n\")\n",
    "\n",
    "def make_word2stem_dict():\n",
    "    \"\"\"\n",
    "    key is a word pos pairs; val is the unique stem\n",
    "    for that pair.\n",
    "    \"\"\"\n",
    "    word2stem_dict = dict()\n",
    "    for (stem0, word_set) in stem_dict.items():\n",
    "        if len(stem0) < 3:\n",
    "            continue\n",
    "        for word in word_set:\n",
    "            for pos in legal_poses:\n",
    "                if wn.synsets(word,pos):\n",
    "                    if (word,pos) in word2stem_dict:\n",
    "                        raise Exception(\"Ambiguous stem for {word} {pos} {stem0} {word2stem_dict[(word,pos)]}\")\n",
    "                    word2stem_dict[(word,pos)] = stem0\n",
    "    return word2stem_dict \n",
    "\n",
    "word2stem_dict  = make_word2stem_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ddda233a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avy'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2stem_dict[(\"aviation\",\"n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a744b32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('elation.n.01'), Synset('elation.n.02')]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"elation\",\"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4870a6",
   "metadata": {},
   "source": [
    "Demoing the idea of the above mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "e3fb120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communion              commun     n\n",
      "Communist              commun     a n\n",
      "communalism            commun     n\n",
      "commune                commun     v n\n",
      "communicant            commun     n\n",
      "communicating          commun     v n\n",
      "communication          commun     n\n",
      "communications         commun     n\n",
      "communicativeness      commun     n\n",
      "communicator           commun     n\n",
      "communion              commun     n\n",
      "communique             commun     n\n",
      "communisation          commun     n\n",
      "communism              commun     n\n",
      "communist              commun     a n\n",
      "community              commun     n\n",
      "communization          commun     n\n",
      "\n",
      "fruit                  fruit      v n\n",
      "fruitage               fruit      n\n",
      "fruiterer              fruit      n\n",
      "fruitfulness           fruit      n\n",
      "fruition               fruit      n\n",
      "\n",
      "International          intern     a n\n",
      "Internationale         intern     n\n",
      "intern                 intern     v n\n",
      "internalisation        intern     n\n",
      "internality            intern     n\n",
      "internalization        intern     n\n",
      "internationalisation   intern     n\n",
      "internationalism       intern     n\n",
      "internationalist       intern     a n\n",
      "internationality       intern     n\n",
      "internationalization   intern     n\n",
      "interne                intern     n\n",
      "internee               intern     n\n",
      "internist              intern     n\n",
      "internment             intern     n\n",
      "internship             intern     n\n",
      "\n",
      "interpretation         interpret  n\n",
      "interpreter            interpret  n\n",
      "interpreting           interpret  v n\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_poses(word):\n",
    "    return [pos for pos in \"a v n\".split() if wn.synsets(word,pos)]\n",
    "    \n",
    "for stem in [\"commun\",\"fruit\", \"intern\", \"interpret\"]:\n",
    "    for word in sorted(list(stem_dict[stem])):\n",
    "        pos_list = find_poses(word)\n",
    "        print(f\"{word:<20}   {stem:<10} {' '.join(pos_list)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "09c4c1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avy'"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2stem_dict[(\"aviation\",\"n\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2ab53",
   "metadata": {},
   "source": [
    "Find verbs related to the noun aviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "68d940b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly\n",
      "aviate\n",
      "pilot\n"
     ]
    }
   ],
   "source": [
    "st_avy = word2stem_dict[(\"aviation\",\"n\")]\n",
    "for wd in stem_dict[st_avy]:\n",
    "    for ss in wn.synsets(wd,\"v\"):\n",
    "        for l in ss.lemmas():\n",
    "            print(l.name())\n",
    "        #print(lem.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2004d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_absolute_root = wn.synset(\"entity.n.01\")\n",
    "\n",
    "def get_related_lemmas(word,pos1,pos2,upper_bound=None):\n",
    "    results = set()\n",
    "    try:\n",
    "        st_avy = word2stem_dict[(word,pos1)]\n",
    "    except KeyError:\n",
    "        return []\n",
    "    for wd in stem_dict[st_avy]:\n",
    "        for ss in wn.synsets(wd,pos2):\n",
    "            if upper_bound is not None and upper_bound in get_hypers_iter(ss):\n",
    "                for l in ss.lemmas():\n",
    "                    results.add(l)\n",
    "            elif upper_bound is None:\n",
    "                for l in ss.lemmas():\n",
    "                    results.add(l)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7b66b244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Lemma('fly.v.03.aviate'), Lemma('fly.v.03.fly'), Lemma('fly.v.03.pilot')}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_related_lemmas(\"aviation\",\"n\",\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "90ea5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Lemma('flying.s.02.fast'),\n",
       " Lemma('fast-flying.s.01.fast-flying'),\n",
       " Lemma('fly.s.01.fly'),\n",
       " Lemma('fast-flying.s.01.flying'),\n",
       " Lemma('flying.s.02.quick')}"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_related_lemmas(\"fly\",\"v\",\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "ab8e689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Lemma('aviator.n.01.aeronaut'),\n",
       " Lemma('air_travel.n.01.air'),\n",
       " Lemma('aviation.n.01.air_power'),\n",
       " Lemma('air_travel.n.01.air_travel'),\n",
       " Lemma('aviator.n.01.airman'),\n",
       " Lemma('aviation.n.03.airmanship'),\n",
       " Lemma('aviary.n.01.aviary'),\n",
       " Lemma('aviation.n.01.aviation'),\n",
       " Lemma('aviator.n.01.aviator'),\n",
       " Lemma('aviary.n.01.bird_sanctuary'),\n",
       " Lemma('aviator.n.01.flier'),\n",
       " Lemma('aviator.n.01.flyer'),\n",
       " Lemma('aviary.n.01.volary')}"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_related_lemmas(\"aviate\",\"v\",\"n\",upper_bound=wn_absolute_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "d8ae5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = wn.synset(\"happiness.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "c0cc096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happiness', 'felicity']"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "cfab87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "class STD ():\n",
    "\n",
    "    def __enter__(self):\n",
    "        return sys.stdout\n",
    "    \n",
    "    def __exit__ (self,a,b,c):\n",
    "        return \n",
    "\n",
    "std_inst = STD()\n",
    "\n",
    "\n",
    "def make_noun2related_adj_dict():\n",
    "    noun2related_adj_dict = defaultdict(set)\n",
    "      \n",
    "    for ss in feeling_nouns:\n",
    "        #for ss in [wn.synset('happiness.n.01')]:\n",
    "        nm = ss.name()\n",
    "        for ln in ss.lemma_names():\n",
    "            #print(nm, ln,file=ofh,end=\"\\n   \")\n",
    "            for rel_l in get_related_lemmas(ln,\"n\",\"a\"):\n",
    "                #print(rel_l.name(),file=ofh,end=\" \")\n",
    "                noun2related_adj_dict[nm].add(rel_l)\n",
    "            #print(\"\\n\",end=\"\",file=ofh)\n",
    "        # Guarantees at least an empty set entry for ln\n",
    "        noun2related_adj_dict[nm]\n",
    "    return noun2related_adj_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_dict_yield(dd):\n",
    "    \"\"\"\n",
    "    dd is a dict with container values\n",
    "    \"\"\"\n",
    "    L = list(dd.items())\n",
    "    S = set()\n",
    "    for (lem, wd_set) in L:\n",
    "        S.update(wd_set)\n",
    "    return S\n",
    "\n",
    "def get_lemma_string(lem):\n",
    "    return f\"{lem.synset().name()}.{lem.name()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d0262",
   "metadata": {},
   "source": [
    "Retired code in next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5d937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_make_noun2related_adj_dict(fn=None):\n",
    "    noun2related_adj_dict = defaultdict(set)\n",
    "    \n",
    "    if fn is None:\n",
    "        entry = STD()\n",
    "    else:\n",
    "        entry = open(fn,\"w\") \n",
    "        \n",
    "    with entry as ofh:\n",
    "        for ss in feeling_nouns:\n",
    "            #for ss in [wn.synset('happiness.n.01')]:\n",
    "            nm = ss.name()\n",
    "            for ln in ss.lemma_names():\n",
    "                print(nm, ln,file=ofh,end=\"\\n   \")\n",
    "                for rel_l in get_related_lemmas(ln,\"n\",\"a\"):\n",
    "                    print(rel_l.name(),file=ofh,end=\" \")\n",
    "                    noun2related_adj_dict[nm].add(rel_l.name())\n",
    "                print(\"\\n\",end=\"\",file=ofh)\n",
    "    return noun2related_adj_dict\n",
    "\n",
    "def old_make_noun2related_adj_dict_simple():\n",
    "    \"\"\"\n",
    "    This circumvents the stemmer, just using the lemmas attribute\n",
    "    .derivationally_related_forms().  Much lower sized yield,\n",
    "    but some new adjectival forms are found.  Presumably\n",
    "    less noise as well.\n",
    "    \"\"\"\n",
    "    noun2related_adj_dict2 = defaultdict(set) \n",
    "    for ss in feeling_nouns:\n",
    "        nm = ss.name()\n",
    "        for ln in ss.lemmas():\n",
    "            ln_name = get_lemma_name(ln)\n",
    "            #print(nm, ln,file=ofh,end=\"\\n   \")\n",
    "            related_forms = ln.derivationally_related_forms()\n",
    "            for rel_l in related_forms:\n",
    "                if rel_l.synset().pos() in [\"a\",\"s\"]:\n",
    "                    #print(f\"{rel_l} [{rel_l.name()}]\",file=ofh,end=\" \")\n",
    "                    #noun2related_adj_dict2[ln_name].add(get_lemma_name(rel_l))\n",
    "                    noun2related_adj_dict2[ln_name].add(rel_l)\n",
    "            # Guarantees at least an empoty set entry for ln\n",
    "            noun2related_adj_dict2[ln_name]\n",
    "    return noun2related_adj_dict2\n",
    "\n",
    "def update_related_form_dict(ln_name, rel_l, dd, pos_seq, with_synset=False):\n",
    "    ss_rel = rel_l.synset()\n",
    "    if ss_rel.pos() in pos_seq:\n",
    "        for ss_rel_l2 in rel_ss.lemmas():\n",
    "            if with_synset:\n",
    "                added = ss_rel_l2.synset.name()\n",
    "            else:\n",
    "                added = ss_rel_l2.name()\n",
    "            dd[ln_name].add(added)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bff8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noun2related_adj_dict():\n",
    "    noun2related_adj_dict = defaultdict(set)\n",
    "      \n",
    "    for ss in feeling_nouns:\n",
    "        #for ss in [wn.synset('happiness.n.01')]:\n",
    "        nm = ss.name()\n",
    "        for lem in ss.lemmas():\n",
    "            ln = lem.name()\n",
    "            lem_str = get_lemma_string(lem)\n",
    "            #ln_name = get_lemma_name(ln)\n",
    "            #print(nm, ln,file=ofh,end=\"\\n   \")\n",
    "            for rel_l in get_related_lemmas(ln,\"n\",\"a\"):\n",
    "                #noun2related_adj_dict[nm].add(rel_l.name())\n",
    "                #update_related_form_dict(ln_name, rel_l.synset(), noun2related_adj_dict)\n",
    "                update_related_form_dict(lem_str, rel_l.synset(), noun2related_adj_dict)\n",
    "            # Guarantees at least an empty set entry for ln\n",
    "            noun2related_adj_dict[lem_str]\n",
    "    return noun2related_adj_dict\n",
    "\n",
    "\n",
    "def make_noun2related_adj_dict_simple(pos_seq=(\"a\",\"s\"),with_synset=False):\n",
    "    \"\"\"\n",
    "    This circumvents the stemmer, just using the lemmas attribute\n",
    "    .derivationally_related_forms().  Much lower sized yield,\n",
    "    but some new adjectival forms are found.  Presumably\n",
    "    less noise as well.\n",
    "    \"\"\"\n",
    "    noun2related_adj_dict2 = defaultdict(set) \n",
    "    for ss in feeling_nouns:\n",
    "        nm = ss.name()\n",
    "        for ln in ss.lemmas():\n",
    "            ln_str = get_lemma_string(ln)\n",
    "            #print(nm, ln,file=ofh,end=\"\\n   \")\n",
    "            related_forms = ln.derivationally_related_forms()\n",
    "            for rel_l in related_forms:\n",
    "                rel_ss = rel_l.synset()\n",
    "                if rel_ss.pos() in pos_seq:\n",
    "                    update_related_form_dict(ln_str, rel_ss, noun2related_adj_dict2,with_synset=with_synset)\n",
    "                    #print(f\"{rel_l} [{rel_l.name()}]\",file=ofh,end=\" \")\n",
    "                    #for ss_rel_l2 in ss_rel.lemmas():\n",
    "                    #    noun2related_adj_dict2[ln_name].add(ss_rel_l2.name())\n",
    "                    #    #noun2related_adj_dict2[ln_name].add(get_lemma_name(ss_rel_l2))\n",
    "                    #    #noun2related_adj_dict2[ln_name].add(rel_l)\n",
    "            # Guarantees at least an empty set entry for ln\n",
    "            noun2related_adj_dict2[ln_str]\n",
    "    return noun2related_adj_dict2\n",
    "\n",
    "def update_related_form_dict(ln_name, rel_ss, dd):\n",
    "    for ln in rel_ss.lemma_names():\n",
    "        dd[ln_name].add(ln)\n",
    "\n",
    "def write_dict_to_file(ln_dict, fn=None):\n",
    "    \"\"\"\n",
    "    This circumvents the stemmer, just using the lemmas attribute\n",
    "    .derivationally_related_forms().  Much lower sized yield,\n",
    "    but some new adjectival forms are found.  Presumably\n",
    "    less noise as well.\n",
    "    \"\"\"\n",
    "    #noun2related_adj_dict2 = defaultdict(set)\n",
    "   \n",
    "    if fn is None:\n",
    "        entry = STD()\n",
    "    else:\n",
    "        entry = open(fn,\"w\") \n",
    " \n",
    "    sorted_lns= sorted(ln_dict.keys())\n",
    "    with entry as ofh:\n",
    "        for nm in sorted_lns:\n",
    "            #nm = ss.name()\n",
    "            print(nm, file=ofh,end=\"\\n   \")\n",
    "            for wd in ln_dict[nm]:#ss.lemmas():\n",
    "                #related_forms = ln.derivationally_related_forms()\n",
    "                #for rel_l in related_forms:\n",
    "                #    if rel_l.synset().pos() in [\"a\",\"s\"]:\n",
    "                #rel_l_name = f\"{rel_l.synset().name()}.{rel_l.name()}\"\n",
    "                print(f\"{wd}\",file=ofh,end=\"\\n   \")\n",
    "                #noun2related_adj_dict2[nm].add(rel_l.name())\n",
    "            print(\"\\n\",end=\"\",file=ofh)\n",
    "\n",
    "def update_set_valued_dict (dd1,dd2):\n",
    "    \"\"\"\n",
    "    dd1 and dd2 have the same keys and setlike values\n",
    "    unoin those setlike bvalues\n",
    "    \"\"\"\n",
    "    for k in dd2:\n",
    "        dd1[k].update(dd2[k])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899bc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "0b8b397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun2related_adj_dict22 has 856 noun lemmas with 613 related adjectives\n"
     ]
    }
   ],
   "source": [
    "noun2related_adj_dict22 = make_noun2related_adj_dict_simple()\n",
    "adj_yield22 = get_dict_yield(noun2related_adj_dict22)\n",
    "dd_yield22a = len(adj_yield22)\n",
    "print(f\"noun2related_adj_dict22 has {len(noun2related_adj_dict22)} noun lemmas with {dd_yield22a} related adjectives\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3edc5054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'ardor.n.03.ardor': set(),\n",
       "             'ardor.n.03.ardour': set(),\n",
       "             'ardor.n.03.fervor': set(),\n",
       "             'ardor.n.03.fervour': set(),\n",
       "             'ardor.n.03.fervency': {'ardent',\n",
       "              'fervent',\n",
       "              'fervid',\n",
       "              'fiery',\n",
       "              'impassioned',\n",
       "              'perfervid',\n",
       "              'torrid'},\n",
       "             'ardor.n.03.fire': {'ardent',\n",
       "              'fervent',\n",
       "              'fervid',\n",
       "              'fiery',\n",
       "              'impassioned',\n",
       "              'perfervid',\n",
       "              'torrid'},\n",
       "             'ardor.n.03.fervidness': {'ardent',\n",
       "              'fervent',\n",
       "              'fervid',\n",
       "              'fiery',\n",
       "              'impassioned',\n",
       "              'perfervid',\n",
       "              'torrid'},\n",
       "             'worry.n.02.worry': set(),\n",
       "             'worry.n.02.trouble': set(),\n",
       "             'shamefacedness.n.01.shamefacedness': {'guilty',\n",
       "              'hangdog',\n",
       "              'shamed',\n",
       "              'shamefaced',\n",
       "              'sheepish'},\n",
       "             'shamefacedness.n.01.sheepishness': {'shamefaced', 'sheepish'},\n",
       "             'heaviness.n.02.heaviness': {'heavy'},\n",
       "             'gaiety.n.01.gaiety': set(),\n",
       "             'gaiety.n.01.merriment': set(),\n",
       "             'benevolence.n.01.benevolence': set(),\n",
       "             'scunner.n.01.scunner': set(),\n",
       "             'stewing.n.01.stewing': set(),\n",
       "             'suffering.n.04.suffering': set(),\n",
       "             'suffering.n.04.hurt': set(),\n",
       "             'plaintiveness.n.01.plaintiveness': {'mournful', 'plaintive'},\n",
       "             'dislike.n.02.dislike': set(),\n",
       "             'tumult.n.02.tumult': set(),\n",
       "             'tumult.n.02.turmoil': set(),\n",
       "             'fit.n.01.fit': set(),\n",
       "             'fit.n.01.tantrum': set(),\n",
       "             'fit.n.01.scene': set(),\n",
       "             'fit.n.01.conniption': set(),\n",
       "             'comfort.n.05.comfort': set(),\n",
       "             'anger.n.01.anger': {'angry'},\n",
       "             'anger.n.01.choler': {'choleric',\n",
       "              'hot-tempered',\n",
       "              'hotheaded',\n",
       "              'irascible',\n",
       "              'quick-tempered',\n",
       "              'short-tempered'},\n",
       "             'anger.n.01.ire': set(),\n",
       "             'stir.n.02.stir': set(),\n",
       "             'pique.n.02.pique': set(),\n",
       "             'pique.n.02.temper': set(),\n",
       "             'pique.n.02.irritation': set(),\n",
       "             'defeatism.n.01.defeatism': set(),\n",
       "             'edginess.n.01.edginess': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'edginess.n.01.uneasiness': {'uneasy'},\n",
       "             'edginess.n.01.inquietude': set(),\n",
       "             'edginess.n.01.disquietude': set(),\n",
       "             'animosity.n.01.animosity': set(),\n",
       "             'animosity.n.01.animus': set(),\n",
       "             'animosity.n.01.bad_blood': set(),\n",
       "             'good_will.n.03.good_will': set(),\n",
       "             'good_will.n.03.goodwill': set(),\n",
       "             'temper.n.02.temper': set(),\n",
       "             'temper.n.02.mood': {'moody', 'temperamental'},\n",
       "             'temper.n.02.humor': set(),\n",
       "             'temper.n.02.humour': set(),\n",
       "             'agape.n.01.agape': set(),\n",
       "             'gloom.n.02.gloom': set(),\n",
       "             'gloom.n.02.gloominess': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'gloom.n.02.somberness': {'melancholy', 'somber', 'sombre'},\n",
       "             'gloom.n.02.sombreness': {'melancholy', 'somber', 'sombre'},\n",
       "             'fever.n.02.fever': set(),\n",
       "             'belligerence.n.01.belligerence': {'aggressive', 'belligerent'},\n",
       "             'belligerence.n.01.belligerency': {'aggressive', 'belligerent'},\n",
       "             'tenderness.n.03.tenderness': {'tender'},\n",
       "             'tenderness.n.03.tenderheartedness': {'tenderhearted'},\n",
       "             'kindheartedness.n.01.kindheartedness': {'kind-hearted',\n",
       "              'kindhearted'},\n",
       "             'kindheartedness.n.01.kind-heartedness': set(),\n",
       "             'cheerlessness.n.01.cheerlessness': {'cheerless',\n",
       "              'depressing',\n",
       "              'uncheerful'},\n",
       "             'cheerlessness.n.01.uncheerfulness': {'cheerless',\n",
       "              'depressing',\n",
       "              'uncheerful'},\n",
       "             'dysphoria.n.01.dysphoria': {'distressed',\n",
       "              'dysphoric',\n",
       "              'unhappy'},\n",
       "             'sexual_pleasure.n.01.sexual_pleasure': set(),\n",
       "             'protectiveness.n.01.protectiveness': {'protective'},\n",
       "             'frustration.n.01.frustration': set(),\n",
       "             'frustration.n.01.defeat': set(),\n",
       "             'stage_fright.n.01.stage_fright': set(),\n",
       "             'appetite.n.01.appetite': set(),\n",
       "             'appetite.n.01.appetency': {'appetent'},\n",
       "             'appetite.n.01.appetence': {'appetent'},\n",
       "             'comfortableness.n.02.comfortableness': {'comfortable'},\n",
       "             'annoyance.n.02.annoyance': set(),\n",
       "             'annoyance.n.02.chafe': set(),\n",
       "             'annoyance.n.02.vexation': set(),\n",
       "             'unhappiness.n.02.unhappiness': {'unhappy'},\n",
       "             'earnestness.n.01.earnestness': {'dear',\n",
       "              'devout',\n",
       "              'earnest',\n",
       "              'heartfelt'},\n",
       "             'earnestness.n.01.seriousness': set(),\n",
       "             'earnestness.n.01.sincerity': {'earnest', 'sincere', 'solemn'},\n",
       "             'relief.n.01.relief': set(),\n",
       "             'relief.n.01.alleviation': set(),\n",
       "             'relief.n.01.assuagement': set(),\n",
       "             'cruelty.n.02.cruelty': set(),\n",
       "             'cruelty.n.02.mercilessness': {'merciless', 'unmerciful'},\n",
       "             'cruelty.n.02.pitilessness': {'pitiless', 'unkind'},\n",
       "             'cruelty.n.02.ruthlessness': {'pitiless',\n",
       "              'remorseless',\n",
       "              'ruthless',\n",
       "              'unpitying'},\n",
       "             'longing.n.01.longing': set(),\n",
       "             'longing.n.01.yearning': set(),\n",
       "             'longing.n.01.hungriness': {'athirst', 'hungry', 'thirsty'},\n",
       "             'wonder.n.01.wonder': set(),\n",
       "             'wonder.n.01.wonderment': set(),\n",
       "             'wonder.n.01.admiration': set(),\n",
       "             'misogyny.n.01.misogyny': {'misogynic',\n",
       "              'misogynistic',\n",
       "              'misogynous'},\n",
       "             'misogyny.n.01.misogynism': set(),\n",
       "             'stupefaction.n.01.stupefaction': set(),\n",
       "             'algolagnia.n.01.algolagnia': {'algolagnic'},\n",
       "             'algolagnia.n.01.algophilia': set(),\n",
       "             'anxiety.n.02.anxiety': set(),\n",
       "             'fear.n.03.fear': set(),\n",
       "             'fear.n.03.reverence': {'godly',\n",
       "              'respectful',\n",
       "              'reverent',\n",
       "              'reverential',\n",
       "              'venerating',\n",
       "              'worshipful'},\n",
       "             'fear.n.03.awe': set(),\n",
       "             'fear.n.03.veneration': set(),\n",
       "             'dissatisfaction.n.01.dissatisfaction': set(),\n",
       "             'unpleasantness.n.01.unpleasantness': {'unpleasant'},\n",
       "             'belonging.n.01.belonging': set(),\n",
       "             'euphoria.n.01.euphoria': set(),\n",
       "             'euphoria.n.01.euphory': {'euphoric'},\n",
       "             'guilt_pang.n.01.guilt_pang': set(),\n",
       "             'dolor.n.01.dolor': {'dolorous',\n",
       "              'dolourous',\n",
       "              'lachrymose',\n",
       "              'tearful',\n",
       "              'weeping'},\n",
       "             'dolor.n.01.dolour': set(),\n",
       "             'shadow.n.04.shadow': set(),\n",
       "             'sulk.n.01.sulk': {'huffish', 'sulky'},\n",
       "             'sulk.n.01.sulkiness': {'huffish', 'sulky'},\n",
       "             'solicitude.n.01.solicitude': set(),\n",
       "             'solicitude.n.01.solicitousness': {'solicitous'},\n",
       "             'hysteria.n.02.hysteria': {'hysterical'},\n",
       "             'penis_envy.n.01.penis_envy': set(),\n",
       "             'civic_pride.n.01.civic_pride': set(),\n",
       "             'civic_pride.n.01.civic_spirit': set(),\n",
       "             'urge.n.02.urge': set(),\n",
       "             'urge.n.02.itch': set(),\n",
       "             'optimism.n.01.optimism': {'affirmative', 'optimistic'},\n",
       "             'intoxication.n.03.intoxication': set(),\n",
       "             'security.n.03.security': {'secure', 'unafraid', 'untroubled'},\n",
       "             'despondency.n.01.despondency': {'despondent', 'heartsick'},\n",
       "             'despondency.n.01.despondence': {'despondent', 'heartsick'},\n",
       "             'despondency.n.01.heartsickness': {'brokenhearted',\n",
       "              'despondent',\n",
       "              'heartbroken',\n",
       "              'heartsick'},\n",
       "             'despondency.n.01.disconsolateness': {'disconsolate',\n",
       "              'inconsolable',\n",
       "              'unconsolable'},\n",
       "             'wish.n.01.wish': set(),\n",
       "             'wish.n.01.wishing': set(),\n",
       "             'wish.n.01.want': set(),\n",
       "             'entrancement.n.01.entrancement': set(),\n",
       "             'entrancement.n.01.ravishment': set(),\n",
       "             'favor.n.04.favor': set(),\n",
       "             'favor.n.04.favour': set(),\n",
       "             'calmness.n.03.calmness': {'calm',\n",
       "              'serene',\n",
       "              'tranquil',\n",
       "              'unagitated'},\n",
       "             'compunction.n.01.compunction': set(),\n",
       "             'compunction.n.01.remorse': set(),\n",
       "             'compunction.n.01.self-reproach': set(),\n",
       "             'misanthropy.n.01.misanthropy': {'misanthropic',\n",
       "              'misanthropical'},\n",
       "             'joy.n.01.joy': {'joyous'},\n",
       "             'joy.n.01.joyousness': {'joyous'},\n",
       "             'joy.n.01.joyfulness': {'elated',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant'},\n",
       "             'masochism.n.01.masochism': {'masochistic'},\n",
       "             'amicability.n.01.amicability': set(),\n",
       "             'amicability.n.01.amicableness': set(),\n",
       "             'forlornness.n.01.forlornness': set(),\n",
       "             'forlornness.n.01.loneliness': {'lonely', 'lonesome'},\n",
       "             'forlornness.n.01.desolation': set(),\n",
       "             'sensation.n.03.sensation': set(),\n",
       "             'horror.n.01.horror': set(),\n",
       "             'gratification.n.01.gratification': set(),\n",
       "             'gratification.n.01.satisfaction': set(),\n",
       "             'pride.n.02.pride': set(),\n",
       "             'gravity.n.03.gravity': set(),\n",
       "             'gravity.n.03.solemnity': {'earnest',\n",
       "              'grave',\n",
       "              'sedate',\n",
       "              'sincere',\n",
       "              'sober',\n",
       "              'solemn'},\n",
       "             'lovesickness.n.01.lovesickness': {'lovesick'},\n",
       "             'encouragement.n.03.encouragement': set(),\n",
       "             'testiness.n.01.testiness': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'testiness.n.01.touchiness': {'feisty',\n",
       "              'huffy',\n",
       "              'thin-skinned',\n",
       "              'touchy'},\n",
       "             'testiness.n.01.tetchiness': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'oppression.n.03.oppression': set(),\n",
       "             'oppression.n.03.oppressiveness': {'oppressive',\n",
       "              'tyrannical',\n",
       "              'tyrannous'},\n",
       "             'pensiveness.n.01.pensiveness': {'brooding',\n",
       "              'broody',\n",
       "              'contemplative',\n",
       "              'meditative',\n",
       "              'musing',\n",
       "              'pensive',\n",
       "              'pondering',\n",
       "              'reflective',\n",
       "              'ruminative'},\n",
       "             'pensiveness.n.01.brooding': set(),\n",
       "             'gloat.n.01.gloat': set(),\n",
       "             'gloat.n.01.gloating': set(),\n",
       "             'gloat.n.01.glee': set(),\n",
       "             'nirvana.n.01.nirvana': set(),\n",
       "             'nirvana.n.01.enlightenment': set(),\n",
       "             'broken_heart.n.01.broken_heart': set(),\n",
       "             'empathy.n.01.empathy': {'empathetic', 'empathic'},\n",
       "             'titillation.n.01.titillation': set(),\n",
       "             'complacency.n.01.complacency': {'complacent',\n",
       "              'self-complacent',\n",
       "              'self-satisfied'},\n",
       "             'complacency.n.01.complacence': {'complacent',\n",
       "              'self-complacent',\n",
       "              'self-satisfied'},\n",
       "             'complacency.n.01.self-complacency': {'complacent',\n",
       "              'self-complacent',\n",
       "              'self-satisfied'},\n",
       "             'complacency.n.01.self-satisfaction': set(),\n",
       "             'sexual_desire.n.01.sexual_desire': set(),\n",
       "             'sexual_desire.n.01.eros': {'erotic', 'titillating'},\n",
       "             'sexual_desire.n.01.concupiscence': {'concupiscent',\n",
       "              'lustful',\n",
       "              'lusty'},\n",
       "             'sexual_desire.n.01.physical_attraction': set(),\n",
       "             'frisson.n.01.frisson': set(),\n",
       "             'frisson.n.01.shiver': {'chilling',\n",
       "              'scarey',\n",
       "              'scary',\n",
       "              'shivery',\n",
       "              'shuddery'},\n",
       "             'frisson.n.01.chill': set(),\n",
       "             'frisson.n.01.quiver': set(),\n",
       "             'frisson.n.01.shudder': {'chilling',\n",
       "              'scarey',\n",
       "              'scary',\n",
       "              'shivery',\n",
       "              'shuddery'},\n",
       "             'frisson.n.01.thrill': set(),\n",
       "             'frisson.n.01.tingle': set(),\n",
       "             'sulkiness.n.02.sulkiness': {'huffish', 'sulky'},\n",
       "             'sulkiness.n.02.huffishness': {'huffish', 'sulky'},\n",
       "             'surprise.n.01.surprise': set(),\n",
       "             'bang.n.04.bang': set(),\n",
       "             'bang.n.04.boot': set(),\n",
       "             'bang.n.04.charge': set(),\n",
       "             'bang.n.04.rush': set(),\n",
       "             'bang.n.04.flush': set(),\n",
       "             'bang.n.04.thrill': set(),\n",
       "             'bang.n.04.kick': set(),\n",
       "             'despair.n.02.despair': set(),\n",
       "             'apprehension.n.01.apprehension': set(),\n",
       "             'apprehension.n.01.apprehensiveness': {'apprehensive', 'worried'},\n",
       "             'apprehension.n.01.dread': {'awful',\n",
       "              'dire',\n",
       "              'direful',\n",
       "              'dread',\n",
       "              'dreaded',\n",
       "              'dreadful',\n",
       "              'fearful',\n",
       "              'fearsome',\n",
       "              'frightening',\n",
       "              'horrendous',\n",
       "              'horrific',\n",
       "              'terrible'},\n",
       "             'state.n.06.state': set(),\n",
       "             'sensuousness.n.01.sensuousness': {'sensuous'},\n",
       "             'frustration.n.03.frustration': set(),\n",
       "             'mercifulness.n.01.mercifulness': {'merciful'},\n",
       "             'mercifulness.n.01.mercy': set(),\n",
       "             'fondness.n.01.fondness': {'fond', 'partial'},\n",
       "             'fondness.n.01.fancy': set(),\n",
       "             'fondness.n.01.partiality': set(),\n",
       "             'hesitance.n.01.hesitance': {'hesitant', 'hesitating'},\n",
       "             'hesitance.n.01.hesitancy': {'hesitant', 'hesitating'},\n",
       "             'sensitivity.n.03.sensitivity': {'sensitive'},\n",
       "             'sensitivity.n.03.sensitiveness': {'sensitive'},\n",
       "             'misology.n.01.misology': set(),\n",
       "             'wildness.n.01.wildness': {'wild'},\n",
       "             'wildness.n.01.abandon': set(),\n",
       "             'jocundity.n.01.jocundity': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'jocundity.n.01.jocularity': {'jesting',\n",
       "              'jocose',\n",
       "              'jocular',\n",
       "              'joking'},\n",
       "             'nostalgia.n.01.nostalgia': {'nostalgic'},\n",
       "             'hero_worship.n.01.hero_worship': set(),\n",
       "             'willies.n.01.willies': set(),\n",
       "             'passion.n.01.passion': set(),\n",
       "             'passion.n.01.passionateness': {'passionate'},\n",
       "             'survivor_guilt.n.01.survivor_guilt': set(),\n",
       "             'american_dream.n.01.American_Dream': set(),\n",
       "             'triumph.n.02.triumph': {'exultant',\n",
       "              'exulting',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'sanguinity.n.01.sanguinity': {'sanguine'},\n",
       "             'sanguinity.n.01.sanguineness': {'sanguine'},\n",
       "             'anxiousness.n.02.anxiousness': {'anxious',\n",
       "              'nervous',\n",
       "              'queasy',\n",
       "              'uneasy',\n",
       "              'unquiet'},\n",
       "             'anxiousness.n.02.disquiet': set(),\n",
       "             'foreboding.n.01.foreboding': set(),\n",
       "             'foreboding.n.01.premonition': set(),\n",
       "             'foreboding.n.01.presentiment': set(),\n",
       "             'foreboding.n.01.boding': set(),\n",
       "             'intimidation.n.02.intimidation': set(),\n",
       "             'soul.n.03.soul': set(),\n",
       "             'soul.n.03.soulfulness': {'soulful'},\n",
       "             'dolefulness.n.01.dolefulness': {'doleful', 'mournful'},\n",
       "             'sentimentality.n.02.sentimentality': {'sentimental'},\n",
       "             'electra_complex.n.01.Electra_complex': set(),\n",
       "             'oversensitiveness.n.01.oversensitiveness': {'oversensitive'},\n",
       "             'hankering.n.01.hankering': set(),\n",
       "             'hankering.n.01.yen': set(),\n",
       "             'exhilaration.n.01.exhilaration': set(),\n",
       "             'exhilaration.n.01.excitement': set(),\n",
       "             'approbation.n.01.approbation': set(),\n",
       "             'world-weariness.n.01.world-weariness': {'bored', 'world-weary'},\n",
       "             'world-weariness.n.01.Weltschmerz': set(),\n",
       "             'disinclination.n.01.disinclination': set(),\n",
       "             'mellowness.n.01.mellowness': {'mellow', 'mellowed'},\n",
       "             'bloodlust.n.01.bloodlust': set(),\n",
       "             'sorrow.n.01.sorrow': set(),\n",
       "             'angst.n.01.angst': set(),\n",
       "             'anguish.n.01.anguish': set(),\n",
       "             'anguish.n.01.torment': set(),\n",
       "             'anguish.n.01.torture': set(),\n",
       "             'caprice.n.01.caprice': {'capricious', 'impulsive', 'whimsical'},\n",
       "             'caprice.n.01.impulse': set(),\n",
       "             'caprice.n.01.whim': set(),\n",
       "             'faintness.n.01.faintness': {'faint',\n",
       "              'light',\n",
       "              'light-headed',\n",
       "              'lightheaded',\n",
       "              'swooning'},\n",
       "             'undertow.n.01.undertow': set(),\n",
       "             'joylessness.n.01.joylessness': {'joyless'},\n",
       "             'hope.n.02.hope': set(),\n",
       "             'embitterment.n.01.embitterment': set(),\n",
       "             'glow.n.04.glow': set(),\n",
       "             'devotion.n.01.devotion': set(),\n",
       "             'devotion.n.01.devotedness': {'devoted'},\n",
       "             'meekness.n.01.meekness': {'meek', 'mild', 'modest', 'tame'},\n",
       "             'meekness.n.01.submission': set(),\n",
       "             'mourning.n.01.mourning': set(),\n",
       "             'mourning.n.01.bereavement': set(),\n",
       "             'amusement.n.01.amusement': set(),\n",
       "             'infuriation.n.01.infuriation': set(),\n",
       "             'infuriation.n.01.enragement': set(),\n",
       "             'downheartedness.n.01.downheartedness': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'downheartedness.n.01.dejectedness': set(),\n",
       "             'downheartedness.n.01.low-spiritedness': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'downheartedness.n.01.lowness': {'blue',\n",
       "              'broken',\n",
       "              'crushed',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'humbled',\n",
       "              'humiliated',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'downheartedness.n.01.dispiritedness': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'listless',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'intimidation.n.03.intimidation': set(),\n",
       "             'electricity.n.03.electricity': {'electric'},\n",
       "             'heartstrings.n.01.heartstrings': set(),\n",
       "             'sensuality.n.01.sensuality': {'animal',\n",
       "              'carnal',\n",
       "              'fleshly',\n",
       "              'sensual'},\n",
       "             'sensuality.n.01.sensualness': {'animal',\n",
       "              'carnal',\n",
       "              'fleshly',\n",
       "              'sensual',\n",
       "              'sultry'},\n",
       "             'sensuality.n.01.sensualism': set(),\n",
       "             'gratitude.n.01.gratitude': set(),\n",
       "             'fatigue.n.03.fatigue': set(),\n",
       "             'maleficence.n.01.maleficence': {'maleficent'},\n",
       "             'growing_pains.n.02.growing_pains': set(),\n",
       "             'covetousness.n.01.covetousness': set(),\n",
       "             'discomfiture.n.01.discomfiture': set(),\n",
       "             'discomfiture.n.01.discomposure': set(),\n",
       "             'discomfiture.n.01.disconcertion': set(),\n",
       "             'discomfiture.n.01.disconcertment': set(),\n",
       "             'pessimism.n.01.pessimism': {'pessimistic'},\n",
       "             'attrition.n.03.attrition': set(),\n",
       "             'attrition.n.03.contrition': set(),\n",
       "             'attrition.n.03.contriteness': {'contrite',\n",
       "              'remorseful',\n",
       "              'rueful',\n",
       "              'ruthful'},\n",
       "             'misoneism.n.01.misoneism': set(),\n",
       "             'diffidence.n.01.diffidence': {'diffident',\n",
       "              'shy',\n",
       "              'timid',\n",
       "              'unsure'},\n",
       "             'diffidence.n.01.self-doubt': set(),\n",
       "             'diffidence.n.01.self-distrust': set(),\n",
       "             'self-esteem.n.01.self-esteem': set(),\n",
       "             'self-esteem.n.01.self-pride': set(),\n",
       "             'liking.n.01.liking': set(),\n",
       "             'grudge.n.01.grudge': set(),\n",
       "             'grudge.n.01.score': set(),\n",
       "             'grudge.n.01.grievance': set(),\n",
       "             'guilt.n.02.guilt': {'guilty', 'hangdog', 'shamed', 'shamefaced'},\n",
       "             'guilt.n.02.guilty_conscience': set(),\n",
       "             'guilt.n.02.guilt_feelings': set(),\n",
       "             'guilt.n.02.guilt_trip': set(),\n",
       "             'love.n.01.love': set(),\n",
       "             'depression.n.04.depression': set(),\n",
       "             'sadism.n.01.sadism': {'sadistic'},\n",
       "             'umbrage.n.01.umbrage': {'incensed',\n",
       "              'indignant',\n",
       "              'outraged',\n",
       "              'umbrageous'},\n",
       "             'umbrage.n.01.offense': set(),\n",
       "             'umbrage.n.01.offence': set(),\n",
       "             'vindictiveness.n.01.vindictiveness': {'despiteful',\n",
       "              'revengeful',\n",
       "              'spiteful',\n",
       "              'vengeful',\n",
       "              'vindictive'},\n",
       "             'vindictiveness.n.01.vengefulness': {'revengeful',\n",
       "              'vengeful',\n",
       "              'vindictive'},\n",
       "             'anglophobia.n.01.Anglophobia': {'Anglophobic'},\n",
       "             'razbliuto.n.01.razbliuto': set(),\n",
       "             'discomfort.n.02.discomfort': set(),\n",
       "             'discomfort.n.02.soreness': {'afflictive',\n",
       "              'huffy',\n",
       "              'mad',\n",
       "              'painful',\n",
       "              'sore'},\n",
       "             'discomfort.n.02.irritation': set(),\n",
       "             'chagrin.n.01.chagrin': set(),\n",
       "             'chagrin.n.01.humiliation': set(),\n",
       "             'chagrin.n.01.mortification': set(),\n",
       "             'mental_anguish.n.01.mental_anguish': set(),\n",
       "             'repugnance.n.01.repugnance': {'abhorrent',\n",
       "              'detestable',\n",
       "              'obscene',\n",
       "              'repugnant',\n",
       "              'repulsive'},\n",
       "             'repugnance.n.01.repulsion': set(),\n",
       "             'repugnance.n.01.revulsion': set(),\n",
       "             'repugnance.n.01.horror': set(),\n",
       "             'antagonism.n.03.antagonism': {'antagonistic'},\n",
       "             'satisfaction.n.01.satisfaction': set(),\n",
       "             'stomach.n.03.stomach': set(),\n",
       "             'antipathy.n.01.antipathy': {'antagonistic',\n",
       "              'antipathetic',\n",
       "              'antipathetical',\n",
       "              'averse',\n",
       "              'indisposed',\n",
       "              'loath',\n",
       "              'loth'},\n",
       "             'antipathy.n.01.aversion': set(),\n",
       "             'antipathy.n.01.distaste': set(),\n",
       "             'sentiment.n.01.sentiment': {'bathetic',\n",
       "              'drippy',\n",
       "              'hokey',\n",
       "              'kitschy',\n",
       "              'maudlin',\n",
       "              'mawkish',\n",
       "              'mushy',\n",
       "              'schmaltzy',\n",
       "              'schmalzy',\n",
       "              'sentimental',\n",
       "              'slushy',\n",
       "              'soppy',\n",
       "              'soupy'},\n",
       "             'unassertiveness.n.01.unassertiveness': {'unassertive'},\n",
       "             'chill.n.04.chill': set(),\n",
       "             'chill.n.04.pall': set(),\n",
       "             'eagerness.n.01.eagerness': {'eager'},\n",
       "             'eagerness.n.01.avidity': {'avid', 'zealous'},\n",
       "             'eagerness.n.01.avidness': {'avid', 'zealous'},\n",
       "             'eagerness.n.01.keenness': set(),\n",
       "             'leaning.n.01.leaning': set(),\n",
       "             'leaning.n.01.propensity': set(),\n",
       "             'leaning.n.01.tendency': set(),\n",
       "             'passion.n.05.passion': set(),\n",
       "             'filial_love.n.01.filial_love': set(),\n",
       "             'insecurity.n.02.insecurity': {'insecure'},\n",
       "             'anglophilia.n.01.Anglophilia': {'Anglophilic'},\n",
       "             'misery.n.02.misery': set(),\n",
       "             'philhellenism.n.01.philhellenism': set(),\n",
       "             'abhorrence.n.01.abhorrence': {'abhorrent',\n",
       "              'detestable',\n",
       "              'obscene',\n",
       "              'repugnant',\n",
       "              'repulsive'},\n",
       "             'abhorrence.n.01.abomination': set(),\n",
       "             'abhorrence.n.01.detestation': set(),\n",
       "             'abhorrence.n.01.execration': set(),\n",
       "             'abhorrence.n.01.loathing': set(),\n",
       "             'abhorrence.n.01.odium': {'abominable',\n",
       "              'detestable',\n",
       "              'execrable',\n",
       "              'odious'},\n",
       "             'resentment.n.01.resentment': set(),\n",
       "             'resentment.n.01.bitterness': {'bitter'},\n",
       "             'resentment.n.01.gall': set(),\n",
       "             'resentment.n.01.rancor': {'rancorous'},\n",
       "             'resentment.n.01.rancour': set(),\n",
       "             'blessedness.n.01.blessedness': {'blessed'},\n",
       "             'blessedness.n.01.beatitude': set(),\n",
       "             'blessedness.n.01.beatification': set(),\n",
       "             'pet.n.03.pet': set(),\n",
       "             'bonheur.n.01.bonheur': set(),\n",
       "             'helplessness.n.03.helplessness': {'helpless', 'lost'},\n",
       "             'tsoris.n.01.tsoris': set(),\n",
       "             'ambivalence.n.01.ambivalence': {'ambivalent'},\n",
       "             'ambivalence.n.01.ambivalency': set(),\n",
       "             'cheerfulness.n.02.cheerfulness': {'cheerful',\n",
       "              'pollyannaish',\n",
       "              'upbeat'},\n",
       "             'cheerfulness.n.02.blitheness': {'cheerful',\n",
       "              'pollyannaish',\n",
       "              'upbeat'},\n",
       "             'bad_temper.n.01.bad_temper': set(),\n",
       "             'bad_temper.n.01.ill_temper': set(),\n",
       "             'happiness.n.02.happiness': {'happy'},\n",
       "             'self-torture.n.01.self-torture': set(),\n",
       "             'self-torture.n.01.self-torment': set(),\n",
       "             'mysophilia.n.01.mysophilia': set(),\n",
       "             'puppy_love.n.01.puppy_love': set(),\n",
       "             'puppy_love.n.01.calf_love': set(),\n",
       "             'puppy_love.n.01.crush': set(),\n",
       "             'puppy_love.n.01.infatuation': set(),\n",
       "             'confusion.n.03.confusion': set(),\n",
       "             'confusion.n.03.discombobulation': set(),\n",
       "             'velleity.n.01.velleity': set(),\n",
       "             'admiration.n.01.admiration': set(),\n",
       "             'admiration.n.01.esteem': set(),\n",
       "             'shame.n.01.shame': set(),\n",
       "             'oedipus_complex.n.01.Oedipus_complex': set(),\n",
       "             'oedipus_complex.n.01.Oedipal_complex': set(),\n",
       "             'buoyancy.n.01.buoyancy': {'buoyant', 'chirpy', 'perky'},\n",
       "             'buoyancy.n.01.perkiness': {'buoyant', 'chirpy', 'perky'},\n",
       "             'peace.n.03.peace': set(),\n",
       "             'peace.n.03.peacefulness': set(),\n",
       "             'peace.n.03.peace_of_mind': set(),\n",
       "             'peace.n.03.repose': set(),\n",
       "             'peace.n.03.serenity': set(),\n",
       "             'peace.n.03.heartsease': set(),\n",
       "             'peace.n.03.ataraxis': set(),\n",
       "             'amour_propre.n.01.amour_propre': set(),\n",
       "             'amour_propre.n.01.conceit': set(),\n",
       "             'amour_propre.n.01.self-love': set(),\n",
       "             'amour_propre.n.01.vanity': {'conceited',\n",
       "              'egotistic',\n",
       "              'egotistical',\n",
       "              'self-conceited',\n",
       "              'swollen',\n",
       "              'swollen-headed',\n",
       "              'vain'},\n",
       "             'scruple.n.02.scruple': {'scrupulous'},\n",
       "             'scruple.n.02.qualm': set(),\n",
       "             'scruple.n.02.misgiving': set(),\n",
       "             'hostility.n.03.hostility': {'hostile'},\n",
       "             'hostility.n.03.enmity': {'inimical', 'unfriendly'},\n",
       "             'hostility.n.03.ill_will': set(),\n",
       "             'technophobia.n.01.technophobia': set(),\n",
       "             'despisal.n.01.despisal': set(),\n",
       "             'despisal.n.01.despising': set(),\n",
       "             'inclination.n.05.inclination': set(),\n",
       "             'embarrassment.n.02.embarrassment': set(),\n",
       "             'heartburning.n.01.heartburning': set(),\n",
       "             'attachment.n.01.attachment': set(),\n",
       "             'attachment.n.01.fond_regard': set(),\n",
       "             'approval.n.02.approval': set(),\n",
       "             'distance.n.04.distance': {'aloof', 'distant', 'upstage'},\n",
       "             'distance.n.04.aloofness': set(),\n",
       "             'suspense.n.03.suspense': set(),\n",
       "             'feelings.n.01.feelings': set(),\n",
       "             'good_humor.n.01.good_humor': set(),\n",
       "             'good_humor.n.01.good_humour': set(),\n",
       "             'good_humor.n.01.good_temper': set(),\n",
       "             'good_humor.n.01.amiability': {'affable',\n",
       "              'amiable',\n",
       "              'cordial',\n",
       "              'genial',\n",
       "              'good-humored',\n",
       "              'good-humoured'},\n",
       "             'levity.n.01.levity': set(),\n",
       "             'soft_spot.n.02.soft_spot': set(),\n",
       "             'distress.n.01.distress': set(),\n",
       "             'distress.n.01.hurt': set(),\n",
       "             'distress.n.01.suffering': set(),\n",
       "             'consolation.n.01.consolation': set(),\n",
       "             'consolation.n.01.solace': set(),\n",
       "             'consolation.n.01.solacement': set(),\n",
       "             'resignation.n.01.resignation': set(),\n",
       "             'resignation.n.01.surrender': set(),\n",
       "             'regard.n.06.regard': set(),\n",
       "             'regard.n.06.respect': set(),\n",
       "             'unrest.n.02.unrest': set(),\n",
       "             'daze.n.01.daze': set(),\n",
       "             'daze.n.01.shock': set(),\n",
       "             'daze.n.01.stupor': set(),\n",
       "             'prurience.n.01.prurience': {'lubricious',\n",
       "              'lustful',\n",
       "              'prurient',\n",
       "              'salacious'},\n",
       "             'prurience.n.01.pruriency': {'lubricious',\n",
       "              'lustful',\n",
       "              'prurient',\n",
       "              'salacious'},\n",
       "             'prurience.n.01.lasciviousness': {'lascivious',\n",
       "              'lewd',\n",
       "              'libidinous',\n",
       "              'lustful'},\n",
       "             'prurience.n.01.carnality': {'animal',\n",
       "              'carnal',\n",
       "              'fleshly',\n",
       "              'sensual'},\n",
       "             'prurience.n.01.lubricity': set(),\n",
       "             'huffiness.n.01.huffiness': {'feisty',\n",
       "              'huffy',\n",
       "              'mad',\n",
       "              'sore',\n",
       "              'thin-skinned',\n",
       "              'touchy'},\n",
       "             'satyriasis.n.01.satyriasis': set(),\n",
       "             'comfort.n.02.comfort': set(),\n",
       "             'ego.n.01.ego': set(),\n",
       "             'ego.n.01.egotism': {'conceited',\n",
       "              'egotistic',\n",
       "              'egotistical',\n",
       "              'self-conceited',\n",
       "              'swollen',\n",
       "              'swollen-headed',\n",
       "              'vain'},\n",
       "             'ego.n.01.self-importance': {'arrogant',\n",
       "              'chesty',\n",
       "              'self-important'},\n",
       "             'mournfulness.n.01.mournfulness': {'doleful',\n",
       "              'mournful',\n",
       "              'plaintive'},\n",
       "             'mournfulness.n.01.sorrowfulness': {'sorrowful'},\n",
       "             'mournfulness.n.01.ruthfulness': {'contrite',\n",
       "              'remorseful',\n",
       "              'rueful',\n",
       "              'ruthful'},\n",
       "             'amorousness.n.01.amorousness': {'amative', 'amorous'},\n",
       "             'amorousness.n.01.enamoredness': {'enamored',\n",
       "              'in_love',\n",
       "              'infatuated',\n",
       "              'potty',\n",
       "              'smitten',\n",
       "              'soft_on',\n",
       "              'taken_with'},\n",
       "             'buck_fever.n.01.buck_fever': set(),\n",
       "             'schadenfreude.n.01.Schadenfreude': set(),\n",
       "             'exultation.n.01.exultation': set(),\n",
       "             'exultation.n.01.jubilance': {'elated',\n",
       "              'exultant',\n",
       "              'exulting',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'exultation.n.01.jubilancy': {'elated',\n",
       "              'exultant',\n",
       "              'exulting',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'exultation.n.01.jubilation': set(),\n",
       "             'affection.n.01.affection': set(),\n",
       "             'affection.n.01.affectionateness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.fondness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.tenderness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.heart': {'hearty'},\n",
       "             'affection.n.01.warmness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.warmheartedness': {'warmhearted'},\n",
       "             'affection.n.01.philia': set(),\n",
       "             'weight.n.05.weight': {'weighty'},\n",
       "             'discouragement.n.01.discouragement': set(),\n",
       "             'discouragement.n.01.disheartenment': set(),\n",
       "             'discouragement.n.01.dismay': set(),\n",
       "             'apathy.n.01.apathy': {'apathetic', 'indifferent'},\n",
       "             'sadness.n.02.sadness': {'sad'},\n",
       "             'sadness.n.02.sorrow': set(),\n",
       "             'sadness.n.02.sorrowfulness': {'sorrowful'},\n",
       "             'cold_comfort.n.01.cold_comfort': set(),\n",
       "             'ingratitude.n.01.ingratitude': set(),\n",
       "             'ingratitude.n.01.ungratefulness': {'thankless',\n",
       "              'ungrateful',\n",
       "              'unthankful'},\n",
       "             'libido.n.01.libido': {'lascivious',\n",
       "              'lewd',\n",
       "              'libidinal',\n",
       "              'libidinous',\n",
       "              'lustful'},\n",
       "             'addiction.n.02.addiction': set(),\n",
       "             'unfriendliness.n.01.unfriendliness': {'inimical', 'unfriendly'},\n",
       "             'weakness.n.05.weakness': set(),\n",
       "             'wistfulness.n.01.wistfulness': {'pensive', 'wistful'},\n",
       "             'anaphrodisia.n.01.anaphrodisia': set(),\n",
       "             'emotion.n.01.emotion': {'emotional'},\n",
       "             'misogamy.n.01.misogamy': set(),\n",
       "             'demoralization.n.03.demoralization': set(),\n",
       "             'demoralization.n.03.demoralisation': set(),\n",
       "             'compassion.n.01.compassion': set(),\n",
       "             'compassion.n.01.compassionateness': {'compassionate'},\n",
       "             'self-pity.n.01.self-pity': set(),\n",
       "             'emulation.n.01.emulation': set(),\n",
       "             'moroseness.n.01.moroseness': {'dark',\n",
       "              'dour',\n",
       "              'glowering',\n",
       "              'glum',\n",
       "              'moody',\n",
       "              'morose',\n",
       "              'saturnine',\n",
       "              'sour',\n",
       "              'sullen'},\n",
       "             'moroseness.n.01.glumness': {'dark',\n",
       "              'dour',\n",
       "              'glowering',\n",
       "              'glum',\n",
       "              'moody',\n",
       "              'morose',\n",
       "              'saturnine',\n",
       "              'sour',\n",
       "              'sullen'},\n",
       "             'moroseness.n.01.sullenness': {'heavy',\n",
       "              'lowering',\n",
       "              'sullen',\n",
       "              'threatening'},\n",
       "             'humility.n.02.humility': set(),\n",
       "             'humility.n.02.humbleness': set(),\n",
       "             'gusto.n.01.gusto': set(),\n",
       "             'gusto.n.01.relish': set(),\n",
       "             'gusto.n.01.zest': {'barmy', 'yeasty', 'zestful', 'zesty'},\n",
       "             'gusto.n.01.zestfulness': {'barmy', 'yeasty', 'zestful', 'zesty'},\n",
       "             'sorrow.n.02.sorrow': set(),\n",
       "             'sorrow.n.02.regret': set(),\n",
       "             'sorrow.n.02.rue': set(),\n",
       "             'sorrow.n.02.ruefulness': {'contrite',\n",
       "              'remorseful',\n",
       "              'rueful',\n",
       "              'ruthful'},\n",
       "             'disgust.n.01.disgust': set(),\n",
       "             'suspense.n.01.suspense': set(),\n",
       "             'embarrassment.n.01.embarrassment': set(),\n",
       "             'lecherousness.n.01.lecherousness': {'lecherous'},\n",
       "             'lecherousness.n.01.lust': {'concupiscent', 'lustful', 'lusty'},\n",
       "             'lecherousness.n.01.lustfulness': {'concupiscent',\n",
       "              'lascivious',\n",
       "              'lewd',\n",
       "              'libidinous',\n",
       "              'lubricious',\n",
       "              'lustful',\n",
       "              'lusty',\n",
       "              'prurient',\n",
       "              'salacious'},\n",
       "             'love.n.04.love': set(),\n",
       "             'love.n.04.sexual_love': set(),\n",
       "             'love.n.04.erotic_love': set(),\n",
       "             'nausea.n.02.nausea': {'loathsome',\n",
       "              'nauseating',\n",
       "              'nauseous',\n",
       "              'noisome',\n",
       "              'offensive',\n",
       "              'queasy',\n",
       "              'sickening',\n",
       "              'vile'},\n",
       "             'philogyny.n.01.philogyny': set(),\n",
       "             'pleasantness.n.01.pleasantness': {'pleasant'},\n",
       "             'lovingness.n.01.lovingness': {'loving'},\n",
       "             'lovingness.n.01.caring': {'caring'},\n",
       "             'tranquillity.n.02.tranquillity': {'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'tranquillity.n.02.tranquility': {'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'tranquillity.n.02.quietness': {'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'tranquillity.n.02.quietude': set(),\n",
       "             'thing.n.11.thing': set(),\n",
       "             'elation.n.02.elation': set(),\n",
       "             'elation.n.02.high_spirits': set(),\n",
       "             'elation.n.02.lightness': {'light'},\n",
       "             'peeve.n.01.peeve': set(),\n",
       "             'smugness.n.01.smugness': {'self-satisfied', 'smug'},\n",
       "             'astonishment.n.01.astonishment': set(),\n",
       "             'astonishment.n.01.amazement': set(),\n",
       "             'hopelessness.n.01.hopelessness': {'hopeless'},\n",
       "             'inferiority_complex.n.01.inferiority_complex': set(),\n",
       "             'impatience.n.02.impatience': {'impatient', 'raring'},\n",
       "             'gratefulness.n.01.gratefulness': {'grateful', 'thankful'},\n",
       "             'gratefulness.n.01.thankfulness': {'grateful', 'thankful'},\n",
       "             'gratefulness.n.01.appreciativeness': {'appreciative'},\n",
       "             'poignance.n.01.poignance': {'poignant'},\n",
       "             'poignance.n.01.poignancy': {'poignant'},\n",
       "             'boredom.n.01.boredom': set(),\n",
       "             'boredom.n.01.ennui': set(),\n",
       "             'boredom.n.01.tedium': {'boring',\n",
       "              'deadening',\n",
       "              'dull',\n",
       "              'ho-hum',\n",
       "              'irksome',\n",
       "              'slow',\n",
       "              'tedious',\n",
       "              'tiresome',\n",
       "              'wearisome'},\n",
       "             'sadomasochism.n.01.sadomasochism': {'sadomasochistic'},\n",
       "             'concern.n.03.concern': set(),\n",
       "             'class_feeling.n.01.class_feeling': set(),\n",
       "             'worship.n.02.worship': set(),\n",
       "             'worship.n.02.adoration': set(),\n",
       "             'conscience.n.03.conscience': {'conscientious'},\n",
       "             'hopefulness.n.02.hopefulness': {'hopeful'},\n",
       "             'rejoicing.n.01.rejoicing': set(),\n",
       "             'shyness.n.01.shyness': {'diffident', 'shy', 'timid', 'unsure'},\n",
       "             'indignation.n.01.indignation': set(),\n",
       "             'indignation.n.01.outrage': set(),\n",
       "             'carefreeness.n.01.carefreeness': {'carefree',\n",
       "              'devil-may-care',\n",
       "              'freewheeling',\n",
       "              'happy-go-lucky',\n",
       "              'harum-scarum',\n",
       "              'slaphappy'},\n",
       "             'carefreeness.n.01.insouciance': {'casual',\n",
       "              'insouciant',\n",
       "              'nonchalant'},\n",
       "             'carefreeness.n.01.lightheartedness': {'blithe',\n",
       "              'blithesome',\n",
       "              'light-hearted',\n",
       "              'lighthearted',\n",
       "              'lightsome'},\n",
       "             'carefreeness.n.01.lightsomeness': {'blithe',\n",
       "              'blithesome',\n",
       "              'light-hearted',\n",
       "              'lighthearted',\n",
       "              'lightsome'},\n",
       "             'agony.n.01.agony': {'agonal'},\n",
       "             'agony.n.01.torment': set(),\n",
       "             'agony.n.01.torture': {'agonising',\n",
       "              'agonizing',\n",
       "              'excruciating',\n",
       "              'harrowing',\n",
       "              'torturesome',\n",
       "              'torturing',\n",
       "              'torturous'},\n",
       "             'temptation.n.02.temptation': set(),\n",
       "             'anticipation.n.01.anticipation': set(),\n",
       "             'anticipation.n.01.expectancy': {'anticipant',\n",
       "              'anticipative',\n",
       "              'expectant'},\n",
       "             'creeps.n.02.creeps': set(),\n",
       "             'self-depreciation.n.01.self-depreciation': set(),\n",
       "             'moodiness.n.01.moodiness': {'dark',\n",
       "              'dour',\n",
       "              'glowering',\n",
       "              'glum',\n",
       "              'moody',\n",
       "              'morose',\n",
       "              'saturnine',\n",
       "              'sour',\n",
       "              'sullen'},\n",
       "             'envy.n.01.envy': set(),\n",
       "             'envy.n.01.enviousness': {'covetous', 'envious', 'jealous'},\n",
       "             'happiness.n.01.happiness': {'felicitous', 'happy'},\n",
       "             'happiness.n.01.felicity': {'felicitous', 'happy'},\n",
       "             'pining.n.01.pining': set(),\n",
       "             'ardor.n.01.ardor': set(),\n",
       "             'ardor.n.01.ardour': set(),\n",
       "             'ardor.n.01.elan': set(),\n",
       "             'ardor.n.01.zeal': {'avid', 'zealous'},\n",
       "             'fear.n.01.fear': set(),\n",
       "             'fear.n.01.fearfulness': {'fearful'},\n",
       "             'fear.n.01.fright': set(),\n",
       "             'hope.n.01.hope': set(),\n",
       "             'fearlessness.n.01.fearlessness': {'audacious',\n",
       "              'brave',\n",
       "              'dauntless',\n",
       "              'fearless',\n",
       "              'hardy',\n",
       "              'intrepid',\n",
       "              'unafraid',\n",
       "              'unfearing'},\n",
       "             'fearlessness.n.01.bravery': set(),\n",
       "             'timidity.n.01.timidity': {'timid'},\n",
       "             'timidity.n.01.timidness': {'diffident',\n",
       "              'faint',\n",
       "              'faint-hearted',\n",
       "              'fainthearted',\n",
       "              'shy',\n",
       "              'timid',\n",
       "              'unsure'},\n",
       "             'timidity.n.01.timorousness': {'faint',\n",
       "              'faint-hearted',\n",
       "              'fainthearted',\n",
       "              'timid'},\n",
       "             'acquired_taste.n.01.acquired_taste': set(),\n",
       "             'desire.n.01.desire': set(),\n",
       "             'technophilia.n.01.technophilia': set(),\n",
       "             'infatuation.n.01.infatuation': set(),\n",
       "             'fidget.n.01.fidget': {'antsy', 'fidgety', 'fretful', 'itchy'},\n",
       "             'fidget.n.01.fidgetiness': {'antsy',\n",
       "              'fidgety',\n",
       "              'fretful',\n",
       "              'itchy'},\n",
       "             'fidget.n.01.restlessness': set(),\n",
       "             'agape.n.02.agape': set(),\n",
       "             'agape.n.02.agape_love': set(),\n",
       "             'homesickness.n.01.homesickness': {'homesick'},\n",
       "             'disappointment.n.01.disappointment': set(),\n",
       "             'disappointment.n.01.letdown': set(),\n",
       "             'self-consciousness.n.01.self-consciousness': {'self-conscious'},\n",
       "             'self-consciousness.n.01.uneasiness': {'awkward',\n",
       "              'ill_at_ease',\n",
       "              'uneasy'},\n",
       "             'self-consciousness.n.01.uncomfortableness': {'uncomfortable'},\n",
       "             'withdrawal.n.04.withdrawal': set(),\n",
       "             'withdrawal.n.04.detachment': set(),\n",
       "             'storminess.n.02.storminess': {'stormy', 'tempestuous'},\n",
       "             'brotherhood.n.03.brotherhood': set(),\n",
       "             'fury.n.01.fury': {'angered',\n",
       "              'enraged',\n",
       "              'furious',\n",
       "              'infuriated',\n",
       "              'maddened'},\n",
       "             'fury.n.01.rage': set(),\n",
       "             'fury.n.01.madness': {'huffy', 'mad', 'sore'},\n",
       "             'displeasure.n.01.displeasure': set(),\n",
       "             'unconcern.n.02.unconcern': set(),\n",
       "             'confidence.n.02.confidence': {'confidential'},\n",
       "             'wrath.n.01.wrath': set(),\n",
       "             'swivet.n.01.swivet': set(),\n",
       "             'misocainea.n.01.misocainea': set(),\n",
       "             'devastation.n.02.devastation': set(),\n",
       "             'quality_of_life.n.01.quality_of_life': set(),\n",
       "             'gladness.n.01.gladness': {'beaming', 'glad'},\n",
       "             'gladness.n.01.gladfulness': set(),\n",
       "             'gladness.n.01.gladsomeness': {'gladsome'},\n",
       "             'emotionlessness.n.01.emotionlessness': {'emotionless',\n",
       "              'passionless'},\n",
       "             'emotionlessness.n.01.impassivity': {'impassive', 'stolid'},\n",
       "             'emotionlessness.n.01.impassiveness': {'deadpan',\n",
       "              'expressionless',\n",
       "              'impassive',\n",
       "              'poker-faced',\n",
       "              'stolid',\n",
       "              'unexpressive'},\n",
       "             'emotionlessness.n.01.phlegm': {'phlegmatic', 'phlegmatical'},\n",
       "             'emotionlessness.n.01.indifference': set(),\n",
       "             'emotionlessness.n.01.stolidity': {'impassive', 'stolid'},\n",
       "             'emotionlessness.n.01.unemotionality': set(),\n",
       "             'nationalism.n.03.nationalism': set(),\n",
       "             'the_hots.n.01.the_hots': set(),\n",
       "             'jollity.n.01.jollity': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'jollity.n.01.jolliness': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'jollity.n.01.joviality': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'aphrodisia.n.01.aphrodisia': set(),\n",
       "             'languor.n.02.languor': set(),\n",
       "             'languor.n.02.lassitude': set(),\n",
       "             'languor.n.02.listlessness': {'dispirited', 'listless'},\n",
       "             'jitteriness.n.01.jitteriness': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'jitteriness.n.01.jumpiness': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'jitteriness.n.01.nervousness': {'aflutter',\n",
       "              'anxious',\n",
       "              'nervous',\n",
       "              'queasy',\n",
       "              'uneasy',\n",
       "              'unquiet'},\n",
       "             'jitteriness.n.01.restiveness': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'ecstasy.n.01.ecstasy': {'ecstatic',\n",
       "              'enraptured',\n",
       "              'rapt',\n",
       "              'rapturous',\n",
       "              'rhapsodic'},\n",
       "             'ecstasy.n.01.rapture': {'ecstatic',\n",
       "              'enraptured',\n",
       "              'rapt',\n",
       "              'rapturous',\n",
       "              'rhapsodic'},\n",
       "             'ecstasy.n.01.transport': set(),\n",
       "             'ecstasy.n.01.exaltation': set(),\n",
       "             'ecstasy.n.01.raptus': set(),\n",
       "             'nymphomania.n.01.nymphomania': {'nymphomaniac',\n",
       "              'nymphomaniacal'},\n",
       "             'sadness.n.01.sadness': {'sad'},\n",
       "             'sadness.n.01.unhappiness': {'distressed',\n",
       "              'dysphoric',\n",
       "              'unhappy'},\n",
       "             'closeness.n.01.closeness': {'close'},\n",
       "             'closeness.n.01.intimacy': set(),\n",
       "             'contempt.n.01.contempt': {'contemptuous',\n",
       "              'disdainful',\n",
       "              'insulting',\n",
       "              'scornful'},\n",
       "             'contempt.n.01.disdain': set(),\n",
       "             'contempt.n.01.scorn': set(),\n",
       "             'contempt.n.01.despite': set(),\n",
       "             'mawkishness.n.01.mawkishness': {'bathetic',\n",
       "              'drippy',\n",
       "              'hokey',\n",
       "              'kitschy',\n",
       "              'maudlin',\n",
       "              'mawkish',\n",
       "              'mushy',\n",
       "              'schmaltzy',\n",
       "              'schmalzy',\n",
       "              'sentimental',\n",
       "              'slushy',\n",
       "              'soppy',\n",
       "              'soupy'},\n",
       "             'mawkishness.n.01.bathos': set(),\n",
       "             'exuberance.n.01.exuberance': {'ebullient',\n",
       "              'exuberant',\n",
       "              'high-spirited'},\n",
       "             'disgruntlement.n.01.disgruntlement': set(),\n",
       "             'alienation.n.01.alienation': set(),\n",
       "             'alienation.n.01.disaffection': set(),\n",
       "             'alienation.n.01.estrangement': set(),\n",
       "             'indifference.n.01.indifference': {'immaterial',\n",
       "              'indifferent',\n",
       "              'unbiased',\n",
       "              'unbiassed'},\n",
       "             'captivation.n.02.captivation': set(),\n",
       "             'captivation.n.02.enchantment': set(),\n",
       "             'captivation.n.02.enthrallment': set(),\n",
       "             'captivation.n.02.fascination': set(),\n",
       "             'pleasure.n.01.pleasure': set(),\n",
       "             'pleasure.n.01.pleasance': {'pleasant'},\n",
       "             'enthusiasm.n.01.enthusiasm': {'enthusiastic'},\n",
       "             'zeal.n.02.zeal': {'avid', 'zealous'},\n",
       "             'aggravation.n.01.aggravation': set(),\n",
       "             'aggravation.n.01.exasperation': set(),\n",
       "             'agitation.n.03.agitation': set(),\n",
       "             'softheartedness.n.01.softheartedness': {'soft-boiled',\n",
       "              'softhearted'},\n",
       "             'softheartedness.n.01.tenderness': {'tender'},\n",
       "             'scare.n.02.scare': {'chilling',\n",
       "              'scarey',\n",
       "              'scary',\n",
       "              'shivery',\n",
       "              'shuddery'},\n",
       "             'scare.n.02.panic_attack': set(),\n",
       "             'irritability.n.01.irritability': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'irritability.n.01.crossness': set(),\n",
       "             'irritability.n.01.fretfulness': {'fretful',\n",
       "              'querulous',\n",
       "              'whiney',\n",
       "              'whiny'},\n",
       "             'irritability.n.01.fussiness': {'bad-tempered',\n",
       "              'crabbed',\n",
       "              'crabby',\n",
       "              'cross',\n",
       "              'fussy',\n",
       "              'grouchy',\n",
       "              'grumpy',\n",
       "              'ill-tempered'},\n",
       "             'irritability.n.01.peevishness': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'irritability.n.01.petulance': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'irritability.n.01.choler': set(),\n",
       "             'sweet_tooth.n.01.sweet_tooth': set(),\n",
       "             'misopedia.n.01.misopedia': set(),\n",
       "             'aggression.n.02.aggression': set(),\n",
       "             'aggression.n.02.aggressiveness': set(),\n",
       "             'ambition.n.01.ambition': {'ambitious', 'challenging'},\n",
       "             'ambition.n.01.aspiration': set(),\n",
       "             'ambition.n.01.dream': set(),\n",
       "             'woe.n.02.woe': set(),\n",
       "             'woe.n.02.woefulness': {'woebegone', 'woeful'},\n",
       "             'sex.n.03.sex': {'aphrodisiac', 'aphrodisiacal', 'sexy'},\n",
       "             'sex.n.03.sexual_urge': set(),\n",
       "             'warmheartedness.n.01.warmheartedness': {'warmhearted'},\n",
       "             'warmheartedness.n.01.warmth': set(),\n",
       "             'pain.n.02.pain': set(),\n",
       "             'pain.n.02.painfulness': {'afflictive', 'painful', 'sore'},\n",
       "             'contentment.n.01.contentment': set(),\n",
       "             'conflict.n.02.conflict': set(),\n",
       "             'abashment.n.01.abashment': set(),\n",
       "             'abashment.n.01.bashfulness': {'bashful'},\n",
       "             'grief.n.01.grief': set(),\n",
       "             'grief.n.01.heartache': set(),\n",
       "             'grief.n.01.heartbreak': set(),\n",
       "             'grief.n.01.brokenheartedness': {'brokenhearted',\n",
       "              'heartbroken',\n",
       "              'heartsick'},\n",
       "             'hilarity.n.01.hilarity': {'hilarious',\n",
       "              'screaming',\n",
       "              'uproarious'},\n",
       "             'hilarity.n.01.mirth': set(),\n",
       "             'hilarity.n.01.mirthfulness': {'amusing',\n",
       "              'comic',\n",
       "              'comical',\n",
       "              'funny',\n",
       "              'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'laughable',\n",
       "              'merry',\n",
       "              'mirthful',\n",
       "              'risible'},\n",
       "             'hilarity.n.01.glee': set(),\n",
       "             'hilarity.n.01.gleefulness': {'elated',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant'},\n",
       "             'repentance.n.01.repentance': {'penitent', 'repentant'},\n",
       "             'repentance.n.01.penitence': {'penitent',\n",
       "              'penitential',\n",
       "              'penitentiary',\n",
       "              'repentant'},\n",
       "             'repentance.n.01.penance': set(),\n",
       "             'panic.n.01.panic': {'frightened',\n",
       "              'panic-stricken',\n",
       "              'panic-struck',\n",
       "              'panicked',\n",
       "              'panicky',\n",
       "              'terrified'},\n",
       "             'panic.n.01.terror': set(),\n",
       "             'panic.n.01.affright': set(),\n",
       "             'amorousness.n.02.amorousness': {'amatory',\n",
       "              'amorous',\n",
       "              'romantic'},\n",
       "             'amorousness.n.02.eroticism': set(),\n",
       "             'amorousness.n.02.erotism': set(),\n",
       "             'amorousness.n.02.sexiness': {'aphrodisiac',\n",
       "              'aphrodisiacal',\n",
       "              'sexy'},\n",
       "             'amorousness.n.02.amativeness': {'amative', 'amorous'},\n",
       "             'afterglow.n.02.afterglow': set(),\n",
       "             'delight.n.01.delight': set(),\n",
       "             'delight.n.01.delectation': set(),\n",
       "             'insight.n.02.insight': set(),\n",
       "             'insight.n.02.perceptiveness': {'perceptive'},\n",
       "             'insight.n.02.perceptivity': {'perceptive'},\n",
       "             'wound.n.03.wound': set(),\n",
       "             'friendliness.n.01.friendliness': {'favorable',\n",
       "              'friendly',\n",
       "              'well-disposed'},\n",
       "             'placidity.n.01.placidity': set(),\n",
       "             'placidity.n.01.placidness': {'equable',\n",
       "              'even-tempered',\n",
       "              'good-tempered',\n",
       "              'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'joie_de_vivre.n.01.joie_de_vivre': set(),\n",
       "             'gaiety.n.02.gaiety': set(),\n",
       "             'gaiety.n.02.playfulness': {'playful'},\n",
       "             'stomach.n.04.stomach': set(),\n",
       "             'sinking.n.03.sinking': set(),\n",
       "             'sinking.n.03.sinking_feeling': set(),\n",
       "             'melancholy.n.01.melancholy': set(),\n",
       "             'concern.n.02.concern': set(),\n",
       "             'concern.n.02.care': set(),\n",
       "             'concern.n.02.fear': set(),\n",
       "             'weepiness.n.01.weepiness': {'weepy'},\n",
       "             'weepiness.n.01.tearfulness': {'dolorous',\n",
       "              'dolourous',\n",
       "              'lachrymose',\n",
       "              'tearful',\n",
       "              'weeping'},\n",
       "             'loyalty.n.02.loyalty': set(),\n",
       "             'dander.n.02.dander': set(),\n",
       "             'dander.n.02.hackles': set(),\n",
       "             'commiseration.n.01.commiseration': set(),\n",
       "             'commiseration.n.01.pity': {'hapless',\n",
       "              'miserable',\n",
       "              'misfortunate',\n",
       "              'pathetic',\n",
       "              'piteous',\n",
       "              'pitiable',\n",
       "              'pitiful',\n",
       "              'poor',\n",
       "              'wretched'},\n",
       "             'commiseration.n.01.ruth': set(),\n",
       "             'commiseration.n.01.pathos': {'hapless',\n",
       "              'miserable',\n",
       "              'misfortunate',\n",
       "              'pathetic',\n",
       "              'piteous',\n",
       "              'pitiable',\n",
       "              'pitiful',\n",
       "              'poor',\n",
       "              'wretched'},\n",
       "             'ardor.n.02.ardor': set(),\n",
       "             'ardor.n.02.ardour': set(),\n",
       "             'dudgeon.n.01.dudgeon': set(),\n",
       "             'dudgeon.n.01.high_dudgeon': set(),\n",
       "             'jealousy.n.01.jealousy': set(),\n",
       "             'jealousy.n.01.green-eyed_monster': set(),\n",
       "             'murderousness.n.01.murderousness': {'homicidal', 'murderous'},\n",
       "             'pride.n.01.pride': set(),\n",
       "             'pride.n.01.pridefulness': {'exultant',\n",
       "              'exulting',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'isolation.n.02.isolation': set(),\n",
       "             'enjoyment.n.01.enjoyment': set(),\n",
       "             'silver_lining.n.01.silver_lining': set(),\n",
       "             'silver_lining.n.01.bright_side': set(),\n",
       "             'sympathy.n.02.sympathy': {'sympathetic'},\n",
       "             'sympathy.n.02.fellow_feeling': set(),\n",
       "             'throes.n.01.throes': set(),\n",
       "             'creepy-crawlies.n.01.creepy-crawlies': set(),\n",
       "             'conditioned_emotional_response.n.01.conditioned_emotional_response': set(),\n",
       "             'conditioned_emotional_response.n.01.CER': set(),\n",
       "             'conditioned_emotional_response.n.01.conditioned_emotion': set(),\n",
       "             'disapproval.n.01.disapproval': set(),\n",
       "             'wishfulness.n.01.wishfulness': {'desirous', 'wishful'},\n",
       "             'malevolence.n.01.malevolence': {'malevolent'},\n",
       "             'malevolence.n.01.malignity': set(),\n",
       "             'heartlessness.n.01.heartlessness': {'hardhearted', 'heartless'},\n",
       "             'heartlessness.n.01.coldheartedness': {'coldhearted'},\n",
       "             'heartlessness.n.01.hardheartedness': {'hardhearted',\n",
       "              'heartless',\n",
       "              'stonyhearted',\n",
       "              'unfeeling'},\n",
       "             'irascibility.n.01.irascibility': {'choleric',\n",
       "              'hot-tempered',\n",
       "              'hotheaded',\n",
       "              'irascible',\n",
       "              'quick-tempered',\n",
       "              'short-tempered'},\n",
       "             'irascibility.n.01.short_temper': set(),\n",
       "             'irascibility.n.01.spleen': {'bristly',\n",
       "              'prickly',\n",
       "              'splenetic',\n",
       "              'waspish'},\n",
       "             'irascibility.n.01.quick_temper': set(),\n",
       "             'compatibility.n.01.compatibility': set(),\n",
       "             'alarm.n.01.alarm': set(),\n",
       "             'alarm.n.01.dismay': set(),\n",
       "             'alarm.n.01.consternation': set(),\n",
       "             'gold_fever.n.01.gold_fever': set(),\n",
       "             'malice.n.01.malice': {'malicious'},\n",
       "             'malice.n.01.maliciousness': {'malicious'},\n",
       "             'malice.n.01.spite': set(),\n",
       "             'malice.n.01.spitefulness': {'despiteful',\n",
       "              'spiteful',\n",
       "              'vindictive'},\n",
       "             'malice.n.01.venom': {'poisonous', 'venomous', 'vicious'},\n",
       "             'affect.n.01.affect': {'affectional', 'affective', 'emotive'},\n",
       "             'fulfillment.n.01.fulfillment': set(),\n",
       "             'fulfillment.n.01.fulfilment': set(),\n",
       "             'ill_humor.n.01.ill_humor': set(),\n",
       "             'ill_humor.n.01.ill_humour': set(),\n",
       "             'ill_humor.n.01.distemper': set(),\n",
       "             'pang.n.01.pang': set(),\n",
       "             'pang.n.01.stab': set(),\n",
       "             'pang.n.01.twinge': set(),\n",
       "             'awe.n.01.awe': set(),\n",
       "             'beneficence.n.01.beneficence': {'beneficent'},\n",
       "             'lividity.n.01.lividity': {'livid'},\n",
       "             'expectation.n.03.expectation': set(),\n",
       "             'coolness.n.01.coolness': {'cool'},\n",
       "             'coolness.n.01.imperturbability': {'imperturbable',\n",
       "              'unflappable'},\n",
       "             'coolness.n.01.imperturbableness': {'imperturbable',\n",
       "              'unflappable'},\n",
       "             'sensibility.n.02.sensibility': set(),\n",
       "             'cynicism.n.01.cynicism': set(),\n",
       "             'preference.n.01.preference': set(),\n",
       "             'preference.n.01.penchant': set(),\n",
       "             'preference.n.01.predilection': set(),\n",
       "             'preference.n.01.taste': set(),\n",
       "             'languor.n.01.languor': set(),\n",
       "             'languor.n.01.dreaminess': {'dreamy',\n",
       "              'lackadaisical',\n",
       "              'languid',\n",
       "              'languorous',\n",
       "              'moony',\n",
       "              'woolgathering'},\n",
       "             'trepidation.n.01.trepidation': set(),\n",
       "             'blahs.n.01.blahs': set(),\n",
       "             'togetherness.n.01.togetherness': {'together'},\n",
       "             'hate.n.01.hate': set(),\n",
       "             'hate.n.01.hatred': set(),\n",
       "             'heavyheartedness.n.01.heavyheartedness': {'heavyhearted'},\n",
       "             'forgiveness.n.01.forgiveness': set(),\n",
       "             'presage.n.01.presage': set(),\n",
       "             'self-disgust.n.01.self-disgust': set(),\n",
       "             'self-disgust.n.01.self-hatred': set(),\n",
       "             'craving.n.01.craving': set(),\n",
       "             'easiness.n.01.easiness': {'easy'},\n",
       "             'easiness.n.01.relaxation': set(),\n",
       "             'dignity.n.01.dignity': set(),\n",
       "             'dignity.n.01.self-respect': set(),\n",
       "             'dignity.n.01.self-regard': set(),\n",
       "             'dignity.n.01.self-worth': set(),\n",
       "             'radiance.n.03.radiance': set(),\n",
       "             'discontentment.n.01.discontentment': set(),\n",
       "             'discontentment.n.01.discontent': {'discontent', 'discontented'},\n",
       "             'discontentment.n.01.discontentedness': {'discontent',\n",
       "              'discontented'},\n",
       "             'warpath.n.01.warpath': set(),\n",
       "             'fetish.n.01.fetish': set(),\n",
       "             'complex.n.03.complex': set(),\n",
       "             'harassment.n.01.harassment': set(),\n",
       "             'harassment.n.01.torment': set(),\n",
       "             'cold_feet.n.01.cold_feet': set(),\n",
       "             'emotional_state.n.01.emotional_state': set(),\n",
       "             'emotional_state.n.01.spirit': set()})"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun2related_adj_dict22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "id": "48e10bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_file(noun2related_adj_dict22, fn=\"related_adjectives_high_quality.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "id": "98aa9232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun2related_adj_dict11 has 856 noun lemmas with 2399 related adjectives\n"
     ]
    }
   ],
   "source": [
    "noun2related_adj_dict11 = make_noun2related_adj_dict()\n",
    "#adj_yield22 = get_dict_yield(noun2related_adj_dict22)\n",
    "adj_yield11 = get_dict_yield(noun2related_adj_dict11)\n",
    "dd_yield11 = len(adj_yield11)\n",
    "print(f\"noun2related_adj_dict11 has {len(noun2related_adj_dict11)} noun lemmas with {dd_yield11} related adjectives\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "id": "4f380b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2444"
      ]
     },
     "execution_count": 1177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj_yield11 | adj_yield22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "id": "3eba110e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856"
      ]
     },
     "execution_count": 1178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(noun2related_adj_dict22.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "id": "84118f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856"
      ]
     },
     "execution_count": 1179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun2related_adj_dict11.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "id": "ffd61447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856"
      ]
     },
     "execution_count": 1180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(noun2related_adj_dict22.keys()).union(noun2related_adj_dict11.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "48a90bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_set_valued_dict (noun2related_adj_dict11,noun2related_adj_dict22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "id": "11288fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856"
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun2related_adj_dict11.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "id": "dacfd7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2444"
      ]
     },
     "execution_count": 1183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_yield_merged = get_dict_yield(noun2related_adj_dict11)\n",
    "len(adj_yield_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "id": "bda13c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_file(noun2related_adj_dict11, fn=\"related_adjectives_high_quality_or_by_stemmer.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "87cb6792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('desire.n.01') lct 1 ct11 0 ct22 1 the feeling that accompanies an unsatisfied state\n",
      "Synset('desire.n.02') lct 1 ct11 0 ct22 0 an inclination to want things\n",
      "Synset('desire.n.03') lct 1 ct11 0 ct22 0 something that is desired\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets(\"desire\",\"n\"):\n",
    "    ls = list(map(get_lemma_string, ss.lemmas()))\n",
    "    ct11 = sum(1 for l in ls if l in noun2related_adj_dict11)\n",
    "    ct22 = sum(1 for l in ls if l in noun2related_adj_dict22) \n",
    "    stats = f\"lct {len(ls)} ct11 {ct11} ct22 {ct22}\"\n",
    "    print(ss, stats, ss.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8c2d8",
   "metadata": {},
   "source": [
    "# Framenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c9dab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foresee.v'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import framenet as fn\n",
    "\n",
    "fn.lu(256).name\n",
    "#'foresee.v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979f1130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COD: be aware of beforehand; predict.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.lu(256).definition\n",
    "#'COD: be aware of beforehand; predict.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a34cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Expectation'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.lu(256).frame.name\n",
    "#'Expectation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db67b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame (26): Expectation\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Expectation.xml\n",
       "\n",
       "[definition]\n",
       "  Words in this frame have to do with a Cognizer believing that\n",
       "  some Phenomenon will take place in the future.  Some words in the\n",
       "  frame (e.g. foresee.v) indicate that the Phenomenon is asserted\n",
       "  also to be true, while others do not.  'Michael expected Abby to\n",
       "  demand examples.' 'From the look on her face Michael expected\n",
       "  that she would say she got the job.'\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[frameRelations] 3 frame relations\n",
       "  <Parent=Awareness -- Inheritance -> Child=Expectation>\n",
       "  <Parent=Expectation -- Using -> Child=Predicting>\n",
       "  <MainEntry=Omen -- See_also -> ReferringEntry=Expectation>\n",
       "\n",
       "[lexUnit] 14 lexical units\n",
       "  anticipate.v (253), await.v (254), expect.v (255), expectation.n\n",
       "  (13081), foresee.v (256), foreseeable.a (3588), predict.v (257),\n",
       "  predictable.a (3585), prediction.n (13082), premonition.n\n",
       "  (13083), unexpected.a (13928), unforeseeable.a (3587),\n",
       "  unpredictable.a (3586), wait.v (16597)\n",
       "\n",
       "[FE] 10 frame elements\n",
       "            Core: Cognizer (109), Phenomenon (110), Topic (9837)\n",
       "      Peripheral: Degree (1029), Evidence (1041), Manner (1033), Place (9835), Time (9836), Time_of_phenomenon (16124)\n",
       "  Extra-Thematic: Depictive (1030)\n",
       "\n",
       "[FEcoreSets] 1 frame element core sets\n",
       "  Topic, Phenomenon"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.frame(\"Expectation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "id": "0a5e4b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'POS': 'V',\n",
       "  'breakBefore': 'false',\n",
       "  'headword': 'false',\n",
       "  'name': 'foresee',\n",
       "  'order': 1}]"
      ]
     },
     "execution_count": 1191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.reader.framenet import PrettyDict,PrettyList\n",
    "list(map(PrettyDict, fn.lu(256).lexemes))\n",
    "[{'POS': 'V', 'breakBefore': 'false', 'headword': 'false', 'name': 'foresee', 'order': 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "id": "389a3b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12393"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This verifies we have FN 1.7\n",
    "ferels = fn.fe_relations()\n",
    "len(ferels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb0ec5",
   "metadata": {},
   "source": [
    "#### The key steps LUs -> frame and frame -> LUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "id": "8fc38e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<frame ID=189 name=Quantified_mass>, <frame ID=2001 name=Degree>]"
      ]
     },
     "execution_count": 1194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "PrettyList(sorted(fn.frames_by_lemma(r'(?i)a little'), key=itemgetter('ID'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "id": "354cc63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<frame ID=40 name=Questioning>, <frame ID=500 name=Criminal_investigation>]"
      ]
     },
     "execution_count": 1206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is form to frame functionality\n",
    "L=sorted(fn.frames_by_lemma(\"inquire\"), key=itemgetter('ID'))\n",
    "PrettyList(L) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "id": "c487408e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cBy', 'cDate', 'name', 'ID', '_type', 'definition', 'definitionMarkup', 'FE', 'FEcoreSets', 'lexUnit', 'semTypes', 'frameRelations', 'URL'])"
      ]
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frames are just dictionaries\n",
    "(L[0]).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40107c53",
   "metadata": {},
   "source": [
    "And here is the frame to lexeme functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "id": "c1551fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ask.v': <lu ID=8421 name=ask.v>, 'grill.v': <lu ID=627 name=grill.v>, 'inquire.v': <lu ID=628 name=inquire.v>, 'inquiry.n': <lu ID=629 name=inquiry.n>, 'interrogate.v': <lu ID=630 name=interrogate.v>, 'interrogation.n': <lu ID=631 name=interrogation.n>, 'query.n': <lu ID=632 name=query.n>, 'query.v': <lu ID=633 name=query.v>, 'question.n': <lu ID=634 name=question.n>, 'question.v': <lu ID=635 name=question.v>, 'questioning.n': <lu ID=636 name=questioning.n>, 'quiz.v': <lu ID=637 name=quiz.v>}"
      ]
     },
     "execution_count": 1198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frame -> lexunit dict\n",
    "#\n",
    "L[0].lexUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fe0f86",
   "metadata": {},
   "source": [
    "The lexunit object has valence info (under `subCorpus`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "id": "7463aa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexical unit (8421): ask.v\n",
       "\n",
       "[definition]\n",
       "  COD: say something in order to obtain an answer or some\n",
       "  information from someone\n",
       "[frame] Questioning(40)\n",
       "\n",
       "[POS] V\n",
       "\n",
       "[status] FN1_Sent\n",
       "\n",
       "[lexemes] ask/V\n",
       "\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu8421.xml\n",
       "\n",
       "[subCorpus] 13 subcorpora\n",
       "  V-coordpass, V-intrans-adverb, V-invertquote, V-np-np, V-np-\n",
       "  pother, V-np-ppother, V-other, V-pother, V-ppother, V-sbse,\n",
       "  V-surepass, V-that-sfin, manually-added\n",
       "\n",
       "[exemplars] 111 sentences across all subcorpora"
      ]
     },
     "execution_count": 1199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[0].lexUnit[\"ask.v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "id": "dd79b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex2colexes (lex,result=None,allowed=None):\n",
    "    if result is None:\n",
    "        result = dict()\n",
    "    frames = fn.frames_by_lemma(lex)\n",
    "    if allowed is not None:\n",
    "        frames = [frame for frame in frames if frame.name in allowed]\n",
    "    for frame in frames:\n",
    "        result[frame.name] = list(frame.lexUnit.keys())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "id": "c96fbed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Criminal_investigation': ['inquiry.n',\n",
       "  'probe.n',\n",
       "  'investigate.v',\n",
       "  'inquire.v',\n",
       "  'probe.v',\n",
       "  'investigation.n',\n",
       "  'lead.n',\n",
       "  'clue.n',\n",
       "  'case.n'],\n",
       " 'Questioning': ['grill.v',\n",
       "  'inquire.v',\n",
       "  'inquiry.n',\n",
       "  'interrogate.v',\n",
       "  'interrogation.n',\n",
       "  'query.n',\n",
       "  'query.v',\n",
       "  'question.n',\n",
       "  'question.v',\n",
       "  'questioning.n',\n",
       "  'quiz.v',\n",
       "  'ask.v']}"
      ]
     },
     "execution_count": 1440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex2colexes(\"inquire.v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2662a",
   "metadata": {},
   "source": [
    "noun_sample =[]\n",
    "for (i,x) in enumerate(feeling_nouns):\n",
    "    noun_sample.append(x.name()[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "05f190eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_frames = \"Judgment Contrition Experiencer_focus Desiring Stimulus_focus\".split()\n",
    "frame.lexUnit.keys()\n",
    "colex_dicts = [lex2colexes (lex,allowed=feeling_frames) for lex in noun_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "9267faca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4004, 366)"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_yield = [form for  colex_dict in colex_dicts for form_list in colex_dict.values() for form in form_list]\n",
    "len(form_yield),len(set(form_yield))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "7753e39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2570, 221)"
      ]
     },
     "execution_count": 1264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list = [adj[:-2] for  colex_dict in colex_dicts for form_list in colex_dict.values() for adj in form_list if adj.endswith(\".a\")]\n",
    "adj_yield = set(adj_list)\n",
    "len(adj_list),len(set(adj_yield))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "66af1db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abominable',\n",
       " 'absorbing',\n",
       " 'admiring',\n",
       " 'agape',\n",
       " 'aggravating',\n",
       " 'agonizing',\n",
       " 'agreeable',\n",
       " 'alarming',\n",
       " 'alienating',\n",
       " 'amazing',\n",
       " 'amusing',\n",
       " 'annoying',\n",
       " 'appalling',\n",
       " 'appreciative',\n",
       " 'apprehensive',\n",
       " 'approving',\n",
       " 'astonishing',\n",
       " 'astounding',\n",
       " 'baffling',\n",
       " 'beguiling',\n",
       " 'bewildering',\n",
       " 'bewitching',\n",
       " 'blood-curdling',\n",
       " 'boring',\n",
       " 'bothersome',\n",
       " 'breathtaking',\n",
       " 'calm',\n",
       " 'calming',\n",
       " 'captivating',\n",
       " 'charming',\n",
       " 'cheering',\n",
       " 'chilling',\n",
       " 'comforting',\n",
       " 'comical',\n",
       " 'confusing',\n",
       " 'consoling',\n",
       " 'contemptuous',\n",
       " 'contrite',\n",
       " 'cool',\n",
       " 'covetous',\n",
       " 'critical',\n",
       " 'dear',\n",
       " 'delightful',\n",
       " 'depressing',\n",
       " 'derisive',\n",
       " 'desired',\n",
       " 'desirous',\n",
       " 'devastating',\n",
       " 'disagreeable',\n",
       " 'disappointing',\n",
       " 'disapproving',\n",
       " 'discomfiting',\n",
       " 'discomforting',\n",
       " 'disconcerting',\n",
       " 'discouraging',\n",
       " 'disdainful',\n",
       " 'disgusting',\n",
       " 'disheartening',\n",
       " 'disillusioning',\n",
       " 'dismaying',\n",
       " 'disorientating',\n",
       " 'displeasing',\n",
       " 'dissatisfied',\n",
       " 'distasteful',\n",
       " 'distressing',\n",
       " 'disturbing',\n",
       " 'dreadful',\n",
       " 'droll',\n",
       " 'dull',\n",
       " 'dying',\n",
       " 'eager',\n",
       " 'earth-shattering',\n",
       " 'easy',\n",
       " 'electrifying',\n",
       " 'embarrassing',\n",
       " 'embittering',\n",
       " 'empty',\n",
       " 'enchanting',\n",
       " 'encouraging',\n",
       " 'engrossing',\n",
       " 'enjoyable',\n",
       " 'enraging',\n",
       " 'entertaining',\n",
       " 'enthralling',\n",
       " 'exasperating',\n",
       " 'exciting',\n",
       " 'exhilarating',\n",
       " 'fascinating',\n",
       " 'fazed',\n",
       " 'fed up',\n",
       " 'feverish',\n",
       " 'fond',\n",
       " 'formidable',\n",
       " 'frightening',\n",
       " 'fulfilled',\n",
       " 'fulfilling',\n",
       " 'full',\n",
       " 'funny',\n",
       " 'galling',\n",
       " 'ghastly',\n",
       " 'gratifying',\n",
       " 'gripping',\n",
       " 'guilty',\n",
       " 'hair-raising',\n",
       " 'harrowing',\n",
       " 'heart-rending',\n",
       " 'heart-stopping',\n",
       " 'heart-warming',\n",
       " 'heartbreaking',\n",
       " 'heartening',\n",
       " 'hilarious',\n",
       " 'humorous',\n",
       " 'hungry',\n",
       " 'impressive',\n",
       " 'infuriating',\n",
       " 'insulting',\n",
       " 'interested',\n",
       " 'intimidated',\n",
       " 'intimidating',\n",
       " 'intriguing',\n",
       " 'invigorating',\n",
       " 'irksome',\n",
       " 'irritated',\n",
       " 'irritating',\n",
       " 'jaw-dropping',\n",
       " 'jolly',\n",
       " 'loath',\n",
       " 'maddening',\n",
       " 'mind-boggling',\n",
       " 'mind-numbing',\n",
       " 'mortifying',\n",
       " 'mystifying',\n",
       " 'nerve-racking',\n",
       " 'nervous',\n",
       " 'nettled',\n",
       " 'nice',\n",
       " 'offensive',\n",
       " 'pacifying',\n",
       " 'pathetic',\n",
       " 'penitent',\n",
       " 'perplexing',\n",
       " 'pitiful',\n",
       " 'placating',\n",
       " 'pleasant',\n",
       " 'pleasing',\n",
       " 'pleasurable',\n",
       " 'poignant',\n",
       " 'raring',\n",
       " 'reassuring',\n",
       " 'relaxing',\n",
       " 'reluctant',\n",
       " 'remorseful',\n",
       " 'remorseless',\n",
       " 'repellent',\n",
       " 'repentant',\n",
       " 'reprehensible',\n",
       " 'reproachful',\n",
       " 'revolting',\n",
       " 'rich',\n",
       " 'rousing',\n",
       " 'rueful',\n",
       " 'sad',\n",
       " 'saddening',\n",
       " 'satisfied',\n",
       " 'satisfying',\n",
       " 'scary',\n",
       " 'scornful',\n",
       " 'shocking',\n",
       " 'sickening',\n",
       " 'side-splitting',\n",
       " 'sobering',\n",
       " 'solemn',\n",
       " 'soothing',\n",
       " 'sorry',\n",
       " 'spine-chilling',\n",
       " 'spine-tingling',\n",
       " 'spoiling',\n",
       " 'startling',\n",
       " 'stimulating',\n",
       " 'stinging',\n",
       " 'stirring',\n",
       " 'stressful',\n",
       " 'striking',\n",
       " 'stupefying',\n",
       " 'surprising',\n",
       " 'suspenseful',\n",
       " 'taken',\n",
       " 'tear-jerking',\n",
       " 'tedious',\n",
       " 'terrifying',\n",
       " 'thirsty',\n",
       " 'thorny',\n",
       " 'thrilling',\n",
       " 'tiresome',\n",
       " 'tiring',\n",
       " 'tormenting',\n",
       " 'touching',\n",
       " 'traumatic',\n",
       " 'traumatising',\n",
       " 'troublesome',\n",
       " 'troubling',\n",
       " 'uncritical',\n",
       " 'unexciting',\n",
       " 'unfazed',\n",
       " 'unfulfilling',\n",
       " 'unfunny',\n",
       " 'unnerving',\n",
       " 'unpleasant',\n",
       " 'unpleasing',\n",
       " 'unrepentant',\n",
       " 'unsettling',\n",
       " 'uplifting',\n",
       " 'upset',\n",
       " 'upsetting',\n",
       " 'vexatious',\n",
       " 'vexing',\n",
       " 'white-knuckle',\n",
       " 'worked up',\n",
       " 'worried',\n",
       " 'worrisome',\n",
       " 'worrying'}"
      ]
     },
     "execution_count": 1265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_yield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd1329c",
   "metadata": {},
   "source": [
    "This little run added 80 high quality adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "cc72caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444\n",
      "2524\n"
     ]
    }
   ],
   "source": [
    "print(len(adj_yield_merged))\n",
    "print(len(adj_yield_merged|adj_yield))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3904788b",
   "metadata": {},
   "source": [
    "The right way to add adjectives using FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "900bcdbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 74, 67)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feeling_frames = \"Judgment Contrition Experiencer_focus Desiring Stimulus_focus\".split()\n",
    "all_lexes =  {lex for frame in feeling_frames for lex in list(fn.frame(frame).lexUnit.keys())}\n",
    "adj_yield = {lex[:-2] for lex in all_lexes if lex.endswith(\".a\")}\n",
    "noun_yield = {lex[:-2] for lex in all_lexes if lex.endswith(\".n\")}\n",
    "verb_yield = {lex[:-2] for lex in all_lexes if lex.endswith(\".v\")}\n",
    "len(adj_yield),len(noun_yield),len(verb_yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "7ad7eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_set = {n[:-2] for n in noun_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "a9290576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 29)"
      ]
     },
     "execution_count": 1290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_sample),len(noun_yield.intersection(noun_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "c894b7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 1296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "id": "3984fff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun_yield.union(noun_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29559dd",
   "metadata": {},
   "source": [
    "What Framenet added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "id": "2f333a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accolade',\n",
       " 'adoration',\n",
       " 'appreciation',\n",
       " 'aspiration',\n",
       " 'blame',\n",
       " 'charm [count]',\n",
       " 'charm [mass]',\n",
       " 'color',\n",
       " 'contrition',\n",
       " 'damnation',\n",
       " 'desperation',\n",
       " 'detestation',\n",
       " 'disdain',\n",
       " 'disrespect',\n",
       " 'esteem',\n",
       " 'exaltation',\n",
       " 'fault',\n",
       " 'hatred',\n",
       " 'hunger',\n",
       " 'impulse',\n",
       " 'loathing',\n",
       " 'lust',\n",
       " 'mockery',\n",
       " 'penitence',\n",
       " 'pity',\n",
       " 'recreation',\n",
       " 'regret',\n",
       " 'relaxation',\n",
       " 'relish',\n",
       " 'remorse',\n",
       " 'reproach',\n",
       " 'respect',\n",
       " 'rest',\n",
       " 'reverence',\n",
       " 'scorn',\n",
       " 'solace',\n",
       " 'stigma',\n",
       " 'stricture',\n",
       " 'thirst',\n",
       " 'vexation',\n",
       " 'vilification',\n",
       " 'wants',\n",
       " 'will',\n",
       " 'yearning',\n",
       " 'yen'}"
      ]
     },
     "execution_count": 1297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(noun_yield - noun_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "id": "5e9443bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2444, 2524)"
      ]
     },
     "execution_count": 1302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj_yield_merged),len(adj_yield_merged|adj_yield)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84a8b0",
   "metadata": {},
   "source": [
    "What Framenet added (with what is sure an incomplete list of relevant frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "id": "ee7909a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiring',\n",
       " 'agreeable',\n",
       " 'baffling',\n",
       " 'bewildering',\n",
       " 'blood-curdling',\n",
       " 'breathtaking',\n",
       " 'calming',\n",
       " 'charming',\n",
       " 'critical',\n",
       " 'derisive',\n",
       " 'disagreeable',\n",
       " 'discomfiting',\n",
       " 'discomforting',\n",
       " 'disillusioning',\n",
       " 'disorientating',\n",
       " 'droll',\n",
       " 'earth-shattering',\n",
       " 'electrifying',\n",
       " 'embittering',\n",
       " 'empty',\n",
       " 'enraging',\n",
       " 'entertaining',\n",
       " 'fazed',\n",
       " 'fed up',\n",
       " 'formidable',\n",
       " 'fulfilling',\n",
       " 'full',\n",
       " 'ghastly',\n",
       " 'hair-raising',\n",
       " 'heart-rending',\n",
       " 'heart-stopping',\n",
       " 'heart-warming',\n",
       " 'impressive',\n",
       " 'intriguing',\n",
       " 'invigorating',\n",
       " 'jaw-dropping',\n",
       " 'mind-boggling',\n",
       " 'mind-numbing',\n",
       " 'mystifying',\n",
       " 'nerve-racking',\n",
       " 'nice',\n",
       " 'pacifying',\n",
       " 'placating',\n",
       " 'reassuring',\n",
       " 'reluctant',\n",
       " 'reprehensible',\n",
       " 'reproachful',\n",
       " 'rich',\n",
       " 'saddening',\n",
       " 'satisfied',\n",
       " 'side-splitting',\n",
       " 'sobering',\n",
       " 'soothing',\n",
       " 'spine-chilling',\n",
       " 'spine-tingling',\n",
       " 'spoiling',\n",
       " 'startling',\n",
       " 'stinging',\n",
       " 'stressful',\n",
       " 'striking',\n",
       " 'taken',\n",
       " 'tear-jerking',\n",
       " 'thorny',\n",
       " 'thrilling',\n",
       " 'tiring',\n",
       " 'tormenting',\n",
       " 'traumatic',\n",
       " 'traumatising',\n",
       " 'troublesome',\n",
       " 'uncritical',\n",
       " 'unexciting',\n",
       " 'unfazed',\n",
       " 'unfulfilling',\n",
       " 'unfunny',\n",
       " 'unnerving',\n",
       " 'unrepentant',\n",
       " 'unsettling',\n",
       " 'uplifting',\n",
       " 'white-knuckle',\n",
       " 'worked up'}"
      ]
     },
     "execution_count": 1303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_yield-adj_yield_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "id": "d26857a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abhor',\n",
       " 'abominate',\n",
       " 'accuse',\n",
       " 'ache',\n",
       " 'admire',\n",
       " 'adore',\n",
       " 'applaud',\n",
       " 'appreciate',\n",
       " 'approve',\n",
       " 'aspire',\n",
       " 'blame',\n",
       " 'boo',\n",
       " 'care',\n",
       " 'covet',\n",
       " 'crave',\n",
       " 'deify',\n",
       " 'delight',\n",
       " 'deplore',\n",
       " 'desire',\n",
       " 'despair',\n",
       " 'despise',\n",
       " 'detest',\n",
       " 'disapprove',\n",
       " 'disdain',\n",
       " 'dislike',\n",
       " 'dread',\n",
       " 'envy',\n",
       " 'esteem',\n",
       " 'exalt',\n",
       " 'fancy',\n",
       " 'fault',\n",
       " 'fear',\n",
       " 'feel like',\n",
       " 'grieve',\n",
       " 'hanker',\n",
       " 'hate',\n",
       " 'hope',\n",
       " 'hunger',\n",
       " 'itch',\n",
       " 'like',\n",
       " 'loathe',\n",
       " 'long',\n",
       " 'love',\n",
       " 'lust',\n",
       " 'mock',\n",
       " 'mourn',\n",
       " 'pine',\n",
       " 'pity',\n",
       " 'prize',\n",
       " 'regret',\n",
       " 'repent',\n",
       " 'resent',\n",
       " 'respect',\n",
       " 'revere',\n",
       " 'rue',\n",
       " 'scorn',\n",
       " 'set store',\n",
       " 'stigmatize',\n",
       " 'strike a chord',\n",
       " 'thirst',\n",
       " 'value',\n",
       " 'want',\n",
       " 'will',\n",
       " 'wish',\n",
       " 'wish (that)',\n",
       " 'yearn',\n",
       " 'yen'}"
      ]
     },
     "execution_count": 1304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6d59691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noun2related_verb_dict():\n",
    "    noun2related_verb_dict = defaultdict(set)\n",
    "      \n",
    "    for ss in feeling_nouns:\n",
    "        #for ss in [wn.synset('happiness.n.01')]:\n",
    "        nm = ss.name()\n",
    "        for ln in ss.lemma_names():\n",
    "            #print(nm, ln,file=ofh,end=\"\\n   \")\n",
    "            for rel_l in get_related_lemmas(ln,\"n\",\"v\"):\n",
    "                #print(rel_l.name(),file=ofh,end=\" \")\n",
    "                noun2related_verb_dict[nm].add(rel_l)\n",
    "            #print(\"\\n\",end=\"\",file=ofh)\n",
    "        # Guarantees at least an empoty set entry for ln\n",
    "        noun2related_verb_dict[nm]\n",
    "    return noun2related_verb_dict\n",
    "\n",
    "noun2related_verb_dict = make_noun2related_verb_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "6d4e8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_yield22 = get_dict_yield(noun2related_verb_dict)\n",
    "len(verb_yield22)\n",
    "verb_set = {v.name() for v in verb_yield22}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "117f3db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verb_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859eb1f",
   "metadata": {},
   "source": [
    "Only 12 verbs were added:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df6787",
   "metadata": {},
   "source": [
    "The multi word expressions *feel like*, *strike a chord*, *set store*  are the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1d3b00bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adore',\n",
       " 'applaud',\n",
       " 'boo',\n",
       " 'deify',\n",
       " 'deplore',\n",
       " 'fault',\n",
       " 'feel like',\n",
       " 'mock',\n",
       " 'set store',\n",
       " 'stigmatize',\n",
       " 'strike a chord',\n",
       " 'wish (that)'}"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_yield  - verb_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "652d7318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['subID', 'supID', 'subFrameName', 'superFrameName', 'ID', '_type', 'feRelations', 'type', 'superFrame', 'Neutral', 'subFrame', 'Perspectivized'])"
      ]
     },
     "execution_count": 1358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fer = fn.lus(\"stream\")[1].frame.frameRelations[1]\n",
    "fer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "a70fbeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Quantified_mass',\n",
       " 'Measure_scenario',\n",
       " frame (189): Quantified_mass\n",
       " \n",
       " [URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Quantified_mass.xml\n",
       " \n",
       " [definition]\n",
       "   This frame contains transparent nouns (and some adjectives)\n",
       "   denoting quantities of a Mass or of Individuals. As opposed to\n",
       "   aggregate words such as group, set, these Quantity do not have a\n",
       "   status as Wholes on their own.   'He found them in the deluge of\n",
       "   papers on his desk.'  Initially, at least, we have annotated both\n",
       "   Quantity of Masses and of Individuals in this frame, though we\n",
       "   may split the frame along these lines later on.\n",
       " [semTypes] 0 semantic types\n",
       " \n",
       " [frameRelations] 2 frame relations\n",
       "   <MainEntry=Quantified_mass -- See_also -> ReferringEntry=Quantity>\n",
       "   <Neutral=Measure_scenario -- Perspective_on -> Perspectivized=Quantified_mass>\n",
       " \n",
       " [lexUnit] 58 lexical units\n",
       "   a bit.n (13797), a few.art (13370), a little.n (14733), a lot.n\n",
       "   (13232), abundance.n (3333), all.a (13747), amount.n (3381),\n",
       "   any.a (13745), avalanche.n (3836), billions.n (3330), both.a\n",
       "   (14734), deal.n (17269), degree.n (3420), deluge.n (3837), dose.n\n",
       "   (14165), dozens.n (3331), fair.a (15420), few.a (13369), few.n\n",
       "   (13276), flood.n (3839), handful.n (11730), heap.n (3321),\n",
       "   hundreds.n (3327), load.n (3322), many.a (13746), many.n (13277),\n",
       "   mass.n (3325), measure.n (3369), millions.n (3329), mite.n\n",
       "   (3324), modicum.n (3323), mountain.n (11729), multiple.a (13874),\n",
       "   myriad.n (3335), no.a (13869), number.n (3338), numerous.a\n",
       "   (13751), oodles.n (3318), ounce.n (3342), pile.n (3319), pinch.n\n",
       "   (3339), plethora.n (3336), quantity.n (3337), raft.n (7451),\n",
       "   scads.n (3326), scores.n (3419), several.a (13368), several.n\n",
       "   (13339), shitload.n (3332), smattering.n (15231), stream.n\n",
       "   (3841), thousands.n (3328), ton.n (3320), torrent.n (3838),\n",
       "   touch.n (3343), trace.n (16191), trickle.n (3840), wave.n (3842)\n",
       " \n",
       " [FE] 5 frame elements\n",
       "             Core: Individuals (1552), Mass (1551), Quantity (1550)\n",
       "       Peripheral: Degree (11951), Q_prop (1553)\n",
       " \n",
       " [FEcoreSets] 1 frame element core sets\n",
       "   Mass, Individuals,\n",
       " frame (1687): Measure_scenario\n",
       " \n",
       " [URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Measure_scenario.xml\n",
       " \n",
       " [definition]\n",
       "   An Entity has a particular Value for an Attribute which may be\n",
       "   described in several different ways, including: '' Degree of\n",
       "   deviation from the Value expected for the kind of Entity seen in\n",
       "   a particular instance, or in comparison to some other explicit\n",
       "   comparison set. '' Absolute quantification in terms of the number\n",
       "   of Counts of a particular Unit which equal the Value for the\n",
       "   Attribute.\n",
       " [semTypes] 1 semantic types\n",
       "   Non-Lexical Frame(16)\n",
       " \n",
       " [frameRelations] 5 frame relations\n",
       "   <Parent=Measure_scenario -- Inheritance -> Child=Duration_scenario>\n",
       "   <Neutral=Measure_scenario -- Perspective_on -> Perspectivized=Dimension>\n",
       "   <Neutral=Measure_scenario -- Perspective_on -> Perspectivized=Measurable_attributes>\n",
       "   <Neutral=Measure_scenario -- Perspective_on -> Perspectivized=Measures>\n",
       "   <Neutral=Measure_scenario -- Perspective_on -> Perspectivized=Quantified_mass>\n",
       " \n",
       " [lexUnit] 0 lexical units\n",
       "   \n",
       " \n",
       " [FE] 8 frame elements\n",
       "             Core: Attribute (9691), Count (9698), Degree (9693), Entity (9690), Unit (9697), Value (9692)\n",
       "   Extra-Thematic: Circumstances (9695), Time (9694)\n",
       " \n",
       " [FEcoreSets] 0 frame element core sets\n",
       "   )"
      ]
     },
     "execution_count": 1363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fer['subFrameName'],fer['superFrameName'],fer[\"Perspectivized\"],fer[\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "id": "15179412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MainEntry=Quantified_mass -- See_also -> ReferringEntry=Quantity>, <Neutral=Measure_scenario -- Perspective_on -> Perspectivized=Quantified_mass>]"
      ]
     },
     "execution_count": 1342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fn.lus(\"stream.n\")[1].frame.keys()\n",
    "#dict_keys(['cBy', 'cDate', 'name', 'ID', '_type', 'definition', 'definitionMarkup', 'FE', \n",
    "#'FEcoreSets', 'lexUnit', 'semTypes', 'frameRelations', 'URL'])\n",
    "qtfd_mass = fn.lus(\"stream.n\")[1].frame\n",
    "qtfd_mass[\"frameRelations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cec62a",
   "metadata": {},
   "source": [
    "### All frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71b7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = fn.frames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257502d",
   "metadata": {},
   "source": [
    "FrameNet 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cbcdc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1221"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636ca9a",
   "metadata": {},
   "source": [
    "## Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79656f3e",
   "metadata": {},
   "source": [
    "A lemma is a sense form pair as in WordNet, but a sense here means an assignment of roles\n",
    "within a frame.   In Framenet lemmas are called **lexUnits**.  So when we note that a lexical form, even\n",
    "a lexical form with an assigned part of speech, may have several frames, we are saying it has several lexical\n",
    "units (several senses) each with an assigned frame.\n",
    "\n",
    "Note there are 7,000 or so frames yielding only 10,000 or so lexunit names but there are actually 13,500 or so\n",
    "lex units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac15958",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = [fn.lexUnit[lu] for fn in all_frames for lu in fn.lexUnit]\n",
    "vocab = {lu.name for lu in vocab_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "id": "40a034f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13572"
      ]
     },
     "execution_count": 1444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "id": "a289d688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abandon.v'"
      ]
     },
     "execution_count": 1446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "id": "414469d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10462"
      ]
     },
     "execution_count": 1372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "id": "897f0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter,defaultdict\n",
    "\n",
    "pos_part = (r\"(\\..*)$\")\n",
    "pos_part_re = re.compile(pos_part)\n",
    "ctr = Counter(pos_part_re.findall(lu.name)[0] for lu in vocab)\n",
    "vocab_dict = defaultdict(set)\n",
    "for v in vocab:\n",
    "    vocab_dict[pos_part_re.findall(v.name)[0][1:]].add(v.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "id": "44b0b697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['v', 'n', 'a', 'prep', 'adv', 'idio', 'intj', 'num', 'c', 'scon', 'art', 'pron'])"
      ]
     },
     "execution_count": 1415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "id": "e56899e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ago.idio',\n",
       " 'be symbol.idio',\n",
       " 'do time.idio',\n",
       " \"dog (someone's) steps.idio\",\n",
       " 'from to.idio',\n",
       " 'gain ground.idio',\n",
       " 'give job.idio',\n",
       " 'give notice.idio',\n",
       " 'give thought.idio',\n",
       " 'give try.idio',\n",
       " \"hold (one's) tongue.idio\",\n",
       " 'in amount.idio',\n",
       " 'in terms.idio',\n",
       " \"jump (someone's) bones.idio\",\n",
       " \"make (someone's) acquaintance.idio\",\n",
       " 'make arrangements.idio',\n",
       " 'make history.idio',\n",
       " 'not a word.idio',\n",
       " 'on authority.idio',\n",
       " 'place weight.idio',\n",
       " 'point out.idio',\n",
       " \"pull (someone's) leg.idio\",\n",
       " \"pull the wool over (someone's) eyes.idio\",\n",
       " 'set ablaze.idio',\n",
       " 'set alight.idio',\n",
       " \"take (someone's) life.idio\",\n",
       " \"tip (someone's) hand.idio\",\n",
       " 'wait tables.idio',\n",
       " 'with on.idio'}"
      ]
     },
     "execution_count": 1420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"idio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85aa7fe",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d89927",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "id": "b36d0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list  = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "id": "cd5b5166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abandon.v'"
      ]
     },
     "execution_count": 1428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu0= vocab_list[0]\n",
    "lu0.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "id": "221cbb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abandonment'"
      ]
     },
     "execution_count": 1432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu0.frame.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "id": "2ae5bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exemplar sentences for abandon.v in Abandonment:\n",
       "\n",
       "[0] The bank has abandoned all plans to finance roads or logging in Cameroon 's forests , in keeping with its ` stringent policy to protect the rights of indigenous people . \"\n",
       "[1] Jamie Hill , prosecuting , said Stevenson and a friend took a Nova car from North Skelton and abandoned it in Nottingham .\n",
       "[2] She had seen no reason to abandon it when she came to Medewich two years ago , even though she might now have been able to afford a car .\n",
       "[3] Unfortunately , as a result of other priorities following the fall of France in June 1940 , the project was abandoned .\n",
       "[4] Leeds Education Authority has abandoned plans for ` drastic \" cuts in travel subsidies for some Catholic students .\n",
       "[5] Moved to rectify this situation , he abandoned plans of working in the missionary field , and offered his services to the Netherlands Indies civil service .\n",
       "[6] The council later abandoned its plans to widen the highway and the reversion passed to the first defendants , who were not a highway authority .\n",
       "[7] It was Osman 's father Mohamed who had returned in his car for the clothes for Mrs Zamzam 's children just before Um Al-Farajh was finally abandoned by the Palestinian Arabs in 1948 .\n",
       "[8] Lola is waiting loyally , if not faithfully , for the lover , Michel ( Jacques Harden ) , who fathered her child and abandoned her seven years before .\n",
       "[9] A pistol was found in a garden at Ava Parade , off Ormeau Road , by police searching the area yesterday after a car was abandoned by two men .\n",
       "[10] That project will then be abandoned in favour of some other quickly completable component elsewhere , so that even relatively minor works can take years to finish .\n",
       "[11] What this argument suggests in Gandhi 's case is that he does not abandon his commitment to the principle of non-violence or qualify it in any way when he approves the destruction of life .\n",
       "[12] There were , ultimately , some findings that were distinctly incompatible with the theory and it was abandoned by its originators .\n",
       "[13] Ironically , Mrs Neil Lyndon has now revealed she was abandoned by her husband last year and only managed to receive child support for their six-year-old son by obtaining a court order .\n",
       "[14] She had been abandoned by her family , seen as an unbearable embarrassment and disgrace , \" the princess told a conference of medical researchers seeking a cure for AIDS .\n",
       "[15] The female eider duck is abandoned by her drake just as soon as she starts incubating the eggs .\n",
       "[16] Whatever social and political abuses Herod might perpetrate , these were seen merely as symptoms of a much more profound dilemma -- the dilemma of a people who had been abandoned by their God .\n",
       "[17] A woman abandoned by her husband found her wage of new and crucial importance and looked to the union for support .\n",
       "[18] Another vehicle was abandoned at Great Victoria Street .\n",
       "[19] Ultimately , therefore , such academics abandon the rigorous analysis of the current content of criminal law and substitute criticism for legal exposition .\n",
       "[20] He also fathered a child by Marevna ( Maria Vorobiev ) and abandoned both women when he left for Mexico in 1921 .\n",
       "[21] Mr. Gonzalez and his colleagues , particularly the finance minister , Carlos Solchaga , are charged with having abandoned their socialist principles and with having become arrogant elitists who refuse even to go on television ( controlled by the state ) to face their accusers .\n",
       "[22] It would be sad for Mr. Gonzalez to abandon them to appease his foes .\n",
       "[23] Their supplies scarce , their harvest meager , and their spirit broken , they abandoned the fort in 1858 .\n"
      ]
     },
     "execution_count": 1430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu0.exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "id": "67cff3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exemplar sentence (1489323):\n",
       "[corpID] 111\n",
       "[docID] 421\n",
       "[paragNo] 216\n",
       "[sentNo] 4\n",
       "[aPos] 35759420\n",
       "\n",
       "[LU] (14839) abandon.v in Abandonment\n",
       "\n",
       "[frame] (2031) Abandonment\n",
       "\n",
       "[annotationSet] 2 annotation sets\n",
       "\n",
       "[POS] 22 tags\n",
       "\n",
       "[POS_tagset] PENN\n",
       "\n",
       "[GF] 2 relations\n",
       "\n",
       "[PT] 2 phrases\n",
       "\n",
       "[text] + [Target] + [FE]\n",
       "\n",
       "Unfortunately , as a result of other priorities following the \n",
       "                ----------------------------------------------\n",
       "                Explanation                                   \n",
       " \n",
       "fall of France in June 1940 , the project was abandoned .\n",
       "---------------------------   -----------     *********\n",
       "                              Theme                     \n",
       " \n",
       " \n",
       " \n",
       "[Agent:CNI]\n",
       " \n"
      ]
     },
     "execution_count": 1429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu0.exemplars[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6316ad",
   "metadata": {},
   "source": [
    "POS asignments are by character spans (to allow for lex units with white space):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "id": "571e9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 13, 'rb'),\n",
       " (14, 15, ','),\n",
       " (16, 18, 'in'),\n",
       " (19, 20, 'dt'),\n",
       " (21, 27, 'nn'),\n",
       " (28, 30, 'in'),\n",
       " (31, 36, 'jj'),\n",
       " (37, 47, 'nns'),\n",
       " (48, 57, 'VVG'),\n",
       " (58, 61, 'dt'),\n",
       " (62, 66, 'nn'),\n",
       " (67, 69, 'in'),\n",
       " (70, 76, 'NP'),\n",
       " (77, 79, 'in'),\n",
       " (80, 84, 'NP'),\n",
       " (85, 89, 'cd'),\n",
       " (90, 91, ','),\n",
       " (92, 95, 'dt'),\n",
       " (96, 103, 'nn'),\n",
       " (104, 107, 'VBD'),\n",
       " (108, 117, 'VVN'),\n",
       " (118, 119, 'sent')]"
      ]
     },
     "execution_count": 1447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu0.exemplars[3].POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "id": "8c6eb00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'result'"
      ]
     },
     "execution_count": 1452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu0.exemplars[3].text[21:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef8eff",
   "metadata": {},
   "source": [
    "#### Iterating through all frames\n",
    "\n",
    "Plan for Framenet\n",
    "\n",
    "1)  Iterate through frame list to find roots relative to all fers.  That is, they are not the parent in any fer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a984577",
   "metadata": {},
   "source": [
    "For example, abandonment is not a root.  It has a parent Intentionally affect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "db35b979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame (230): Intentionally_affect\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Intentionally_affect.xml\n",
       "\n",
       "[definition]\n",
       "  An Agent causes a Patient to be affected, sometimes by a\n",
       "  particular Means or by use of an Instrument.  'A professional\n",
       "  dishwasher doesn't do dishes with a rag anymore!'\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[frameRelations] 52 frame relations\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Intentionally_affect>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Abandonment>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Adjusting>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Apply_heat>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Appointing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Arranging>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Arrest>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Attaching>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Attack>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Breaking_out_captive>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Cause_emotion>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Cause_to_amalgamate>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Cause_to_experience>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Cause_to_make_progress>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Cause_to_perceive>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Change_accessibility>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Change_operational_state>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Closure>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Cutting>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Detaching>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Education_teaching>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Extradition>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Firing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Gathering_up>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Grooming>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Hiding_objects>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Hiring>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Hit_target>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Immobilization>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Inhibit_movement>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Limiting>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Making_arrangements>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Manipulate_into_doing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Manipulate_into_shape>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Processing_materials>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Publishing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Rape>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Releasing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Reparation>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Replacing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Rescuing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Rewards_and_punishments>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Separating>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Short_selling>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Silencing>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Soaking>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Taking>\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Using>\n",
       "  <Parent=Transitive_action -- Inheritance -> Child=Intentionally_affect>\n",
       "  <Parent=Intentionally_affect -- Using -> Child=Arson>\n",
       "  <Parent=Intentionally_affect -- Using -> Child=Bungling>\n",
       "  <Parent=Intentionally_affect -- Using -> Child=Import_export_scenario>\n",
       "\n",
       "[lexUnit] 3 lexical units\n",
       "  do something (to/with).v (14334), do what (to/with).v (14336),\n",
       "  do.v (4348)\n",
       "\n",
       "[FE] 12 frame elements\n",
       "            Core: Agent (2000), Patient (2006)\n",
       "Core-Unexpressed: Event (1999)\n",
       "      Peripheral: Manner (2583), Means (1997), Place (2003), Purpose (2004), Time (2005)\n",
       "  Extra-Thematic: Degree (5363), Event_description (12000), Explanation (3668), Instrument (2001)\n",
       "\n",
       "[FEcoreSets] 1 frame element core sets\n",
       "  Patient, Event"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abandonmentframe fers\n",
    "IntentionallyAffect = fn.frames_by_lemma(lu0.name)[0][\"frameRelations\"][0][\"Parent\"]\n",
    "IntentionallyAffect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b1bfe",
   "metadata": {},
   "source": [
    "IntentionallyAffect is not a root either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "id": "d9fd38bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame (198): Intentionally_act\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Intentionally_act.xml\n",
       "\n",
       "[definition]\n",
       "  This is an abstract frame for acts performed by sentient beings.\n",
       "  It exists mostly for FE inheritance.  'I carried out the deed\n",
       "  easily .'\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[frameRelations] 59 frame relations\n",
       "  <Parent=Event -- Inheritance -> Child=Intentionally_act>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Activity_finish>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Assemble>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Assistance>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Atonement>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Attempt>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Attempting_and_resolving_scenario>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Attending>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Avoiding>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Bail_decision>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Becoming_a_member>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Change_posture>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Change_tool>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Choosing>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Clemency>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Collaboration>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Confronting_problem>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Contacting>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Daring>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Examination>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Exchange>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Execute_plan>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Exercising>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Forming_relationships>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Front_for>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Get_a_job>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Giving>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Heralding>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Hostile_encounter>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Ingest_substance>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Intentionally_affect>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Intentionally_create>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Intercepting>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Legal_rulings>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Manipulation>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Military_operation>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Name_conferral>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Passing_off>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Perception_active>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Piracy>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Practice>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Quitting>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Resolve_problem>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Self_motion>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Visiting>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Working_a_post>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Accomplishment>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Assistance>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Bungling>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Competition>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Conduct>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Deciding>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Experience_bodily_harm>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Reason>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Remembering_to_do>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Responsibility>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Rite>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Subjective_influence>\n",
       "  <Parent=Intentionally_act -- Using -> Child=Waiting>\n",
       "\n",
       "[lexUnit] 17 lexical units\n",
       "  act.n (13488), act.v (10614), action.n (10611), activity.n\n",
       "  (10616), actor.n (14863), agent.n (14864), carry out.v (11705),\n",
       "  conduct.v (11736), deed.n (17271), do.v (10612), doing.n (10615),\n",
       "  engage.v (12777), execute.v (11839), measures.n (12778), move.n\n",
       "  (14600), perform.v (10912), step.n (10613)\n",
       "\n",
       "[FE] 15 frame elements\n",
       "            Core: Agent (1610)\n",
       "Core-Unexpressed: Act (1609)\n",
       "      Peripheral: Manner (2574), Means (2573), Place (1613), Purpose (1614), Time (1616)\n",
       "  Extra-Thematic: Apparent_conclusion (16874), Domain (7982), Event_description (12001), Explanation (11991), Frequency (7983), Particular_iteration (11863), Period_of_iterations (11078), Result (11079)\n",
       "\n",
       "[FEcoreSets] 0 frame element core sets\n",
       "  "
      ]
     },
     "execution_count": 1459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IntentionallyAffect[\"frameRelations\"][0][\"Parent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea3fe3",
   "metadata": {},
   "source": [
    "And so on:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b3d478",
   "metadata": {},
   "source": [
    "The complete set of frame relation types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eb584578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causative_of',\n",
       " 'Inchoative_of',\n",
       " 'Inheritance',\n",
       " 'Metaphor',\n",
       " 'Perspective_on',\n",
       " 'Precedes',\n",
       " 'ReFraming_Mapping',\n",
       " 'See_also',\n",
       " 'Subframe',\n",
       " 'Using']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_rel.name for fr_rel in (fn.frame_relation_types())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c938a3",
   "metadata": {},
   "source": [
    "The next two frame relation types capture the State -> Inchoative -> Causative\n",
    "relation (cool.a, cool.v.intr, cool.v.tr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "38b76618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Causative=Apply_heat -- Causative_of -> Inchoative/state=Absorb_heat>,\n",
       " <Causative=Attaching -- Causative_of -> Inchoative/state=Becoming_attached>,\n",
       " <Causative=Cause_bodily_experience -- Causative_of -> Inchoative/state=Perception_body>,\n",
       " <Causative=Cause_change -- Causative_of -> Inchoative/state=Undergo_change>,\n",
       " <Causative=Cause_change_of_consistency -- Causative_of -> Inchoative/state=Change_of_consistency>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_rel for fr_rel in fn.frame_relations() if fr_rel.type.name == \"Causative_of\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bee6b492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Inchoative=Becoming_a_member -- Inchoative_of -> Stative=Membership>,\n",
       " <Inchoative=Becoming_attached -- Inchoative_of -> Stative=Being_attached>,\n",
       " <Inchoative=Becoming_detached -- Inchoative_of -> Stative=Being_detached>,\n",
       " <Inchoative=Becoming_dry -- Inchoative_of -> Stative=Being_dry>,\n",
       " <Inchoative=Cause_change_of_phase -- Inchoative_of -> Stative=Substance_by_phase>]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_rel for fr_rel in fn.frame_relations() if fr_rel.type.name == \"Inchoative_of\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6395c36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Source=Activity_finish -- ReFraming_Mapping -> Target=Activity_stop>,\n",
       " <Source=Activity_start -- ReFraming_Mapping -> Target=Cause_to_start>,\n",
       " <Source=Adding_up -- ReFraming_Mapping -> Target=Amounting_to>,\n",
       " <Source=Appeal -- ReFraming_Mapping -> Target=Entering_of_plea>,\n",
       " <Source=Apply_heat -- ReFraming_Mapping -> Target=Soaking>]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_rel for fr_rel in fn.frame_relations() if fr_rel.type.name == \"ReFraming_Mapping\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ed0838db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Earlier=Achieving_first -- Precedes -> Later=Product_development>,\n",
       " <Earlier=Activity_finish -- Precedes -> Later=Activity_done_state>,\n",
       " <Earlier=Activity_ongoing -- Precedes -> Later=Activity_finish>,\n",
       " <Earlier=Activity_ongoing -- Precedes -> Later=Activity_pause>,\n",
       " <Earlier=Activity_ongoing -- Precedes -> Later=Activity_stop>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_rel for fr_rel in fn.frame_relations() if fr_rel.type.name == \"Precedes\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4cb8b5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MainEntry=Appellations -- See_also -> ReferringEntry=Kinship>,\n",
       " <MainEntry=Appellations -- See_also -> ReferringEntry=Leadership>,\n",
       " <MainEntry=Apply_heat -- See_also -> ReferringEntry=Cooking_creation>,\n",
       " <MainEntry=Attempt_means -- See_also -> ReferringEntry=Attempt>,\n",
       " <MainEntry=Awareness -- See_also -> ReferringEntry=Certainty>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_rel for fr_rel in fn.frame_relations() if fr_rel.type.name == \"See_also\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "aa299d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import framenet as fn\n",
    "#all_frames = fn.frames()\n",
    "vocab_list = [fn.lexUnit[lu] for fn in fn.frames() for lu in fn.lexUnit]\n",
    "#vocab = {lu.name for lu in vocab_list}\n",
    "event = fn.frame(\"Event\")\n",
    "\n",
    "def parent_closure (frame,n=0,bd=100):\n",
    "    res = [frame.name]\n",
    "    for fer in frame.frameRelations:\n",
    "        parent = fer.get(\"Parent\", None)\n",
    "        if parent is None:\n",
    "            return res\n",
    "        elif parent.name == frame.name:\n",
    "            return res\n",
    "        elif n > bd:\n",
    "            return res\n",
    "        else:\n",
    "            res.extend(parent_closure(parent,n+1))\n",
    "    return res\n",
    "\n",
    "def is_root_old(frame):\n",
    "    #parents = [fer.get(\"Parent\", None) for fer in frame.frameRelations if fer.get(\"Parent\", None).name != frame]\n",
    "    parents=[]\n",
    "    for fr_rel in frame.frameRelations:\n",
    "        p  = fr_rel.get(\"Parent\", None)\n",
    "        if p is not None:\n",
    "            # It IS a parent-child type fr_rel\n",
    "            p_name = p.name\n",
    "            if p_name != frame.name:\n",
    "                # It's the child\n",
    "                parents.append(p_name)\n",
    "    if parents:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def is_root (frame):\n",
    "    is_child = False\n",
    "    for fr_rel in frame.frameRelations:\n",
    "        \n",
    "        p  = fr_rel.get(\"Child\", None)\n",
    "        if p is not None and p.name == frame.name:\n",
    "            is_child=True\n",
    "    if is_child:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "def lex2colexes (lex,result=None,allowed=None):\n",
    "    if result is None:\n",
    "        result = dict()\n",
    "    frames = fn.frames_by_lemma(lex)\n",
    "    if allowed is not None:\n",
    "        frames = [frame for frame in frames if frame.name in allowed]\n",
    "    for frame in frames:\n",
    "        result[frame.name] = list(frame.lexUnit.keys())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242305e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu0=vocab_list[0]\n",
    "v_frame = lu0.frame\n",
    "#v_frame = fn.frame(\"Transitive_action\")\n",
    "cl = parent_closure (v_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919d01a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abandonment', 'Intentionally_affect', 'Intentionally_act', 'Event']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9354c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame (2031): Abandonment\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Abandonment.xml\n",
       "\n",
       "[definition]\n",
       "  An Agent leaves behind a Theme effectively rendering it no longer\n",
       "  within their control or of the normal security as one's property.\n",
       "  'Carolyn abandoned her car and jumped on a red double decker\n",
       "  bus.'  'Perhaps he left the key in the ignition'  'Abandonment of\n",
       "  a child is considered to be a serious crime in many\n",
       "  jurisdictions.'  There are also metaphorically used examples:\n",
       "  'She left her old ways behind .'\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[frameRelations] 1 frame relations\n",
       "  <Parent=Intentionally_affect -- Inheritance -> Child=Abandonment>\n",
       "\n",
       "[lexUnit] 5 lexical units\n",
       "  abandon.v (14839), abandoned.a (14843), abandonment.n (14842),\n",
       "  forget.v (15317), leave.v (14841)\n",
       "\n",
       "[FE] 12 frame elements\n",
       "            Core: Agent (12338), Theme (12339)\n",
       "      Peripheral: Degree (14482), Duration (12343), Manner (12342), Means (15920), Place (12340), Purpose (15921), Time (12341)\n",
       "  Extra-Thematic: Depictive (12862), Event_description (15962), Explanation (12861)\n",
       "\n",
       "[FEcoreSets] 0 frame element core sets\n",
       "  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d667e609",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#roots = [rt for fm in fn.frames() for rt in parent_closure(fm)[-1:]]\n",
    "roots = [fm.name for fm in fn.frames() if is_root(fm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7d069eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(roots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "61568e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Awareness_situation',\n",
    "#roots[50:100]\n",
    "# \"Event\",'Experiencer_focus', 'Importance',\n",
    "#roots[50:100]\n",
    "# 'Mental_activity','Mental_stimulus_stimulus_focus', \"Possession\", \"Opinion\"\n",
    "#roots[100:150]\n",
    "# 'Reciprocality','Stimulus_focus','Subjective_temperature','Undergoing_scenario'\n",
    "#roots[150:201]\n",
    "def get_lexes_from_frame_list (frame_list):\n",
    "    return {frame_name: get_lexes_from_frame(fn.frame(frame_name))}\n",
    "\n",
    "def get_lexes_from_frame_old(frame,seen=None,n=0):\n",
    "    \n",
    "    print(frame.name)\n",
    "    if seen is None:\n",
    "        seen=[]\n",
    "    #if frame.name in seen:\n",
    "    #    return []\n",
    "    if n > 2:\n",
    "        return []\n",
    "    res = []\n",
    "    for (lu_name, lu) in frame.lexUnit.items():\n",
    "        res.append(lu_name)\n",
    "        #res.extend([frame2 for fr_rel in frame.frameRelations \n",
    "        #           for frame2 in get_lexes_from_frame(fr_rel.Child)])\n",
    "        for fr_rel in frame.frameRelations:\n",
    "            if \"Child\" in fr_rel and fr_rel[\"Parent\"].name not in seen and fr_rel[\"Child\"].name not in seen:\n",
    "                new_seen = seen + [frame.name]\n",
    "                res.extend(get_lexes_from_frame(fr_rel.Child,seen=new_seen,n=n+1))\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_lexes_from_frame(frame,res=None,seen=None,n=0):\n",
    "    \n",
    "    #print(n,frame.name)\n",
    "    if res is None:\n",
    "        res =[]\n",
    "    if seen is None:\n",
    "        seen = []\n",
    "    seen.append(frame.name)\n",
    "    #if n > 2:\n",
    "    #    return res\n",
    "    for (lu_name, lu) in frame.lexUnit.items():\n",
    "        res.append(lu_name)\n",
    "        #res.extend([frame2 for fr_rel in frame.frameRelations \n",
    "        #           for frame2 in get_lexes_from_frame(fr_rel.Child)])\n",
    "        #print(\"Len fr_rels\", len(frame.frameRelations))\n",
    "    for fr_rel in frame.frameRelations:\n",
    "        if \"Child\" in fr_rel and fr_rel[\"Child\"].name not in seen:\n",
    "            res = get_lexes_from_frame(frame=fr_rel.Child,res=res,seen=seen,n=n+1)\n",
    "    return res\n",
    "        \n",
    "def find_path_from_frame(frame,target, path = None, seen=None,n=0):\n",
    "    \"\"\"\n",
    "    Find parent-child loinks from frame to target lu:\n",
    "    Example:\n",
    "     \n",
    "     find_path_from_frame(fn.frame(\"Experiencer_focus\"), \"enemy.n\")\n",
    "    \"\"\"\n",
    "\n",
    "    if seen is None:\n",
    "        seen = []\n",
    "    if path is None:\n",
    "        path = []\n",
    "    seen.append(frame.name)\n",
    "    \n",
    "    for (lu_name, lu) in frame.lexUnit.items():\n",
    "        if lu_name == target:\n",
    "            return ' '.join(path + [frame.name])\n",
    "    for fr_rel in frame.frameRelations:\n",
    "        if \"Child\" in fr_rel and fr_rel[\"Child\"].name not in seen:\n",
    "            new_path = path + [frame.name,fr_rel.type.name]\n",
    "            res = find_path_from_frame(frame=fr_rel.Child,target=target,path=new_path,seen=seen,n=n+1)\n",
    "            if res is not None:\n",
    "                return res\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "a59f641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "Experiencer_focus_words = get_lexes_from_frame(fn.frame('Experiencer_focus'),res=None,n=0)\n",
    "print(len(Experiencer_focus_words))\n",
    "Experiencer_focus_words = set(Experiencer_focus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "238e0bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abhor.v',\n",
       " 'abhorrence.n',\n",
       " 'ablution.n',\n",
       " 'abominate.v',\n",
       " 'absorbed.a',\n",
       " 'ache.v',\n",
       " 'acquiesce.v',\n",
       " 'adoration.n',\n",
       " 'adore.v',\n",
       " 'affray.n',\n",
       " 'against.prep',\n",
       " 'agape.a',\n",
       " 'aim.n',\n",
       " 'aim.v',\n",
       " 'airman.n',\n",
       " 'altercation.n',\n",
       " 'amazing.a',\n",
       " 'ambition.n',\n",
       " 'antipathy.n',\n",
       " 'appalling.a',\n",
       " 'apprehensive.a',\n",
       " 'aspiration.n',\n",
       " 'aspire.v',\n",
       " 'astonishing.a',\n",
       " 'astounding.a',\n",
       " 'atrocious.a',\n",
       " 'attack.v',\n",
       " 'average.a',\n",
       " 'awesome.a',\n",
       " 'awful.a',\n",
       " 'back.v',\n",
       " 'backing.n',\n",
       " 'bad idea.n',\n",
       " 'bad.a',\n",
       " 'bathe.v',\n",
       " 'battle.n',\n",
       " 'battle.v',\n",
       " 'be supposed to.v',\n",
       " 'bear.v',\n",
       " 'beautiful.a',\n",
       " 'believe (in).v',\n",
       " 'belligerent.n',\n",
       " 'bent.a',\n",
       " 'best thing since sliced bread.n',\n",
       " 'bias.n',\n",
       " 'bias.v',\n",
       " 'biased.a',\n",
       " 'bout.n',\n",
       " 'brawl.n',\n",
       " 'brawl.v',\n",
       " 'brush [hair].v',\n",
       " 'brush [teeth].v',\n",
       " 'bw.n',\n",
       " 'calm.a',\n",
       " 'capitulate.v',\n",
       " 'captivated.a',\n",
       " 'care.v',\n",
       " 'cave in.v',\n",
       " 'cave.v',\n",
       " 'clash.n',\n",
       " 'clash.v',\n",
       " 'cleanse.v',\n",
       " 'comb.v',\n",
       " 'combat.n',\n",
       " 'combatant.n',\n",
       " 'comfort.n',\n",
       " 'commando.n',\n",
       " 'common.a',\n",
       " 'compassion.n',\n",
       " 'compromise.v',\n",
       " 'conflict.n',\n",
       " 'confront.v',\n",
       " 'confrontation.n',\n",
       " 'control.v',\n",
       " 'cool.a',\n",
       " 'count.v',\n",
       " 'covet.v',\n",
       " 'covetous.a',\n",
       " 'crap.n',\n",
       " 'crappy.a',\n",
       " 'crave.v',\n",
       " 'craving.n',\n",
       " 'curious.a',\n",
       " 'cw.n',\n",
       " 'decent.a',\n",
       " 'delight.v',\n",
       " 'demonstrate.v',\n",
       " 'demonstration.n',\n",
       " 'depend.v',\n",
       " 'dependence.n',\n",
       " 'dependency.n',\n",
       " 'desirable.a',\n",
       " 'desire.n',\n",
       " 'desire.v',\n",
       " 'desired.a',\n",
       " 'desirous.a',\n",
       " 'despair.v',\n",
       " 'desperation.n',\n",
       " 'despise.v',\n",
       " 'determined.a',\n",
       " 'detest.v',\n",
       " 'detestation.n',\n",
       " 'discomfort.n',\n",
       " 'dislike.n',\n",
       " 'dislike.v',\n",
       " 'disprefer.v',\n",
       " 'dissatisfied.a',\n",
       " 'do.v',\n",
       " 'donnybrook.n',\n",
       " 'dread.v',\n",
       " 'dreadful.a',\n",
       " 'duel.n',\n",
       " 'duel.v',\n",
       " 'dust-up.n',\n",
       " 'dying.a',\n",
       " 'eager.a',\n",
       " 'easy.a',\n",
       " 'elegant.a',\n",
       " 'elude.v',\n",
       " 'empathy.n',\n",
       " 'endorse.v',\n",
       " 'endure.v',\n",
       " 'enemy.n',\n",
       " 'engage.v',\n",
       " 'engagement.n',\n",
       " 'engrossed.a',\n",
       " 'enthralled.a',\n",
       " 'envy.n',\n",
       " 'envy.v',\n",
       " 'escape.v',\n",
       " 'evade.v',\n",
       " 'excellence.n',\n",
       " 'excellent.a',\n",
       " 'execrable.a',\n",
       " 'extraordinary.a',\n",
       " 'fabulous.a',\n",
       " 'facial.n',\n",
       " 'fair.a',\n",
       " 'fancy.v',\n",
       " 'fantastic.a',\n",
       " 'fare.v',\n",
       " 'fascinated.a',\n",
       " 'favor.v',\n",
       " 'fazed.a',\n",
       " 'fear.v',\n",
       " 'fed up.a',\n",
       " 'feel like.v',\n",
       " 'feverish.a',\n",
       " 'feverishly.adv',\n",
       " 'fight.n',\n",
       " 'fight.v',\n",
       " 'fighter.n',\n",
       " 'fighting.n',\n",
       " 'file.v',\n",
       " 'fine.a',\n",
       " 'fire fighting.n',\n",
       " 'firefight.n',\n",
       " 'first-rate.a',\n",
       " 'fistfight.n',\n",
       " 'floss.v',\n",
       " 'flourish.v',\n",
       " 'fold [to demands].v',\n",
       " 'fond.a',\n",
       " 'for.prep',\n",
       " 'forget.v',\n",
       " 'fracas.n',\n",
       " 'fray.n',\n",
       " 'free-for-all.n',\n",
       " 'friendly.a',\n",
       " 'friendly.n',\n",
       " 'fulfilled.a',\n",
       " 'fulfillment.n',\n",
       " 'function.n',\n",
       " 'gain ground.idio',\n",
       " 'garbage.n',\n",
       " 'gem.n',\n",
       " 'give in.v',\n",
       " 'give way.v',\n",
       " 'goal.n',\n",
       " 'gold.n',\n",
       " 'good idea.n',\n",
       " 'good.a',\n",
       " 'great.a',\n",
       " 'grieve.v',\n",
       " 'groom.v',\n",
       " 'guerrilla.n',\n",
       " 'gunfight.n',\n",
       " 'gunner.n',\n",
       " 'handsome.a',\n",
       " 'hanker.v',\n",
       " 'hankering.n',\n",
       " 'happily.adv',\n",
       " 'hate.v',\n",
       " 'hatred.n',\n",
       " 'have to.v',\n",
       " 'hideous.a',\n",
       " 'hope.n',\n",
       " 'hope.v',\n",
       " 'horrible.a',\n",
       " 'hostile.a',\n",
       " 'hostile.n',\n",
       " 'hostility.n',\n",
       " 'hot.a',\n",
       " 'humble.a',\n",
       " 'hunger.n',\n",
       " 'hunger.v',\n",
       " 'hungry.a',\n",
       " 'idyllic.a',\n",
       " 'impartial.a',\n",
       " 'impartiality.n',\n",
       " 'impulse.n',\n",
       " 'in demand.a',\n",
       " 'in favor.prep',\n",
       " 'in hopes of.prep',\n",
       " 'in order.adv',\n",
       " 'in the hope of.prep',\n",
       " 'in.a',\n",
       " 'incredible.a',\n",
       " 'infantryman.n',\n",
       " 'infatuated.a',\n",
       " 'inferior.a',\n",
       " 'infighting.n',\n",
       " 'intend.v',\n",
       " 'intent.a',\n",
       " 'intention.n',\n",
       " 'interested.a',\n",
       " 'intimidated.a',\n",
       " 'irritated.a',\n",
       " 'itch.v',\n",
       " 'junk.n',\n",
       " 'killer.a',\n",
       " 'lame.a',\n",
       " 'lamer.n',\n",
       " 'languish.v',\n",
       " 'lave.v',\n",
       " 'left.a',\n",
       " 'like.v',\n",
       " 'live.v',\n",
       " 'loath.a',\n",
       " 'loathe.v',\n",
       " 'loathing.n',\n",
       " 'long.v',\n",
       " 'longing.n',\n",
       " 'look.n',\n",
       " 'lost (in).a',\n",
       " 'love.v',\n",
       " 'lovely.a',\n",
       " 'low.a',\n",
       " 'lust.n',\n",
       " 'lust.v',\n",
       " 'magnificent.a',\n",
       " 'manicure.n',\n",
       " 'manicure.v',\n",
       " 'marine.n',\n",
       " 'marvellous.a',\n",
       " 'mean.v',\n",
       " 'mediocre.a',\n",
       " 'melee.n',\n",
       " 'militant.n',\n",
       " 'miserable.a',\n",
       " 'moisturize.v',\n",
       " 'mourn.v',\n",
       " 'nasty.a',\n",
       " 'need.n',\n",
       " 'need.v',\n",
       " 'nervous.a',\n",
       " 'nettled.a',\n",
       " 'neutral.a',\n",
       " 'neutrality.n',\n",
       " 'object.n',\n",
       " 'objective.n',\n",
       " 'okay.a',\n",
       " 'opponent.n',\n",
       " 'oppose.v',\n",
       " 'opposition [act].n',\n",
       " 'opposition [entity].n',\n",
       " 'order.n',\n",
       " 'ought to.v',\n",
       " 'outstanding.a',\n",
       " 'part.n',\n",
       " 'partial.a',\n",
       " 'partiality.n',\n",
       " 'pathetic.a',\n",
       " 'pedestrian.a',\n",
       " 'pedicure.n',\n",
       " 'pine.v',\n",
       " 'pitiful.a',\n",
       " 'pity.n',\n",
       " 'pity.v',\n",
       " 'plait.v',\n",
       " 'plan.n',\n",
       " 'plan.v',\n",
       " 'pleasure.n',\n",
       " 'plebeian.a',\n",
       " 'pluck.v',\n",
       " 'poor.a',\n",
       " 'popular.a',\n",
       " 'prefer.v',\n",
       " 'prejudge.v',\n",
       " 'prejudice.n',\n",
       " 'prejudiced.a',\n",
       " 'pro.adv',\n",
       " 'program.n',\n",
       " 'project.n',\n",
       " 'proletarian.a',\n",
       " 'prosper.v',\n",
       " 'prosperity.n',\n",
       " 'protest.n',\n",
       " 'protest.v',\n",
       " 'protester.n',\n",
       " 'purpose.n',\n",
       " 'raring.a',\n",
       " 'regret.n',\n",
       " 'regret.v',\n",
       " 'relent.v',\n",
       " 'reliance.n',\n",
       " 'relish.n',\n",
       " 'reluctant.a',\n",
       " 'rely.v',\n",
       " 'remain.v',\n",
       " 'remainder.n',\n",
       " 'remember.v',\n",
       " 'require.v',\n",
       " 'resent.v',\n",
       " 'resentment.n',\n",
       " 'rock.v',\n",
       " 'rotten.a',\n",
       " 'row.n',\n",
       " 'rue.v',\n",
       " 'rueful.a',\n",
       " 'sacrifice.v',\n",
       " 'sailor.n',\n",
       " 'satisfaction.n',\n",
       " 'satisfied.a',\n",
       " 'scheme.n',\n",
       " 'scuffle.n',\n",
       " 'scuffle.v',\n",
       " 'second-rate.a',\n",
       " 'sensational.a',\n",
       " 'service member.n',\n",
       " 'shampoo.v',\n",
       " 'shave.v',\n",
       " 'shit.n',\n",
       " 'shitty.a',\n",
       " 'shootout.n',\n",
       " 'should.v',\n",
       " 'showdown.n',\n",
       " 'shower.v',\n",
       " 'side.n',\n",
       " 'side.v',\n",
       " 'signaller.n',\n",
       " 'skirmish.n',\n",
       " 'skirmish.v',\n",
       " 'slump.n',\n",
       " 'smart.a',\n",
       " 'smitten.a',\n",
       " 'sniper.n',\n",
       " 'so-so.a',\n",
       " 'soap.v',\n",
       " 'solace.n',\n",
       " 'soldier.n',\n",
       " 'sound.n',\n",
       " 'spat.n',\n",
       " 'splendid.a',\n",
       " 'spoiling.a',\n",
       " 'squabble.n',\n",
       " 'stalemate.n',\n",
       " 'stand.v',\n",
       " 'standoff.n',\n",
       " 'standout.n',\n",
       " 'strife.n',\n",
       " 'struggle.n',\n",
       " 'struggle.v',\n",
       " 'stupendous.a',\n",
       " 'style.n',\n",
       " 'submit.v',\n",
       " 'substandard.a',\n",
       " 'suck.v',\n",
       " 'super.a',\n",
       " 'superb.a',\n",
       " 'superlative.a',\n",
       " 'support.v',\n",
       " 'supporter.n',\n",
       " 'supportive.a',\n",
       " 'suspicious.a',\n",
       " 'sweet.a',\n",
       " 'tackle.v',\n",
       " 'taken.a',\n",
       " 'target.n',\n",
       " 'tasty.a',\n",
       " 'terrible.a',\n",
       " 'terrific.a',\n",
       " 'third-rate.a',\n",
       " 'thirst.n',\n",
       " 'thirst.v',\n",
       " 'thirsty.a',\n",
       " 'thrive.v',\n",
       " 'tiff.n',\n",
       " 'tip-top.a',\n",
       " 'tolerable.a',\n",
       " 'tolerant.a',\n",
       " 'tolerate.v',\n",
       " 'toleration.n',\n",
       " 'top-notch.a',\n",
       " 'tremendous.a',\n",
       " 'troop.n',\n",
       " 'tussle.n',\n",
       " 'ugly.a',\n",
       " 'uncool.a',\n",
       " 'unfazed.a',\n",
       " 'unfortunate.a',\n",
       " 'upper-class.a',\n",
       " 'upset.a',\n",
       " 'urge.n',\n",
       " 'use.n',\n",
       " 'vulgar.a',\n",
       " 'want.v',\n",
       " 'wants.n',\n",
       " 'war.n',\n",
       " 'war.v',\n",
       " 'warfare.n',\n",
       " 'wash.v',\n",
       " 'wax.v',\n",
       " 'well.adv',\n",
       " 'will.n',\n",
       " 'will.v',\n",
       " 'wish (that).v',\n",
       " 'wish.n',\n",
       " 'wish.v',\n",
       " 'wonderful.a',\n",
       " 'worked up.a',\n",
       " 'working-class.a',\n",
       " 'worried.a',\n",
       " 'worthless.a',\n",
       " 'wrangling.n',\n",
       " 'wrapped up (in).a',\n",
       " 'yearn.v',\n",
       " 'yearning.n',\n",
       " 'yen.n',\n",
       " 'yen.v',\n",
       " 'yield.v'}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiencer_focus_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4db1c",
   "metadata": {},
   "source": [
    "Why is *enemy.n* in this list?  What does it have to do with experiencer focus predicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69718596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experiencer_focus Using Desirability Inheritance Desirable_event Using Taking_sides Using Hostile_encounter Using Friendly_or_hostile'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_path_from_frame(fn.frame(\"Experiencer_focus\"), \"enemy.n\", path = None, seen=None,n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1cc7ba00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Parent=Desirable_event -- Using -> Child=Taking_sides>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.frame(\"Desirable_event\").frameRelations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0050ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame (1383): Desirable_event\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Desirable_event.xml\n",
       "\n",
       "[definition]\n",
       "  A particular State_of_affairs is desirable.  The State_of_affairs\n",
       "  may be required to achieve a Purpose.  A set of Circumstances may\n",
       "  be specified under which the assessment of desirability holds.\n",
       "  'You should take the doses about 12 hours apart and at the same\n",
       "  time each day.' ' If the metal is seriously rusted or warped, it\n",
       "  should be repaired or replaced with a chimney top damper.' 'To\n",
       "  ensure that, you should have no CLASSPATH set.'\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[frameRelations] 5 frame relations\n",
       "  <Parent=Desirability -- Inheritance -> Child=Desirable_event>\n",
       "  <Parent=Desirable_event -- Using -> Child=Taking_sides>\n",
       "  <Parent=Required_event -- Using -> Child=Desirable_event>\n",
       "  <Source=Required_event -- ReFraming_Mapping -> Target=Desirable_event>\n",
       "  <Neutral=Preferred_alternative_scenario -- Perspective_on -> Perspectivized=Desirable_event>\n",
       "\n",
       "[lexUnit] 6 lexical units\n",
       "  bad idea.n (11822), be supposed to.v (17416), good idea.n\n",
       "  (11823), have to.v (17415), ought to.v (11821), should.v (11820)\n",
       "\n",
       "[FE] 4 frame elements\n",
       "            Core: State_of_affairs (7756)\n",
       "      Peripheral: Degree (9674), Purpose (7758)\n",
       "  Extra-Thematic: Circumstances (7757)\n",
       "\n",
       "[FEcoreSets] 0 frame element core sets\n",
       "  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.frame(\"Desirable_event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c6c99f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame (1306): Taking_sides\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Taking_sides.xml\n",
       "\n",
       "[definition]\n",
       "  A Cognizer has a relatively fixed positive or negative point of\n",
       "  view towards an Issue.  A Side in a debate concerning an Issue or\n",
       "  an Action of a Side may stand in for the Issue.  The Cognizer's\n",
       "  Degree of alignment may also be specified.  'In interviews , it\n",
       "  seems like everyone is completely against this expenditure .'\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[frameRelations] 6 frame relations\n",
       "  <Parent=Desirable_event -- Using -> Child=Taking_sides>\n",
       "  <Parent=Opinion -- Using -> Child=Taking_sides>\n",
       "  <Parent=Taking_sides -- Using -> Child=Giving_in>\n",
       "  <Parent=Taking_sides -- Using -> Child=Hostile_encounter>\n",
       "  <Parent=Taking_sides -- Using -> Child=Partiality>\n",
       "  <Parent=Taking_sides -- Using -> Child=Protest>\n",
       "\n",
       "[lexUnit] 18 lexical units\n",
       "  against.prep (11499), back.v (13989), backing.n (14562), believe\n",
       "  (in).v (15794), endorse.v (13711), for.prep (11498), in\n",
       "  favor.prep (11505), opponent.n (13140), oppose.v (11496),\n",
       "  opposition [act].n (11504), opposition [entity].n (13389), part.n\n",
       "  (17329), pro.adv (11500), side.n (11503), side.v (11502),\n",
       "  support.v (11501), supporter.n (13141), supportive.a (11506)\n",
       "\n",
       "[FE] 12 frame elements\n",
       "            Core: Action (9155), Cognizer (7433), Issue (7434), Side (7435)\n",
       "      Peripheral: Degree (7436), Manner (10453), Place (11886), Time (8160)\n",
       "  Extra-Thematic: Concessive (10941), Descriptor (10443), Explanation (8161), Particular_iteration (10452)\n",
       "\n",
       "[FEcoreSets] 1 frame element core sets\n",
       "  Side, Issue, Action"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.frame(\"Taking_sides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86447b7",
   "metadata": {},
   "source": [
    "The Step from *Taking_sides* to *Hostile_encounter* is the step that loses the Cognizer frame element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9526a249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame (93): Hostile_encounter\n",
       "\n",
       "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Hostile_encounter.xml\n",
       "\n",
       "[definition]\n",
       "  This frame consists of words that describe a hostile encounter\n",
       "  between opposing forces (Side_1 and Side_2, collectively\n",
       "  conceptualizable as Sides) over a disputed Issue and/or in order\n",
       "  to reach a specific  Purpose. '' 'He still wants to fight Mike\n",
       "  Tyson in about 8 months.'  'Dennis Andries's European\n",
       "  cruiserweight title clash against Akim Tafer of France in\n",
       "  Beausoleil last February has been voted as the EBU's fight of the\n",
       "  year.'\n",
       "[semTypes] 0 semantic types\n",
       "\n",
       "[frameRelations] 9 frame relations\n",
       "  <Parent=Hostile_encounter -- Inheritance -> Child=Fighting_activity>\n",
       "  <Parent=Intentionally_act -- Inheritance -> Child=Hostile_encounter>\n",
       "  <Parent=Hostile_encounter -- Using -> Child=Firefighting>\n",
       "  <Parent=Hostile_encounter -- Using -> Child=Friendly_or_hostile>\n",
       "  <Parent=Hostile_encounter -- Using -> Child=Irregular_combatants>\n",
       "  <Parent=Hostile_encounter -- Using -> Child=Member_of_military>\n",
       "  <Parent=Taking_sides -- Using -> Child=Hostile_encounter>\n",
       "  <Neutral=Hostile_encounter -- Perspective_on -> Perspectivized=Attack>\n",
       "  <Source=Hostile_encounter -- Metaphor -> Target=Firefighting>\n",
       "\n",
       "[lexUnit] 47 lexical units\n",
       "  altercation.n (1913), battle.n (1909), battle.v (1931), bout.n\n",
       "  (1920), brawl.n (1928), brawl.v (1935), bw.n (11623), clash.n\n",
       "  (1916), clash.v (1933), combat.n (1925), conflict.n (10638),\n",
       "  confront.v (1938), confrontation.n (1917), cw.n (11611), duel.n\n",
       "  (1914), duel.v (1932), dust-up.n (10917), engage.v (16741),\n",
       "  engagement.n (16742), fight.n (1910), fight.v (1930), fighting.n\n",
       "  (1919), firefight.n (10458), fistfight.n (10457), gunfight.n\n",
       "  (3803), hostility.n (1922), infighting.n (14981), row.n (1918),\n",
       "  scuffle.n (1911), scuffle.v (1937), shootout.n (3804), showdown.n\n",
       "  (3806), skirmish.n (1924), skirmish.v (1936), spat.n (1912),\n",
       "  squabble.n (1926), stalemate.n (1927), standoff.n (3805),\n",
       "  strife.n (1929), struggle.n (1921), struggle.v (14676), tiff.n\n",
       "  (5149), tussle.n (13315), war.n (1939), war.v (1940), warfare.n\n",
       "  (11600), wrangling.n (3807)\n",
       "\n",
       "[FE] 17 frame elements\n",
       "            Core: Issue (442), Purpose (443), Side_1 (439), Side_2 (440), Sides (441)\n",
       "      Peripheral: Degree (710), Duration (718), Instrument (1523), Manner (445), Means (444), Place (446), Time (447)\n",
       "  Extra-Thematic: Depictive (711), Explanation (1097), Internal_cause (1526), Particular_iteration (13320), Result (716)\n",
       "\n",
       "[FEcoreSets] 1 frame element core sets\n",
       "  Issue, Purpose"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fn.lexUnit(\"enemy.n\")\n",
    "Friendly_or_hostile = fn.frames_by_lemma(\"enemy.n\")[0].frameRelations[0].Parent\n",
    "Friendly_or_hostile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7dc9d",
   "metadata": {},
   "source": [
    "All this suggests teh frame relation based approach should give way to an fe-based\n",
    "approach.  Find expressive-related fes.  Fiund associated frames.  Just\n",
    "use the lexunits in that fra,e/  Dont do a recursive parent-to-child\n",
    "search to find the lex units associated with frames, because , as demonstrated in the discussion\n",
    "above, that introduces noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2ae7698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stimulus_focus_words = get_lexes_from_frame(fn.frame('Stimulus_focus'),res=None,n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed248818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Experiencer_focus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61d63086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abhor.v',\n",
       " 'abhorrence.n',\n",
       " 'ablution.n',\n",
       " 'abominate.v',\n",
       " 'absorbed.a',\n",
       " 'ache.v',\n",
       " 'acquiesce.v',\n",
       " 'adoration.n',\n",
       " 'adore.v',\n",
       " 'affray.n',\n",
       " 'against.prep',\n",
       " 'agape.a',\n",
       " 'aim.n',\n",
       " 'aim.v',\n",
       " 'airman.n',\n",
       " 'altercation.n',\n",
       " 'amazing.a',\n",
       " 'ambition.n',\n",
       " 'antipathy.n',\n",
       " 'appalling.a',\n",
       " 'apprehensive.a',\n",
       " 'aspiration.n',\n",
       " 'aspire.v',\n",
       " 'astonishing.a',\n",
       " 'astounding.a',\n",
       " 'atrocious.a',\n",
       " 'attack.v',\n",
       " 'average.a',\n",
       " 'awesome.a',\n",
       " 'awful.a',\n",
       " 'back.v',\n",
       " 'backing.n',\n",
       " 'bad idea.n',\n",
       " 'bad.a',\n",
       " 'bathe.v',\n",
       " 'battle.n',\n",
       " 'battle.v',\n",
       " 'be supposed to.v',\n",
       " 'bear.v',\n",
       " 'beautiful.a',\n",
       " 'believe (in).v',\n",
       " 'belligerent.n',\n",
       " 'bent.a',\n",
       " 'best thing since sliced bread.n',\n",
       " 'bias.n',\n",
       " 'bias.v',\n",
       " 'biased.a',\n",
       " 'bout.n',\n",
       " 'brawl.n',\n",
       " 'brawl.v',\n",
       " 'brush [hair].v',\n",
       " 'brush [teeth].v',\n",
       " 'bw.n',\n",
       " 'calm.a',\n",
       " 'capitulate.v',\n",
       " 'captivated.a',\n",
       " 'care.v',\n",
       " 'cave in.v',\n",
       " 'cave.v',\n",
       " 'clash.n',\n",
       " 'clash.v',\n",
       " 'cleanse.v',\n",
       " 'comb.v',\n",
       " 'combat.n',\n",
       " 'combatant.n',\n",
       " 'comfort.n',\n",
       " 'commando.n',\n",
       " 'common.a',\n",
       " 'compassion.n',\n",
       " 'compromise.v',\n",
       " 'conflict.n',\n",
       " 'confront.v',\n",
       " 'confrontation.n',\n",
       " 'control.v',\n",
       " 'cool.a',\n",
       " 'count.v',\n",
       " 'covet.v',\n",
       " 'covetous.a',\n",
       " 'crap.n',\n",
       " 'crappy.a',\n",
       " 'crave.v',\n",
       " 'craving.n',\n",
       " 'curious.a',\n",
       " 'cw.n',\n",
       " 'decent.a',\n",
       " 'delight.v',\n",
       " 'demonstrate.v',\n",
       " 'demonstration.n',\n",
       " 'depend.v',\n",
       " 'dependence.n',\n",
       " 'dependency.n',\n",
       " 'desirable.a',\n",
       " 'desire.n',\n",
       " 'desire.v',\n",
       " 'desired.a',\n",
       " 'desirous.a',\n",
       " 'despair.v',\n",
       " 'desperation.n',\n",
       " 'despise.v',\n",
       " 'determined.a',\n",
       " 'detest.v',\n",
       " 'detestation.n',\n",
       " 'discomfort.n',\n",
       " 'dislike.n',\n",
       " 'dislike.v',\n",
       " 'disprefer.v',\n",
       " 'dissatisfied.a',\n",
       " 'do.v',\n",
       " 'donnybrook.n',\n",
       " 'dread.v',\n",
       " 'dreadful.a',\n",
       " 'duel.n',\n",
       " 'duel.v',\n",
       " 'dust-up.n',\n",
       " 'dying.a',\n",
       " 'eager.a',\n",
       " 'easy.a',\n",
       " 'elegant.a',\n",
       " 'elude.v',\n",
       " 'empathy.n',\n",
       " 'endorse.v',\n",
       " 'endure.v',\n",
       " 'enemy.n',\n",
       " 'engage.v',\n",
       " 'engagement.n',\n",
       " 'engrossed.a',\n",
       " 'enthralled.a',\n",
       " 'envy.n',\n",
       " 'envy.v',\n",
       " 'escape.v',\n",
       " 'evade.v',\n",
       " 'excellence.n',\n",
       " 'excellent.a',\n",
       " 'execrable.a',\n",
       " 'extraordinary.a',\n",
       " 'fabulous.a',\n",
       " 'facial.n',\n",
       " 'fair.a',\n",
       " 'fancy.v',\n",
       " 'fantastic.a',\n",
       " 'fare.v',\n",
       " 'fascinated.a',\n",
       " 'favor.v',\n",
       " 'fazed.a',\n",
       " 'fear.v',\n",
       " 'fed up.a',\n",
       " 'feel like.v',\n",
       " 'feverish.a',\n",
       " 'feverishly.adv',\n",
       " 'fight.n',\n",
       " 'fight.v',\n",
       " 'fighter.n',\n",
       " 'fighting.n',\n",
       " 'file.v',\n",
       " 'fine.a',\n",
       " 'fire fighting.n',\n",
       " 'firefight.n',\n",
       " 'first-rate.a',\n",
       " 'fistfight.n',\n",
       " 'floss.v',\n",
       " 'flourish.v',\n",
       " 'fold [to demands].v',\n",
       " 'fond.a',\n",
       " 'for.prep',\n",
       " 'forget.v',\n",
       " 'fracas.n',\n",
       " 'fray.n',\n",
       " 'free-for-all.n',\n",
       " 'friendly.a',\n",
       " 'friendly.n',\n",
       " 'fulfilled.a',\n",
       " 'fulfillment.n',\n",
       " 'function.n',\n",
       " 'gain ground.idio',\n",
       " 'garbage.n',\n",
       " 'gem.n',\n",
       " 'give in.v',\n",
       " 'give way.v',\n",
       " 'goal.n',\n",
       " 'gold.n',\n",
       " 'good idea.n',\n",
       " 'good.a',\n",
       " 'great.a',\n",
       " 'grieve.v',\n",
       " 'groom.v',\n",
       " 'guerrilla.n',\n",
       " 'gunfight.n',\n",
       " 'gunner.n',\n",
       " 'handsome.a',\n",
       " 'hanker.v',\n",
       " 'hankering.n',\n",
       " 'happily.adv',\n",
       " 'hate.v',\n",
       " 'hatred.n',\n",
       " 'have to.v',\n",
       " 'hideous.a',\n",
       " 'hope.n',\n",
       " 'hope.v',\n",
       " 'horrible.a',\n",
       " 'hostile.a',\n",
       " 'hostile.n',\n",
       " 'hostility.n',\n",
       " 'hot.a',\n",
       " 'humble.a',\n",
       " 'hunger.n',\n",
       " 'hunger.v',\n",
       " 'hungry.a',\n",
       " 'idyllic.a',\n",
       " 'impartial.a',\n",
       " 'impartiality.n',\n",
       " 'impulse.n',\n",
       " 'in demand.a',\n",
       " 'in favor.prep',\n",
       " 'in hopes of.prep',\n",
       " 'in order.adv',\n",
       " 'in the hope of.prep',\n",
       " 'in.a',\n",
       " 'incredible.a',\n",
       " 'infantryman.n',\n",
       " 'infatuated.a',\n",
       " 'inferior.a',\n",
       " 'infighting.n',\n",
       " 'intend.v',\n",
       " 'intent.a',\n",
       " 'intention.n',\n",
       " 'interested.a',\n",
       " 'intimidated.a',\n",
       " 'irritated.a',\n",
       " 'itch.v',\n",
       " 'junk.n',\n",
       " 'killer.a',\n",
       " 'lame.a',\n",
       " 'lamer.n',\n",
       " 'languish.v',\n",
       " 'lave.v',\n",
       " 'left.a',\n",
       " 'like.v',\n",
       " 'live.v',\n",
       " 'loath.a',\n",
       " 'loathe.v',\n",
       " 'loathing.n',\n",
       " 'long.v',\n",
       " 'longing.n',\n",
       " 'look.n',\n",
       " 'lost (in).a',\n",
       " 'love.v',\n",
       " 'lovely.a',\n",
       " 'low.a',\n",
       " 'lust.n',\n",
       " 'lust.v',\n",
       " 'magnificent.a',\n",
       " 'manicure.n',\n",
       " 'manicure.v',\n",
       " 'marine.n',\n",
       " 'marvellous.a',\n",
       " 'mean.v',\n",
       " 'mediocre.a',\n",
       " 'melee.n',\n",
       " 'militant.n',\n",
       " 'miserable.a',\n",
       " 'moisturize.v',\n",
       " 'mourn.v',\n",
       " 'nasty.a',\n",
       " 'need.n',\n",
       " 'need.v',\n",
       " 'nervous.a',\n",
       " 'nettled.a',\n",
       " 'neutral.a',\n",
       " 'neutrality.n',\n",
       " 'object.n',\n",
       " 'objective.n',\n",
       " 'okay.a',\n",
       " 'opponent.n',\n",
       " 'oppose.v',\n",
       " 'opposition [act].n',\n",
       " 'opposition [entity].n',\n",
       " 'order.n',\n",
       " 'ought to.v',\n",
       " 'outstanding.a',\n",
       " 'part.n',\n",
       " 'partial.a',\n",
       " 'partiality.n',\n",
       " 'pathetic.a',\n",
       " 'pedestrian.a',\n",
       " 'pedicure.n',\n",
       " 'pine.v',\n",
       " 'pitiful.a',\n",
       " 'pity.n',\n",
       " 'pity.v',\n",
       " 'plait.v',\n",
       " 'plan.n',\n",
       " 'plan.v',\n",
       " 'pleasure.n',\n",
       " 'plebeian.a',\n",
       " 'pluck.v',\n",
       " 'poor.a',\n",
       " 'popular.a',\n",
       " 'prefer.v',\n",
       " 'prejudge.v',\n",
       " 'prejudice.n',\n",
       " 'prejudiced.a',\n",
       " 'pro.adv',\n",
       " 'program.n',\n",
       " 'project.n',\n",
       " 'proletarian.a',\n",
       " 'prosper.v',\n",
       " 'prosperity.n',\n",
       " 'protest.n',\n",
       " 'protest.v',\n",
       " 'protester.n',\n",
       " 'purpose.n',\n",
       " 'raring.a',\n",
       " 'regret.n',\n",
       " 'regret.v',\n",
       " 'relent.v',\n",
       " 'reliance.n',\n",
       " 'relish.n',\n",
       " 'reluctant.a',\n",
       " 'rely.v',\n",
       " 'remain.v',\n",
       " 'remainder.n',\n",
       " 'remember.v',\n",
       " 'require.v',\n",
       " 'resent.v',\n",
       " 'resentment.n',\n",
       " 'rock.v',\n",
       " 'rotten.a',\n",
       " 'row.n',\n",
       " 'rue.v',\n",
       " 'rueful.a',\n",
       " 'sacrifice.v',\n",
       " 'sailor.n',\n",
       " 'satisfaction.n',\n",
       " 'satisfied.a',\n",
       " 'scheme.n',\n",
       " 'scuffle.n',\n",
       " 'scuffle.v',\n",
       " 'second-rate.a',\n",
       " 'sensational.a',\n",
       " 'service member.n',\n",
       " 'shampoo.v',\n",
       " 'shave.v',\n",
       " 'shit.n',\n",
       " 'shitty.a',\n",
       " 'shootout.n',\n",
       " 'should.v',\n",
       " 'showdown.n',\n",
       " 'shower.v',\n",
       " 'side.n',\n",
       " 'side.v',\n",
       " 'signaller.n',\n",
       " 'skirmish.n',\n",
       " 'skirmish.v',\n",
       " 'slump.n',\n",
       " 'smart.a',\n",
       " 'smitten.a',\n",
       " 'sniper.n',\n",
       " 'so-so.a',\n",
       " 'soap.v',\n",
       " 'solace.n',\n",
       " 'soldier.n',\n",
       " 'sound.n',\n",
       " 'spat.n',\n",
       " 'splendid.a',\n",
       " 'spoiling.a',\n",
       " 'squabble.n',\n",
       " 'stalemate.n',\n",
       " 'stand.v',\n",
       " 'standoff.n',\n",
       " 'standout.n',\n",
       " 'strife.n',\n",
       " 'struggle.n',\n",
       " 'struggle.v',\n",
       " 'stupendous.a',\n",
       " 'style.n',\n",
       " 'submit.v',\n",
       " 'substandard.a',\n",
       " 'suck.v',\n",
       " 'super.a',\n",
       " 'superb.a',\n",
       " 'superlative.a',\n",
       " 'support.v',\n",
       " 'supporter.n',\n",
       " 'supportive.a',\n",
       " 'suspicious.a',\n",
       " 'sweet.a',\n",
       " 'tackle.v',\n",
       " 'taken.a',\n",
       " 'target.n',\n",
       " 'tasty.a',\n",
       " 'terrible.a',\n",
       " 'terrific.a',\n",
       " 'third-rate.a',\n",
       " 'thirst.n',\n",
       " 'thirst.v',\n",
       " 'thirsty.a',\n",
       " 'thrive.v',\n",
       " 'tiff.n',\n",
       " 'tip-top.a',\n",
       " 'tolerable.a',\n",
       " 'tolerant.a',\n",
       " 'tolerate.v',\n",
       " 'toleration.n',\n",
       " 'top-notch.a',\n",
       " 'tremendous.a',\n",
       " 'troop.n',\n",
       " 'tussle.n',\n",
       " 'ugly.a',\n",
       " 'uncool.a',\n",
       " 'unfazed.a',\n",
       " 'unfortunate.a',\n",
       " 'upper-class.a',\n",
       " 'upset.a',\n",
       " 'urge.n',\n",
       " 'use.n',\n",
       " 'vulgar.a',\n",
       " 'want.v',\n",
       " 'wants.n',\n",
       " 'war.n',\n",
       " 'war.v',\n",
       " 'warfare.n',\n",
       " 'wash.v',\n",
       " 'wax.v',\n",
       " 'well.adv',\n",
       " 'will.n',\n",
       " 'will.v',\n",
       " 'wish (that).v',\n",
       " 'wish.n',\n",
       " 'wish.v',\n",
       " 'wonderful.a',\n",
       " 'worked up.a',\n",
       " 'working-class.a',\n",
       " 'worried.a',\n",
       " 'worthless.a',\n",
       " 'wrangling.n',\n",
       " 'wrapped up (in).a',\n",
       " 'yearn.v',\n",
       " 'yearning.n',\n",
       " 'yen.n',\n",
       " 'yen.v',\n",
       " 'yield.v'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiencer_focus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e28b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'abominable.a',\n",
       " 'absorbing.a',\n",
       " 'aggravating.a',\n",
       " 'aggravation.n',\n",
       " 'agonizing.a',\n",
       " 'agreeable.a',\n",
       " 'alarming.a',\n",
       " 'alienating.a',\n",
       " 'amazing.a',\n",
       " 'amusing.a',\n",
       " 'annoyance.n',\n",
       " 'annoying.a',\n",
       " 'appalling.a',\n",
       " 'astonishing.a',\n",
       " 'astounding.a',\n",
       " 'baffling.a',\n",
       " 'beguiling.a',\n",
       " 'bewildering.a',\n",
       " 'bewitching.a',\n",
       " 'blood-curdling.a',\n",
       " 'boring.a',\n",
       " 'bothersome.a',\n",
       " 'breathtaking.a',\n",
       " 'calming.a',\n",
       " 'captivating.a',\n",
       " 'charm [count].n',\n",
       " 'charm [mass].n',\n",
       " 'charming.a',\n",
       " 'cheering.a',\n",
       " 'chilling.a',\n",
       " 'color.n',\n",
       " 'comforting.a',\n",
       " 'comical.a',\n",
       " 'confusing.a',\n",
       " 'consoling.a',\n",
       " 'cool.a',\n",
       " 'dear.a',\n",
       " 'delight.n',\n",
       " 'delightful.a',\n",
       " 'depressing.a',\n",
       " 'devastating.a',\n",
       " 'disagreeable.a',\n",
       " 'disappointing.a',\n",
       " 'discomfiting.a',\n",
       " 'discomforting.a',\n",
       " 'disconcerting.a',\n",
       " 'discouraging.a',\n",
       " 'disgusting.a',\n",
       " 'disheartening.a',\n",
       " 'disillusioning.a',\n",
       " 'dismaying.a',\n",
       " 'disorientating.a',\n",
       " 'displeasing.a',\n",
       " 'distasteful.a',\n",
       " 'distressing.a',\n",
       " 'disturbing.a',\n",
       " 'dreadful.a',\n",
       " 'droll.a',\n",
       " 'dull.a',\n",
       " 'earth-shattering.a',\n",
       " 'electrifying.a',\n",
       " 'embarrassing.a',\n",
       " 'embittering.a',\n",
       " 'empty.a',\n",
       " 'enchanting.a',\n",
       " 'encouraging.a',\n",
       " 'engrossing.a',\n",
       " 'enjoyable.a',\n",
       " 'enraging.a',\n",
       " 'entertaining.a',\n",
       " 'enthralling.a',\n",
       " 'exasperating.a',\n",
       " 'exciting.a',\n",
       " 'exhilarating.a',\n",
       " 'fascinating.a',\n",
       " 'formidable.a',\n",
       " 'frightening.a',\n",
       " 'fulfilling.a',\n",
       " 'full.a',\n",
       " 'funny.a',\n",
       " 'galling.a',\n",
       " 'ghastly.a',\n",
       " 'gratifying.a',\n",
       " 'gripping.a',\n",
       " 'hair-raising.a',\n",
       " 'harrowing.a',\n",
       " 'heart-rending.a',\n",
       " 'heart-stopping.a',\n",
       " 'heart-warming.a',\n",
       " 'heartbreaking.a',\n",
       " 'heartening.a',\n",
       " 'hilarious.a',\n",
       " 'humorous.a',\n",
       " 'impressive.a',\n",
       " 'ineffability.n',\n",
       " 'ineffable.a',\n",
       " 'infuriating.a',\n",
       " 'insulting.a',\n",
       " 'intimidating.a',\n",
       " 'intriguing.a',\n",
       " 'invigorating.a',\n",
       " 'irksome.a',\n",
       " 'irritating.a',\n",
       " 'jaw-dropping.a',\n",
       " 'je ne sais quoi.n',\n",
       " 'jolly.a',\n",
       " 'maddening.a',\n",
       " 'magic.a',\n",
       " 'magic.n',\n",
       " 'magical.a',\n",
       " 'magicalness.n',\n",
       " 'mind-boggling.a',\n",
       " 'mind-numbing.a',\n",
       " 'mortifying.a',\n",
       " 'mystifying.a',\n",
       " 'nerve-racking.a',\n",
       " 'nice.a',\n",
       " 'offensive.a',\n",
       " 'pacifying.a',\n",
       " 'pathetic.a',\n",
       " 'perplexing.a',\n",
       " 'pitiful.a',\n",
       " 'placating.a',\n",
       " 'pleasant.a',\n",
       " 'pleasing.a',\n",
       " 'pleasurable.a',\n",
       " 'poignant.a',\n",
       " 'reassuring.a',\n",
       " 'recreation.n',\n",
       " 'relaxation.n',\n",
       " 'relaxing.a',\n",
       " 'repellent.a',\n",
       " 'rest.n',\n",
       " 'revolting.a',\n",
       " 'rich.a',\n",
       " 'rousing.a',\n",
       " 'sad.a',\n",
       " 'saddening.a',\n",
       " 'satisfying.a',\n",
       " 'scary.a',\n",
       " 'shocking.a',\n",
       " 'sickening.a',\n",
       " 'side-splitting.a',\n",
       " 'sobering.a',\n",
       " 'solemn.a',\n",
       " 'soothing.a',\n",
       " 'spine-chilling.a',\n",
       " 'spine-tingling.a',\n",
       " 'startling.a',\n",
       " 'stimulating.a',\n",
       " 'stinging.a',\n",
       " 'stirring.a',\n",
       " 'stressful.a',\n",
       " 'strike a chord.v',\n",
       " 'striking.a',\n",
       " 'stupefying.a',\n",
       " 'surprising.a',\n",
       " 'suspenseful.a',\n",
       " 'tear-jerking.a',\n",
       " 'tedious.a',\n",
       " 'terrifying.a',\n",
       " 'thorny.a',\n",
       " 'thrilling.a',\n",
       " 'tiresome.a',\n",
       " 'tiring.a',\n",
       " 'tormenting.a',\n",
       " 'touching.a',\n",
       " 'traumatic.a',\n",
       " 'traumatising.a',\n",
       " 'troublesome.a',\n",
       " 'troubling.a',\n",
       " 'unexciting.a',\n",
       " 'unfulfilling.a',\n",
       " 'unfunny.a',\n",
       " 'unnerving.a',\n",
       " 'unpleasant.a',\n",
       " 'unpleasing.a',\n",
       " 'unsettling.a',\n",
       " 'uplifting.a',\n",
       " 'upsetting.a',\n",
       " 'vexation.n',\n",
       " 'vexatious.a',\n",
       " 'vexing.a',\n",
       " 'white-knuckle.a',\n",
       " 'worrisome.a',\n",
       " 'worrying.a'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Stimulus_focus_words))\n",
    "Stimulus_focus_words = set(Stimulus_focus_words)\n",
    "Stimulus_focus_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a71146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiencer_words = set(Experiencer_focus_words).union(Stimulus_focus_words)\n",
    "len(Experiencer_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67212a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abhor.v',\n",
       " 'abhorrence.n',\n",
       " 'ablution.n',\n",
       " 'abominable.a',\n",
       " 'abominate.v',\n",
       " 'absorbed.a',\n",
       " 'absorbing.a',\n",
       " 'ache.v',\n",
       " 'acquiesce.v',\n",
       " 'adoration.n',\n",
       " 'adore.v',\n",
       " 'affray.n',\n",
       " 'against.prep',\n",
       " 'agape.a',\n",
       " 'aggravating.a',\n",
       " 'aggravation.n',\n",
       " 'agonizing.a',\n",
       " 'agreeable.a',\n",
       " 'aim.n',\n",
       " 'aim.v',\n",
       " 'airman.n',\n",
       " 'alarming.a',\n",
       " 'alienating.a',\n",
       " 'altercation.n',\n",
       " 'amazing.a',\n",
       " 'ambition.n',\n",
       " 'amusing.a',\n",
       " 'annoyance.n',\n",
       " 'annoying.a',\n",
       " 'antipathy.n',\n",
       " 'appalling.a',\n",
       " 'apprehensive.a',\n",
       " 'aspiration.n',\n",
       " 'aspire.v',\n",
       " 'astonishing.a',\n",
       " 'astounding.a',\n",
       " 'atrocious.a',\n",
       " 'attack.v',\n",
       " 'average.a',\n",
       " 'awesome.a',\n",
       " 'awful.a',\n",
       " 'back.v',\n",
       " 'backing.n',\n",
       " 'bad idea.n',\n",
       " 'bad.a',\n",
       " 'baffling.a',\n",
       " 'bathe.v',\n",
       " 'battle.n',\n",
       " 'battle.v',\n",
       " 'be supposed to.v',\n",
       " 'bear.v',\n",
       " 'beautiful.a',\n",
       " 'beguiling.a',\n",
       " 'believe (in).v',\n",
       " 'belligerent.n',\n",
       " 'bent.a',\n",
       " 'best thing since sliced bread.n',\n",
       " 'bewildering.a',\n",
       " 'bewitching.a',\n",
       " 'bias.n',\n",
       " 'bias.v',\n",
       " 'biased.a',\n",
       " 'blood-curdling.a',\n",
       " 'boring.a',\n",
       " 'bothersome.a',\n",
       " 'bout.n',\n",
       " 'brawl.n',\n",
       " 'brawl.v',\n",
       " 'breathtaking.a',\n",
       " 'brush [hair].v',\n",
       " 'brush [teeth].v',\n",
       " 'bw.n',\n",
       " 'calm.a',\n",
       " 'calming.a',\n",
       " 'capitulate.v',\n",
       " 'captivated.a',\n",
       " 'captivating.a',\n",
       " 'care.v',\n",
       " 'cave in.v',\n",
       " 'cave.v',\n",
       " 'charm [count].n',\n",
       " 'charm [mass].n',\n",
       " 'charming.a',\n",
       " 'cheering.a',\n",
       " 'chilling.a',\n",
       " 'clash.n',\n",
       " 'clash.v',\n",
       " 'cleanse.v',\n",
       " 'color.n',\n",
       " 'comb.v',\n",
       " 'combat.n',\n",
       " 'combatant.n',\n",
       " 'comfort.n',\n",
       " 'comforting.a',\n",
       " 'comical.a',\n",
       " 'commando.n',\n",
       " 'common.a',\n",
       " 'compassion.n',\n",
       " 'compromise.v',\n",
       " 'conflict.n',\n",
       " 'confront.v',\n",
       " 'confrontation.n',\n",
       " 'confusing.a',\n",
       " 'consoling.a',\n",
       " 'control.v',\n",
       " 'cool.a',\n",
       " 'count.v',\n",
       " 'covet.v',\n",
       " 'covetous.a',\n",
       " 'crap.n',\n",
       " 'crappy.a',\n",
       " 'crave.v',\n",
       " 'craving.n',\n",
       " 'curious.a',\n",
       " 'cw.n',\n",
       " 'dear.a',\n",
       " 'decent.a',\n",
       " 'delight.n',\n",
       " 'delight.v',\n",
       " 'delightful.a',\n",
       " 'demonstrate.v',\n",
       " 'demonstration.n',\n",
       " 'depend.v',\n",
       " 'dependence.n',\n",
       " 'dependency.n',\n",
       " 'depressing.a',\n",
       " 'desirable.a',\n",
       " 'desire.n',\n",
       " 'desire.v',\n",
       " 'desired.a',\n",
       " 'desirous.a',\n",
       " 'despair.v',\n",
       " 'desperation.n',\n",
       " 'despise.v',\n",
       " 'determined.a',\n",
       " 'detest.v',\n",
       " 'detestation.n',\n",
       " 'devastating.a',\n",
       " 'disagreeable.a',\n",
       " 'disappointing.a',\n",
       " 'discomfiting.a',\n",
       " 'discomfort.n',\n",
       " 'discomforting.a',\n",
       " 'disconcerting.a',\n",
       " 'discouraging.a',\n",
       " 'disgusting.a',\n",
       " 'disheartening.a',\n",
       " 'disillusioning.a',\n",
       " 'dislike.n',\n",
       " 'dislike.v',\n",
       " 'dismaying.a',\n",
       " 'disorientating.a',\n",
       " 'displeasing.a',\n",
       " 'disprefer.v',\n",
       " 'dissatisfied.a',\n",
       " 'distasteful.a',\n",
       " 'distressing.a',\n",
       " 'disturbing.a',\n",
       " 'do.v',\n",
       " 'donnybrook.n',\n",
       " 'dread.v',\n",
       " 'dreadful.a',\n",
       " 'droll.a',\n",
       " 'duel.n',\n",
       " 'duel.v',\n",
       " 'dull.a',\n",
       " 'dust-up.n',\n",
       " 'dying.a',\n",
       " 'eager.a',\n",
       " 'earth-shattering.a',\n",
       " 'easy.a',\n",
       " 'electrifying.a',\n",
       " 'elegant.a',\n",
       " 'elude.v',\n",
       " 'embarrassing.a',\n",
       " 'embittering.a',\n",
       " 'empathy.n',\n",
       " 'empty.a',\n",
       " 'enchanting.a',\n",
       " 'encouraging.a',\n",
       " 'endorse.v',\n",
       " 'endure.v',\n",
       " 'enemy.n',\n",
       " 'engage.v',\n",
       " 'engagement.n',\n",
       " 'engrossed.a',\n",
       " 'engrossing.a',\n",
       " 'enjoyable.a',\n",
       " 'enraging.a',\n",
       " 'entertaining.a',\n",
       " 'enthralled.a',\n",
       " 'enthralling.a',\n",
       " 'envy.n',\n",
       " 'envy.v',\n",
       " 'escape.v',\n",
       " 'evade.v',\n",
       " 'exasperating.a',\n",
       " 'excellence.n',\n",
       " 'excellent.a',\n",
       " 'exciting.a',\n",
       " 'execrable.a',\n",
       " 'exhilarating.a',\n",
       " 'extraordinary.a',\n",
       " 'fabulous.a',\n",
       " 'facial.n',\n",
       " 'fair.a',\n",
       " 'fancy.v',\n",
       " 'fantastic.a',\n",
       " 'fare.v',\n",
       " 'fascinated.a',\n",
       " 'fascinating.a',\n",
       " 'favor.v',\n",
       " 'fazed.a',\n",
       " 'fear.v',\n",
       " 'fed up.a',\n",
       " 'feel like.v',\n",
       " 'feverish.a',\n",
       " 'feverishly.adv',\n",
       " 'fight.n',\n",
       " 'fight.v',\n",
       " 'fighter.n',\n",
       " 'fighting.n',\n",
       " 'file.v',\n",
       " 'fine.a',\n",
       " 'fire fighting.n',\n",
       " 'firefight.n',\n",
       " 'first-rate.a',\n",
       " 'fistfight.n',\n",
       " 'floss.v',\n",
       " 'flourish.v',\n",
       " 'fold [to demands].v',\n",
       " 'fond.a',\n",
       " 'for.prep',\n",
       " 'forget.v',\n",
       " 'formidable.a',\n",
       " 'fracas.n',\n",
       " 'fray.n',\n",
       " 'free-for-all.n',\n",
       " 'friendly.a',\n",
       " 'friendly.n',\n",
       " 'frightening.a',\n",
       " 'fulfilled.a',\n",
       " 'fulfilling.a',\n",
       " 'fulfillment.n',\n",
       " 'full.a',\n",
       " 'function.n',\n",
       " 'funny.a',\n",
       " 'gain ground.idio',\n",
       " 'galling.a',\n",
       " 'garbage.n',\n",
       " 'gem.n',\n",
       " 'ghastly.a',\n",
       " 'give in.v',\n",
       " 'give way.v',\n",
       " 'goal.n',\n",
       " 'gold.n',\n",
       " 'good idea.n',\n",
       " 'good.a',\n",
       " 'gratifying.a',\n",
       " 'great.a',\n",
       " 'grieve.v',\n",
       " 'gripping.a',\n",
       " 'groom.v',\n",
       " 'guerrilla.n',\n",
       " 'gunfight.n',\n",
       " 'gunner.n',\n",
       " 'hair-raising.a',\n",
       " 'handsome.a',\n",
       " 'hanker.v',\n",
       " 'hankering.n',\n",
       " 'happily.adv',\n",
       " 'harrowing.a',\n",
       " 'hate.v',\n",
       " 'hatred.n',\n",
       " 'have to.v',\n",
       " 'heart-rending.a',\n",
       " 'heart-stopping.a',\n",
       " 'heart-warming.a',\n",
       " 'heartbreaking.a',\n",
       " 'heartening.a',\n",
       " 'hideous.a',\n",
       " 'hilarious.a',\n",
       " 'hope.n',\n",
       " 'hope.v',\n",
       " 'horrible.a',\n",
       " 'hostile.a',\n",
       " 'hostile.n',\n",
       " 'hostility.n',\n",
       " 'hot.a',\n",
       " 'humble.a',\n",
       " 'humorous.a',\n",
       " 'hunger.n',\n",
       " 'hunger.v',\n",
       " 'hungry.a',\n",
       " 'idyllic.a',\n",
       " 'impartial.a',\n",
       " 'impartiality.n',\n",
       " 'impressive.a',\n",
       " 'impulse.n',\n",
       " 'in demand.a',\n",
       " 'in favor.prep',\n",
       " 'in hopes of.prep',\n",
       " 'in order.adv',\n",
       " 'in the hope of.prep',\n",
       " 'in.a',\n",
       " 'incredible.a',\n",
       " 'ineffability.n',\n",
       " 'ineffable.a',\n",
       " 'infantryman.n',\n",
       " 'infatuated.a',\n",
       " 'inferior.a',\n",
       " 'infighting.n',\n",
       " 'infuriating.a',\n",
       " 'insulting.a',\n",
       " 'intend.v',\n",
       " 'intent.a',\n",
       " 'intention.n',\n",
       " 'interested.a',\n",
       " 'intimidated.a',\n",
       " 'intimidating.a',\n",
       " 'intriguing.a',\n",
       " 'invigorating.a',\n",
       " 'irksome.a',\n",
       " 'irritated.a',\n",
       " 'irritating.a',\n",
       " 'itch.v',\n",
       " 'jaw-dropping.a',\n",
       " 'je ne sais quoi.n',\n",
       " 'jolly.a',\n",
       " 'junk.n',\n",
       " 'killer.a',\n",
       " 'lame.a',\n",
       " 'lamer.n',\n",
       " 'languish.v',\n",
       " 'lave.v',\n",
       " 'left.a',\n",
       " 'like.v',\n",
       " 'live.v',\n",
       " 'loath.a',\n",
       " 'loathe.v',\n",
       " 'loathing.n',\n",
       " 'long.v',\n",
       " 'longing.n',\n",
       " 'look.n',\n",
       " 'lost (in).a',\n",
       " 'love.v',\n",
       " 'lovely.a',\n",
       " 'low.a',\n",
       " 'lust.n',\n",
       " 'lust.v',\n",
       " 'maddening.a',\n",
       " 'magic.a',\n",
       " 'magic.n',\n",
       " 'magical.a',\n",
       " 'magicalness.n',\n",
       " 'magnificent.a',\n",
       " 'manicure.n',\n",
       " 'manicure.v',\n",
       " 'marine.n',\n",
       " 'marvellous.a',\n",
       " 'mean.v',\n",
       " 'mediocre.a',\n",
       " 'melee.n',\n",
       " 'militant.n',\n",
       " 'mind-boggling.a',\n",
       " 'mind-numbing.a',\n",
       " 'miserable.a',\n",
       " 'moisturize.v',\n",
       " 'mortifying.a',\n",
       " 'mourn.v',\n",
       " 'mystifying.a',\n",
       " 'nasty.a',\n",
       " 'need.n',\n",
       " 'need.v',\n",
       " 'nerve-racking.a',\n",
       " 'nervous.a',\n",
       " 'nettled.a',\n",
       " 'neutral.a',\n",
       " 'neutrality.n',\n",
       " 'nice.a',\n",
       " 'object.n',\n",
       " 'objective.n',\n",
       " 'offensive.a',\n",
       " 'okay.a',\n",
       " 'opponent.n',\n",
       " 'oppose.v',\n",
       " 'opposition [act].n',\n",
       " 'opposition [entity].n',\n",
       " 'order.n',\n",
       " 'ought to.v',\n",
       " 'outstanding.a',\n",
       " 'pacifying.a',\n",
       " 'part.n',\n",
       " 'partial.a',\n",
       " 'partiality.n',\n",
       " 'pathetic.a',\n",
       " 'pedestrian.a',\n",
       " 'pedicure.n',\n",
       " 'perplexing.a',\n",
       " 'pine.v',\n",
       " 'pitiful.a',\n",
       " 'pity.n',\n",
       " 'pity.v',\n",
       " 'placating.a',\n",
       " 'plait.v',\n",
       " 'plan.n',\n",
       " 'plan.v',\n",
       " 'pleasant.a',\n",
       " 'pleasing.a',\n",
       " 'pleasurable.a',\n",
       " 'pleasure.n',\n",
       " 'plebeian.a',\n",
       " 'pluck.v',\n",
       " 'poignant.a',\n",
       " 'poor.a',\n",
       " 'popular.a',\n",
       " 'prefer.v',\n",
       " 'prejudge.v',\n",
       " 'prejudice.n',\n",
       " 'prejudiced.a',\n",
       " 'pro.adv',\n",
       " 'program.n',\n",
       " 'project.n',\n",
       " 'proletarian.a',\n",
       " 'prosper.v',\n",
       " 'prosperity.n',\n",
       " 'protest.n',\n",
       " 'protest.v',\n",
       " 'protester.n',\n",
       " 'purpose.n',\n",
       " 'raring.a',\n",
       " 'reassuring.a',\n",
       " 'recreation.n',\n",
       " 'regret.n',\n",
       " 'regret.v',\n",
       " 'relaxation.n',\n",
       " 'relaxing.a',\n",
       " 'relent.v',\n",
       " 'reliance.n',\n",
       " 'relish.n',\n",
       " 'reluctant.a',\n",
       " 'rely.v',\n",
       " 'remain.v',\n",
       " 'remainder.n',\n",
       " 'remember.v',\n",
       " 'repellent.a',\n",
       " 'require.v',\n",
       " 'resent.v',\n",
       " 'resentment.n',\n",
       " 'rest.n',\n",
       " 'revolting.a',\n",
       " 'rich.a',\n",
       " 'rock.v',\n",
       " 'rotten.a',\n",
       " 'rousing.a',\n",
       " 'row.n',\n",
       " 'rue.v',\n",
       " 'rueful.a',\n",
       " 'sacrifice.v',\n",
       " 'sad.a',\n",
       " 'saddening.a',\n",
       " 'sailor.n',\n",
       " 'satisfaction.n',\n",
       " 'satisfied.a',\n",
       " 'satisfying.a',\n",
       " 'scary.a',\n",
       " 'scheme.n',\n",
       " 'scuffle.n',\n",
       " 'scuffle.v',\n",
       " 'second-rate.a',\n",
       " 'sensational.a',\n",
       " 'service member.n',\n",
       " 'shampoo.v',\n",
       " 'shave.v',\n",
       " 'shit.n',\n",
       " 'shitty.a',\n",
       " 'shocking.a',\n",
       " 'shootout.n',\n",
       " 'should.v',\n",
       " 'showdown.n',\n",
       " 'shower.v',\n",
       " 'sickening.a',\n",
       " 'side-splitting.a',\n",
       " 'side.n',\n",
       " 'side.v',\n",
       " 'signaller.n',\n",
       " 'skirmish.n',\n",
       " 'skirmish.v',\n",
       " 'slump.n',\n",
       " 'smart.a',\n",
       " 'smitten.a',\n",
       " 'sniper.n',\n",
       " 'so-so.a',\n",
       " 'soap.v',\n",
       " 'sobering.a',\n",
       " 'solace.n',\n",
       " 'soldier.n',\n",
       " 'solemn.a',\n",
       " 'soothing.a',\n",
       " 'sound.n',\n",
       " 'spat.n',\n",
       " 'spine-chilling.a',\n",
       " 'spine-tingling.a',\n",
       " 'splendid.a',\n",
       " 'spoiling.a',\n",
       " 'squabble.n',\n",
       " 'stalemate.n',\n",
       " 'stand.v',\n",
       " 'standoff.n',\n",
       " 'standout.n',\n",
       " 'startling.a',\n",
       " 'stimulating.a',\n",
       " 'stinging.a',\n",
       " 'stirring.a',\n",
       " 'stressful.a',\n",
       " 'strife.n',\n",
       " 'strike a chord.v',\n",
       " 'striking.a',\n",
       " 'struggle.n',\n",
       " 'struggle.v',\n",
       " 'stupefying.a',\n",
       " 'stupendous.a',\n",
       " 'style.n',\n",
       " 'submit.v',\n",
       " 'substandard.a',\n",
       " 'suck.v',\n",
       " 'super.a',\n",
       " 'superb.a',\n",
       " 'superlative.a',\n",
       " 'support.v',\n",
       " 'supporter.n',\n",
       " 'supportive.a',\n",
       " 'surprising.a',\n",
       " 'suspenseful.a',\n",
       " 'suspicious.a',\n",
       " 'sweet.a',\n",
       " 'tackle.v',\n",
       " 'taken.a',\n",
       " 'target.n',\n",
       " 'tasty.a',\n",
       " 'tear-jerking.a',\n",
       " 'tedious.a',\n",
       " 'terrible.a',\n",
       " 'terrific.a',\n",
       " 'terrifying.a',\n",
       " 'third-rate.a',\n",
       " 'thirst.n',\n",
       " 'thirst.v',\n",
       " 'thirsty.a',\n",
       " 'thorny.a',\n",
       " 'thrilling.a',\n",
       " 'thrive.v',\n",
       " 'tiff.n',\n",
       " 'tip-top.a',\n",
       " 'tiresome.a',\n",
       " 'tiring.a',\n",
       " 'tolerable.a',\n",
       " 'tolerant.a',\n",
       " 'tolerate.v',\n",
       " 'toleration.n',\n",
       " 'top-notch.a',\n",
       " 'tormenting.a',\n",
       " 'touching.a',\n",
       " 'traumatic.a',\n",
       " 'traumatising.a',\n",
       " 'tremendous.a',\n",
       " 'troop.n',\n",
       " 'troublesome.a',\n",
       " 'troubling.a',\n",
       " 'tussle.n',\n",
       " 'ugly.a',\n",
       " 'uncool.a',\n",
       " 'unexciting.a',\n",
       " 'unfazed.a',\n",
       " 'unfortunate.a',\n",
       " 'unfulfilling.a',\n",
       " 'unfunny.a',\n",
       " 'unnerving.a',\n",
       " 'unpleasant.a',\n",
       " 'unpleasing.a',\n",
       " 'unsettling.a',\n",
       " 'uplifting.a',\n",
       " 'upper-class.a',\n",
       " 'upset.a',\n",
       " 'upsetting.a',\n",
       " 'urge.n',\n",
       " 'use.n',\n",
       " 'vexation.n',\n",
       " 'vexatious.a',\n",
       " 'vexing.a',\n",
       " 'vulgar.a',\n",
       " 'want.v',\n",
       " 'wants.n',\n",
       " 'war.n',\n",
       " 'war.v',\n",
       " 'warfare.n',\n",
       " 'wash.v',\n",
       " 'wax.v',\n",
       " 'well.adv',\n",
       " 'white-knuckle.a',\n",
       " 'will.n',\n",
       " 'will.v',\n",
       " 'wish (that).v',\n",
       " 'wish.n',\n",
       " 'wish.v',\n",
       " 'wonderful.a',\n",
       " 'worked up.a',\n",
       " 'working-class.a',\n",
       " 'worried.a',\n",
       " 'worrisome.a',\n",
       " 'worrying.a',\n",
       " 'worthless.a',\n",
       " 'wrangling.n',\n",
       " 'wrapped up (in).a',\n",
       " 'yearn.v',\n",
       " 'yearning.n',\n",
       " 'yen.n',\n",
       " 'yen.v',\n",
       " 'yield.v'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiencer_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4786af9",
   "metadata": {},
   "source": [
    "##  Using the wordnet  adj wheel information to expand the set of adjective words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b902f6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['envy.n',\n",
       " 'calm.a',\n",
       " 'abhorrence.n',\n",
       " 'sacrifice.v',\n",
       " 'believe (in).v',\n",
       " 'desire.v',\n",
       " 'should.v',\n",
       " 'yen.n',\n",
       " 'scuffle.v',\n",
       " 'pine.v']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2246a1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 284 1268\n"
     ]
    }
   ],
   "source": [
    "L = list(Experiencer_focus_words)\n",
    "L_ss = [ss for w in  L if w[-1] == \"a\" for ss in wn.synsets(w[:-2],\"a\") if ss.pos()==\"s\"]\n",
    "# filter out some highly ambiguous noise makers\n",
    "L_ss = [ss for ss in L_ss if ss.lemmas()[0].name() not in [\"hot\", \"in\",\"good\", \"bad\", \"easy\", \"common\", \"neutral\"]]\n",
    "extended_experiencer_focus_adjectives_wn = sorted(list({ss2.name() for ss in L_ss for ss2 in get_wheels_and_axle(ss,return_set=True)}))\n",
    "print(len(L),len(L_ss),len(expanded_L_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "07680cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 217 1268\n"
     ]
    }
   ],
   "source": [
    "L2 = list(Stimulus_focus_words)\n",
    "L2_ss = [ss for w in  L2 if w[-1] == \"a\" for ss in wn.synsets(w[:-2],\"a\") if ss.pos()==\"s\"]\n",
    "# filter out some highly ambiguous noise makers\n",
    "#L_ss = [ss for ss in L_ss if ss.lemmas()[0].name() not in [\"hot\", \"in\",\"good\", \"bad\", \"easy\", \"common\", \"neutral\"]]\n",
    "extended_stimulus_focus_adjectives_wn = sorted(list({ss2.name() for ss in L2_ss for ss2 in get_wheels_and_axle(ss,return_set=True)}))\n",
    "print(len(L2),len(L2_ss),len(expanded_L2_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b6c3bbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extended_stimulus_focus_adjectives_wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "37031ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abashed.s.01',\n",
       " 'abhorrent.s.01',\n",
       " 'abject.s.01',\n",
       " 'abject.s.02',\n",
       " 'ablaze.s.03',\n",
       " 'abominable.s.01',\n",
       " 'abortive.s.01',\n",
       " 'abounding.s.01',\n",
       " 'absolute.s.02',\n",
       " 'absorbefacient.s.01',\n",
       " 'absorbent.a.01',\n",
       " 'absorbing.s.01',\n",
       " 'abundant.a.01',\n",
       " 'acarpous.s.01',\n",
       " 'accessary.s.01',\n",
       " 'accessory.s.02',\n",
       " 'accomplished.s.02',\n",
       " 'accordant.a.01',\n",
       " 'accordant.s.02',\n",
       " 'according.s.01',\n",
       " 'acerb.s.02',\n",
       " 'aching.s.01',\n",
       " 'acid-tasting.s.01',\n",
       " 'acknowledged.s.02',\n",
       " 'active.a.07',\n",
       " 'adequate.s.03',\n",
       " 'admirable.s.01',\n",
       " 'admirable.s.02',\n",
       " 'admired.s.01',\n",
       " 'admonitory.s.01',\n",
       " 'adorable.s.01',\n",
       " 'adored.s.01',\n",
       " 'adrenocorticotropic.s.01',\n",
       " 'advanced.s.04',\n",
       " 'affecting.s.01',\n",
       " 'afflicted.s.01',\n",
       " 'afflictive.s.01',\n",
       " 'aggravating.s.01',\n",
       " 'agitative.s.01',\n",
       " 'agonized.s.01',\n",
       " 'agonizing.s.01',\n",
       " 'agreeable.a.01',\n",
       " 'agreeable.s.03',\n",
       " 'aguish.s.01',\n",
       " 'ailing.s.01',\n",
       " 'airheaded.s.01',\n",
       " 'airsick.s.01',\n",
       " 'alarming.a.01',\n",
       " 'alienated.s.02',\n",
       " 'alienating.s.01',\n",
       " 'aligning.s.01',\n",
       " 'alimentary.s.01',\n",
       " 'aliquot.s.01',\n",
       " 'alive.s.04',\n",
       " 'all-or-none.s.01',\n",
       " 'all-out.s.01',\n",
       " 'all.s.02',\n",
       " 'all_right.s.01',\n",
       " 'alleged.s.02',\n",
       " 'alleviative.s.01',\n",
       " 'allover.s.01',\n",
       " 'alluring.s.01',\n",
       " 'alright.s.01',\n",
       " 'amazing.s.01',\n",
       " 'amazing.s.02',\n",
       " 'ambidextrous.s.02',\n",
       " 'ambitious.s.02',\n",
       " 'ambrosial.s.01',\n",
       " 'amentiferous.s.01',\n",
       " 'amiable.s.01',\n",
       " 'ample.a.01',\n",
       " 'ample.s.02',\n",
       " 'amusing.s.01',\n",
       " 'amusing.s.02',\n",
       " 'analeptic.s.01',\n",
       " 'analgesic.s.01',\n",
       " 'anechoic.s.01',\n",
       " 'angelic.s.03',\n",
       " 'anguished.s.01',\n",
       " 'animating.s.01',\n",
       " 'annihilating.s.02',\n",
       " 'annihilative.s.01',\n",
       " 'annoying.s.01',\n",
       " 'anserine.s.02',\n",
       " 'antagonistic.a.03',\n",
       " 'antic.s.01',\n",
       " 'antique.s.02',\n",
       " 'antsy.s.01',\n",
       " 'aphoristic.s.02',\n",
       " 'apocryphal.s.01',\n",
       " 'appalling.s.01',\n",
       " 'apparitional.s.01',\n",
       " 'appeasing.s.01',\n",
       " 'approximate.s.02',\n",
       " 'arable.s.01',\n",
       " 'arduous.s.01',\n",
       " 'arduous.s.02',\n",
       " 'arduous.s.03',\n",
       " 'armed.a.03',\n",
       " 'aroused.s.03',\n",
       " 'arresting.s.01',\n",
       " 'ashen.s.01',\n",
       " 'assimilating.s.01',\n",
       " 'assuasive.s.01',\n",
       " 'assuring.s.01',\n",
       " 'astonishing.s.02',\n",
       " 'astounding.s.01',\n",
       " 'astute.s.01',\n",
       " 'asymptomatic.s.01',\n",
       " 'at_odds.s.01',\n",
       " 'at_variance.s.01',\n",
       " 'ataractic.s.01',\n",
       " 'atrabilious.s.01',\n",
       " 'atrocious.s.02',\n",
       " 'atrocious.s.03',\n",
       " 'attention-getting.s.01',\n",
       " 'attractive.a.01',\n",
       " 'augmentative.s.02',\n",
       " 'autistic.s.01',\n",
       " 'awful.s.02',\n",
       " 'awkward.s.05',\n",
       " 'bad.a.01',\n",
       " 'bad.s.03',\n",
       " 'baffling.s.01',\n",
       " 'baleful.s.02',\n",
       " 'bang-up.s.01',\n",
       " 'bantering.s.01',\n",
       " 'barbed.s.02',\n",
       " 'bare.s.02',\n",
       " 'bargain-priced.s.01',\n",
       " 'baronial.s.01',\n",
       " 'bastardly.s.02',\n",
       " 'beastly.s.01',\n",
       " 'beatific.s.01',\n",
       " 'beautiful.s.02',\n",
       " 'bedfast.s.01',\n",
       " 'beguiling.s.02',\n",
       " 'beloved.s.01',\n",
       " 'benign.s.03',\n",
       " 'benignant.s.02',\n",
       " 'bereaved.s.01',\n",
       " 'bereft.s.01',\n",
       " 'berried.s.01',\n",
       " 'better_off.s.01',\n",
       " 'bewitching.s.01',\n",
       " 'beyond_doubt.s.01',\n",
       " 'big-ticket.s.01',\n",
       " 'big.s.04',\n",
       " 'big.s.05',\n",
       " 'bilious.s.02',\n",
       " 'biting.s.02',\n",
       " 'bitter.s.04',\n",
       " 'bitter.s.06',\n",
       " 'bitterish.s.01',\n",
       " 'bittersweet.s.02',\n",
       " 'black.s.06',\n",
       " 'bland.s.01',\n",
       " 'bland.s.02',\n",
       " 'blaring.s.01',\n",
       " 'blasting.s.01',\n",
       " 'bleached.s.01',\n",
       " 'blockheaded.s.01',\n",
       " 'bloodcurdling.s.01',\n",
       " 'blue-chip.s.01',\n",
       " 'blue-eyed.s.01',\n",
       " 'blue-fruited.s.01',\n",
       " 'blurred.s.02',\n",
       " 'blushful.s.01',\n",
       " 'bold.s.02',\n",
       " 'bona_fide.s.01',\n",
       " 'booming.s.02',\n",
       " 'boon.s.01',\n",
       " 'bootless.s.01',\n",
       " 'bootlicking.s.01',\n",
       " 'boring.s.01',\n",
       " 'bothered.s.01',\n",
       " 'bountiful.s.02',\n",
       " 'bracing.s.01',\n",
       " 'brackish.s.01',\n",
       " 'bratty.s.01',\n",
       " 'breathless.s.02',\n",
       " 'breeding.s.01',\n",
       " 'brief.s.02',\n",
       " 'bright.s.02',\n",
       " 'bright.s.08',\n",
       " 'brilliant.s.03',\n",
       " 'brisk.s.03',\n",
       " 'bristlelike.s.01',\n",
       " 'bristly.s.01',\n",
       " 'broad.s.04',\n",
       " 'broad.s.05',\n",
       " 'broken.s.13',\n",
       " 'brokenhearted.s.01',\n",
       " 'bronchitic.s.01',\n",
       " 'brumous.s.01',\n",
       " 'brushlike.s.01',\n",
       " 'buffoonish.s.01',\n",
       " 'burdensome.s.01',\n",
       " 'bustling.s.01',\n",
       " 'busy.s.04',\n",
       " 'buttery.s.01',\n",
       " 'cagey.s.01',\n",
       " 'callous.s.01',\n",
       " 'calm.s.01',\n",
       " 'cantankerous.s.02',\n",
       " 'casual.s.09',\n",
       " 'cataclysmal.s.01',\n",
       " 'catchpenny.s.01',\n",
       " 'catchy.s.01',\n",
       " 'categoric.s.02',\n",
       " 'caustic.s.02',\n",
       " 'certificatory.s.01',\n",
       " 'chafed.s.01',\n",
       " 'chaffy.s.02',\n",
       " 'challenging.s.02',\n",
       " 'challenging.s.03',\n",
       " 'changeable.s.04',\n",
       " 'charged.s.04',\n",
       " 'charismatic.s.01',\n",
       " 'charitable.s.03',\n",
       " 'charming.s.01',\n",
       " 'charming.s.02',\n",
       " 'charnel.s.01',\n",
       " 'chaste.s.03',\n",
       " 'cheap.a.01',\n",
       " 'cherished.s.01',\n",
       " 'childless.s.01',\n",
       " 'chilling.s.01',\n",
       " 'choice.s.02',\n",
       " 'choleric.s.02',\n",
       " 'choosy.s.01',\n",
       " 'chummy.s.02',\n",
       " 'churlish.s.01',\n",
       " 'churlish.s.02',\n",
       " 'clarion.s.01',\n",
       " 'clawed.s.02',\n",
       " 'clean.s.02',\n",
       " 'clean.s.10',\n",
       " 'clean.s.14',\n",
       " 'clean.s.15',\n",
       " 'clear-cut.s.01',\n",
       " 'clear.a.01',\n",
       " 'clear.a.11',\n",
       " 'cliff-hanging.s.01',\n",
       " 'clinking.s.01',\n",
       " 'cloddish.s.01',\n",
       " 'close-knit.s.01',\n",
       " 'close.a.02',\n",
       " 'cloud-covered.s.01',\n",
       " 'cloudless.s.01',\n",
       " 'cloudlike.s.01',\n",
       " 'cloudy.a.02',\n",
       " 'coaxing.s.01',\n",
       " 'cogent.s.01',\n",
       " 'collateral.s.02',\n",
       " 'collected.s.02',\n",
       " 'colorful.a.01',\n",
       " 'colorless.a.02',\n",
       " 'comfortable.a.01',\n",
       " 'comforting.s.01',\n",
       " 'comforting.s.02',\n",
       " 'comfortless.s.01',\n",
       " 'common.s.04',\n",
       " 'common_or_garden.s.01',\n",
       " 'commonplace.s.02',\n",
       " 'compelling.s.02',\n",
       " 'compendious.s.01',\n",
       " 'complete.a.01',\n",
       " 'completed.s.03',\n",
       " 'composed.a.01',\n",
       " 'conciliatory.a.02',\n",
       " 'concise.a.01',\n",
       " 'concordant.s.02',\n",
       " 'conditional.s.01',\n",
       " 'confidential.s.03',\n",
       " 'confounding.s.01',\n",
       " 'confusing.s.01',\n",
       " 'confusing.s.02',\n",
       " 'congenial.a.01',\n",
       " 'consensual.s.01',\n",
       " 'consentaneous.s.01',\n",
       " 'consistent.a.01',\n",
       " 'conspicuous.a.01',\n",
       " 'constructive.a.01',\n",
       " 'consumptive.s.02',\n",
       " 'contemptible.a.01',\n",
       " 'contemptuous.s.01',\n",
       " 'contumelious.s.01',\n",
       " 'convalescent.s.01',\n",
       " 'convincing.a.01',\n",
       " 'cool.s.02',\n",
       " 'cool.s.05',\n",
       " 'cool.s.06',\n",
       " 'copacetic.s.01',\n",
       " 'copious.s.01',\n",
       " 'cordial.s.03',\n",
       " 'corked.s.01',\n",
       " 'corn-fed.s.01',\n",
       " 'corroborant.s.01',\n",
       " 'corrupting.s.01',\n",
       " 'costly.s.02',\n",
       " 'courteous.s.01',\n",
       " 'courtly.s.01',\n",
       " 'cozy.s.01',\n",
       " 'cozy.s.03',\n",
       " 'crabbed.s.01',\n",
       " 'cranky.s.02',\n",
       " 'crazy.s.04',\n",
       " 'creative.s.02',\n",
       " 'credible.a.01',\n",
       " 'credible.s.03',\n",
       " 'creepy.s.01',\n",
       " 'creepy.s.02',\n",
       " 'crisp.s.06',\n",
       " 'crushing.s.01',\n",
       " 'crusty.s.02',\n",
       " 'crying.s.02',\n",
       " 'cryptic.s.01',\n",
       " 'cryptic.s.03',\n",
       " 'cuddlesome.s.01',\n",
       " 'cunning.s.01',\n",
       " 'cured.s.01',\n",
       " 'curious.s.01',\n",
       " 'currish.s.02',\n",
       " 'cushy.s.01',\n",
       " 'cutting.s.01',\n",
       " 'dainty.s.03',\n",
       " 'dainty.s.04',\n",
       " 'damaging.s.02',\n",
       " 'dapper.s.01',\n",
       " 'dark-fruited.s.01',\n",
       " 'dark.s.06',\n",
       " 'dark.s.11',\n",
       " 'dated.s.01',\n",
       " 'daunting.s.01',\n",
       " 'dazzling.s.01',\n",
       " 'dead.s.04',\n",
       " 'dead.s.06',\n",
       " 'dead.s.08',\n",
       " 'dead.s.15',\n",
       " 'dead.s.17',\n",
       " 'deafening.s.01',\n",
       " 'dear.s.02',\n",
       " 'dear.s.03',\n",
       " 'dearly-won.s.01',\n",
       " 'debased.s.02',\n",
       " 'debatable.s.01',\n",
       " 'debauched.s.01',\n",
       " 'debilitating.a.01',\n",
       " 'debilitative.s.01',\n",
       " 'deceitful.s.01',\n",
       " 'decent.s.01',\n",
       " 'deceptive.s.02',\n",
       " 'deep.s.07',\n",
       " 'deepening.s.01',\n",
       " 'deferent.s.01',\n",
       " 'degage.s.01',\n",
       " 'delectable.s.01',\n",
       " 'delicate.s.06',\n",
       " 'delightful.s.01',\n",
       " 'delirious.s.01',\n",
       " 'demeaning.s.01',\n",
       " 'demonstrative_of.s.01',\n",
       " 'demoralizing.s.01',\n",
       " 'dense.s.04',\n",
       " 'deplorable.s.01',\n",
       " 'depressant.a.01',\n",
       " 'depressed.s.01',\n",
       " 'derisive.s.01',\n",
       " 'describable.s.01',\n",
       " 'despised.s.01',\n",
       " 'destructive.a.01',\n",
       " 'diabetic.s.02',\n",
       " 'difficult.a.01',\n",
       " 'diffuse.s.03',\n",
       " 'dignified.a.01',\n",
       " 'dimensioning.s.01',\n",
       " 'dinky.s.02',\n",
       " 'dirt_cheap.s.01',\n",
       " 'dirty.s.03',\n",
       " 'disagreeable.a.01',\n",
       " 'disagreeable.s.02',\n",
       " 'disagreeable.s.03',\n",
       " 'disappointing.s.01',\n",
       " 'disarming.s.01',\n",
       " 'discombobulated.s.01',\n",
       " 'discomposed.a.01',\n",
       " 'disconcerting.s.01',\n",
       " 'disconfirming.s.02',\n",
       " 'discordant.a.01',\n",
       " 'discouraging.a.01',\n",
       " 'discouraging.s.02',\n",
       " 'discourteous.s.02',\n",
       " 'discrepant.s.01',\n",
       " 'disenchanting.s.01',\n",
       " 'disgraceful.s.01',\n",
       " 'disgusting.s.01',\n",
       " 'dishonest.a.01',\n",
       " 'disinherited.s.01',\n",
       " 'disorienting.a.01',\n",
       " 'displeasing.a.01',\n",
       " 'dispossessed.s.01',\n",
       " 'disrespectful.a.01',\n",
       " 'dissentious.s.01',\n",
       " 'dissimulative.s.01',\n",
       " 'dissuasive.a.01',\n",
       " 'distant.a.02',\n",
       " 'distasteful.s.01',\n",
       " 'distinguished.s.02',\n",
       " 'distressing.s.01',\n",
       " 'divine.s.04',\n",
       " 'divisional.s.03',\n",
       " 'dizzy.s.01',\n",
       " 'dolorous.s.01',\n",
       " 'doomed.s.03',\n",
       " 'doubtful.s.01',\n",
       " 'dour.s.02',\n",
       " 'dowdy.s.02',\n",
       " 'downright.s.01',\n",
       " 'downtrodden.s.01',\n",
       " 'drab.s.02',\n",
       " 'dragging.s.01',\n",
       " 'drained.a.01',\n",
       " 'draining.s.01',\n",
       " 'dramatic.s.02',\n",
       " 'dreadful.s.03',\n",
       " 'droll.s.01',\n",
       " 'dry.s.02',\n",
       " 'dry.s.09',\n",
       " 'dry.s.11',\n",
       " 'dulcet.s.01',\n",
       " 'dull.s.03',\n",
       " 'dull.s.05',\n",
       " 'dull.s.08',\n",
       " 'dull.s.10',\n",
       " 'dull.s.11',\n",
       " 'dull.s.12',\n",
       " 'dulled.s.03',\n",
       " 'dyspeptic.s.01',\n",
       " 'earnest.s.01',\n",
       " 'earthshaking.s.01',\n",
       " 'easy.a.01',\n",
       " 'easy.s.04',\n",
       " 'easy.s.09',\n",
       " 'easy.s.12',\n",
       " 'echoing.s.01',\n",
       " 'ecstatic.s.01',\n",
       " 'edgy.s.01',\n",
       " 'eerie.s.01',\n",
       " 'eerie.s.02',\n",
       " 'effective.a.01',\n",
       " 'effortful.a.01',\n",
       " 'effortless.a.01',\n",
       " 'elated.s.02',\n",
       " 'elating.s.01',\n",
       " 'eldritch.s.01',\n",
       " 'electric.s.02',\n",
       " 'electric.s.03',\n",
       " 'electrifying.s.01',\n",
       " 'elegant.s.02',\n",
       " 'elegiac.s.02',\n",
       " 'elementary.s.01',\n",
       " 'elfin.s.01',\n",
       " 'elliptic.s.03',\n",
       " 'embarrassing.s.02',\n",
       " 'empty.s.02',\n",
       " 'empty.s.03',\n",
       " 'empty.s.04',\n",
       " 'encouraging.a.01',\n",
       " 'encouraging.s.02',\n",
       " 'engaging.s.01',\n",
       " 'enjoyable.s.01',\n",
       " 'entertaining.s.01',\n",
       " 'entire.s.01',\n",
       " 'equable.s.02',\n",
       " 'equivocal.s.02',\n",
       " 'erosive.s.01',\n",
       " 'estimable.a.01',\n",
       " 'estranging.s.01',\n",
       " 'etiolate.s.01',\n",
       " 'euphonious.s.02',\n",
       " 'everyday.s.03',\n",
       " 'exasperating.s.01',\n",
       " 'excitant.s.01',\n",
       " 'exciting.a.01',\n",
       " 'exciting.s.02',\n",
       " 'exhausted.s.03',\n",
       " 'exhausting.s.02',\n",
       " 'exhaustive.s.01',\n",
       " 'exhilarating.s.01',\n",
       " 'exhortative.s.01',\n",
       " 'exiguous.s.01',\n",
       " 'exotic.s.02',\n",
       " 'expansive.s.02',\n",
       " 'expensive.a.01',\n",
       " 'explainable.s.01',\n",
       " 'explicable.a.01',\n",
       " 'expressible.a.01',\n",
       " 'exuberant.s.03',\n",
       " 'fabulous.s.01',\n",
       " 'fabulous.s.03',\n",
       " 'facile.s.02',\n",
       " 'faddish.s.01',\n",
       " 'failing.s.01',\n",
       " 'faint.s.04',\n",
       " 'fair.s.09',\n",
       " 'false.s.04',\n",
       " 'false.s.07',\n",
       " 'familiar.a.02',\n",
       " 'familiar.s.04',\n",
       " 'familiarizing.s.01',\n",
       " 'famished.s.01',\n",
       " 'faraway.s.02',\n",
       " 'farcical.s.01',\n",
       " 'fashionable.a.01',\n",
       " 'fastidious.a.01',\n",
       " 'fat.s.05',\n",
       " 'favored.s.01',\n",
       " 'fearful.s.04',\n",
       " 'featured.s.01',\n",
       " 'fecund.s.02',\n",
       " 'feigned.s.01',\n",
       " 'felicitous.s.02',\n",
       " 'fetching.s.01',\n",
       " 'feverish.s.03',\n",
       " 'fine.s.02',\n",
       " 'finespun.s.02',\n",
       " 'finical.s.01',\n",
       " 'fishy.s.02',\n",
       " 'flavorful.s.01',\n",
       " 'fleshed_out.s.01',\n",
       " 'flighty.s.01',\n",
       " 'flippant.s.01',\n",
       " 'fluorescent.s.02',\n",
       " 'flustered.s.01',\n",
       " 'fogbound.s.01',\n",
       " 'fogyish.s.01',\n",
       " 'foodless.s.01',\n",
       " 'fooling.s.01',\n",
       " 'for_sure.s.01',\n",
       " 'formative.s.01',\n",
       " 'formative.s.02',\n",
       " 'formidable.s.01',\n",
       " 'formidable.s.02',\n",
       " 'fortuitous.s.02',\n",
       " 'fortunate.a.01',\n",
       " 'fractional.a.01',\n",
       " 'fractious.s.03',\n",
       " 'fragmental.s.01',\n",
       " 'freaky.s.01',\n",
       " 'frivolous.a.01',\n",
       " 'fruitful.a.01',\n",
       " 'fruity.s.01',\n",
       " 'frustrating.s.01',\n",
       " 'full-blown.s.02',\n",
       " 'full-bodied.s.01',\n",
       " 'full-dress.s.03',\n",
       " 'full-length.s.01',\n",
       " 'full-page.s.01',\n",
       " 'full.a.05',\n",
       " 'full.s.03',\n",
       " 'full.s.04',\n",
       " 'full.s.06',\n",
       " 'funereal.s.01',\n",
       " 'funny.s.04',\n",
       " 'fur-bearing.s.01',\n",
       " 'gallant.s.03',\n",
       " 'gaumless.s.01',\n",
       " 'gay.s.02',\n",
       " 'gay.s.05',\n",
       " 'general.s.05',\n",
       " 'generative.s.02',\n",
       " 'generous.s.03',\n",
       " 'gentle.s.02',\n",
       " 'gentle.s.03',\n",
       " 'genuine.s.02',\n",
       " 'ghastly.s.01',\n",
       " 'ghoulish.s.01',\n",
       " 'gilbertian.s.02',\n",
       " 'gilded.s.02',\n",
       " 'gingery.s.01',\n",
       " 'glamorous.s.01',\n",
       " 'glib.s.03',\n",
       " 'glossy.s.03',\n",
       " 'going.s.01',\n",
       " 'good-for-nothing.s.01',\n",
       " 'good-natured.a.01',\n",
       " 'good.a.01',\n",
       " 'good.s.06',\n",
       " 'good.s.09',\n",
       " 'good.s.13',\n",
       " 'good.s.15',\n",
       " 'good_enough.s.01',\n",
       " 'goodish.s.01',\n",
       " 'gothic.s.05',\n",
       " 'gouty.s.01',\n",
       " 'graceless.s.01',\n",
       " 'gracious.a.01',\n",
       " 'graduate.s.01',\n",
       " 'grandiose.s.01',\n",
       " 'grapey.s.01',\n",
       " 'grateful.s.02',\n",
       " 'gratifying.s.01',\n",
       " 'grave.s.01',\n",
       " 'green.s.04',\n",
       " 'grievous.s.02',\n",
       " 'groovy.s.02',\n",
       " 'grotty.s.01',\n",
       " 'grumbling.s.01',\n",
       " 'hairy.s.02',\n",
       " 'half.s.01',\n",
       " 'half.s.02',\n",
       " 'halfway.s.03',\n",
       " 'hand-to-mouth.s.01',\n",
       " 'hands-down.s.01',\n",
       " 'hapless.s.01',\n",
       " 'hard-fought.s.01',\n",
       " 'hard-hitting.s.01',\n",
       " 'hard.s.11',\n",
       " 'hardscrabble.s.01',\n",
       " 'harsh-voiced.s.01',\n",
       " 'harsh.s.01',\n",
       " 'harsh.s.02',\n",
       " 'harsh.s.04',\n",
       " 'harsh.s.06',\n",
       " 'hateful.a.01',\n",
       " 'hateful.s.02',\n",
       " 'haunting.s.02',\n",
       " 'heady.s.02',\n",
       " 'healthy.s.03',\n",
       " 'heart-healthy.s.01',\n",
       " 'heart-whole.s.01',\n",
       " 'heartening.s.01',\n",
       " 'heartwarming.s.01',\n",
       " 'hearty.s.02',\n",
       " 'hearty.s.05',\n",
       " 'heaven-sent.s.01',\n",
       " 'heavy.a.04',\n",
       " 'heavy.s.07',\n",
       " 'heavy.s.15',\n",
       " 'heavy.s.23',\n",
       " 'hedged.s.01',\n",
       " 'heightening.s.01',\n",
       " 'herculean.s.02',\n",
       " 'hideous.s.01',\n",
       " 'high-yield.s.01',\n",
       " 'high.a.01',\n",
       " 'higher.s.01',\n",
       " 'higher.s.02',\n",
       " 'hilarious.s.01',\n",
       " 'hollow.s.02',\n",
       " 'homelike.s.01',\n",
       " 'homely.s.01',\n",
       " 'homing.s.01',\n",
       " 'honest.a.01',\n",
       " 'honest.s.02',\n",
       " 'honorific.s.01',\n",
       " 'hopeless.s.04',\n",
       " 'horrid.s.01',\n",
       " 'hot.s.09',\n",
       " 'hot.s.12',\n",
       " 'hot.s.15',\n",
       " 'huffish.s.01',\n",
       " 'huffy.s.01',\n",
       " 'humorless.a.01',\n",
       " 'humorous.a.01',\n",
       " 'hungry.a.01',\n",
       " 'hurtful.s.01',\n",
       " 'hushed.s.01',\n",
       " 'hygroscopic.s.01',\n",
       " 'hypnotic.s.02',\n",
       " 'hypocritical.s.01',\n",
       " 'icky.s.01',\n",
       " 'iconoclastic.s.02',\n",
       " 'idle.s.03',\n",
       " 'idle.s.04',\n",
       " 'idyllic.s.02',\n",
       " 'ill-fed.s.01',\n",
       " 'ill-mannered.s.01',\n",
       " 'ill-natured.a.01',\n",
       " 'ill.a.01',\n",
       " 'ill.s.03',\n",
       " 'immoral.a.01',\n",
       " 'impelling.s.01',\n",
       " 'imperturbable.s.01',\n",
       " 'impious.s.02',\n",
       " 'impolite.a.01',\n",
       " 'important-looking.s.01',\n",
       " 'imprecise.a.01',\n",
       " 'impressive.a.01',\n",
       " 'impressive.s.02',\n",
       " 'improbable.s.03',\n",
       " 'impudent.s.01',\n",
       " 'impugnable.s.01',\n",
       " 'in.s.03',\n",
       " 'in_evidence.s.01',\n",
       " 'inactive.a.07',\n",
       " 'incendiary.s.02',\n",
       " 'incompetent.s.04',\n",
       " 'incomplete.a.01',\n",
       " 'inconsistent.a.01',\n",
       " 'inconspicuous.a.01',\n",
       " 'incorrupt.s.02',\n",
       " 'incredible.a.01',\n",
       " 'indefinable.s.02',\n",
       " 'ineffable.s.02',\n",
       " 'ineffective.a.01',\n",
       " 'inexplicable.a.01',\n",
       " 'inexpressible.a.01',\n",
       " 'infelicitous.s.02',\n",
       " 'inferential.s.05',\n",
       " 'infra_dig.s.01',\n",
       " 'ingratiating.s.01',\n",
       " 'innocuous.s.02',\n",
       " 'inoffensive.a.02',\n",
       " 'insalubrious.s.01',\n",
       " 'insensible.s.02',\n",
       " 'insensitive.a.02',\n",
       " 'insidious.s.01',\n",
       " 'insignificant.s.02',\n",
       " 'insincere.a.01',\n",
       " 'insipid.s.02',\n",
       " 'inspirational.s.01',\n",
       " 'insubstantial.s.02',\n",
       " 'integral.s.02',\n",
       " 'intense.s.03',\n",
       " 'intensifying.a.01',\n",
       " 'interesting.a.01',\n",
       " 'intimate.s.01',\n",
       " 'intriguing.s.02',\n",
       " 'invaluable.s.01',\n",
       " 'invigorating.a.01',\n",
       " 'inviolable.s.03',\n",
       " 'irresistible.s.02',\n",
       " 'irritating.s.02',\n",
       " 'irritating.s.03',\n",
       " 'isotonic.s.04',\n",
       " 'itchy.s.02',\n",
       " 'jesting.s.01',\n",
       " 'jilted.s.01',\n",
       " 'jingling.s.01',\n",
       " 'joyful.a.01',\n",
       " 'joyless.a.01',\n",
       " 'joyous.a.01',\n",
       " 'killing.s.01',\n",
       " 'kind.a.01',\n",
       " 'kindhearted.s.01',\n",
       " 'labor-intensive.s.01',\n",
       " 'laic.s.01',\n",
       " 'laid-back.s.01',\n",
       " 'laid_low.s.01',\n",
       " 'laid_up.s.01',\n",
       " 'lamenting.s.01',\n",
       " 'last.s.07',\n",
       " 'latest.s.02',\n",
       " 'leaden.s.02',\n",
       " 'leaden.s.04',\n",
       " 'life-giving.s.01',\n",
       " 'light.a.05',\n",
       " 'light.s.20',\n",
       " 'likely.s.04',\n",
       " 'limited.s.04',\n",
       " 'limpid.s.03',\n",
       " 'little.s.05',\n",
       " 'live.s.04',\n",
       " 'livelong.s.01',\n",
       " 'long-winded.s.01',\n",
       " 'long.s.09',\n",
       " 'loosely_knit.s.01',\n",
       " 'loud-mouthed.s.01',\n",
       " 'loud-voiced.s.01',\n",
       " 'loud.a.01',\n",
       " 'lovable.a.01',\n",
       " 'loved.a.01',\n",
       " 'loveless.s.02',\n",
       " 'low-budget.s.01',\n",
       " 'low-cost.s.01',\n",
       " 'low-level.s.01',\n",
       " 'low.a.01',\n",
       " 'low.s.03',\n",
       " 'lucky.s.01',\n",
       " 'lugubrious.s.01',\n",
       " 'lumpish.s.01',\n",
       " 'lurid.s.02',\n",
       " 'lurid.s.04',\n",
       " 'malnourished.a.01',\n",
       " 'manky.s.01',\n",
       " 'mannerly.s.01',\n",
       " 'marked.s.02',\n",
       " 'marvelous.s.03',\n",
       " 'mathematical.s.03',\n",
       " 'meager.a.01',\n",
       " 'meaning.s.01',\n",
       " 'meaningful.a.01',\n",
       " 'meaningless.a.01',\n",
       " 'measly.s.01',\n",
       " 'meaty.s.02',\n",
       " 'mediocre.s.03',\n",
       " 'merciful.s.02',\n",
       " 'metaphysical.s.02',\n",
       " 'meticulous.s.01',\n",
       " 'meticulous.s.02',\n",
       " 'miasmal.s.01',\n",
       " 'microscopic.s.03',\n",
       " 'mild-tasting.s.01',\n",
       " 'milk-sick.s.01',\n",
       " 'mind-boggling.s.01',\n",
       " 'mindless.s.01',\n",
       " 'mirthless.s.01',\n",
       " 'misanthropic.s.02',\n",
       " 'miserable.s.05',\n",
       " 'misogynous.s.01',\n",
       " 'mod.s.01',\n",
       " 'moderating.a.01',\n",
       " 'moral.a.01',\n",
       " 'moralistic.s.01',\n",
       " 'morbid.s.01',\n",
       " 'mournful.s.01',\n",
       " 'moving.a.02',\n",
       " 'murmuring.s.01',\n",
       " 'murmurous.s.01',\n",
       " 'narcotic.s.02',\n",
       " 'narcotic.s.03',\n",
       " 'nasty.a.01',\n",
       " 'nasty.s.02',\n",
       " 'natural.a.03',\n",
       " 'naughty.s.02',\n",
       " 'nauseated.s.01',\n",
       " 'nauseating.s.01',\n",
       " 'necromantic.s.02',\n",
       " 'negative.s.03',\n",
       " 'negligible.s.02',\n",
       " 'neither.s.01',\n",
       " 'nerve-racking.s.01',\n",
       " 'nervous.s.01',\n",
       " 'newsworthy.s.01',\n",
       " 'nice.a.01',\n",
       " 'nice.s.03',\n",
       " 'nickel-and-dime.s.02',\n",
       " 'nippy.s.01',\n",
       " 'nitwitted.s.01',\n",
       " 'nonabsorbent.a.01',\n",
       " 'noninflammatory.s.01',\n",
       " 'nonnatural.s.01',\n",
       " 'nonproductive.s.01',\n",
       " 'nonsense.s.01',\n",
       " 'nourished.a.01',\n",
       " 'nugatory.s.01',\n",
       " 'numinous.s.01',\n",
       " 'nut-bearing.s.01',\n",
       " 'nutty.s.01',\n",
       " 'objectionable.s.01',\n",
       " 'obscure.s.01',\n",
       " 'obscure.s.05',\n",
       " 'oddish.s.01',\n",
       " 'off-putting.s.01',\n",
       " 'off.s.02',\n",
       " 'offending.a.01',\n",
       " 'offensive.a.05',\n",
       " 'offensive.s.01',\n",
       " 'oil-bearing.s.01',\n",
       " 'old-maidish.s.01',\n",
       " 'old-time.s.01',\n",
       " 'on_the_nose.s.01',\n",
       " 'open.s.21',\n",
       " 'oppressive.s.01',\n",
       " 'organic.s.04',\n",
       " 'orienting.a.01',\n",
       " 'orotund.s.02',\n",
       " 'other.s.04',\n",
       " 'otiose.s.01',\n",
       " 'out.s.07',\n",
       " 'outright.s.01',\n",
       " 'outstanding.s.02',\n",
       " 'oval-fruited.s.01',\n",
       " 'overabundant.s.01',\n",
       " 'overfed.s.01',\n",
       " 'overjoyed.s.01',\n",
       " 'overpriced.s.01',\n",
       " 'oversensitive.s.01',\n",
       " 'overserious.s.01',\n",
       " 'pacific.s.03',\n",
       " 'pain-free.s.01',\n",
       " 'painful.a.01',\n",
       " 'painless.a.02',\n",
       " 'painless.s.01',\n",
       " 'palatable.a.01',\n",
       " 'palatial.s.02',\n",
       " 'pale.s.04',\n",
       " 'pale.s.05',\n",
       " 'palsied.s.01',\n",
       " 'paradoxical.s.01',\n",
       " 'paralytic.s.02',\n",
       " 'paraplegic.s.01',\n",
       " 'partial.s.01',\n",
       " 'passing.s.03',\n",
       " 'pasty.s.01',\n",
       " 'pathetic.s.02',\n",
       " 'pathetic.s.03',\n",
       " 'peckish.s.01',\n",
       " 'pedestrian.s.01',\n",
       " 'peppery.s.01',\n",
       " 'pernickety.s.01',\n",
       " 'personable.s.01',\n",
       " 'persuasive.a.01',\n",
       " 'petrifying.s.01',\n",
       " 'photogenic.s.01',\n",
       " 'physical.s.04',\n",
       " 'picaresque.s.01',\n",
       " 'piquant.s.01',\n",
       " 'piquant.s.02',\n",
       " 'pithy.s.01',\n",
       " 'plangent.s.01',\n",
       " 'plausible.s.02',\n",
       " 'pleasant.a.01',\n",
       " 'pleasant.s.02',\n",
       " 'pleasing.a.01',\n",
       " 'plentiful.s.01',\n",
       " 'pleonastic.s.01',\n",
       " 'po-faced.s.01',\n",
       " 'poignant.s.02',\n",
       " 'polite.a.01',\n",
       " 'ponderous.s.03',\n",
       " 'poor.s.06',\n",
       " 'precious.s.02',\n",
       " 'precise.a.01',\n",
       " 'prefaded.s.01',\n",
       " 'prehistoric.s.03',\n",
       " 'prepossessing.s.01',\n",
       " 'presentable.s.01',\n",
       " 'presumptive.s.02',\n",
       " 'pretty.s.02',\n",
       " 'prima_facie.s.01',\n",
       " 'prismatic.s.02',\n",
       " 'productive.a.01',\n",
       " 'profanatory.s.01',\n",
       " 'profane.a.02',\n",
       " 'prolific.s.02',\n",
       " 'prolix.a.01',\n",
       " 'promotive.s.01',\n",
       " 'propitiative.s.01',\n",
       " 'provocative.a.01',\n",
       " 'psychedelic.s.02',\n",
       " 'pumped-up.s.01',\n",
       " 'pungent.s.01',\n",
       " 'purposeful.s.02',\n",
       " 'pursuant.s.01',\n",
       " 'putdownable.s.01',\n",
       " 'quaint.s.01',\n",
       " 'quaint.s.02',\n",
       " 'qualified.a.02',\n",
       " 'quasi-religious.s.01',\n",
       " 'questionable.a.01',\n",
       " 'racking.s.01',\n",
       " 'rallying.s.01',\n",
       " 'rampant.s.03',\n",
       " 'rank.s.02',\n",
       " 'rank.s.05',\n",
       " 'rare.s.03',\n",
       " 'rascally.s.02',\n",
       " 'ravaging.s.01',\n",
       " 'real.s.03',\n",
       " 'reassuring.a.01',\n",
       " 'rebarbative.s.01',\n",
       " 'receptive.s.04',\n",
       " 'reconciled.s.01',\n",
       " 'reconstructive.s.01',\n",
       " 'red-fruited.s.01',\n",
       " 'redeeming.s.02',\n",
       " 'reduced.s.02',\n",
       " 'regrettable.s.01',\n",
       " 'relaxant.s.01',\n",
       " 'relaxed.a.01',\n",
       " 'religious.s.01',\n",
       " 'removed.s.01',\n",
       " 'renewing.s.01',\n",
       " 'repellent.s.03',\n",
       " 'representable.s.01',\n",
       " 'resonant.s.01',\n",
       " 'respectable.a.01',\n",
       " 'respectful.a.01',\n",
       " 'reverberant.a.01',\n",
       " 'reverend.s.01',\n",
       " 'rich.s.03',\n",
       " 'rich.s.06',\n",
       " 'rich.s.09',\n",
       " 'rich.s.11',\n",
       " 'rickety.s.02',\n",
       " 'right.s.08',\n",
       " 'righteous.s.02',\n",
       " 'rocky.s.04',\n",
       " 'rough-and-ready.s.01',\n",
       " 'round-fruited.s.01',\n",
       " 'rousing.s.01',\n",
       " 'rousing.s.02',\n",
       " 'rubber.s.01',\n",
       " 'rubbishy.s.01',\n",
       " 'rudimentary.s.02',\n",
       " 'rugged.s.04',\n",
       " 'sacral.s.02',\n",
       " ...]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_L2_ss# == expanded_L_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51c8f6b",
   "metadata": {},
   "source": [
    "Same thing for related adj list from feeling  Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "987c05db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([set(), set(), set(), set(), {'fiery', 'ardent', 'perfervid', 'fervent', 'fervid', 'impassioned', 'torrid'}, {'fiery', 'ardent', 'perfervid', 'fervent', 'fervid', 'impassioned', 'torrid'}, {'fiery', 'ardent', 'perfervid', 'fervent', 'fervid', 'impassioned', 'torrid'}, set(), set(), {'shamed', 'hangdog', 'guilty', 'shamefaced', 'sheepish'}, {'shamefaced', 'sheepish'}, {'heavy'}, set(), set(), set(), set(), set(), set(), set(), {'plaintive', 'mournful'}, set(), set(), set(), set(), set(), set(), set(), set(), {'angry'}, {'hotheaded', 'hot-tempered', 'short-tempered', 'choleric', 'quick-tempered', 'irascible'}, set(), set(), set(), set(), set(), set(), {'nervy', 'overstrung', 'edgy', 'jittery', 'restive', 'highly_strung', 'jumpy', 'high-strung', 'uptight'}, {'uneasy'}, set(), set(), set(), set(), set(), set(), set(), set(), {'moody', 'temperamental'}, set(), set(), set(), set(), {'blue', 'down', 'downcast', 'grim', 'depressed', 'downhearted', 'down_in_the_mouth', 'gloomy', 'low', 'low-spirited', 'dispirited'}, {'melancholy', 'somber', 'sombre'}, {'melancholy', 'somber', 'sombre'}, set(), {'aggressive', 'belligerent'}, {'aggressive', 'belligerent'}, {'tender'}, {'tenderhearted'}, {'kind-hearted', 'kindhearted'}, set(), {'uncheerful', 'depressing', 'cheerless'}, {'uncheerful', 'depressing', 'cheerless'}, {'dysphoric', 'unhappy', 'distressed'}, set(), {'protective'}, set(), set(), set(), set(), {'appetent'}, {'appetent'}, {'comfortable'}, set(), set(), set(), {'unhappy'}, {'earnest', 'heartfelt', 'devout', 'dear'}, set(), {'earnest', 'solemn', 'sincere'}, set(), set(), set(), set(), {'unmerciful', 'merciless'}, {'unkind', 'pitiless'}, {'remorseless', 'ruthless', 'pitiless', 'unpitying'}, set(), set(), {'hungry', 'thirsty', 'athirst'}, set(), set(), set(), {'misogynic', 'misogynous', 'misogynistic'}, set(), set(), {'algolagnic'}, set(), set(), set(), {'reverent', 'godly', 'reverential', 'venerating', 'worshipful', 'respectful'}, set(), set(), set(), {'unpleasant'}, set(), set(), {'euphoric'}, set(), {'lachrymose', 'weeping', 'tearful', 'dolourous', 'dolorous'}, set(), set(), {'huffish', 'sulky'}, {'huffish', 'sulky'}, set(), {'solicitous'}, {'hysterical'}, set(), set(), set(), set(), set(), {'optimistic', 'affirmative'}, set(), {'untroubled', 'unafraid', 'secure'}, {'despondent', 'heartsick'}, {'despondent', 'heartsick'}, {'despondent', 'heartsick', 'heartbroken', 'brokenhearted'}, {'disconsolate', 'unconsolable', 'inconsolable'}, set(), set(), set(), set(), set(), set(), set(), {'unagitated', 'tranquil', 'calm', 'serene'}, set(), set(), set(), {'misanthropical', 'misanthropic'}, {'joyous'}, {'joyous'}, {'gleeful', 'jubilant', 'elated', 'joyful'}, {'masochistic'}, set(), set(), set(), {'lonely', 'lonesome'}, set(), set(), set(), set(), set(), set(), set(), {'sedate', 'sincere', 'sober', 'grave', 'solemn', 'earnest'}, {'lovesick'}, set(), {'tetchy', 'techy', 'scratchy', 'nettlesome', 'peckish', 'petulant', 'irritable', 'testy', 'fractious', 'cranky', 'pettish', 'peevish'}, {'feisty', 'thin-skinned', 'touchy', 'huffy'}, {'tetchy', 'techy', 'scratchy', 'nettlesome', 'peckish', 'petulant', 'irritable', 'testy', 'fractious', 'cranky', 'pettish', 'peevish'}, set(), {'tyrannous', 'oppressive', 'tyrannical'}, {'brooding', 'broody', 'reflective', 'meditative', 'ruminative', 'musing', 'contemplative', 'pondering', 'pensive'}, set(), set(), set(), set(), set(), set(), set(), {'empathetic', 'empathic'}, set(), {'self-satisfied', 'complacent', 'self-complacent'}, {'self-satisfied', 'complacent', 'self-complacent'}, {'self-satisfied', 'complacent', 'self-complacent'}, set(), set(), {'titillating', 'erotic'}, {'lustful', 'lusty', 'concupiscent'}, set(), set(), {'scarey', 'shivery', 'chilling', 'shuddery', 'scary'}, set(), set(), {'scarey', 'shivery', 'chilling', 'shuddery', 'scary'}, set(), set(), {'huffish', 'sulky'}, {'huffish', 'sulky'}, set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), {'worried', 'apprehensive'}, {'horrific', 'fearsome', 'frightening', 'terrible', 'awful', 'horrendous', 'dreaded', 'dreadful', 'dread', 'dire', 'fearful', 'direful'}, set(), {'sensuous'}, set(), {'merciful'}, set(), {'partial', 'fond'}, set(), set(), {'hesitant', 'hesitating'}, {'hesitant', 'hesitating'}, {'sensitive'}, {'sensitive'}, set(), {'wild'}, set(), {'merry', 'jocund', 'gay', 'jolly', 'mirthful', 'jovial'}, {'joking', 'jesting', 'jocose', 'jocular'}, {'nostalgic'}, set(), set(), set(), {'passionate'}, set(), set(), {'jubilant', 'exulting', 'prideful', 'triumphant', 'rejoicing', 'triumphal', 'exultant'}, {'sanguine'}, {'sanguine'}, {'queasy', 'uneasy', 'unquiet', 'nervous', 'anxious'}, set(), set(), set(), set(), set(), set(), set(), {'soulful'}, {'doleful', 'mournful'}, {'sentimental'}, set(), {'oversensitive'}, set(), set(), set(), set(), set(), {'bored', 'world-weary'}, set(), set(), {'mellowed', 'mellow'}, set(), set(), set(), set(), set(), set(), {'impulsive', 'capricious', 'whimsical'}, set(), set(), {'faint', 'light-headed', 'lightheaded', 'light', 'swooning'}, set(), {'joyless'}, set(), set(), set(), set(), {'devoted'}, {'meek', 'tame', 'mild', 'modest'}, set(), set(), set(), set(), set(), set(), {'blue', 'down', 'downcast', 'grim', 'depressed', 'downhearted', 'down_in_the_mouth', 'gloomy', 'low', 'low-spirited', 'dispirited'}, set(), {'blue', 'down', 'downcast', 'grim', 'depressed', 'downhearted', 'down_in_the_mouth', 'gloomy', 'low', 'low-spirited', 'dispirited'}, {'blue', 'down', 'crushed', 'broken', 'downcast', 'humbled', 'grim', 'depressed', 'downhearted', 'down_in_the_mouth', 'gloomy', 'humiliated', 'low', 'low-spirited', 'dispirited'}, {'blue', 'listless', 'down', 'downcast', 'grim', 'depressed', 'downhearted', 'down_in_the_mouth', 'gloomy', 'low', 'low-spirited', 'dispirited'}, set(), {'electric'}, set(), {'sensual', 'fleshly', 'carnal', 'animal'}, {'sultry', 'fleshly', 'animal', 'sensual', 'carnal'}, set(), set(), set(), {'maleficent'}, set(), set(), set(), set(), set(), set(), {'pessimistic'}, set(), set(), {'ruthful', 'remorseful', 'rueful', 'contrite'}, set(), {'timid', 'diffident', 'shy', 'unsure'}, set(), set(), set(), set(), set(), set(), set(), set(), {'hangdog', 'shamed', 'guilty', 'shamefaced'}, set(), set(), set(), set(), set(), {'sadistic'}, {'umbrageous', 'indignant', 'incensed', 'outraged'}, set(), set(), {'vengeful', 'spiteful', 'revengeful', 'despiteful', 'vindictive'}, {'vengeful', 'revengeful', 'vindictive'}, {'Anglophobic'}, set(), set(), {'sore', 'afflictive', 'painful', 'mad', 'huffy'}, set(), set(), set(), set(), set(), {'repugnant', 'repulsive', 'abhorrent', 'detestable', 'obscene'}, set(), set(), set(), {'antagonistic'}, set(), set(), {'antipathetic', 'loath', 'antipathetical', 'indisposed', 'averse', 'antagonistic', 'loth'}, set(), set(), {'kitschy', 'mawkish', 'mushy', 'soupy', 'slushy', 'hokey', 'maudlin', 'sentimental', 'schmalzy', 'bathetic', 'schmaltzy', 'soppy', 'drippy'}, {'unassertive'}, set(), set(), {'eager'}, {'avid', 'zealous'}, {'avid', 'zealous'}, set(), set(), set(), set(), set(), set(), {'insecure'}, {'Anglophilic'}, set(), set(), {'repugnant', 'repulsive', 'abhorrent', 'detestable', 'obscene'}, set(), set(), set(), set(), {'execrable', 'odious', 'detestable', 'abominable'}, set(), {'bitter'}, set(), {'rancorous'}, set(), {'blessed'}, set(), set(), set(), set(), {'lost', 'helpless'}, set(), {'ambivalent'}, set(), {'pollyannaish', 'upbeat', 'cheerful'}, {'pollyannaish', 'upbeat', 'cheerful'}, set(), set(), {'happy'}, set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), {'buoyant', 'perky', 'chirpy'}, {'buoyant', 'perky', 'chirpy'}, set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), {'vain', 'swollen', 'egotistic', 'swollen-headed', 'conceited', 'self-conceited', 'egotistical'}, {'scrupulous'}, set(), set(), {'hostile'}, {'inimical', 'unfriendly'}, set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), {'distant', 'aloof', 'upstage'}, set(), set(), set(), set(), set(), set(), {'amiable', 'good-humored', 'genial', 'affable', 'good-humoured', 'cordial'}, set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), set(), {'lustful', 'lubricious', 'salacious', 'prurient'}, {'lustful', 'lubricious', 'salacious', 'prurient'}, {'libidinous', 'lascivious', 'lewd', 'lustful'}, {'sensual', 'fleshly', 'carnal', 'animal'}, set(), {'sore', 'mad', 'huffy', 'thin-skinned', 'touchy', 'feisty'}, set(), set(), set(), {'vain', 'swollen', 'egotistic', 'swollen-headed', 'conceited', 'self-conceited', 'egotistical'}, {'self-important', 'arrogant', 'chesty'}, {'doleful', 'plaintive', 'mournful'}, {'sorrowful'}, {'ruthful', 'remorseful', 'rueful', 'contrite'}, {'amative', 'amorous'}, {'potty', 'enamored', 'soft_on', 'infatuated', 'smitten', 'taken_with', 'in_love'}, set(), set(), set(), {'jubilant', 'exulting', 'gleeful', 'prideful', 'triumphant', 'rejoicing', 'elated', 'triumphal', 'joyful', 'exultant'}, {'jubilant', 'exulting', 'gleeful', 'prideful', 'triumphant', 'rejoicing', 'elated', 'triumphal', 'joyful', 'exultant'}, set(), set(), {'affectionate', 'lovesome', 'fond', 'warm', 'tender'}, {'affectionate', 'lovesome', 'fond', 'warm', 'tender'}, {'affectionate', 'lovesome', 'fond', 'warm', 'tender'}, {'hearty'}, {'affectionate', 'lovesome', 'fond', 'warm', 'tender'}, {'warmhearted'}, set(), {'weighty'}, set(), set(), set(), {'indifferent', 'apathetic'}, {'sad'}, set(), {'sorrowful'}, set(), set(), {'unthankful', 'thankless', 'ungrateful'}, {'libidinous', 'libidinal', 'lewd', 'lustful', 'lascivious'}, set(), {'inimical', 'unfriendly'}, set(), {'pensive', 'wistful'}, set(), {'emotional'}, set(), set(), set(), set(), {'compassionate'}, set(), set(), {'glowering', 'sullen', 'morose', 'dour', 'dark', 'saturnine', 'moody', 'sour', 'glum'}, {'glowering', 'sullen', 'morose', 'dour', 'dark', 'saturnine', 'moody', 'sour', 'glum'}, {'sullen', 'threatening', 'heavy', 'lowering'}, set(), set(), set(), set(), {'zesty', 'barmy', 'zestful', 'yeasty'}, {'zesty', 'barmy', 'zestful', 'yeasty'}, set(), set(), set(), {'ruthful', 'remorseful', 'rueful', 'contrite'}, set(), set(), set(), {'lecherous'}, {'lustful', 'lusty', 'concupiscent'}, {'lusty', 'prurient', 'libidinous', 'lewd', 'lustful', 'concupiscent', 'lascivious', 'lubricious', 'salacious'}, set(), set(), set(), {'nauseating', 'sickening', 'queasy', 'vile', 'loathsome', 'noisome', 'offensive', 'nauseous'}, set(), {'pleasant'}, {'loving'}, {'caring'}, {'still', 'placid', 'quiet', 'unruffled', 'smooth', 'tranquil'}, {'still', 'placid', 'quiet', 'unruffled', 'smooth', 'tranquil'}, {'still', 'placid', 'quiet', 'unruffled', 'smooth', 'tranquil'}, set(), set(), set(), set(), {'light'}, set(), {'self-satisfied', 'smug'}, set(), set(), {'hopeless'}, set(), {'raring', 'impatient'}, {'grateful', 'thankful'}, {'grateful', 'thankful'}, {'appreciative'}, {'poignant'}, {'poignant'}, set(), set(), {'slow', 'boring', 'wearisome', 'ho-hum', 'tiresome', 'irksome', 'tedious', 'deadening', 'dull'}, {'sadomasochistic'}, set(), set(), set(), set(), {'conscientious'}, {'hopeful'}, set(), {'timid', 'diffident', 'shy', 'unsure'}, set(), set(), {'harum-scarum', 'freewheeling', 'devil-may-care', 'happy-go-lucky', 'slaphappy', 'carefree'}, {'casual', 'insouciant', 'nonchalant'}, {'light-hearted', 'lightsome', 'lighthearted', 'blithe', 'blithesome'}, {'light-hearted', 'lightsome', 'lighthearted', 'blithe', 'blithesome'}, {'agonal'}, set(), {'excruciating', 'torturous', 'agonising', 'torturing', 'harrowing', 'torturesome', 'agonizing'}, set(), set(), {'anticipative', 'anticipant', 'expectant'}, set(), set(), {'glowering', 'sullen', 'morose', 'dour', 'dark', 'saturnine', 'moody', 'sour', 'glum'}, set(), {'jealous', 'covetous', 'envious'}, {'happy', 'felicitous'}, {'happy', 'felicitous'}, set(), set(), set(), set(), {'avid', 'zealous'}, set(), {'fearful'}, set(), set(), {'fearless', 'hardy', 'dauntless', 'unfearing', 'brave', 'audacious', 'intrepid', 'unafraid'}, set(), {'timid'}, {'fainthearted', 'timid', 'faint', 'faint-hearted', 'diffident', 'shy', 'unsure'}, {'faint', 'fainthearted', 'faint-hearted', 'timid'}, set(), set(), set(), set(), {'antsy', 'itchy', 'fidgety', 'fretful'}, {'antsy', 'itchy', 'fidgety', 'fretful'}, set(), set(), set(), {'homesick'}, set(), set(), {'self-conscious'}, {'uneasy', 'ill_at_ease', 'awkward'}, {'uncomfortable'}, set(), set(), {'tempestuous', 'stormy'}, set(), {'infuriated', 'furious', 'angered', 'enraged', 'maddened'}, set(), {'sore', 'mad', 'huffy'}, set(), set(), {'confidential'}, set(), set(), set(), set(), set(), {'beaming', 'glad'}, set(), {'gladsome'}, {'emotionless', 'passionless'}, {'stolid', 'impassive'}, {'impassive', 'expressionless', 'deadpan', 'poker-faced', 'unexpressive', 'stolid'}, {'phlegmatic', 'phlegmatical'}, set(), {'stolid', 'impassive'}, set(), set(), set(), {'merry', 'jocund', 'gay', 'jolly', 'mirthful', 'jovial'}, {'merry', 'jocund', 'gay', 'jolly', 'mirthful', 'jovial'}, {'merry', 'jocund', 'gay', 'jolly', 'mirthful', 'jovial'}, set(), set(), set(), {'listless', 'dispirited'}, {'nervy', 'overstrung', 'edgy', 'jittery', 'restive', 'highly_strung', 'jumpy', 'high-strung', 'uptight'}, {'nervy', 'overstrung', 'edgy', 'jittery', 'restive', 'highly_strung', 'jumpy', 'high-strung', 'uptight'}, {'queasy', 'uneasy', 'unquiet', 'aflutter', 'nervous', 'anxious'}, {'nervy', 'overstrung', 'edgy', 'jittery', 'restive', 'highly_strung', 'jumpy', 'high-strung', 'uptight'}, {'ecstatic', 'rapt', 'rapturous', 'rhapsodic', 'enraptured'}, {'ecstatic', 'rapt', 'rapturous', 'rhapsodic', 'enraptured'}, set(), set(), set(), {'nymphomaniacal', 'nymphomaniac'}, {'sad'}, {'dysphoric', 'unhappy', 'distressed'}, {'close'}, set(), {'insulting', 'scornful', 'contemptuous', 'disdainful'}, set(), set(), set(), {'kitschy', 'mawkish', 'mushy', 'soupy', 'slushy', 'hokey', 'maudlin', 'sentimental', 'schmalzy', 'bathetic', 'schmaltzy', 'soppy', 'drippy'}, set(), {'exuberant', 'high-spirited', 'ebullient'}, set(), set(), set(), set(), {'immaterial', 'unbiassed', 'indifferent', 'unbiased'}, set(), set(), set(), set(), set(), {'pleasant'}, {'enthusiastic'}, {'avid', 'zealous'}, set(), set(), set(), {'softhearted', 'soft-boiled'}, {'tender'}, {'scarey', 'shivery', 'chilling', 'shuddery', 'scary'}, set(), {'tetchy', 'techy', 'scratchy', 'nettlesome', 'peckish', 'petulant', 'irritable', 'testy', 'fractious', 'cranky', 'pettish', 'peevish'}, set(), {'fretful', 'whiny', 'whiney', 'querulous'}, {'cross', 'grumpy', 'fussy', 'crabby', 'ill-tempered', 'grouchy', 'bad-tempered', 'crabbed'}, {'tetchy', 'techy', 'scratchy', 'nettlesome', 'peckish', 'petulant', 'irritable', 'testy', 'fractious', 'cranky', 'pettish', 'peevish'}, {'tetchy', 'techy', 'scratchy', 'nettlesome', 'peckish', 'petulant', 'irritable', 'testy', 'fractious', 'cranky', 'pettish', 'peevish'}, set(), set(), set(), set(), set(), {'challenging', 'ambitious'}, set(), set(), set(), {'woeful', 'woebegone'}, {'sexy', 'aphrodisiac', 'aphrodisiacal'}, set(), {'warmhearted'}, set(), set(), {'sore', 'painful', 'afflictive'}, set(), set(), set(), {'bashful'}, set(), set(), set(), {'heartsick', 'heartbroken', 'brokenhearted'}, {'screaming', 'uproarious', 'hilarious'}, set(), {'merry', 'jocund', 'gay', 'amusing', 'comic', 'jolly', 'mirthful', 'risible', 'funny', 'laughable', 'comical', 'jovial'}, set(), {'gleeful', 'jubilant', 'elated', 'joyful'}, {'penitent', 'repentant'}, {'penitent', 'repentant', 'penitential', 'penitentiary'}, set(), {'panicked', 'panic-struck', 'panicky', 'terrified', 'panic-stricken', 'frightened'}, set(), set(), {'romantic', 'amatory', 'amorous'}, set(), set(), {'sexy', 'aphrodisiac', 'aphrodisiacal'}, {'amative', 'amorous'}, set(), set(), set(), set(), {'perceptive'}, {'perceptive'}, set(), {'well-disposed', 'friendly', 'favorable'}, set(), {'good-tempered', 'still', 'placid', 'even-tempered', 'quiet', 'unruffled', 'equable', 'smooth', 'tranquil'}, set(), set(), {'playful'}, set(), set(), set(), set(), set(), set(), set(), {'weepy'}, {'lachrymose', 'weeping', 'tearful', 'dolourous', 'dolorous'}, set(), set(), set(), set(), {'wretched', 'miserable', 'piteous', 'hapless', 'pitiable', 'pitiful', 'misfortunate', 'poor', 'pathetic'}, set(), {'wretched', 'miserable', 'piteous', 'hapless', 'pitiable', 'pitiful', 'misfortunate', 'poor', 'pathetic'}, set(), set(), set(), set(), set(), set(), {'homicidal', 'murderous'}, set(), {'jubilant', 'exulting', 'prideful', 'triumphant', 'rejoicing', 'triumphal', 'exultant'}, set(), set(), set(), set(), {'sympathetic'}, set(), set(), set(), set(), set(), set(), set(), {'desirous', 'wishful'}, {'malevolent'}, set(), {'hardhearted', 'heartless'}, {'coldhearted'}, {'hardhearted', 'unfeeling', 'stonyhearted', 'heartless'}, {'hotheaded', 'hot-tempered', 'short-tempered', 'choleric', 'quick-tempered', 'irascible'}, set(), {'splenetic', 'bristly', 'waspish', 'prickly'}, set(), set(), set(), set(), set(), set(), {'malicious'}, {'malicious'}, set(), {'despiteful', 'spiteful', 'vindictive'}, {'poisonous', 'venomous', 'vicious'}, {'affectional', 'affective', 'emotive'}, set(), set(), set(), set(), set(), set(), set(), set(), set(), {'beneficent'}, {'livid'}, set(), {'cool'}, {'unflappable', 'imperturbable'}, {'unflappable', 'imperturbable'}, set(), set(), set(), set(), set(), set(), set(), {'dreamy', 'languorous', 'woolgathering', 'languid', 'moony', 'lackadaisical'}, set(), set(), {'together'}, set(), set(), {'heavyhearted'}, set(), set(), set(), set(), set(), {'easy'}, set(), set(), set(), set(), set(), set(), set(), {'discontented', 'discontent'}, {'discontented', 'discontent'}, set(), set(), set(), set(), set(), set(), set(), set()])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun2related_adj_dict22.values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "68f7057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun2related_adj_dict22 has 856 noun lemmas with 613 related adjectives\n"
     ]
    }
   ],
   "source": [
    "noun2related_adj_dict22 = make_noun2related_adj_dict_simple()\n",
    "adj_yield22 = get_dict_yield(noun2related_adj_dict22)\n",
    "dd_yield22a = len(adj_yield22)\n",
    "print(f\"noun2related_adj_dict22 has {len(noun2related_adj_dict22)}\"\\\n",
    "      f\" noun lemmas with {dd_yield22a} related adjectives\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "6db1944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'ardor.n.03.ardor': set(),\n",
       "             'ardor.n.03.ardour': set(),\n",
       "             'ardor.n.03.fervor': set(),\n",
       "             'ardor.n.03.fervour': set(),\n",
       "             'ardor.n.03.fervency': {'ardent',\n",
       "              'fervent',\n",
       "              'fervid',\n",
       "              'fiery',\n",
       "              'impassioned',\n",
       "              'perfervid',\n",
       "              'torrid'},\n",
       "             'ardor.n.03.fire': {'ardent',\n",
       "              'fervent',\n",
       "              'fervid',\n",
       "              'fiery',\n",
       "              'impassioned',\n",
       "              'perfervid',\n",
       "              'torrid'},\n",
       "             'ardor.n.03.fervidness': {'ardent',\n",
       "              'fervent',\n",
       "              'fervid',\n",
       "              'fiery',\n",
       "              'impassioned',\n",
       "              'perfervid',\n",
       "              'torrid'},\n",
       "             'worry.n.02.worry': set(),\n",
       "             'worry.n.02.trouble': set(),\n",
       "             'shamefacedness.n.01.shamefacedness': {'guilty',\n",
       "              'hangdog',\n",
       "              'shamed',\n",
       "              'shamefaced',\n",
       "              'sheepish'},\n",
       "             'shamefacedness.n.01.sheepishness': {'shamefaced', 'sheepish'},\n",
       "             'heaviness.n.02.heaviness': {'heavy'},\n",
       "             'gaiety.n.01.gaiety': set(),\n",
       "             'gaiety.n.01.merriment': set(),\n",
       "             'benevolence.n.01.benevolence': set(),\n",
       "             'scunner.n.01.scunner': set(),\n",
       "             'stewing.n.01.stewing': set(),\n",
       "             'suffering.n.04.suffering': set(),\n",
       "             'suffering.n.04.hurt': set(),\n",
       "             'plaintiveness.n.01.plaintiveness': {'mournful', 'plaintive'},\n",
       "             'dislike.n.02.dislike': set(),\n",
       "             'tumult.n.02.tumult': set(),\n",
       "             'tumult.n.02.turmoil': set(),\n",
       "             'fit.n.01.fit': set(),\n",
       "             'fit.n.01.tantrum': set(),\n",
       "             'fit.n.01.scene': set(),\n",
       "             'fit.n.01.conniption': set(),\n",
       "             'comfort.n.05.comfort': set(),\n",
       "             'anger.n.01.anger': {'angry'},\n",
       "             'anger.n.01.choler': {'choleric',\n",
       "              'hot-tempered',\n",
       "              'hotheaded',\n",
       "              'irascible',\n",
       "              'quick-tempered',\n",
       "              'short-tempered'},\n",
       "             'anger.n.01.ire': set(),\n",
       "             'stir.n.02.stir': set(),\n",
       "             'pique.n.02.pique': set(),\n",
       "             'pique.n.02.temper': set(),\n",
       "             'pique.n.02.irritation': set(),\n",
       "             'defeatism.n.01.defeatism': set(),\n",
       "             'edginess.n.01.edginess': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'edginess.n.01.uneasiness': {'uneasy'},\n",
       "             'edginess.n.01.inquietude': set(),\n",
       "             'edginess.n.01.disquietude': set(),\n",
       "             'animosity.n.01.animosity': set(),\n",
       "             'animosity.n.01.animus': set(),\n",
       "             'animosity.n.01.bad_blood': set(),\n",
       "             'good_will.n.03.good_will': set(),\n",
       "             'good_will.n.03.goodwill': set(),\n",
       "             'temper.n.02.temper': set(),\n",
       "             'temper.n.02.mood': {'moody', 'temperamental'},\n",
       "             'temper.n.02.humor': set(),\n",
       "             'temper.n.02.humour': set(),\n",
       "             'agape.n.01.agape': set(),\n",
       "             'gloom.n.02.gloom': set(),\n",
       "             'gloom.n.02.gloominess': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'gloom.n.02.somberness': {'melancholy', 'somber', 'sombre'},\n",
       "             'gloom.n.02.sombreness': {'melancholy', 'somber', 'sombre'},\n",
       "             'fever.n.02.fever': set(),\n",
       "             'belligerence.n.01.belligerence': {'aggressive', 'belligerent'},\n",
       "             'belligerence.n.01.belligerency': {'aggressive', 'belligerent'},\n",
       "             'tenderness.n.03.tenderness': {'tender'},\n",
       "             'tenderness.n.03.tenderheartedness': {'tenderhearted'},\n",
       "             'kindheartedness.n.01.kindheartedness': {'kind-hearted',\n",
       "              'kindhearted'},\n",
       "             'kindheartedness.n.01.kind-heartedness': set(),\n",
       "             'cheerlessness.n.01.cheerlessness': {'cheerless',\n",
       "              'depressing',\n",
       "              'uncheerful'},\n",
       "             'cheerlessness.n.01.uncheerfulness': {'cheerless',\n",
       "              'depressing',\n",
       "              'uncheerful'},\n",
       "             'dysphoria.n.01.dysphoria': {'distressed',\n",
       "              'dysphoric',\n",
       "              'unhappy'},\n",
       "             'sexual_pleasure.n.01.sexual_pleasure': set(),\n",
       "             'protectiveness.n.01.protectiveness': {'protective'},\n",
       "             'frustration.n.01.frustration': set(),\n",
       "             'frustration.n.01.defeat': set(),\n",
       "             'stage_fright.n.01.stage_fright': set(),\n",
       "             'appetite.n.01.appetite': set(),\n",
       "             'appetite.n.01.appetency': {'appetent'},\n",
       "             'appetite.n.01.appetence': {'appetent'},\n",
       "             'comfortableness.n.02.comfortableness': {'comfortable'},\n",
       "             'annoyance.n.02.annoyance': set(),\n",
       "             'annoyance.n.02.chafe': set(),\n",
       "             'annoyance.n.02.vexation': set(),\n",
       "             'unhappiness.n.02.unhappiness': {'unhappy'},\n",
       "             'earnestness.n.01.earnestness': {'dear',\n",
       "              'devout',\n",
       "              'earnest',\n",
       "              'heartfelt'},\n",
       "             'earnestness.n.01.seriousness': set(),\n",
       "             'earnestness.n.01.sincerity': {'earnest', 'sincere', 'solemn'},\n",
       "             'relief.n.01.relief': set(),\n",
       "             'relief.n.01.alleviation': set(),\n",
       "             'relief.n.01.assuagement': set(),\n",
       "             'cruelty.n.02.cruelty': set(),\n",
       "             'cruelty.n.02.mercilessness': {'merciless', 'unmerciful'},\n",
       "             'cruelty.n.02.pitilessness': {'pitiless', 'unkind'},\n",
       "             'cruelty.n.02.ruthlessness': {'pitiless',\n",
       "              'remorseless',\n",
       "              'ruthless',\n",
       "              'unpitying'},\n",
       "             'longing.n.01.longing': set(),\n",
       "             'longing.n.01.yearning': set(),\n",
       "             'longing.n.01.hungriness': {'athirst', 'hungry', 'thirsty'},\n",
       "             'wonder.n.01.wonder': set(),\n",
       "             'wonder.n.01.wonderment': set(),\n",
       "             'wonder.n.01.admiration': set(),\n",
       "             'misogyny.n.01.misogyny': {'misogynic',\n",
       "              'misogynistic',\n",
       "              'misogynous'},\n",
       "             'misogyny.n.01.misogynism': set(),\n",
       "             'stupefaction.n.01.stupefaction': set(),\n",
       "             'algolagnia.n.01.algolagnia': {'algolagnic'},\n",
       "             'algolagnia.n.01.algophilia': set(),\n",
       "             'anxiety.n.02.anxiety': set(),\n",
       "             'fear.n.03.fear': set(),\n",
       "             'fear.n.03.reverence': {'godly',\n",
       "              'respectful',\n",
       "              'reverent',\n",
       "              'reverential',\n",
       "              'venerating',\n",
       "              'worshipful'},\n",
       "             'fear.n.03.awe': set(),\n",
       "             'fear.n.03.veneration': set(),\n",
       "             'dissatisfaction.n.01.dissatisfaction': set(),\n",
       "             'unpleasantness.n.01.unpleasantness': {'unpleasant'},\n",
       "             'belonging.n.01.belonging': set(),\n",
       "             'euphoria.n.01.euphoria': set(),\n",
       "             'euphoria.n.01.euphory': {'euphoric'},\n",
       "             'guilt_pang.n.01.guilt_pang': set(),\n",
       "             'dolor.n.01.dolor': {'dolorous',\n",
       "              'dolourous',\n",
       "              'lachrymose',\n",
       "              'tearful',\n",
       "              'weeping'},\n",
       "             'dolor.n.01.dolour': set(),\n",
       "             'shadow.n.04.shadow': set(),\n",
       "             'sulk.n.01.sulk': {'huffish', 'sulky'},\n",
       "             'sulk.n.01.sulkiness': {'huffish', 'sulky'},\n",
       "             'solicitude.n.01.solicitude': set(),\n",
       "             'solicitude.n.01.solicitousness': {'solicitous'},\n",
       "             'hysteria.n.02.hysteria': {'hysterical'},\n",
       "             'penis_envy.n.01.penis_envy': set(),\n",
       "             'civic_pride.n.01.civic_pride': set(),\n",
       "             'civic_pride.n.01.civic_spirit': set(),\n",
       "             'urge.n.02.urge': set(),\n",
       "             'urge.n.02.itch': set(),\n",
       "             'optimism.n.01.optimism': {'affirmative', 'optimistic'},\n",
       "             'intoxication.n.03.intoxication': set(),\n",
       "             'security.n.03.security': {'secure', 'unafraid', 'untroubled'},\n",
       "             'despondency.n.01.despondency': {'despondent', 'heartsick'},\n",
       "             'despondency.n.01.despondence': {'despondent', 'heartsick'},\n",
       "             'despondency.n.01.heartsickness': {'brokenhearted',\n",
       "              'despondent',\n",
       "              'heartbroken',\n",
       "              'heartsick'},\n",
       "             'despondency.n.01.disconsolateness': {'disconsolate',\n",
       "              'inconsolable',\n",
       "              'unconsolable'},\n",
       "             'wish.n.01.wish': set(),\n",
       "             'wish.n.01.wishing': set(),\n",
       "             'wish.n.01.want': set(),\n",
       "             'entrancement.n.01.entrancement': set(),\n",
       "             'entrancement.n.01.ravishment': set(),\n",
       "             'favor.n.04.favor': set(),\n",
       "             'favor.n.04.favour': set(),\n",
       "             'calmness.n.03.calmness': {'calm',\n",
       "              'serene',\n",
       "              'tranquil',\n",
       "              'unagitated'},\n",
       "             'compunction.n.01.compunction': set(),\n",
       "             'compunction.n.01.remorse': set(),\n",
       "             'compunction.n.01.self-reproach': set(),\n",
       "             'misanthropy.n.01.misanthropy': {'misanthropic',\n",
       "              'misanthropical'},\n",
       "             'joy.n.01.joy': {'joyous'},\n",
       "             'joy.n.01.joyousness': {'joyous'},\n",
       "             'joy.n.01.joyfulness': {'elated',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant'},\n",
       "             'masochism.n.01.masochism': {'masochistic'},\n",
       "             'amicability.n.01.amicability': set(),\n",
       "             'amicability.n.01.amicableness': set(),\n",
       "             'forlornness.n.01.forlornness': set(),\n",
       "             'forlornness.n.01.loneliness': {'lonely', 'lonesome'},\n",
       "             'forlornness.n.01.desolation': set(),\n",
       "             'sensation.n.03.sensation': set(),\n",
       "             'horror.n.01.horror': set(),\n",
       "             'gratification.n.01.gratification': set(),\n",
       "             'gratification.n.01.satisfaction': set(),\n",
       "             'pride.n.02.pride': set(),\n",
       "             'gravity.n.03.gravity': set(),\n",
       "             'gravity.n.03.solemnity': {'earnest',\n",
       "              'grave',\n",
       "              'sedate',\n",
       "              'sincere',\n",
       "              'sober',\n",
       "              'solemn'},\n",
       "             'lovesickness.n.01.lovesickness': {'lovesick'},\n",
       "             'encouragement.n.03.encouragement': set(),\n",
       "             'testiness.n.01.testiness': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'testiness.n.01.touchiness': {'feisty',\n",
       "              'huffy',\n",
       "              'thin-skinned',\n",
       "              'touchy'},\n",
       "             'testiness.n.01.tetchiness': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'oppression.n.03.oppression': set(),\n",
       "             'oppression.n.03.oppressiveness': {'oppressive',\n",
       "              'tyrannical',\n",
       "              'tyrannous'},\n",
       "             'pensiveness.n.01.pensiveness': {'brooding',\n",
       "              'broody',\n",
       "              'contemplative',\n",
       "              'meditative',\n",
       "              'musing',\n",
       "              'pensive',\n",
       "              'pondering',\n",
       "              'reflective',\n",
       "              'ruminative'},\n",
       "             'pensiveness.n.01.brooding': set(),\n",
       "             'gloat.n.01.gloat': set(),\n",
       "             'gloat.n.01.gloating': set(),\n",
       "             'gloat.n.01.glee': set(),\n",
       "             'nirvana.n.01.nirvana': set(),\n",
       "             'nirvana.n.01.enlightenment': set(),\n",
       "             'broken_heart.n.01.broken_heart': set(),\n",
       "             'empathy.n.01.empathy': {'empathetic', 'empathic'},\n",
       "             'titillation.n.01.titillation': set(),\n",
       "             'complacency.n.01.complacency': {'complacent',\n",
       "              'self-complacent',\n",
       "              'self-satisfied'},\n",
       "             'complacency.n.01.complacence': {'complacent',\n",
       "              'self-complacent',\n",
       "              'self-satisfied'},\n",
       "             'complacency.n.01.self-complacency': {'complacent',\n",
       "              'self-complacent',\n",
       "              'self-satisfied'},\n",
       "             'complacency.n.01.self-satisfaction': set(),\n",
       "             'sexual_desire.n.01.sexual_desire': set(),\n",
       "             'sexual_desire.n.01.eros': {'erotic', 'titillating'},\n",
       "             'sexual_desire.n.01.concupiscence': {'concupiscent',\n",
       "              'lustful',\n",
       "              'lusty'},\n",
       "             'sexual_desire.n.01.physical_attraction': set(),\n",
       "             'frisson.n.01.frisson': set(),\n",
       "             'frisson.n.01.shiver': {'chilling',\n",
       "              'scarey',\n",
       "              'scary',\n",
       "              'shivery',\n",
       "              'shuddery'},\n",
       "             'frisson.n.01.chill': set(),\n",
       "             'frisson.n.01.quiver': set(),\n",
       "             'frisson.n.01.shudder': {'chilling',\n",
       "              'scarey',\n",
       "              'scary',\n",
       "              'shivery',\n",
       "              'shuddery'},\n",
       "             'frisson.n.01.thrill': set(),\n",
       "             'frisson.n.01.tingle': set(),\n",
       "             'sulkiness.n.02.sulkiness': {'huffish', 'sulky'},\n",
       "             'sulkiness.n.02.huffishness': {'huffish', 'sulky'},\n",
       "             'surprise.n.01.surprise': set(),\n",
       "             'bang.n.04.bang': set(),\n",
       "             'bang.n.04.boot': set(),\n",
       "             'bang.n.04.charge': set(),\n",
       "             'bang.n.04.rush': set(),\n",
       "             'bang.n.04.flush': set(),\n",
       "             'bang.n.04.thrill': set(),\n",
       "             'bang.n.04.kick': set(),\n",
       "             'despair.n.02.despair': set(),\n",
       "             'apprehension.n.01.apprehension': set(),\n",
       "             'apprehension.n.01.apprehensiveness': {'apprehensive', 'worried'},\n",
       "             'apprehension.n.01.dread': {'awful',\n",
       "              'dire',\n",
       "              'direful',\n",
       "              'dread',\n",
       "              'dreaded',\n",
       "              'dreadful',\n",
       "              'fearful',\n",
       "              'fearsome',\n",
       "              'frightening',\n",
       "              'horrendous',\n",
       "              'horrific',\n",
       "              'terrible'},\n",
       "             'state.n.06.state': set(),\n",
       "             'sensuousness.n.01.sensuousness': {'sensuous'},\n",
       "             'frustration.n.03.frustration': set(),\n",
       "             'mercifulness.n.01.mercifulness': {'merciful'},\n",
       "             'mercifulness.n.01.mercy': set(),\n",
       "             'fondness.n.01.fondness': {'fond', 'partial'},\n",
       "             'fondness.n.01.fancy': set(),\n",
       "             'fondness.n.01.partiality': set(),\n",
       "             'hesitance.n.01.hesitance': {'hesitant', 'hesitating'},\n",
       "             'hesitance.n.01.hesitancy': {'hesitant', 'hesitating'},\n",
       "             'sensitivity.n.03.sensitivity': {'sensitive'},\n",
       "             'sensitivity.n.03.sensitiveness': {'sensitive'},\n",
       "             'misology.n.01.misology': set(),\n",
       "             'wildness.n.01.wildness': {'wild'},\n",
       "             'wildness.n.01.abandon': set(),\n",
       "             'jocundity.n.01.jocundity': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'jocundity.n.01.jocularity': {'jesting',\n",
       "              'jocose',\n",
       "              'jocular',\n",
       "              'joking'},\n",
       "             'nostalgia.n.01.nostalgia': {'nostalgic'},\n",
       "             'hero_worship.n.01.hero_worship': set(),\n",
       "             'willies.n.01.willies': set(),\n",
       "             'passion.n.01.passion': set(),\n",
       "             'passion.n.01.passionateness': {'passionate'},\n",
       "             'survivor_guilt.n.01.survivor_guilt': set(),\n",
       "             'american_dream.n.01.American_Dream': set(),\n",
       "             'triumph.n.02.triumph': {'exultant',\n",
       "              'exulting',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'sanguinity.n.01.sanguinity': {'sanguine'},\n",
       "             'sanguinity.n.01.sanguineness': {'sanguine'},\n",
       "             'anxiousness.n.02.anxiousness': {'anxious',\n",
       "              'nervous',\n",
       "              'queasy',\n",
       "              'uneasy',\n",
       "              'unquiet'},\n",
       "             'anxiousness.n.02.disquiet': set(),\n",
       "             'foreboding.n.01.foreboding': set(),\n",
       "             'foreboding.n.01.premonition': set(),\n",
       "             'foreboding.n.01.presentiment': set(),\n",
       "             'foreboding.n.01.boding': set(),\n",
       "             'intimidation.n.02.intimidation': set(),\n",
       "             'soul.n.03.soul': set(),\n",
       "             'soul.n.03.soulfulness': {'soulful'},\n",
       "             'dolefulness.n.01.dolefulness': {'doleful', 'mournful'},\n",
       "             'sentimentality.n.02.sentimentality': {'sentimental'},\n",
       "             'electra_complex.n.01.Electra_complex': set(),\n",
       "             'oversensitiveness.n.01.oversensitiveness': {'oversensitive'},\n",
       "             'hankering.n.01.hankering': set(),\n",
       "             'hankering.n.01.yen': set(),\n",
       "             'exhilaration.n.01.exhilaration': set(),\n",
       "             'exhilaration.n.01.excitement': set(),\n",
       "             'approbation.n.01.approbation': set(),\n",
       "             'world-weariness.n.01.world-weariness': {'bored', 'world-weary'},\n",
       "             'world-weariness.n.01.Weltschmerz': set(),\n",
       "             'disinclination.n.01.disinclination': set(),\n",
       "             'mellowness.n.01.mellowness': {'mellow', 'mellowed'},\n",
       "             'bloodlust.n.01.bloodlust': set(),\n",
       "             'sorrow.n.01.sorrow': set(),\n",
       "             'angst.n.01.angst': set(),\n",
       "             'anguish.n.01.anguish': set(),\n",
       "             'anguish.n.01.torment': set(),\n",
       "             'anguish.n.01.torture': set(),\n",
       "             'caprice.n.01.caprice': {'capricious', 'impulsive', 'whimsical'},\n",
       "             'caprice.n.01.impulse': set(),\n",
       "             'caprice.n.01.whim': set(),\n",
       "             'faintness.n.01.faintness': {'faint',\n",
       "              'light',\n",
       "              'light-headed',\n",
       "              'lightheaded',\n",
       "              'swooning'},\n",
       "             'undertow.n.01.undertow': set(),\n",
       "             'joylessness.n.01.joylessness': {'joyless'},\n",
       "             'hope.n.02.hope': set(),\n",
       "             'embitterment.n.01.embitterment': set(),\n",
       "             'glow.n.04.glow': set(),\n",
       "             'devotion.n.01.devotion': set(),\n",
       "             'devotion.n.01.devotedness': {'devoted'},\n",
       "             'meekness.n.01.meekness': {'meek', 'mild', 'modest', 'tame'},\n",
       "             'meekness.n.01.submission': set(),\n",
       "             'mourning.n.01.mourning': set(),\n",
       "             'mourning.n.01.bereavement': set(),\n",
       "             'amusement.n.01.amusement': set(),\n",
       "             'infuriation.n.01.infuriation': set(),\n",
       "             'infuriation.n.01.enragement': set(),\n",
       "             'downheartedness.n.01.downheartedness': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'downheartedness.n.01.dejectedness': set(),\n",
       "             'downheartedness.n.01.low-spiritedness': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'downheartedness.n.01.lowness': {'blue',\n",
       "              'broken',\n",
       "              'crushed',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'humbled',\n",
       "              'humiliated',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'downheartedness.n.01.dispiritedness': {'blue',\n",
       "              'depressed',\n",
       "              'dispirited',\n",
       "              'down',\n",
       "              'down_in_the_mouth',\n",
       "              'downcast',\n",
       "              'downhearted',\n",
       "              'gloomy',\n",
       "              'grim',\n",
       "              'listless',\n",
       "              'low',\n",
       "              'low-spirited'},\n",
       "             'intimidation.n.03.intimidation': set(),\n",
       "             'electricity.n.03.electricity': {'electric'},\n",
       "             'heartstrings.n.01.heartstrings': set(),\n",
       "             'sensuality.n.01.sensuality': {'animal',\n",
       "              'carnal',\n",
       "              'fleshly',\n",
       "              'sensual'},\n",
       "             'sensuality.n.01.sensualness': {'animal',\n",
       "              'carnal',\n",
       "              'fleshly',\n",
       "              'sensual',\n",
       "              'sultry'},\n",
       "             'sensuality.n.01.sensualism': set(),\n",
       "             'gratitude.n.01.gratitude': set(),\n",
       "             'fatigue.n.03.fatigue': set(),\n",
       "             'maleficence.n.01.maleficence': {'maleficent'},\n",
       "             'growing_pains.n.02.growing_pains': set(),\n",
       "             'covetousness.n.01.covetousness': set(),\n",
       "             'discomfiture.n.01.discomfiture': set(),\n",
       "             'discomfiture.n.01.discomposure': set(),\n",
       "             'discomfiture.n.01.disconcertion': set(),\n",
       "             'discomfiture.n.01.disconcertment': set(),\n",
       "             'pessimism.n.01.pessimism': {'pessimistic'},\n",
       "             'attrition.n.03.attrition': set(),\n",
       "             'attrition.n.03.contrition': set(),\n",
       "             'attrition.n.03.contriteness': {'contrite',\n",
       "              'remorseful',\n",
       "              'rueful',\n",
       "              'ruthful'},\n",
       "             'misoneism.n.01.misoneism': set(),\n",
       "             'diffidence.n.01.diffidence': {'diffident',\n",
       "              'shy',\n",
       "              'timid',\n",
       "              'unsure'},\n",
       "             'diffidence.n.01.self-doubt': set(),\n",
       "             'diffidence.n.01.self-distrust': set(),\n",
       "             'self-esteem.n.01.self-esteem': set(),\n",
       "             'self-esteem.n.01.self-pride': set(),\n",
       "             'liking.n.01.liking': set(),\n",
       "             'grudge.n.01.grudge': set(),\n",
       "             'grudge.n.01.score': set(),\n",
       "             'grudge.n.01.grievance': set(),\n",
       "             'guilt.n.02.guilt': {'guilty', 'hangdog', 'shamed', 'shamefaced'},\n",
       "             'guilt.n.02.guilty_conscience': set(),\n",
       "             'guilt.n.02.guilt_feelings': set(),\n",
       "             'guilt.n.02.guilt_trip': set(),\n",
       "             'love.n.01.love': set(),\n",
       "             'depression.n.04.depression': set(),\n",
       "             'sadism.n.01.sadism': {'sadistic'},\n",
       "             'umbrage.n.01.umbrage': {'incensed',\n",
       "              'indignant',\n",
       "              'outraged',\n",
       "              'umbrageous'},\n",
       "             'umbrage.n.01.offense': set(),\n",
       "             'umbrage.n.01.offence': set(),\n",
       "             'vindictiveness.n.01.vindictiveness': {'despiteful',\n",
       "              'revengeful',\n",
       "              'spiteful',\n",
       "              'vengeful',\n",
       "              'vindictive'},\n",
       "             'vindictiveness.n.01.vengefulness': {'revengeful',\n",
       "              'vengeful',\n",
       "              'vindictive'},\n",
       "             'anglophobia.n.01.Anglophobia': {'Anglophobic'},\n",
       "             'razbliuto.n.01.razbliuto': set(),\n",
       "             'discomfort.n.02.discomfort': set(),\n",
       "             'discomfort.n.02.soreness': {'afflictive',\n",
       "              'huffy',\n",
       "              'mad',\n",
       "              'painful',\n",
       "              'sore'},\n",
       "             'discomfort.n.02.irritation': set(),\n",
       "             'chagrin.n.01.chagrin': set(),\n",
       "             'chagrin.n.01.humiliation': set(),\n",
       "             'chagrin.n.01.mortification': set(),\n",
       "             'mental_anguish.n.01.mental_anguish': set(),\n",
       "             'repugnance.n.01.repugnance': {'abhorrent',\n",
       "              'detestable',\n",
       "              'obscene',\n",
       "              'repugnant',\n",
       "              'repulsive'},\n",
       "             'repugnance.n.01.repulsion': set(),\n",
       "             'repugnance.n.01.revulsion': set(),\n",
       "             'repugnance.n.01.horror': set(),\n",
       "             'antagonism.n.03.antagonism': {'antagonistic'},\n",
       "             'satisfaction.n.01.satisfaction': set(),\n",
       "             'stomach.n.03.stomach': set(),\n",
       "             'antipathy.n.01.antipathy': {'antagonistic',\n",
       "              'antipathetic',\n",
       "              'antipathetical',\n",
       "              'averse',\n",
       "              'indisposed',\n",
       "              'loath',\n",
       "              'loth'},\n",
       "             'antipathy.n.01.aversion': set(),\n",
       "             'antipathy.n.01.distaste': set(),\n",
       "             'sentiment.n.01.sentiment': {'bathetic',\n",
       "              'drippy',\n",
       "              'hokey',\n",
       "              'kitschy',\n",
       "              'maudlin',\n",
       "              'mawkish',\n",
       "              'mushy',\n",
       "              'schmaltzy',\n",
       "              'schmalzy',\n",
       "              'sentimental',\n",
       "              'slushy',\n",
       "              'soppy',\n",
       "              'soupy'},\n",
       "             'unassertiveness.n.01.unassertiveness': {'unassertive'},\n",
       "             'chill.n.04.chill': set(),\n",
       "             'chill.n.04.pall': set(),\n",
       "             'eagerness.n.01.eagerness': {'eager'},\n",
       "             'eagerness.n.01.avidity': {'avid', 'zealous'},\n",
       "             'eagerness.n.01.avidness': {'avid', 'zealous'},\n",
       "             'eagerness.n.01.keenness': set(),\n",
       "             'leaning.n.01.leaning': set(),\n",
       "             'leaning.n.01.propensity': set(),\n",
       "             'leaning.n.01.tendency': set(),\n",
       "             'passion.n.05.passion': set(),\n",
       "             'filial_love.n.01.filial_love': set(),\n",
       "             'insecurity.n.02.insecurity': {'insecure'},\n",
       "             'anglophilia.n.01.Anglophilia': {'Anglophilic'},\n",
       "             'misery.n.02.misery': set(),\n",
       "             'philhellenism.n.01.philhellenism': set(),\n",
       "             'abhorrence.n.01.abhorrence': {'abhorrent',\n",
       "              'detestable',\n",
       "              'obscene',\n",
       "              'repugnant',\n",
       "              'repulsive'},\n",
       "             'abhorrence.n.01.abomination': set(),\n",
       "             'abhorrence.n.01.detestation': set(),\n",
       "             'abhorrence.n.01.execration': set(),\n",
       "             'abhorrence.n.01.loathing': set(),\n",
       "             'abhorrence.n.01.odium': {'abominable',\n",
       "              'detestable',\n",
       "              'execrable',\n",
       "              'odious'},\n",
       "             'resentment.n.01.resentment': set(),\n",
       "             'resentment.n.01.bitterness': {'bitter'},\n",
       "             'resentment.n.01.gall': set(),\n",
       "             'resentment.n.01.rancor': {'rancorous'},\n",
       "             'resentment.n.01.rancour': set(),\n",
       "             'blessedness.n.01.blessedness': {'blessed'},\n",
       "             'blessedness.n.01.beatitude': set(),\n",
       "             'blessedness.n.01.beatification': set(),\n",
       "             'pet.n.03.pet': set(),\n",
       "             'bonheur.n.01.bonheur': set(),\n",
       "             'helplessness.n.03.helplessness': {'helpless', 'lost'},\n",
       "             'tsoris.n.01.tsoris': set(),\n",
       "             'ambivalence.n.01.ambivalence': {'ambivalent'},\n",
       "             'ambivalence.n.01.ambivalency': set(),\n",
       "             'cheerfulness.n.02.cheerfulness': {'cheerful',\n",
       "              'pollyannaish',\n",
       "              'upbeat'},\n",
       "             'cheerfulness.n.02.blitheness': {'cheerful',\n",
       "              'pollyannaish',\n",
       "              'upbeat'},\n",
       "             'bad_temper.n.01.bad_temper': set(),\n",
       "             'bad_temper.n.01.ill_temper': set(),\n",
       "             'happiness.n.02.happiness': {'happy'},\n",
       "             'self-torture.n.01.self-torture': set(),\n",
       "             'self-torture.n.01.self-torment': set(),\n",
       "             'mysophilia.n.01.mysophilia': set(),\n",
       "             'puppy_love.n.01.puppy_love': set(),\n",
       "             'puppy_love.n.01.calf_love': set(),\n",
       "             'puppy_love.n.01.crush': set(),\n",
       "             'puppy_love.n.01.infatuation': set(),\n",
       "             'confusion.n.03.confusion': set(),\n",
       "             'confusion.n.03.discombobulation': set(),\n",
       "             'velleity.n.01.velleity': set(),\n",
       "             'admiration.n.01.admiration': set(),\n",
       "             'admiration.n.01.esteem': set(),\n",
       "             'shame.n.01.shame': set(),\n",
       "             'oedipus_complex.n.01.Oedipus_complex': set(),\n",
       "             'oedipus_complex.n.01.Oedipal_complex': set(),\n",
       "             'buoyancy.n.01.buoyancy': {'buoyant', 'chirpy', 'perky'},\n",
       "             'buoyancy.n.01.perkiness': {'buoyant', 'chirpy', 'perky'},\n",
       "             'peace.n.03.peace': set(),\n",
       "             'peace.n.03.peacefulness': set(),\n",
       "             'peace.n.03.peace_of_mind': set(),\n",
       "             'peace.n.03.repose': set(),\n",
       "             'peace.n.03.serenity': set(),\n",
       "             'peace.n.03.heartsease': set(),\n",
       "             'peace.n.03.ataraxis': set(),\n",
       "             'amour_propre.n.01.amour_propre': set(),\n",
       "             'amour_propre.n.01.conceit': set(),\n",
       "             'amour_propre.n.01.self-love': set(),\n",
       "             'amour_propre.n.01.vanity': {'conceited',\n",
       "              'egotistic',\n",
       "              'egotistical',\n",
       "              'self-conceited',\n",
       "              'swollen',\n",
       "              'swollen-headed',\n",
       "              'vain'},\n",
       "             'scruple.n.02.scruple': {'scrupulous'},\n",
       "             'scruple.n.02.qualm': set(),\n",
       "             'scruple.n.02.misgiving': set(),\n",
       "             'hostility.n.03.hostility': {'hostile'},\n",
       "             'hostility.n.03.enmity': {'inimical', 'unfriendly'},\n",
       "             'hostility.n.03.ill_will': set(),\n",
       "             'technophobia.n.01.technophobia': set(),\n",
       "             'despisal.n.01.despisal': set(),\n",
       "             'despisal.n.01.despising': set(),\n",
       "             'inclination.n.05.inclination': set(),\n",
       "             'embarrassment.n.02.embarrassment': set(),\n",
       "             'heartburning.n.01.heartburning': set(),\n",
       "             'attachment.n.01.attachment': set(),\n",
       "             'attachment.n.01.fond_regard': set(),\n",
       "             'approval.n.02.approval': set(),\n",
       "             'distance.n.04.distance': {'aloof', 'distant', 'upstage'},\n",
       "             'distance.n.04.aloofness': set(),\n",
       "             'suspense.n.03.suspense': set(),\n",
       "             'feelings.n.01.feelings': set(),\n",
       "             'good_humor.n.01.good_humor': set(),\n",
       "             'good_humor.n.01.good_humour': set(),\n",
       "             'good_humor.n.01.good_temper': set(),\n",
       "             'good_humor.n.01.amiability': {'affable',\n",
       "              'amiable',\n",
       "              'cordial',\n",
       "              'genial',\n",
       "              'good-humored',\n",
       "              'good-humoured'},\n",
       "             'levity.n.01.levity': set(),\n",
       "             'soft_spot.n.02.soft_spot': set(),\n",
       "             'distress.n.01.distress': set(),\n",
       "             'distress.n.01.hurt': set(),\n",
       "             'distress.n.01.suffering': set(),\n",
       "             'consolation.n.01.consolation': set(),\n",
       "             'consolation.n.01.solace': set(),\n",
       "             'consolation.n.01.solacement': set(),\n",
       "             'resignation.n.01.resignation': set(),\n",
       "             'resignation.n.01.surrender': set(),\n",
       "             'regard.n.06.regard': set(),\n",
       "             'regard.n.06.respect': set(),\n",
       "             'unrest.n.02.unrest': set(),\n",
       "             'daze.n.01.daze': set(),\n",
       "             'daze.n.01.shock': set(),\n",
       "             'daze.n.01.stupor': set(),\n",
       "             'prurience.n.01.prurience': {'lubricious',\n",
       "              'lustful',\n",
       "              'prurient',\n",
       "              'salacious'},\n",
       "             'prurience.n.01.pruriency': {'lubricious',\n",
       "              'lustful',\n",
       "              'prurient',\n",
       "              'salacious'},\n",
       "             'prurience.n.01.lasciviousness': {'lascivious',\n",
       "              'lewd',\n",
       "              'libidinous',\n",
       "              'lustful'},\n",
       "             'prurience.n.01.carnality': {'animal',\n",
       "              'carnal',\n",
       "              'fleshly',\n",
       "              'sensual'},\n",
       "             'prurience.n.01.lubricity': set(),\n",
       "             'huffiness.n.01.huffiness': {'feisty',\n",
       "              'huffy',\n",
       "              'mad',\n",
       "              'sore',\n",
       "              'thin-skinned',\n",
       "              'touchy'},\n",
       "             'satyriasis.n.01.satyriasis': set(),\n",
       "             'comfort.n.02.comfort': set(),\n",
       "             'ego.n.01.ego': set(),\n",
       "             'ego.n.01.egotism': {'conceited',\n",
       "              'egotistic',\n",
       "              'egotistical',\n",
       "              'self-conceited',\n",
       "              'swollen',\n",
       "              'swollen-headed',\n",
       "              'vain'},\n",
       "             'ego.n.01.self-importance': {'arrogant',\n",
       "              'chesty',\n",
       "              'self-important'},\n",
       "             'mournfulness.n.01.mournfulness': {'doleful',\n",
       "              'mournful',\n",
       "              'plaintive'},\n",
       "             'mournfulness.n.01.sorrowfulness': {'sorrowful'},\n",
       "             'mournfulness.n.01.ruthfulness': {'contrite',\n",
       "              'remorseful',\n",
       "              'rueful',\n",
       "              'ruthful'},\n",
       "             'amorousness.n.01.amorousness': {'amative', 'amorous'},\n",
       "             'amorousness.n.01.enamoredness': {'enamored',\n",
       "              'in_love',\n",
       "              'infatuated',\n",
       "              'potty',\n",
       "              'smitten',\n",
       "              'soft_on',\n",
       "              'taken_with'},\n",
       "             'buck_fever.n.01.buck_fever': set(),\n",
       "             'schadenfreude.n.01.Schadenfreude': set(),\n",
       "             'exultation.n.01.exultation': set(),\n",
       "             'exultation.n.01.jubilance': {'elated',\n",
       "              'exultant',\n",
       "              'exulting',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'exultation.n.01.jubilancy': {'elated',\n",
       "              'exultant',\n",
       "              'exulting',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'exultation.n.01.jubilation': set(),\n",
       "             'affection.n.01.affection': set(),\n",
       "             'affection.n.01.affectionateness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.fondness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.tenderness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.heart': {'hearty'},\n",
       "             'affection.n.01.warmness': {'affectionate',\n",
       "              'fond',\n",
       "              'lovesome',\n",
       "              'tender',\n",
       "              'warm'},\n",
       "             'affection.n.01.warmheartedness': {'warmhearted'},\n",
       "             'affection.n.01.philia': set(),\n",
       "             'weight.n.05.weight': {'weighty'},\n",
       "             'discouragement.n.01.discouragement': set(),\n",
       "             'discouragement.n.01.disheartenment': set(),\n",
       "             'discouragement.n.01.dismay': set(),\n",
       "             'apathy.n.01.apathy': {'apathetic', 'indifferent'},\n",
       "             'sadness.n.02.sadness': {'sad'},\n",
       "             'sadness.n.02.sorrow': set(),\n",
       "             'sadness.n.02.sorrowfulness': {'sorrowful'},\n",
       "             'cold_comfort.n.01.cold_comfort': set(),\n",
       "             'ingratitude.n.01.ingratitude': set(),\n",
       "             'ingratitude.n.01.ungratefulness': {'thankless',\n",
       "              'ungrateful',\n",
       "              'unthankful'},\n",
       "             'libido.n.01.libido': {'lascivious',\n",
       "              'lewd',\n",
       "              'libidinal',\n",
       "              'libidinous',\n",
       "              'lustful'},\n",
       "             'addiction.n.02.addiction': set(),\n",
       "             'unfriendliness.n.01.unfriendliness': {'inimical', 'unfriendly'},\n",
       "             'weakness.n.05.weakness': set(),\n",
       "             'wistfulness.n.01.wistfulness': {'pensive', 'wistful'},\n",
       "             'anaphrodisia.n.01.anaphrodisia': set(),\n",
       "             'emotion.n.01.emotion': {'emotional'},\n",
       "             'misogamy.n.01.misogamy': set(),\n",
       "             'demoralization.n.03.demoralization': set(),\n",
       "             'demoralization.n.03.demoralisation': set(),\n",
       "             'compassion.n.01.compassion': set(),\n",
       "             'compassion.n.01.compassionateness': {'compassionate'},\n",
       "             'self-pity.n.01.self-pity': set(),\n",
       "             'emulation.n.01.emulation': set(),\n",
       "             'moroseness.n.01.moroseness': {'dark',\n",
       "              'dour',\n",
       "              'glowering',\n",
       "              'glum',\n",
       "              'moody',\n",
       "              'morose',\n",
       "              'saturnine',\n",
       "              'sour',\n",
       "              'sullen'},\n",
       "             'moroseness.n.01.glumness': {'dark',\n",
       "              'dour',\n",
       "              'glowering',\n",
       "              'glum',\n",
       "              'moody',\n",
       "              'morose',\n",
       "              'saturnine',\n",
       "              'sour',\n",
       "              'sullen'},\n",
       "             'moroseness.n.01.sullenness': {'heavy',\n",
       "              'lowering',\n",
       "              'sullen',\n",
       "              'threatening'},\n",
       "             'humility.n.02.humility': set(),\n",
       "             'humility.n.02.humbleness': set(),\n",
       "             'gusto.n.01.gusto': set(),\n",
       "             'gusto.n.01.relish': set(),\n",
       "             'gusto.n.01.zest': {'barmy', 'yeasty', 'zestful', 'zesty'},\n",
       "             'gusto.n.01.zestfulness': {'barmy', 'yeasty', 'zestful', 'zesty'},\n",
       "             'sorrow.n.02.sorrow': set(),\n",
       "             'sorrow.n.02.regret': set(),\n",
       "             'sorrow.n.02.rue': set(),\n",
       "             'sorrow.n.02.ruefulness': {'contrite',\n",
       "              'remorseful',\n",
       "              'rueful',\n",
       "              'ruthful'},\n",
       "             'disgust.n.01.disgust': set(),\n",
       "             'suspense.n.01.suspense': set(),\n",
       "             'embarrassment.n.01.embarrassment': set(),\n",
       "             'lecherousness.n.01.lecherousness': {'lecherous'},\n",
       "             'lecherousness.n.01.lust': {'concupiscent', 'lustful', 'lusty'},\n",
       "             'lecherousness.n.01.lustfulness': {'concupiscent',\n",
       "              'lascivious',\n",
       "              'lewd',\n",
       "              'libidinous',\n",
       "              'lubricious',\n",
       "              'lustful',\n",
       "              'lusty',\n",
       "              'prurient',\n",
       "              'salacious'},\n",
       "             'love.n.04.love': set(),\n",
       "             'love.n.04.sexual_love': set(),\n",
       "             'love.n.04.erotic_love': set(),\n",
       "             'nausea.n.02.nausea': {'loathsome',\n",
       "              'nauseating',\n",
       "              'nauseous',\n",
       "              'noisome',\n",
       "              'offensive',\n",
       "              'queasy',\n",
       "              'sickening',\n",
       "              'vile'},\n",
       "             'philogyny.n.01.philogyny': set(),\n",
       "             'pleasantness.n.01.pleasantness': {'pleasant'},\n",
       "             'lovingness.n.01.lovingness': {'loving'},\n",
       "             'lovingness.n.01.caring': {'caring'},\n",
       "             'tranquillity.n.02.tranquillity': {'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'tranquillity.n.02.tranquility': {'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'tranquillity.n.02.quietness': {'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'tranquillity.n.02.quietude': set(),\n",
       "             'thing.n.11.thing': set(),\n",
       "             'elation.n.02.elation': set(),\n",
       "             'elation.n.02.high_spirits': set(),\n",
       "             'elation.n.02.lightness': {'light'},\n",
       "             'peeve.n.01.peeve': set(),\n",
       "             'smugness.n.01.smugness': {'self-satisfied', 'smug'},\n",
       "             'astonishment.n.01.astonishment': set(),\n",
       "             'astonishment.n.01.amazement': set(),\n",
       "             'hopelessness.n.01.hopelessness': {'hopeless'},\n",
       "             'inferiority_complex.n.01.inferiority_complex': set(),\n",
       "             'impatience.n.02.impatience': {'impatient', 'raring'},\n",
       "             'gratefulness.n.01.gratefulness': {'grateful', 'thankful'},\n",
       "             'gratefulness.n.01.thankfulness': {'grateful', 'thankful'},\n",
       "             'gratefulness.n.01.appreciativeness': {'appreciative'},\n",
       "             'poignance.n.01.poignance': {'poignant'},\n",
       "             'poignance.n.01.poignancy': {'poignant'},\n",
       "             'boredom.n.01.boredom': set(),\n",
       "             'boredom.n.01.ennui': set(),\n",
       "             'boredom.n.01.tedium': {'boring',\n",
       "              'deadening',\n",
       "              'dull',\n",
       "              'ho-hum',\n",
       "              'irksome',\n",
       "              'slow',\n",
       "              'tedious',\n",
       "              'tiresome',\n",
       "              'wearisome'},\n",
       "             'sadomasochism.n.01.sadomasochism': {'sadomasochistic'},\n",
       "             'concern.n.03.concern': set(),\n",
       "             'class_feeling.n.01.class_feeling': set(),\n",
       "             'worship.n.02.worship': set(),\n",
       "             'worship.n.02.adoration': set(),\n",
       "             'conscience.n.03.conscience': {'conscientious'},\n",
       "             'hopefulness.n.02.hopefulness': {'hopeful'},\n",
       "             'rejoicing.n.01.rejoicing': set(),\n",
       "             'shyness.n.01.shyness': {'diffident', 'shy', 'timid', 'unsure'},\n",
       "             'indignation.n.01.indignation': set(),\n",
       "             'indignation.n.01.outrage': set(),\n",
       "             'carefreeness.n.01.carefreeness': {'carefree',\n",
       "              'devil-may-care',\n",
       "              'freewheeling',\n",
       "              'happy-go-lucky',\n",
       "              'harum-scarum',\n",
       "              'slaphappy'},\n",
       "             'carefreeness.n.01.insouciance': {'casual',\n",
       "              'insouciant',\n",
       "              'nonchalant'},\n",
       "             'carefreeness.n.01.lightheartedness': {'blithe',\n",
       "              'blithesome',\n",
       "              'light-hearted',\n",
       "              'lighthearted',\n",
       "              'lightsome'},\n",
       "             'carefreeness.n.01.lightsomeness': {'blithe',\n",
       "              'blithesome',\n",
       "              'light-hearted',\n",
       "              'lighthearted',\n",
       "              'lightsome'},\n",
       "             'agony.n.01.agony': {'agonal'},\n",
       "             'agony.n.01.torment': set(),\n",
       "             'agony.n.01.torture': {'agonising',\n",
       "              'agonizing',\n",
       "              'excruciating',\n",
       "              'harrowing',\n",
       "              'torturesome',\n",
       "              'torturing',\n",
       "              'torturous'},\n",
       "             'temptation.n.02.temptation': set(),\n",
       "             'anticipation.n.01.anticipation': set(),\n",
       "             'anticipation.n.01.expectancy': {'anticipant',\n",
       "              'anticipative',\n",
       "              'expectant'},\n",
       "             'creeps.n.02.creeps': set(),\n",
       "             'self-depreciation.n.01.self-depreciation': set(),\n",
       "             'moodiness.n.01.moodiness': {'dark',\n",
       "              'dour',\n",
       "              'glowering',\n",
       "              'glum',\n",
       "              'moody',\n",
       "              'morose',\n",
       "              'saturnine',\n",
       "              'sour',\n",
       "              'sullen'},\n",
       "             'envy.n.01.envy': set(),\n",
       "             'envy.n.01.enviousness': {'covetous', 'envious', 'jealous'},\n",
       "             'happiness.n.01.happiness': {'felicitous', 'happy'},\n",
       "             'happiness.n.01.felicity': {'felicitous', 'happy'},\n",
       "             'pining.n.01.pining': set(),\n",
       "             'ardor.n.01.ardor': set(),\n",
       "             'ardor.n.01.ardour': set(),\n",
       "             'ardor.n.01.elan': set(),\n",
       "             'ardor.n.01.zeal': {'avid', 'zealous'},\n",
       "             'fear.n.01.fear': set(),\n",
       "             'fear.n.01.fearfulness': {'fearful'},\n",
       "             'fear.n.01.fright': set(),\n",
       "             'hope.n.01.hope': set(),\n",
       "             'fearlessness.n.01.fearlessness': {'audacious',\n",
       "              'brave',\n",
       "              'dauntless',\n",
       "              'fearless',\n",
       "              'hardy',\n",
       "              'intrepid',\n",
       "              'unafraid',\n",
       "              'unfearing'},\n",
       "             'fearlessness.n.01.bravery': set(),\n",
       "             'timidity.n.01.timidity': {'timid'},\n",
       "             'timidity.n.01.timidness': {'diffident',\n",
       "              'faint',\n",
       "              'faint-hearted',\n",
       "              'fainthearted',\n",
       "              'shy',\n",
       "              'timid',\n",
       "              'unsure'},\n",
       "             'timidity.n.01.timorousness': {'faint',\n",
       "              'faint-hearted',\n",
       "              'fainthearted',\n",
       "              'timid'},\n",
       "             'acquired_taste.n.01.acquired_taste': set(),\n",
       "             'desire.n.01.desire': set(),\n",
       "             'technophilia.n.01.technophilia': set(),\n",
       "             'infatuation.n.01.infatuation': set(),\n",
       "             'fidget.n.01.fidget': {'antsy', 'fidgety', 'fretful', 'itchy'},\n",
       "             'fidget.n.01.fidgetiness': {'antsy',\n",
       "              'fidgety',\n",
       "              'fretful',\n",
       "              'itchy'},\n",
       "             'fidget.n.01.restlessness': set(),\n",
       "             'agape.n.02.agape': set(),\n",
       "             'agape.n.02.agape_love': set(),\n",
       "             'homesickness.n.01.homesickness': {'homesick'},\n",
       "             'disappointment.n.01.disappointment': set(),\n",
       "             'disappointment.n.01.letdown': set(),\n",
       "             'self-consciousness.n.01.self-consciousness': {'self-conscious'},\n",
       "             'self-consciousness.n.01.uneasiness': {'awkward',\n",
       "              'ill_at_ease',\n",
       "              'uneasy'},\n",
       "             'self-consciousness.n.01.uncomfortableness': {'uncomfortable'},\n",
       "             'withdrawal.n.04.withdrawal': set(),\n",
       "             'withdrawal.n.04.detachment': set(),\n",
       "             'storminess.n.02.storminess': {'stormy', 'tempestuous'},\n",
       "             'brotherhood.n.03.brotherhood': set(),\n",
       "             'fury.n.01.fury': {'angered',\n",
       "              'enraged',\n",
       "              'furious',\n",
       "              'infuriated',\n",
       "              'maddened'},\n",
       "             'fury.n.01.rage': set(),\n",
       "             'fury.n.01.madness': {'huffy', 'mad', 'sore'},\n",
       "             'displeasure.n.01.displeasure': set(),\n",
       "             'unconcern.n.02.unconcern': set(),\n",
       "             'confidence.n.02.confidence': {'confidential'},\n",
       "             'wrath.n.01.wrath': set(),\n",
       "             'swivet.n.01.swivet': set(),\n",
       "             'misocainea.n.01.misocainea': set(),\n",
       "             'devastation.n.02.devastation': set(),\n",
       "             'quality_of_life.n.01.quality_of_life': set(),\n",
       "             'gladness.n.01.gladness': {'beaming', 'glad'},\n",
       "             'gladness.n.01.gladfulness': set(),\n",
       "             'gladness.n.01.gladsomeness': {'gladsome'},\n",
       "             'emotionlessness.n.01.emotionlessness': {'emotionless',\n",
       "              'passionless'},\n",
       "             'emotionlessness.n.01.impassivity': {'impassive', 'stolid'},\n",
       "             'emotionlessness.n.01.impassiveness': {'deadpan',\n",
       "              'expressionless',\n",
       "              'impassive',\n",
       "              'poker-faced',\n",
       "              'stolid',\n",
       "              'unexpressive'},\n",
       "             'emotionlessness.n.01.phlegm': {'phlegmatic', 'phlegmatical'},\n",
       "             'emotionlessness.n.01.indifference': set(),\n",
       "             'emotionlessness.n.01.stolidity': {'impassive', 'stolid'},\n",
       "             'emotionlessness.n.01.unemotionality': set(),\n",
       "             'nationalism.n.03.nationalism': set(),\n",
       "             'the_hots.n.01.the_hots': set(),\n",
       "             'jollity.n.01.jollity': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'jollity.n.01.jolliness': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'jollity.n.01.joviality': {'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'merry',\n",
       "              'mirthful'},\n",
       "             'aphrodisia.n.01.aphrodisia': set(),\n",
       "             'languor.n.02.languor': set(),\n",
       "             'languor.n.02.lassitude': set(),\n",
       "             'languor.n.02.listlessness': {'dispirited', 'listless'},\n",
       "             'jitteriness.n.01.jitteriness': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'jitteriness.n.01.jumpiness': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'jitteriness.n.01.nervousness': {'aflutter',\n",
       "              'anxious',\n",
       "              'nervous',\n",
       "              'queasy',\n",
       "              'uneasy',\n",
       "              'unquiet'},\n",
       "             'jitteriness.n.01.restiveness': {'edgy',\n",
       "              'high-strung',\n",
       "              'highly_strung',\n",
       "              'jittery',\n",
       "              'jumpy',\n",
       "              'nervy',\n",
       "              'overstrung',\n",
       "              'restive',\n",
       "              'uptight'},\n",
       "             'ecstasy.n.01.ecstasy': {'ecstatic',\n",
       "              'enraptured',\n",
       "              'rapt',\n",
       "              'rapturous',\n",
       "              'rhapsodic'},\n",
       "             'ecstasy.n.01.rapture': {'ecstatic',\n",
       "              'enraptured',\n",
       "              'rapt',\n",
       "              'rapturous',\n",
       "              'rhapsodic'},\n",
       "             'ecstasy.n.01.transport': set(),\n",
       "             'ecstasy.n.01.exaltation': set(),\n",
       "             'ecstasy.n.01.raptus': set(),\n",
       "             'nymphomania.n.01.nymphomania': {'nymphomaniac',\n",
       "              'nymphomaniacal'},\n",
       "             'sadness.n.01.sadness': {'sad'},\n",
       "             'sadness.n.01.unhappiness': {'distressed',\n",
       "              'dysphoric',\n",
       "              'unhappy'},\n",
       "             'closeness.n.01.closeness': {'close'},\n",
       "             'closeness.n.01.intimacy': set(),\n",
       "             'contempt.n.01.contempt': {'contemptuous',\n",
       "              'disdainful',\n",
       "              'insulting',\n",
       "              'scornful'},\n",
       "             'contempt.n.01.disdain': set(),\n",
       "             'contempt.n.01.scorn': set(),\n",
       "             'contempt.n.01.despite': set(),\n",
       "             'mawkishness.n.01.mawkishness': {'bathetic',\n",
       "              'drippy',\n",
       "              'hokey',\n",
       "              'kitschy',\n",
       "              'maudlin',\n",
       "              'mawkish',\n",
       "              'mushy',\n",
       "              'schmaltzy',\n",
       "              'schmalzy',\n",
       "              'sentimental',\n",
       "              'slushy',\n",
       "              'soppy',\n",
       "              'soupy'},\n",
       "             'mawkishness.n.01.bathos': set(),\n",
       "             'exuberance.n.01.exuberance': {'ebullient',\n",
       "              'exuberant',\n",
       "              'high-spirited'},\n",
       "             'disgruntlement.n.01.disgruntlement': set(),\n",
       "             'alienation.n.01.alienation': set(),\n",
       "             'alienation.n.01.disaffection': set(),\n",
       "             'alienation.n.01.estrangement': set(),\n",
       "             'indifference.n.01.indifference': {'immaterial',\n",
       "              'indifferent',\n",
       "              'unbiased',\n",
       "              'unbiassed'},\n",
       "             'captivation.n.02.captivation': set(),\n",
       "             'captivation.n.02.enchantment': set(),\n",
       "             'captivation.n.02.enthrallment': set(),\n",
       "             'captivation.n.02.fascination': set(),\n",
       "             'pleasure.n.01.pleasure': set(),\n",
       "             'pleasure.n.01.pleasance': {'pleasant'},\n",
       "             'enthusiasm.n.01.enthusiasm': {'enthusiastic'},\n",
       "             'zeal.n.02.zeal': {'avid', 'zealous'},\n",
       "             'aggravation.n.01.aggravation': set(),\n",
       "             'aggravation.n.01.exasperation': set(),\n",
       "             'agitation.n.03.agitation': set(),\n",
       "             'softheartedness.n.01.softheartedness': {'soft-boiled',\n",
       "              'softhearted'},\n",
       "             'softheartedness.n.01.tenderness': {'tender'},\n",
       "             'scare.n.02.scare': {'chilling',\n",
       "              'scarey',\n",
       "              'scary',\n",
       "              'shivery',\n",
       "              'shuddery'},\n",
       "             'scare.n.02.panic_attack': set(),\n",
       "             'irritability.n.01.irritability': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'irritability.n.01.crossness': set(),\n",
       "             'irritability.n.01.fretfulness': {'fretful',\n",
       "              'querulous',\n",
       "              'whiney',\n",
       "              'whiny'},\n",
       "             'irritability.n.01.fussiness': {'bad-tempered',\n",
       "              'crabbed',\n",
       "              'crabby',\n",
       "              'cross',\n",
       "              'fussy',\n",
       "              'grouchy',\n",
       "              'grumpy',\n",
       "              'ill-tempered'},\n",
       "             'irritability.n.01.peevishness': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'irritability.n.01.petulance': {'cranky',\n",
       "              'fractious',\n",
       "              'irritable',\n",
       "              'nettlesome',\n",
       "              'peckish',\n",
       "              'peevish',\n",
       "              'pettish',\n",
       "              'petulant',\n",
       "              'scratchy',\n",
       "              'techy',\n",
       "              'testy',\n",
       "              'tetchy'},\n",
       "             'irritability.n.01.choler': set(),\n",
       "             'sweet_tooth.n.01.sweet_tooth': set(),\n",
       "             'misopedia.n.01.misopedia': set(),\n",
       "             'aggression.n.02.aggression': set(),\n",
       "             'aggression.n.02.aggressiveness': set(),\n",
       "             'ambition.n.01.ambition': {'ambitious', 'challenging'},\n",
       "             'ambition.n.01.aspiration': set(),\n",
       "             'ambition.n.01.dream': set(),\n",
       "             'woe.n.02.woe': set(),\n",
       "             'woe.n.02.woefulness': {'woebegone', 'woeful'},\n",
       "             'sex.n.03.sex': {'aphrodisiac', 'aphrodisiacal', 'sexy'},\n",
       "             'sex.n.03.sexual_urge': set(),\n",
       "             'warmheartedness.n.01.warmheartedness': {'warmhearted'},\n",
       "             'warmheartedness.n.01.warmth': set(),\n",
       "             'pain.n.02.pain': set(),\n",
       "             'pain.n.02.painfulness': {'afflictive', 'painful', 'sore'},\n",
       "             'contentment.n.01.contentment': set(),\n",
       "             'conflict.n.02.conflict': set(),\n",
       "             'abashment.n.01.abashment': set(),\n",
       "             'abashment.n.01.bashfulness': {'bashful'},\n",
       "             'grief.n.01.grief': set(),\n",
       "             'grief.n.01.heartache': set(),\n",
       "             'grief.n.01.heartbreak': set(),\n",
       "             'grief.n.01.brokenheartedness': {'brokenhearted',\n",
       "              'heartbroken',\n",
       "              'heartsick'},\n",
       "             'hilarity.n.01.hilarity': {'hilarious',\n",
       "              'screaming',\n",
       "              'uproarious'},\n",
       "             'hilarity.n.01.mirth': set(),\n",
       "             'hilarity.n.01.mirthfulness': {'amusing',\n",
       "              'comic',\n",
       "              'comical',\n",
       "              'funny',\n",
       "              'gay',\n",
       "              'jocund',\n",
       "              'jolly',\n",
       "              'jovial',\n",
       "              'laughable',\n",
       "              'merry',\n",
       "              'mirthful',\n",
       "              'risible'},\n",
       "             'hilarity.n.01.glee': set(),\n",
       "             'hilarity.n.01.gleefulness': {'elated',\n",
       "              'gleeful',\n",
       "              'joyful',\n",
       "              'jubilant'},\n",
       "             'repentance.n.01.repentance': {'penitent', 'repentant'},\n",
       "             'repentance.n.01.penitence': {'penitent',\n",
       "              'penitential',\n",
       "              'penitentiary',\n",
       "              'repentant'},\n",
       "             'repentance.n.01.penance': set(),\n",
       "             'panic.n.01.panic': {'frightened',\n",
       "              'panic-stricken',\n",
       "              'panic-struck',\n",
       "              'panicked',\n",
       "              'panicky',\n",
       "              'terrified'},\n",
       "             'panic.n.01.terror': set(),\n",
       "             'panic.n.01.affright': set(),\n",
       "             'amorousness.n.02.amorousness': {'amatory',\n",
       "              'amorous',\n",
       "              'romantic'},\n",
       "             'amorousness.n.02.eroticism': set(),\n",
       "             'amorousness.n.02.erotism': set(),\n",
       "             'amorousness.n.02.sexiness': {'aphrodisiac',\n",
       "              'aphrodisiacal',\n",
       "              'sexy'},\n",
       "             'amorousness.n.02.amativeness': {'amative', 'amorous'},\n",
       "             'afterglow.n.02.afterglow': set(),\n",
       "             'delight.n.01.delight': set(),\n",
       "             'delight.n.01.delectation': set(),\n",
       "             'insight.n.02.insight': set(),\n",
       "             'insight.n.02.perceptiveness': {'perceptive'},\n",
       "             'insight.n.02.perceptivity': {'perceptive'},\n",
       "             'wound.n.03.wound': set(),\n",
       "             'friendliness.n.01.friendliness': {'favorable',\n",
       "              'friendly',\n",
       "              'well-disposed'},\n",
       "             'placidity.n.01.placidity': set(),\n",
       "             'placidity.n.01.placidness': {'equable',\n",
       "              'even-tempered',\n",
       "              'good-tempered',\n",
       "              'placid',\n",
       "              'quiet',\n",
       "              'smooth',\n",
       "              'still',\n",
       "              'tranquil',\n",
       "              'unruffled'},\n",
       "             'joie_de_vivre.n.01.joie_de_vivre': set(),\n",
       "             'gaiety.n.02.gaiety': set(),\n",
       "             'gaiety.n.02.playfulness': {'playful'},\n",
       "             'stomach.n.04.stomach': set(),\n",
       "             'sinking.n.03.sinking': set(),\n",
       "             'sinking.n.03.sinking_feeling': set(),\n",
       "             'melancholy.n.01.melancholy': set(),\n",
       "             'concern.n.02.concern': set(),\n",
       "             'concern.n.02.care': set(),\n",
       "             'concern.n.02.fear': set(),\n",
       "             'weepiness.n.01.weepiness': {'weepy'},\n",
       "             'weepiness.n.01.tearfulness': {'dolorous',\n",
       "              'dolourous',\n",
       "              'lachrymose',\n",
       "              'tearful',\n",
       "              'weeping'},\n",
       "             'loyalty.n.02.loyalty': set(),\n",
       "             'dander.n.02.dander': set(),\n",
       "             'dander.n.02.hackles': set(),\n",
       "             'commiseration.n.01.commiseration': set(),\n",
       "             'commiseration.n.01.pity': {'hapless',\n",
       "              'miserable',\n",
       "              'misfortunate',\n",
       "              'pathetic',\n",
       "              'piteous',\n",
       "              'pitiable',\n",
       "              'pitiful',\n",
       "              'poor',\n",
       "              'wretched'},\n",
       "             'commiseration.n.01.ruth': set(),\n",
       "             'commiseration.n.01.pathos': {'hapless',\n",
       "              'miserable',\n",
       "              'misfortunate',\n",
       "              'pathetic',\n",
       "              'piteous',\n",
       "              'pitiable',\n",
       "              'pitiful',\n",
       "              'poor',\n",
       "              'wretched'},\n",
       "             'ardor.n.02.ardor': set(),\n",
       "             'ardor.n.02.ardour': set(),\n",
       "             'dudgeon.n.01.dudgeon': set(),\n",
       "             'dudgeon.n.01.high_dudgeon': set(),\n",
       "             'jealousy.n.01.jealousy': set(),\n",
       "             'jealousy.n.01.green-eyed_monster': set(),\n",
       "             'murderousness.n.01.murderousness': {'homicidal', 'murderous'},\n",
       "             'pride.n.01.pride': set(),\n",
       "             'pride.n.01.pridefulness': {'exultant',\n",
       "              'exulting',\n",
       "              'jubilant',\n",
       "              'prideful',\n",
       "              'rejoicing',\n",
       "              'triumphal',\n",
       "              'triumphant'},\n",
       "             'isolation.n.02.isolation': set(),\n",
       "             'enjoyment.n.01.enjoyment': set(),\n",
       "             'silver_lining.n.01.silver_lining': set(),\n",
       "             'silver_lining.n.01.bright_side': set(),\n",
       "             'sympathy.n.02.sympathy': {'sympathetic'},\n",
       "             'sympathy.n.02.fellow_feeling': set(),\n",
       "             'throes.n.01.throes': set(),\n",
       "             'creepy-crawlies.n.01.creepy-crawlies': set(),\n",
       "             'conditioned_emotional_response.n.01.conditioned_emotional_response': set(),\n",
       "             'conditioned_emotional_response.n.01.CER': set(),\n",
       "             'conditioned_emotional_response.n.01.conditioned_emotion': set(),\n",
       "             'disapproval.n.01.disapproval': set(),\n",
       "             'wishfulness.n.01.wishfulness': {'desirous', 'wishful'},\n",
       "             'malevolence.n.01.malevolence': {'malevolent'},\n",
       "             'malevolence.n.01.malignity': set(),\n",
       "             'heartlessness.n.01.heartlessness': {'hardhearted', 'heartless'},\n",
       "             'heartlessness.n.01.coldheartedness': {'coldhearted'},\n",
       "             'heartlessness.n.01.hardheartedness': {'hardhearted',\n",
       "              'heartless',\n",
       "              'stonyhearted',\n",
       "              'unfeeling'},\n",
       "             'irascibility.n.01.irascibility': {'choleric',\n",
       "              'hot-tempered',\n",
       "              'hotheaded',\n",
       "              'irascible',\n",
       "              'quick-tempered',\n",
       "              'short-tempered'},\n",
       "             'irascibility.n.01.short_temper': set(),\n",
       "             'irascibility.n.01.spleen': {'bristly',\n",
       "              'prickly',\n",
       "              'splenetic',\n",
       "              'waspish'},\n",
       "             'irascibility.n.01.quick_temper': set(),\n",
       "             'compatibility.n.01.compatibility': set(),\n",
       "             'alarm.n.01.alarm': set(),\n",
       "             'alarm.n.01.dismay': set(),\n",
       "             'alarm.n.01.consternation': set(),\n",
       "             'gold_fever.n.01.gold_fever': set(),\n",
       "             'malice.n.01.malice': {'malicious'},\n",
       "             'malice.n.01.maliciousness': {'malicious'},\n",
       "             'malice.n.01.spite': set(),\n",
       "             'malice.n.01.spitefulness': {'despiteful',\n",
       "              'spiteful',\n",
       "              'vindictive'},\n",
       "             'malice.n.01.venom': {'poisonous', 'venomous', 'vicious'},\n",
       "             'affect.n.01.affect': {'affectional', 'affective', 'emotive'},\n",
       "             'fulfillment.n.01.fulfillment': set(),\n",
       "             'fulfillment.n.01.fulfilment': set(),\n",
       "             'ill_humor.n.01.ill_humor': set(),\n",
       "             'ill_humor.n.01.ill_humour': set(),\n",
       "             'ill_humor.n.01.distemper': set(),\n",
       "             'pang.n.01.pang': set(),\n",
       "             'pang.n.01.stab': set(),\n",
       "             'pang.n.01.twinge': set(),\n",
       "             'awe.n.01.awe': set(),\n",
       "             'beneficence.n.01.beneficence': {'beneficent'},\n",
       "             'lividity.n.01.lividity': {'livid'},\n",
       "             'expectation.n.03.expectation': set(),\n",
       "             'coolness.n.01.coolness': {'cool'},\n",
       "             'coolness.n.01.imperturbability': {'imperturbable',\n",
       "              'unflappable'},\n",
       "             'coolness.n.01.imperturbableness': {'imperturbable',\n",
       "              'unflappable'},\n",
       "             'sensibility.n.02.sensibility': set(),\n",
       "             'cynicism.n.01.cynicism': set(),\n",
       "             'preference.n.01.preference': set(),\n",
       "             'preference.n.01.penchant': set(),\n",
       "             'preference.n.01.predilection': set(),\n",
       "             'preference.n.01.taste': set(),\n",
       "             'languor.n.01.languor': set(),\n",
       "             'languor.n.01.dreaminess': {'dreamy',\n",
       "              'lackadaisical',\n",
       "              'languid',\n",
       "              'languorous',\n",
       "              'moony',\n",
       "              'woolgathering'},\n",
       "             'trepidation.n.01.trepidation': set(),\n",
       "             'blahs.n.01.blahs': set(),\n",
       "             'togetherness.n.01.togetherness': {'together'},\n",
       "             'hate.n.01.hate': set(),\n",
       "             'hate.n.01.hatred': set(),\n",
       "             'heavyheartedness.n.01.heavyheartedness': {'heavyhearted'},\n",
       "             'forgiveness.n.01.forgiveness': set(),\n",
       "             'presage.n.01.presage': set(),\n",
       "             'self-disgust.n.01.self-disgust': set(),\n",
       "             'self-disgust.n.01.self-hatred': set(),\n",
       "             'craving.n.01.craving': set(),\n",
       "             'easiness.n.01.easiness': {'easy'},\n",
       "             'easiness.n.01.relaxation': set(),\n",
       "             'dignity.n.01.dignity': set(),\n",
       "             'dignity.n.01.self-respect': set(),\n",
       "             'dignity.n.01.self-regard': set(),\n",
       "             'dignity.n.01.self-worth': set(),\n",
       "             'radiance.n.03.radiance': set(),\n",
       "             'discontentment.n.01.discontentment': set(),\n",
       "             'discontentment.n.01.discontent': {'discontent', 'discontented'},\n",
       "             'discontentment.n.01.discontentedness': {'discontent',\n",
       "              'discontented'},\n",
       "             'warpath.n.01.warpath': set(),\n",
       "             'fetish.n.01.fetish': set(),\n",
       "             'complex.n.03.complex': set(),\n",
       "             'harassment.n.01.harassment': set(),\n",
       "             'harassment.n.01.torment': set(),\n",
       "             'cold_feet.n.01.cold_feet': set(),\n",
       "             'emotional_state.n.01.emotional_state': set(),\n",
       "             'emotional_state.n.01.spirit': set()})"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun2related_adj_dict22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "dbad64f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[316], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rel_adjs_22 \u001b[38;5;241m=\u001b[39m [wn\u001b[38;5;241m.\u001b[39msynset(adj) \u001b[38;5;28;01mfor\u001b[39;00m adj_list \u001b[38;5;129;01min\u001b[39;00m noun2related_adj_dict22\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mfor\u001b[39;00m adj \u001b[38;5;129;01min\u001b[39;00m adj_list]\n\u001b[1;32m      2\u001b[0m extended_rel_adjs_22 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m({ss2\u001b[38;5;241m.\u001b[39mname() \u001b[38;5;28;01mfor\u001b[39;00m ss \u001b[38;5;129;01min\u001b[39;00m rel_adjs_22 \u001b[38;5;28;01mfor\u001b[39;00m ss2 \u001b[38;5;129;01min\u001b[39;00m get_wheels_and_axle(ss,return_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rel_adjs_22),\u001b[38;5;28mlen\u001b[39m(extended_rel_adjs_22))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/p312/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1509\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synset\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msynset\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m# split name into lemma, part of speech and synset number\u001b[39;00m\n\u001b[0;32m-> 1509\u001b[0m     lemma, pos, synset_index_str \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1510\u001b[0m     synset_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(synset_index_str) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# get the offset for this synset\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "rel_adjs_22 = [wn.synset(adj) for adj_list in noun2related_adj_dict22.values() for adj in adj_list]\n",
    "extended_rel_adjs_22 = sorted(list({ss2.name() for ss in rel_adjs_22 for ss2 in get_wheels_and_axle(ss,return_set=True)}))\n",
    "print(len(rel_adjs_22),len(extended_rel_adjs_22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877beb38",
   "metadata": {},
   "source": [
    "## Abortive fe relation expriment\n",
    "\n",
    "Thoughts while compiling the fe list below:\n",
    "\n",
    "1.  Medical frames out.  The only interesting case to think about  was Ailment->Medical_Condition->cold.n\n",
    "    \n",
    "    \n",
    "    I have a cold.\n",
    "   \n",
    "    \n",
    "    Why is this not an expressive? (On the most natural content, it is prompted by tbe speaker's \n",
    "    own internal perceptions.  Are we taking the line that it may be prompted by those perceptions\n",
    "    [miserable headache] but is not a report of those perceptions?)\n",
    "    \n",
    "2.  Cognizer_agent -> Seeking -> feel.v (for), listen (for), dig (for). ThisWhy not an expressive. is the case to wonder 'bout:\n",
    "\n",
    "    a.  I'm digging for worms.\n",
    "    b.  Shh!  I'm listening for termites.\n",
    "    \n",
    "    Why not an expressive?  Especially b.  A report on an internal state.  Why is it descriptive/ascriptve\n",
    "    rather than depictive?\n",
    "    \n",
    "3.  Faculty -> Grasp -> see.v\n",
    "    \n",
    "    I don't see what you're getting at.\n",
    "    \n",
    "    Report on cognitive state.  No perceptual, emotional, surprise.  This is the heart of it.  Within\n",
    "    cognitive states we make a distinction between those that are wriggling to get out (internal to external\n",
    "    moment) and those that are not (grasping, understanding).  The resultant state is internal?  Grasping\n",
    "    leads to further thought.  Surprise leads to a gasp.\n",
    "    \n",
    "4. Expression -> {Emotion_heat,Facial_expression}\n",
    "    \n",
    "   The former is a bunch of verbs, the latter a bunch of nouns.  Consider \n",
    "   \n",
    "   I'm seething.\n",
    "   \n",
    "   Not an expressive.  On the following grounds:  Most natural context is when speaker has\n",
    "   just been asked how they are feeling about X.  In part because X has to be salient for this\n",
    "   sentence to be natural.  But on the line where the property of being usable as an expressive\n",
    "   is gradable, this is an indicator:  Dependent on prior contextual setup.  In others\n",
    "   the word prefers contexts in which a description has been called for, and is used to\n",
    "   supply one.\n",
    "   \n",
    "5. Information -> Trust -> trust.v\n",
    "\n",
    "   a.  I trust you.\n",
    "   b.  I trust John.\n",
    "   \n",
    "   (a) seems very likely to be an expression of an emotional state, one which could \n",
    "   result in greater bonding with the addressee; (b) certainly can be a description,\n",
    "   so can (a), especially in a context inviting affirmation (\"Will you let me handle this?\")\n",
    "   \n",
    "6.  Judge -> {Rashnessness, Volubility}\n",
    "\n",
    "    The *Rashness* frame has no expressives but has a lot of clear cases of adjectives imposing\n",
    "    an external perspective on empotional states: *impatient.a, impetuous.a, rash.a*.  Ditto\n",
    "    *Volubility* (*chatterbox, voluble,  terse*).\n",
    "     \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebef031a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A cobbled together list of FEs with known expressive frames\n",
    "fe_string = \\\n",
    "\"\"\"\n",
    "Cognizer,Cognizer_1,Cognizer_2,Cognizer_agent,Cognizers,Communicator,Complainer,Conveyed_emotion,\n",
    "Desirability,Desirable_action,Desirable_situation,Desired_goal,Desired_state_of_affairs,Emotional_state,\n",
    "Emotion,Expectation,Expected_entity,Expected_event,Expected_request,Experience,Experiencer,\n",
    "Expressor,Faculty,Interested_party,Means_of_communication,Mental_content,Message,Opinion,\n",
    "Requirement,Responsible_party,Seeker,Sentient_entity,Sleep_state,Speaker,Stimulus,Supporter\n",
    "\"\"\"\n",
    "fe_list = fe_string.replace(\"\\n\",\"\").split(\",\")\n",
    "\n",
    "#  The fes that brought these up are very noisy so just use the frames directly.\n",
    "expr_frame_list = \"Trust Importance Cognitive_impact Regard Estimating Be_in_agreement_on_assessment Catastrophe Desirable_event\".split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3572d788",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2391\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "expressive_fes2frames_dict = defaultdict(set)\n",
    "for fe_name in fe_list:\n",
    "    expressive_fes2frames_dict[fe_name]\n",
    "for fr in expr_frame_list:\n",
    "    expressive_fes2frames_dict[\"Dummy_fe\"].add(fr)\n",
    "\n",
    "def collect_expressive_frames(expressive_frames_dict, lexical_frames_only=False):\n",
    "    fe_set = set(expressive_frames_dict.keys())\n",
    "    frame_lex_dict = defaultdict(set)\n",
    "    frame_fe_dict = defaultdict(set)\n",
    "    for frame in fn.frames():\n",
    "        if lexical_frames_only and len(frame.lexUnit) == 0:\n",
    "            continue\n",
    "        try:\n",
    "            frame_fes = frame.FE\n",
    "        except:\n",
    "            continue\n",
    "        for fe in fe_set:\n",
    "            if fe in frame_fes and frame_fes[fe].coreType != \"Extra-Thematic\":\n",
    "                expressive_frames_dict[fe].add(frame.name)\n",
    "                frame_lex_dict[frame.name].update(frame.lexUnit.keys())\n",
    "                frame_fe_dict[frame.name].add(fe)\n",
    "    return frame_lex_dict,frame_fe_dict\n",
    "\n",
    "frame_lex_dict0,frame_fe_dict = collect_expressive_frames(expressive_fes2frames_dict)\n",
    "\n",
    "expressive_frame_yield = {frame for fe,frame_set in expressive_fes2frames_dict.items() for frame in frame_set}\n",
    "expressive_fes_yield = {lu for frame in expressive_frame_yield for lu in fn.frame(frame).lexUnit}\n",
    "print(len(expressive_fes_yield))\n",
    "#expressive_fes_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "071baea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_ex (ex0):\n",
    "    try:\n",
    "        part1 = f\"> {ex0['LU'].name} {ex0['frame'].name} corp{ex0['corpID']}_doc{ex0['docID']}_sent{ex0['sentNo']}_para{ex0['paragNo']}_aPos{ex0['aPos']}\"\n",
    "    except KeyError:\n",
    "        part1 = f\"> {ex0['LU'].name} {ex0['frame'].name}\"\n",
    "    start,end = ex0.frameAnnotation.Target[0]\n",
    "    text = ex0.frameAnnotation.text  \n",
    "    part2 = text[:start]+ \"<\" + ex0.frameAnnotation.text[start:end] + \">\" + text[end:]\n",
    "    return \"\\n\".join([part1,part2+\"\\n\"])\n",
    "\n",
    "def write_minicorpus (frame_lex_dict,fn0,max_ex=20):\n",
    "    today = datetime.date.today().__str__()\n",
    "    filename = f\"{fn0}_{today}.txt\"\n",
    "    ctr_lex,ctr_fm,ctr22=0,0,0\n",
    "    with open(filename,'w') as ofh:\n",
    "        for fm,lexset in frame_lex_dict.items():\n",
    "            ctr_fm+=1\n",
    "            for lex in lexset:\n",
    "                ctr_lex += 1\n",
    "                lu = fn.frame(fm).lexUnit[lex]\n",
    "                for ex in lu.exemplars[:max_ex]:\n",
    "                    ctr22 += 1\n",
    "                    if ctr22%50 == 0:\n",
    "                        print(f\"{ctr_fm} frames {ctr_lex} LUs {ctr22} examples\")\n",
    "                    try:\n",
    "                        print(get_ex(ex),file=ofh)\n",
    "                    except:\n",
    "                        print(f\"bad ex {ctr22}\")\n",
    "                        print(\"\\n\", file=ofh)\n",
    "\n",
    "def write_frame_corpus (frame_name, max_ex=20):\n",
    "    today = datetime.date.today().__str__()\n",
    "    filename = f\"{frame_name}_minicorpus_{today}.txt\"\n",
    "    ctr_lex, ctr22=0,0\n",
    "    frame = fn.frame(frame_name)\n",
    "    with open(filename,'w') as ofh:\n",
    "        LUs = frame.lexUnit\n",
    "        for lex in LUs:\n",
    "            ctr_lex += 1\n",
    "            lu = LUs[lex]\n",
    "            for ex in lu.exemplars[:max_ex]:\n",
    "                ctr22 += 1\n",
    "                if ctr22%50 == 0:\n",
    "                    print(f\"{ctr_lex} LUs {ctr22} examples\")\n",
    "                try:\n",
    "                    print(get_ex(ex),file=ofh)\n",
    "                except:\n",
    "                    print(f\"bad ex {ctr22}\")\n",
    "                    print(\"\\n\", file=ofh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4d4c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 LUs 50 examples\n",
      "6 LUs 100 examples\n",
      "9 LUs 150 examples\n",
      "11 LUs 200 examples\n",
      "14 LUs 250 examples\n",
      "16 LUs 300 examples\n",
      "19 LUs 350 examples\n",
      "23 LUs 400 examples\n",
      "25 LUs 450 examples\n",
      "28 LUs 500 examples\n",
      "31 LUs 550 examples\n",
      "33 LUs 600 examples\n",
      "38 LUs 650 examples\n",
      "40 LUs 700 examples\n",
      "65 LUs 750 examples\n"
     ]
    }
   ],
   "source": [
    "write_frame_corpus (\"Experiencer_focus\", max_ex=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3cad431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 LUs 50 examples\n",
      "8 LUs 100 examples\n",
      "10 LUs 150 examples\n",
      "15 LUs 200 examples\n",
      "21 LUs 250 examples\n",
      "26 LUs 300 examples\n",
      "28 LUs 350 examples\n",
      "32 LUs 400 examples\n",
      "35 LUs 450 examples\n",
      "37 LUs 500 examples\n",
      "40 LUs 550 examples\n",
      "42 LUs 600 examples\n",
      "46 LUs 650 examples\n",
      "49 LUs 700 examples\n",
      "52 LUs 750 examples\n",
      "55 LUs 800 examples\n",
      "59 LUs 850 examples\n",
      "61 LUs 900 examples\n",
      "65 LUs 950 examples\n",
      "69 LUs 1000 examples\n",
      "72 LUs 1050 examples\n",
      "74 LUs 1100 examples\n",
      "77 LUs 1150 examples\n",
      "80 LUs 1200 examples\n",
      "83 LUs 1250 examples\n",
      "86 LUs 1300 examples\n",
      "88 LUs 1350 examples\n",
      "91 LUs 1400 examples\n",
      "93 LUs 1450 examples\n",
      "96 LUs 1500 examples\n",
      "100 LUs 1550 examples\n",
      "103 LUs 1600 examples\n",
      "106 LUs 1650 examples\n",
      "110 LUs 1700 examples\n",
      "114 LUs 1750 examples\n",
      "119 LUs 1800 examples\n",
      "122 LUs 1850 examples\n",
      "124 LUs 1900 examples\n",
      "127 LUs 1950 examples\n",
      "130 LUs 2000 examples\n",
      "133 LUs 2050 examples\n",
      "137 LUs 2100 examples\n",
      "139 LUs 2150 examples\n",
      "142 LUs 2200 examples\n",
      "144 LUs 2250 examples\n",
      "150 LUs 2300 examples\n",
      "154 LUs 2350 examples\n",
      "156 LUs 2400 examples\n"
     ]
    }
   ],
   "source": [
    "write_frame_corpus (\"Stimulus_focus\", max_ex=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42e0750c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_frames = \"Achieving_first Adducing Adding_up Age\".split()\n",
    "for fm in bad_frames:\n",
    "    try:\n",
    "        del frame_lex_dict0[fm]\n",
    "    except:\n",
    "        continue\n",
    "write_minicorpus (frame_lex_dict0,\"fe_driven_frame_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "9980694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex0 = exemplars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2bc97d63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['corpID', 'docID', 'sentNo', 'paragNo', 'aPos', 'ID', '_type', 'annotationSet', '_ascii', 'text', 'POS', 'POS_tagset', 'frameAnnotation', 'Target', 'FE', 'GF', 'PT', 'Other', 'Sent', 'Verb', 'LU', 'frame'])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex0.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3e799",
   "metadata": {},
   "source": [
    "The following set is largely noise but there are some words we want we lose by not doiing\n",
    "the recursiove parent-child link descent (e.g., execellent.a, fantastic.a).  We should\n",
    "capture these by frame by frame stipulation unless there are fe-based generalizations\n",
    "that work better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7146a606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ablution.n',\n",
       " 'acquiesce.v',\n",
       " 'affray.n',\n",
       " 'aim.n',\n",
       " 'aim.v',\n",
       " 'airman.n',\n",
       " 'altercation.n',\n",
       " 'average.a',\n",
       " 'awesome.a',\n",
       " 'awful.a',\n",
       " 'bathe.v',\n",
       " 'battle.n',\n",
       " 'battle.v',\n",
       " 'beautiful.a',\n",
       " 'belligerent.n',\n",
       " 'bent.a',\n",
       " 'best thing since sliced bread.n',\n",
       " 'bout.n',\n",
       " 'brawl.n',\n",
       " 'brawl.v',\n",
       " 'brush [hair].v',\n",
       " 'brush [teeth].v',\n",
       " 'bw.n',\n",
       " 'capitulate.v',\n",
       " 'cave in.v',\n",
       " 'cave.v',\n",
       " 'clash.n',\n",
       " 'clash.v',\n",
       " 'cleanse.v',\n",
       " 'combat.n',\n",
       " 'combatant.n',\n",
       " 'commando.n',\n",
       " 'common.a',\n",
       " 'compromise.v',\n",
       " 'conflict.n',\n",
       " 'confront.v',\n",
       " 'confrontation.n',\n",
       " 'control.v',\n",
       " 'crap.n',\n",
       " 'crappy.a',\n",
       " 'cw.n',\n",
       " 'depend.v',\n",
       " 'dependence.n',\n",
       " 'dependency.n',\n",
       " 'desirable.a',\n",
       " 'determined.a',\n",
       " 'donnybrook.n',\n",
       " 'duel.n',\n",
       " 'duel.v',\n",
       " 'dust-up.n',\n",
       " 'elegant.a',\n",
       " 'enemy.n',\n",
       " 'engagement.n',\n",
       " 'excellence.n',\n",
       " 'excellent.a',\n",
       " 'execrable.a',\n",
       " 'extraordinary.a',\n",
       " 'fabulous.a',\n",
       " 'facial.n',\n",
       " 'fair.a',\n",
       " 'fantastic.a',\n",
       " 'fight.n',\n",
       " 'fight.v',\n",
       " 'fighter.n',\n",
       " 'fighting.n',\n",
       " 'file.v',\n",
       " 'fire fighting.n',\n",
       " 'firefight.n',\n",
       " 'first-rate.a',\n",
       " 'fistfight.n',\n",
       " 'floss.v',\n",
       " 'fold [to demands].v',\n",
       " 'fracas.n',\n",
       " 'fray.n',\n",
       " 'free-for-all.n',\n",
       " 'friendly.n',\n",
       " 'function.n',\n",
       " 'gain ground.idio',\n",
       " 'garbage.n',\n",
       " 'gem.n',\n",
       " 'give in.v',\n",
       " 'give way.v',\n",
       " 'goal.n',\n",
       " 'gold.n',\n",
       " 'great.a',\n",
       " 'groom.v',\n",
       " 'guerrilla.n',\n",
       " 'gunfight.n',\n",
       " 'gunner.n',\n",
       " 'handsome.a',\n",
       " 'hideous.a',\n",
       " 'hostile.a',\n",
       " 'hostile.n',\n",
       " 'hostility.n',\n",
       " 'humble.a',\n",
       " 'idyllic.a',\n",
       " 'in demand.a',\n",
       " 'in order.adv',\n",
       " 'in.a',\n",
       " 'incredible.a',\n",
       " 'infantryman.n',\n",
       " 'inferior.a',\n",
       " 'infighting.n',\n",
       " 'intend.v',\n",
       " 'intent.a',\n",
       " 'intention.n',\n",
       " 'junk.n',\n",
       " 'killer.a',\n",
       " 'lame.a',\n",
       " 'lamer.n',\n",
       " 'lave.v',\n",
       " 'left.a',\n",
       " 'lovely.a',\n",
       " 'magnificent.a',\n",
       " 'manicure.n',\n",
       " 'manicure.v',\n",
       " 'marine.n',\n",
       " 'marvellous.a',\n",
       " 'mediocre.a',\n",
       " 'melee.n',\n",
       " 'militant.n',\n",
       " 'moisturize.v',\n",
       " 'nasty.a',\n",
       " 'object.n',\n",
       " 'objective.n',\n",
       " 'okay.a',\n",
       " 'outstanding.a',\n",
       " 'pedestrian.a',\n",
       " 'pedicure.n',\n",
       " 'plait.v',\n",
       " 'plan.n',\n",
       " 'plan.v',\n",
       " 'plebeian.a',\n",
       " 'pluck.v',\n",
       " 'poor.a',\n",
       " 'popular.a',\n",
       " 'program.n',\n",
       " 'project.n',\n",
       " 'proletarian.a',\n",
       " 'protest.n',\n",
       " 'protest.v',\n",
       " 'protester.n',\n",
       " 'purpose.n',\n",
       " 'relent.v',\n",
       " 'reliance.n',\n",
       " 'rely.v',\n",
       " 'remain.v',\n",
       " 'remainder.n',\n",
       " 'rock.v',\n",
       " 'rotten.a',\n",
       " 'row.n',\n",
       " 'sailor.n',\n",
       " 'scheme.n',\n",
       " 'scuffle.n',\n",
       " 'scuffle.v',\n",
       " 'second-rate.a',\n",
       " 'sensational.a',\n",
       " 'service member.n',\n",
       " 'shampoo.v',\n",
       " 'shave.v',\n",
       " 'shit.n',\n",
       " 'shitty.a',\n",
       " 'shootout.n',\n",
       " 'showdown.n',\n",
       " 'shower.v',\n",
       " 'signaller.n',\n",
       " 'skirmish.n',\n",
       " 'skirmish.v',\n",
       " 'sniper.n',\n",
       " 'so-so.a',\n",
       " 'soap.v',\n",
       " 'soldier.n',\n",
       " 'spat.n',\n",
       " 'splendid.a',\n",
       " 'squabble.n',\n",
       " 'stalemate.n',\n",
       " 'standoff.n',\n",
       " 'standout.n',\n",
       " 'strife.n',\n",
       " 'struggle.n',\n",
       " 'struggle.v',\n",
       " 'stupendous.a',\n",
       " 'style.n',\n",
       " 'submit.v',\n",
       " 'substandard.a',\n",
       " 'suck.v',\n",
       " 'super.a',\n",
       " 'superb.a',\n",
       " 'superlative.a',\n",
       " 'tackle.v',\n",
       " 'target.n',\n",
       " 'tasty.a',\n",
       " 'terrible.a',\n",
       " 'terrific.a',\n",
       " 'third-rate.a',\n",
       " 'tiff.n',\n",
       " 'tip-top.a',\n",
       " 'tolerable.a',\n",
       " 'top-notch.a',\n",
       " 'tremendous.a',\n",
       " 'troop.n',\n",
       " 'tussle.n',\n",
       " 'ugly.a',\n",
       " 'uncool.a',\n",
       " 'unfortunate.a',\n",
       " 'upper-class.a',\n",
       " 'use.n',\n",
       " 'vulgar.a',\n",
       " 'war.n',\n",
       " 'war.v',\n",
       " 'warfare.n',\n",
       " 'wash.v',\n",
       " 'wax.v',\n",
       " 'well.adv',\n",
       " 'wonderful.a',\n",
       " 'working-class.a',\n",
       " 'worthless.a',\n",
       " 'wrangling.n',\n",
       " 'yield.v'}"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiencer_focus_words - expressive_fes_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "16857d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame (1301): Operational_testing\n",
      "\n",
      "[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/frame/Operational_testing.xml\n",
      "\n",
      "[definition]\n",
      "  A Tester uses a concrete or conceptual Product in order to\n",
      "  determine either whether it works or to find out how well or in\n",
      "  which manner it works. The Tester may have particular\n",
      "  Unwanted_characteristics in mind that they are specifically\n",
      "  looking for. The operational test may also be carried out under a\n",
      "  particular set of Circumstances that are typically relevant to\n",
      "  the functioning of the Product.  'Sun has (hopefully) already\n",
      "  tested it for compliance.' 'The Velcro hook and loop closure\n",
      "  system has been tested under wet conditions and retains its\n",
      "  holding power after 10,000 open and close functions. CNI INI'\n",
      "  'Roe revisited the compound and tested it as a mosquito\n",
      "  repellent.'\n",
      "[semTypes] 0 semantic types\n",
      "\n",
      "[frameRelations] 1 frame relations\n",
      "  <Parent=Operating_a_system -- Using -> Child=Operational_testing>\n",
      "\n",
      "[lexUnit] 10 lexical units\n",
      "  crash-test.v (11465), flight test.n (12255), flight test.v\n",
      "  (13084), flight-test.v (11464), flight-testing.n (11467), test.n\n",
      "  (11463), test.v (11462), testing.n (11466), trial.n (18806), try\n",
      "  out.v (18808)\n",
      "\n",
      "[FE] 17 frame elements\n",
      "            Core: Desired_state_of_affairs (7369), Product (7362), Purpose (7365), Tested_property (7375), Tester (7361), Unwanted_characteristics (7363)\n",
      "      Peripheral: Degree (7367), Duration (7372), Function (7374), Manner (7366), Means (7364), Place (7373), Time (7370)\n",
      "  Extra-Thematic: Circumstances (7371), Location_of_protagonist (7368), Period_of_iterations (11033), Result (11080)\n",
      "\n",
      "[FEcoreSets] 1 frame element core sets\n",
      "  Purpose, Unwanted_characteristics, Tested_property, Desired_state_of_affairs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for frame in expressive_fes2frames_dict[\"Unwanted_characteristics\"]:\n",
    "    print(fn.frame(frame),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1fa958",
   "metadata": {},
   "source": [
    "## output word sets to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3739ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivationally_related_words(ss_set, stemmer, pos=\"a\"):\n",
    "    new_pos_ss_set = []\n",
    "    for ss1 in ss_set:\n",
    "        #for ss2 in wn.synsets(stemmer.stem(ss1.name()),\"a\"):\n",
    "        for l in ss1.lemmas():\n",
    "            #[l.name() for l in sadness_ss.lemmas()]\n",
    "            for ss_res in wn.synsets(stemmer.stem(l.name()),pos):\n",
    "                new_pos_ss_set.append(ss_res)\n",
    "    return new_pos_ss_set\n",
    "\n",
    "def ss_set_to_word_set (ss_set):\n",
    "    return sorted(list(set([nm for ss in ss_set for nm in ss.lemma_names()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "747ed289",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"expressive_corpora/emotion_nouns_0.1.txt\",\"w\") as ofh:\n",
    "    for wd in emotion_noun_words:\n",
    "        print(wd,file=ofh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f1aefeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"expressive_corpora/emotion_adjectives_0.1.txt\",\"w\") as ofh:\n",
    "    for wd in emotion_adjective_words:\n",
    "        print(wd,file=ofh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d539c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"expressive_corpora/extended_experiencer_focus_adjectives_wn.txt\",\"w\") as ofh:\n",
    "    for wd in extended_experiencer_focus_adjectives_wn:\n",
    "        print(wd,file=ofh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "02dc52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"expressive_corpora/extended_stimulus_focus_adjectives_wn.txt\",\"w\") as ofh:\n",
    "    for wd in extended_stimulus_focus_adjectives_wn:\n",
    "        print(wd,file=ofh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f8715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
