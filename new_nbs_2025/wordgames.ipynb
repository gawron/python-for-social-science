{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e15544a",
   "metadata": {},
   "source": [
    "## Word games\n",
    "\n",
    "The purpose of these exrecises is to give you some practice with user-defined classes,\n",
    "in poarticular, practice at adding methods and refining your class definitions\n",
    "as the functionality oif the class becomes richer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7fce89",
   "metadata": {},
   "source": [
    "## Spelling Bees\n",
    "\n",
    "The New York Times games section has a game called **Spelling Bee** which presents the user with the following sort of information:\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img \n",
    "src='https://gawron.sdsu.edu/spelling_bee_06_03_25.png'\n",
    "     width=250\n",
    "     />\n",
    "<figcaption>A partially filled mini crossword (NYT June 9, 2025)</figcaption>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "We are given a set of seven letters we'll call  `candidates`,  in this case:\n",
    "\n",
    "```python\n",
    "{'a', 'g', 'i', 'l', 'm', 'n', 'u'}\n",
    "```\n",
    "\n",
    "The goal is to construct as many words as possible using only the letters in `candidates`. Valid words  must be at least four letters long, may contain duplicate instances of the same letter,  and must contain the center letter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633a193",
   "metadata": {},
   "source": [
    "For example, in the game above, *mull*, *glum*, and *lunging* are valid words,  but *mangling* (missing the center letter), *gum* (too short) and *mauls* (contains a letter not in `candidates`) are not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6882d58",
   "metadata": {},
   "source": [
    "Our task will be to implement a function that returns all valid words built from `candidates`. \n",
    "\n",
    "We will call the list of English words satisfying our minimum length constraint\n",
    "`english_words`.  We will the set of possible letters  the `upper_bd` set.  We will allow it to be of any size. \n",
    "And we will allow there to be a (possibly disjoint) set of required letters  (the `lower_bd` set).  We can use\n",
    "`set(wd)` to compute the set of letters in a word string.  Then\n",
    "we want our function to return the following set:\n",
    "\n",
    "$$\n",
    "\\lbrace \\text{wd} \\in \\text{english_words} \\mid \\text{lower_bd} \\subseteq \\text{set}(\\text{wd}) \\subseteq \\text{upper_bd} \\rbrace\n",
    "$$\n",
    "\n",
    "\n",
    "We will use the `nltk` words corpus as `english_words`. Since it's constructed from\n",
    "naturally occurring texts, this word set actually contains\n",
    "a number of forms not accepted  in playing the *Spelling Bee* game online (proper names, extremely rare words,\n",
    "and misspellings), but for the sake of clean code and simplicity, let's set those problems\n",
    "aside in this demonstration exercise.\n",
    "\n",
    "Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "eb1a062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "corp = words.words()\n",
    "min_length= 4\n",
    "corp = [wd for wd in corp if len(wd) >= min_length]\n",
    "\n",
    "def find_words(lower_bd, upper_bd, candidates=corp):\n",
    "    \"\"\"\n",
    "    Return the result of filtering candidates down to::\n",
    "    \n",
    "    { wd in candidates | lower_bd < wd < upper_bd }\n",
    "    \"\"\"\n",
    "    \n",
    "    lower_bd, upper_bd = set(lower_bd),set(upper_bd)\n",
    "    # what's required must also be allowed\n",
    "    upper_bd.update(lower_bd)\n",
    "    return [wd for wd in candidates if upper_bd >= (letterset := set(wd)) and lower_bd <= letterset ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "31561692",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agua',\n",
       " 'alalunga',\n",
       " 'algum',\n",
       " 'almug',\n",
       " 'alnuin',\n",
       " 'alula',\n",
       " 'alum',\n",
       " 'alumina',\n",
       " 'aluminium',\n",
       " 'aluminum',\n",
       " 'alumium',\n",
       " 'alumna',\n",
       " 'alumnal',\n",
       " 'alumni',\n",
       " 'amamau',\n",
       " 'ammu',\n",
       " 'amula',\n",
       " 'amulla',\n",
       " 'amunam',\n",
       " 'anagua',\n",
       " 'angula',\n",
       " 'anilau',\n",
       " 'annual',\n",
       " 'annul',\n",
       " 'aula']"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the game pictured above as our example\n",
    "upper_bound,lower_bound = \"limgna\",\"u\"\n",
    "L1 = find_words(lower_bound, upper_bound)\n",
    "L1[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "35d9ee9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "58d28886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blay',\n",
       " 'byth',\n",
       " 'haab',\n",
       " 'hability',\n",
       " 'habit',\n",
       " 'habitability',\n",
       " 'habitably',\n",
       " 'habitally',\n",
       " 'habitat',\n",
       " 'hillbilly']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words containing \"b\" containing no letters not in the word habitability\n",
    "L2 = find_words(\"b\", \"habitability\")\n",
    "L2[60:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71796717",
   "metadata": {},
   "source": [
    "### Coding point: Walrus operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7e7cc",
   "metadata": {},
   "source": [
    "The code above contains the expression:\n",
    "\n",
    "```python\n",
    "[wd for wd in candidates if upper_bd >= (letterset := set(wd)) and lower_bd =< letterset ]\n",
    "```\n",
    "\n",
    "What does that `:=` mean?  It's called the Walrus operator and it is worth a little discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9861d",
   "metadata": {},
   "source": [
    "Let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "2c5c5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = set(\"abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202170b",
   "metadata": {},
   "source": [
    "Then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "3f0063f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(T := S - {\"b\"}).issubset(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c976093",
   "metadata": {},
   "source": [
    "is shorthand for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "a6f52b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = (S - {\"b\"})\n",
    "T.issubset(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85cd039",
   "metadata": {},
   "source": [
    "In general\n",
    "\n",
    "```python\n",
    "<name> := <expression>\n",
    "```\n",
    "\n",
    "is an expression whose value is the same as `<expression>`.  However the assignment \n",
    "\n",
    "```python\n",
    "<name> = <expression>\n",
    "```\n",
    "\n",
    "has also been performed.  Note that using a normal assignment in  the example above is a Syntax error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "1550af0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (2306610694.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[408], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    (T = S - {\"b\"}).issubset(S)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "(T = S - {\"b\"}).issubset(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c2292",
   "metadata": {},
   "source": [
    "because \n",
    "\n",
    "```python\n",
    "T = S - {\"b\"}\n",
    "```\n",
    "\n",
    "is not an expression.  It has no value.  Python assignments are part of a larger class of Python terms\n",
    "called **statements** which include deletions (`del dd[key]`) and `if`-constructions (`if X < 2: X += 3`).\n",
    "Statements have no values. The idea is that either they just do something that changes the computational state or they are complex blocks of code with no part that can naturally thought of as the value for the whole block.   Expressions, which include most Python terms, do have values. The expression `3+4`, for example, has the value `7`.\n",
    "\n",
    "Terms containing the so-called **walrus operator** (`|=`) have the form `<name> := <expression>`; they are themselves expressions (which therefore have values), but, simultaneously, they  change the computational state by executing assignments.  \n",
    "\n",
    "They are a shortcut.  Generally it is considered clearer and better computational style to avoid the shortcut.\n",
    "Write\n",
    "\n",
    "```python\n",
    "T = (S - {\"b\"})\n",
    "T.issubset(S)\n",
    "```\n",
    "\n",
    "instead of \n",
    "\n",
    "```python\n",
    "(T := S - {\"b\"}).issubset(S)\n",
    "```\n",
    "\n",
    "However using the Walrus operator sometimes saves computation. This is the case in the code above.\n",
    "\n",
    "```python\n",
    "[wd for wd in candidates if upper_bd >= (letterset := set(wd)) and lower_bd <= letterset ]\n",
    "```\n",
    "\n",
    "could have been written\n",
    "\n",
    "```python\n",
    "[wd for wd in candidates if upper_bd >= set(wd) and lower_bd <= set(wd) ]\n",
    "```\n",
    "\n",
    "But then the computation `set(wd)` would have to be done twice.  This conversion to a set at the\n",
    "very least involves removing duplicates, which could be costly if `wd` is a large string.  Another idea\n",
    "\n",
    "```python\n",
    "[wd for wd in candidates if letterset = set(wd) and upper_bd > letterset and lower_bd < letterset ]\n",
    "```\n",
    "\n",
    "raises a `SyntaxError`.  This is because terms formed with the `and` operator are expressions and expressions can contain expressions, but not statements.  So we can see that  by providing an expression that executes an assignment inside it, the walrus operator serves a real need; but it's worth pointing out that even in this example there are conflicting considerations.  One is saving a computation; the other is writing clear and simple code.  You complicate the code with something like the Walrus operator when the tradeoff in computation time is worth it. If your strings are always short (English words probably always count as short) it may not be worth it.\n",
    "\n",
    "**Footnote**:  A final option which may occur to the attentive reader is \n",
    "\n",
    "```python\n",
    "[wd for wd in candidates if letterset := set(wd) and upper_bd > letterset and lower_bd < letterset ]\n",
    "```\n",
    "\n",
    "which is valid, and arguably clearer; but it is not quite equivalent. The if-condition will  fail whenever `letterset` is the empty set, so empty-string `wd`s will be filtered, even when  the lower bound is the emoty set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dddc03",
   "metadata": {},
   "source": [
    "## Word Information States\n",
    "\n",
    "Consider the problem of representing partial information about a computational or linguistic object.\n",
    "\n",
    "To be concrete, let's consider partial information about a **word**, and to be even more concrete,\n",
    "let's the consider the information you acquire about a word as you are filling\n",
    "in a crossword puzzle.  The highlighted squares in the \n",
    "image below show what we know at a particular stage in\n",
    "solving the the New York Times mini-puzzle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb597086",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img \n",
    "width=500,\n",
    "src='https://gawron.sdsu.edu/mini_crossword_game_partial.png'\n",
    "     />\n",
    "<figcaption>A partially filled mini crossword (NYT June 9, 2025)</figcaption>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9acf7a",
   "metadata": {},
   "source": [
    "Let's call the things we know abour our **constraints**.  The constraints on  the word at 4-down are that\n",
    "it has five letters; the first letter is \"p\"; the third and fourth are \"i\" and \"o\" respectively.\n",
    "\n",
    "Let's cook up a class (call it `WordInformationState`) for representing constraints on a word.  The intuition guiding the implementation is that a `WordInformationState` should behave like a word string as much as possible.  It should print like a string; it should be indexable like a string (`word[2]`) and it should print and return the letter at an index when it is known and a place-holder when it is not. It should also enforce length constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b1f85d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p*io*"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "corp = words.words()\n",
    "\n",
    "class WordInformationState ():\n",
    "    \n",
    "    # self.__position_dict_[idx] is the value at position idx \n",
    "    # in self's character sequence\n",
    "    # We implement it as a dictionary so that there can\n",
    "    # be positions whose letter is unknown.\n",
    "   \n",
    "    # This one shd be accessible to users\n",
    "    blank_char = \"*\"\n",
    "    \n",
    "    def __init__ (self,position_dict,length,blank_char=None):\n",
    "      \n",
    "        self.len = length\n",
    "        if blank_char is not None:\n",
    "            self.blank_char = blank_char\n",
    "        # We update the word state with positional info and simultaneously\n",
    "        # check that each position index is a valid index\n",
    "        self._position_dict_ = {}\n",
    "        for (k,v) in position_dict.items():\n",
    "            self._index_check_(k)\n",
    "            self._position_dict_[k] = v\n",
    "          \n",
    "        \n",
    "    def _index_check_(self,idx):\n",
    "        # check that position index idx is a valid index \n",
    "        assert isinstance(idx,int), f\"{idx} is not an integer and therefore not a valid position index\"\n",
    "        assert idx < self.len, f\"{idx} is too large a position index for a word of length {self.len}\"\n",
    "        \n",
    "    def __getitem__ (self, k):\n",
    "        self._index_check_(k)\n",
    "        try:\n",
    "            return self._position_dict_[k]\n",
    "        except KeyError:\n",
    "            return self.blank_char\n",
    "        \n",
    "    def __repr__ (self):\n",
    "        #return \"\".join([self._position_dict_[k] if k in self._position_dict_ else \"*\" \n",
    "        #                for k in range(self.len)])\n",
    "        return \"\".join([self[k] for k in range(self.len)])\n",
    "\n",
    "# A sample instance of a WordInformationState incorporating\n",
    "# the length and position constraints of 4 down in the partially\n",
    "# solved crossword above.\n",
    "wis = WordInformationState (position_dict={0:\"p\",2:\"i\",3:\"o\"}, length=5)\n",
    "wis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a913508e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3d61ba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "10003672",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "6 is too large a position index for a word of length 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[287], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wis[\u001b[38;5;241m6\u001b[39m]\n",
      "Cell \u001b[0;32mIn[278], line 37\u001b[0m, in \u001b[0;36mWordInformationState.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m (\u001b[38;5;28mself\u001b[39m, k):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    This allows us to look up the letter at position key using\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    list-indexing syntax: self[2] returns the letter at poisition 2 if\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    known, or the the filler character if not knot known.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_check_(k)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_position_dict_[k]\n",
      "Cell \u001b[0;32mIn[278], line 29\u001b[0m, in \u001b[0;36mWordInformationState._index_check_\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_check_\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# check that position index idx is a valid index \u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx,\u001b[38;5;28mint\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not an integer and therefore not a valid position index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is too large a position index for a word of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 6 is too large a position index for a word of length 5"
     ]
    }
   ],
   "source": [
    "wis[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51c77a",
   "metadata": {},
   "source": [
    "Building on the class definition above, complete the following tasks:\n",
    "\n",
    "1.  Your first task is to add a new method to the `WordInformationState` class (call the new method `matches`), which has two arguments, the word information-state (call it `self`) and a word (call it `word`),  The `matches` method returns  `True` if `word` satisfies the constraints in `self`. Otherwise, it returns `False`. \n",
    "In particular in order for `matches` to return `True`, `word` has to be the right length \n",
    "and it has to have the required letters at the positions `self` has information about.\n",
    "2.  Your second task is to add a second new method to the `WordInformationState` class (call it `filter_words`); `filter_words` should also  have two arguments, the word information-state (call it `self`) and a word sequence.  The `filter_words` method returns the words in the sequence which satisfy the constraints in `self`. \n",
    "\n",
    "Before testing your new methods don't forget to re-execute the cell defining the class\n",
    "and make sure you create your new instance (`wis`) after redefining the class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d193e1",
   "metadata": {},
   "source": [
    "Here are some test cases for both of the new methods; `wis` is the `WordInformationState` instance defined\n",
    "above.  It incorporates the constraints from the mini-crossword example.\n",
    "\n",
    "Since we have only partial information on the word in question, multiple character\n",
    "sequences may be compatible with what we know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5a4df531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior True\n",
      "prion True\n",
      "priod True\n",
      "proof False\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "# This satisfies the constraints in wis and it happens to be the right word for the  crossword\n",
    "word_list.append(\"prior\")\n",
    "# This also satisfies the constraints in wis and is also a word (though a weird one),\n",
    "# but it happens not to be the right word for the  crossword\n",
    "word_list.append(\"prion\")\n",
    "# This is not a word, but it satisfies the constraints in wis.\n",
    "word_list.append(\"priod\")\n",
    "# This is a word, but it does not satisfy the crossword's constraints\n",
    "word_list.append(\"proof\")\n",
    "for word in word_list:\n",
    "    print(word, wis.matches(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15d779c",
   "metadata": {},
   "source": [
    "To test `filter_words`, use the `corp` word_list defined in the previous example.  Even limiting\n",
    "our candidates to a set of known words, multiple words may still satisfy the constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8ff16d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prion', 'prior']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis.filter_words(corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29f4a6",
   "metadata": {},
   "source": [
    "Here's another word state to test `filter_words` on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f903c776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['habitably',\n",
       " 'habitally',\n",
       " 'hackingly',\n",
       " 'haggardly',\n",
       " 'haggishly',\n",
       " 'haltingly',\n",
       " 'hangingly',\n",
       " 'haplessly',\n",
       " 'haplolaly',\n",
       " 'harmfully',\n",
       " 'hastately',\n",
       " 'hatefully',\n",
       " 'haughtily',\n",
       " 'healingly',\n",
       " 'healthily',\n",
       " 'heartedly',\n",
       " 'heatingly',\n",
       " 'hedgingly',\n",
       " 'heedfully',\n",
       " 'heinously',\n",
       " 'helically',\n",
       " 'hellishly',\n",
       " 'helpfully',\n",
       " 'helpingly',\n",
       " 'heritably',\n",
       " 'hideously',\n",
       " 'hillbilly',\n",
       " 'hintingly',\n",
       " 'hissingly',\n",
       " 'hoggishly',\n",
       " 'holdingly',\n",
       " 'homophyly',\n",
       " 'homostyly',\n",
       " 'honeyedly',\n",
       " 'honorably',\n",
       " 'hootingly',\n",
       " 'hopefully',\n",
       " 'hoppingly',\n",
       " 'hostilely',\n",
       " 'howlingly',\n",
       " 'huffingly',\n",
       " 'huffishly',\n",
       " 'hugeously',\n",
       " 'huggingly',\n",
       " 'hurriedly',\n",
       " 'hurtfully',\n",
       " 'husbandly',\n",
       " 'hushfully',\n",
       " 'hushingly',\n",
       " 'hypertely']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis2 = WordInformationState ({0:\"h\",7:\"l\",8:\"y\"},9)\n",
    "wis2.filter_words(corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced51be",
   "metadata": {},
   "source": [
    "## A further wrinkle\n",
    "\n",
    "The last exercise is to modify the definition of the `WordInformationState` class to allow two new kinds of letter constraints on the unknown word: upper and lower bound constraints. These kinds of constraints were discussed in the **Spelling Bees** section of this notebook.\n",
    "\n",
    "That is, in addition to length and positional information, we allow constraints of the following form:\n",
    "\n",
    "1.  Any letter in the lower bound set must occur in a valid candidate word.\n",
    "2.  Only letters in the upper bound set may occur in a valid candidate word.\n",
    "3.  When defining a `WordInformationState` any of the following may be supplied: a lower bound set, an upper bound set, a position dict, and a length.  None of those **must** be supplied.\n",
    "\n",
    "Let's take an example instance of your new `WordInformationStateHere` class and call it `wis`. Here are some things to think about.\n",
    "\n",
    "1.  Modify the `wis.match()`  method to enforce lower and upper bound constraints.  The code in `find_words` defined in the **Spelling Bees** section should be of help.\n",
    "2.  There are potentially consistency issues among the constraints.  For example, suppose the `position_dict` contains a letter not in the upper bound set. What should you do about that? Note that this is the tip of an iceberg.  What if our position dict incorporates constraints not satisfiable by any English word, for example, that \"q\" must be immediately followed by \"b\"? What should we do about that?  Let's assume that we have a default corpus that includes all English words, possibly filtered by some additional constraints such as minimum length. Consider using the `nltk` words corpus to help with that. For convenience make the default corpus an attribute of each `WordInformationState` instance.  Can we use that to help with all our consistency issues?\n",
    "3.  You should be able to create a `wis` that captures the Spelling Bee game in the Spelling Bee section of this notebook; `wis.filter_words(wis.default_corp)` should give the set of solution words.  To better capture the constraints of the game, filter `wis.default_corp` to only include words with length greater than 4.  You can then check the result of `wis.filter_words(wis.default_corp)` against the word set produced by `find_words` in the Spelling Bee section. \n",
    "4. You should also be able to create a `wis` that captures the position and length constraints of 4-down in crossword puzzle example above; `wis.filter_words(wis.default_corp)` should then give you all possible fillers for 4-down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a371059",
   "metadata": {},
   "source": [
    "## Final wrinkle (negative information)\n",
    "\n",
    "We have been using word games to concoct instances where we have partial information about the identity\n",
    "of a word, and defining classes that represent that partial information.\n",
    "\n",
    "Now consider a more difficult kind of game state which arises in playing the game **Wordle**.\n",
    "\n",
    "[Game description]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2666010",
   "metadata": {},
   "source": [
    "At first glance Wordle may seem like more of the same.  You have the length constraint of 5 letters and when a guess letter is colored green you know the identity of the letter at a particular position.  When a guess letter is colored yellow you know an upper bound constraint. Valid words must contain that letter.\n",
    "\n",
    "However, there is more to it.  Wordl game states introduce two new kinds of information, both of which can be thought of as **negative** information.\n",
    "\n",
    "1.  If a guess letter is colored black, that means that letter may **not** occur in a valid word.\n",
    "2.  A guess letter colored yellow tells us more than just an upper bound constraint. If a guess letter at position k is colored yellow, that also means that a valid word may not contain that letter at position k.\n",
    "\n",
    "\n",
    "> Introduce a new kind of internal data structure to explicitly represent the negative constraints and modify the `.match()` method to enforce them.\n",
    "    \n",
    "    \n",
    "We might then proceed in either of two ways.\n",
    "\n",
    "1.  Enforce all constraints when the `WordInformationState` instance is created by calling `.match()` on the default corpus: Call the result of that the Filtered English Words.  This is a big efficiency win since constraint-matching only need to be computed once, after which all constraints can be forgotten.  Then `.filter_words()` could simply be the intersection of the Filtered English Words with whatever word list passed in as an argument to `.filter_words()`.   Note the hidden assumption here: We are assuming default corpus contains all possible English words.  Therefore after the constraints are applied, the Filtered English Words contained all possible words that satisfy our constraints.  \n",
    "2.  Proceed along the lines we outline when we introduced out first wrinkle.  Maintain explicit representations of all constraints and enforce them on whatever word  `.match()`  is called on.   In that case `.filter_words()` would call `.match()` and the word set returned by `.filter_words()` might returns words not in the default corpus.\n",
    "\n",
    "With respect to distinguishing the two solution paths, consider the word \"gleepsite\", which is the title of a story by Joanna Russ, but is also a word used by a small community of real speakers, as she has explained.  It happens that it does not occur in our unfiltered default corpus.  Suppose that the word \"gleepsite\" satisfies all constraints used to define `wis`.  What should `wis.filter_words([\"gleepsite\"])` return?  Will both solutions (1) and (2) get this right?\n",
    "\n",
    "We can have the best of both worlds if we implement solution 1 with two versions of `filter_words`, one\n",
    "which applies the `wis` constraints while iterating through the word list (by calling `match` on each word and without consulting the default corpus) and one which performs an intersection with the default corpus.  Let's call the first version `filter_words_by_matching`. This is the version which will be used to create the Filtered English Words by filtering the default corpus when `wis` is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "81ee5fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"gleepsite\" in corp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78953e",
   "metadata": {},
   "source": [
    "### Debugging advice\n",
    "\n",
    "To check your ideas for implementing the final wrinkle, make sure that you can represent the game state of\n",
    "some Wordle game.  Here's an example of a partially completed game.  See if your solution to the final wrinkle\n",
    "can represent what we know about the target word after these four guesses:\n",
    "\n",
    "<p>\n",
    "<figure>\n",
    "<center>\n",
    "<img \n",
    "src='https://gawron.sdsu.edu/wordle_archive_108.png'\n",
    "     width=250\n",
    "     />\n",
    "<figcaption>An incomplete Wordle game</figcaption>\n",
    "</center>\n",
    "</figure>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaea94f",
   "metadata": {},
   "source": [
    "One way to represent the above information (there are others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0f6b76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellow and black letter info\n",
    "\n",
    "black_letters = set(\"rtioclshmndpu\")\n",
    "# negative yellow letter info\n",
    "neg_position_dict = {0:set(\"a\"),\n",
    "                     1:set(\"a\"),\n",
    "                     2:set(\"ae\"),\n",
    "                     3:set(),\n",
    "                     4:set(\"e\")}\n",
    "# merge negative yellow and black letter info\n",
    "neg_position_dict = {k:black_letters|s for (k,s) in neg_position_dict.items()}\n",
    "# green letter info\n",
    "position_dict = {\n",
    "                 3:\"a\",\n",
    "                 }\n",
    "\n",
    "# yellow letter info\n",
    "lower_bound = set(\"ae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417d15d",
   "metadata": {},
   "source": [
    "Note:  The solution to the Wordle game above (which is quite difficult) will be computed in\n",
    "the exercise solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92cac2c",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d4f82",
   "metadata": {},
   "source": [
    "### Information states solution\n",
    "\n",
    "We implement `matches` and `filter_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "752772c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordInformationState ():\n",
    "    \n",
    "    # self.__position_dict_[idx] is the value at position idx \n",
    "    # in self's character sequence\n",
    "    # We implement it as a dictionary so that there can\n",
    "    # be positions whose letter is unknown.\n",
    "   \n",
    "    # This one shd be accessible to users.\n",
    "    # character to be used as  filler when the letter\n",
    "    # at a position is unknown.\n",
    "    filler_char = \"*\"\n",
    "    \n",
    "    def __init__ (self,position_dict,length,filler_char=None):\n",
    "      \n",
    "        self.len = length\n",
    "        if filler_char is not None:\n",
    "            self.filler_char = filler_char\n",
    "        # We update the word state with positional info and simultaneously\n",
    "        # check that each position index is a valid index\n",
    "        self._position_dict_ = {}\n",
    "        for (k,v) in position_dict.items():\n",
    "            self._index_check_(k)\n",
    "            self._position_dict_[k] = v\n",
    "          \n",
    "        \n",
    "    def _index_check_(self,idx):\n",
    "        # check that position index idx is a valid index \n",
    "        assert isinstance(idx,int), f\"{idx} is not an integer and therefore not a valid position index\"\n",
    "        assert idx < self.len, f\"{idx} is too large a position index for a word of length {self.len}\"\n",
    "        \n",
    "    def __getitem__ (self, k):\n",
    "        \"\"\"\n",
    "        This allows us to look up the letter at position key using\n",
    "        list-indexing syntax: self[2] returns the letter at poisition 2 if\n",
    "        known, or the the filler character if not knot known.\n",
    "        \"\"\"\n",
    "        self._index_check_(k)\n",
    "        try:\n",
    "            return self._position_dict_[k]\n",
    "        except KeyError:\n",
    "            return self.filler_char\n",
    "        \n",
    "    def __repr__ (self):\n",
    "        #return \"\".join([self._position_dict_[k] if k in self._position_dict_ else \"*\" \n",
    "        #                for k in range(self.len)])\n",
    "        return \"\".join([self[k] for k in range(self.len)])\n",
    "    \n",
    "    def matches (self, word):\n",
    "        if not len(word) == self.len:\n",
    "            return False\n",
    "        for (idx,let) in self._position_dict_.items():\n",
    "                if not word[idx] == let:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    def filter_words (self, word_list):\n",
    "        return [wd for wd in word_list if self.matches(wd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b1fc053d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p*io*"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis = WordInformationState ({0:\"p\",2:\"i\",3:\"o\"},5)\n",
    "wis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "fdc6042a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prion', 'prior']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis.filter_words(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f06c56ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['habitably',\n",
       " 'habitally',\n",
       " 'hackingly',\n",
       " 'haggardly',\n",
       " 'haggishly',\n",
       " 'haltingly',\n",
       " 'hangingly',\n",
       " 'haplessly',\n",
       " 'haplolaly',\n",
       " 'harmfully',\n",
       " 'hastately',\n",
       " 'hatefully',\n",
       " 'haughtily',\n",
       " 'healingly',\n",
       " 'healthily',\n",
       " 'heartedly',\n",
       " 'heatingly',\n",
       " 'hedgingly',\n",
       " 'heedfully',\n",
       " 'heinously',\n",
       " 'helically',\n",
       " 'hellishly',\n",
       " 'helpfully',\n",
       " 'helpingly',\n",
       " 'heritably',\n",
       " 'hideously',\n",
       " 'hillbilly',\n",
       " 'hintingly',\n",
       " 'hissingly',\n",
       " 'hoggishly',\n",
       " 'holdingly',\n",
       " 'homophyly',\n",
       " 'homostyly',\n",
       " 'honeyedly',\n",
       " 'honorably',\n",
       " 'hootingly',\n",
       " 'hopefully',\n",
       " 'hoppingly',\n",
       " 'hostilely',\n",
       " 'howlingly',\n",
       " 'huffingly',\n",
       " 'huffishly',\n",
       " 'hugeously',\n",
       " 'huggingly',\n",
       " 'hurriedly',\n",
       " 'hurtfully',\n",
       " 'husbandly',\n",
       " 'hushfully',\n",
       " 'hushingly',\n",
       " 'hypertely']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis2 = WordInformationState ({0:\"h\",7:\"l\",8:\"y\"},9)\n",
    "wis2.filter_words(corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455ac26",
   "metadata": {},
   "source": [
    "### A further wrinkle solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417bc96e",
   "metadata": {},
   "source": [
    "We implement lower bound and upper bound constraints, allowing them to be passed in as\n",
    "container arguments to `WordInformationState` when the instance is created;\n",
    "we also modify `matches` to enforce the intended constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "f746c75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p*io*"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "from string import ascii_lowercase\n",
    "\n",
    "corp = words.words()\n",
    "\n",
    "class WordInformationState ():\n",
    "    \n",
    "    # self.__position_dict_[idx] is the value at position idx \n",
    "    # in self's character sequence\n",
    "    # We implement it as a dictionary so that there can\n",
    "    # be positions whose letter is unknown.\n",
    "   \n",
    "    # This one shd be accessible to users\n",
    "    blank_char = \"*\"\n",
    "    default_corp = corp\n",
    "    \n",
    "    def __init__ (self,position_dict=None,length=None,\n",
    "                  lower_bound=None, upper_bound=None,\n",
    "                  blank_char=None,default_corp=None):\n",
    "      \n",
    "        self.len = length\n",
    "        if blank_char is not None:\n",
    "            self.blank_char = blank_char\n",
    "        # We update the word state with positional info and simultaneously\n",
    "        # check that each position index is a valid index\n",
    "        self._position_dict_ = {}\n",
    "        if position_dict is not None:\n",
    "            for (k,v) in position_dict.items():\n",
    "                self._index_check_(k)\n",
    "                self._position_dict_[k] = v\n",
    "        if default_corp is not None:\n",
    "            self.default_corp = default_corp\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        if self.upper_bound is not None:\n",
    "            self.upper_bound = set(upper_bound)\n",
    "        else:\n",
    "            self.upper_bound = set(ascii_lowercase)\n",
    "        if self.lower_bound is not None:\n",
    "            self.lower_bound = set(lower_bound)\n",
    "        else:\n",
    "            self.lower_bound = set()\n",
    "        # what's required must also be allowed\n",
    "        self.upper_bound.update(self.lower_bound)\n",
    "        #consistency check\n",
    "        assert len(self.filter_words(self.default_corp)) > 0, \"The current constraints are not consistent\"\\\n",
    "        \" with the default corpus.  Check for a contradiction.\"\n",
    "          \n",
    "        \n",
    "    def _index_check_(self,idx):\n",
    "        # check that position index idx is a valid index \n",
    "        assert isinstance(idx,int), f\"{idx} is not an integer and therefore not a valid position index\"\n",
    "        if self.len is not None:\n",
    "            assert idx < self.len, f\"{idx} is too large a position index for a word of length {self.len}\"\n",
    "        \n",
    "    def __getitem__ (self, k):\n",
    "        self._index_check_(k)\n",
    "        try:\n",
    "            return self._position_dict_[k]\n",
    "        except:\n",
    "            return self.blank_char\n",
    "        \n",
    "    def __repr__ (self):\n",
    "        #return \"\".join([self._position_dict_[k] if k in self._position_dict_ else \"*\" \n",
    "        #                for k in range(self.len)])\n",
    "        if self.len is not None:\n",
    "            return \"\".join([self[k] for k in range(self.len)])\n",
    "        elif len(self._position_dict_) > 0:\n",
    "            max_pos = max(list(self._position_dict_.keys()))\n",
    "            return \"\".join([self[k] for k in range(max_pos)]) + \"...\"\n",
    "        else:\n",
    "            return \"...\"\n",
    "\n",
    "    def matches (self, word,verbose=False):\n",
    "        if self.len is not None and not len(word)== self.len:\n",
    "            if verbose: print(\"len\")\n",
    "            return False\n",
    "        if self._position_dict_ is not None:\n",
    "            for (idx,let) in self._position_dict_.items():\n",
    "                if not word[idx] == let:\n",
    "                    if verbose: print(\"position\",idx,let)\n",
    "                    return False\n",
    "        letterset = set(word)\n",
    "        if not self.upper_bound >= letterset:\n",
    "            if verbose: print(\"upper_bound\")\n",
    "            return False\n",
    "        if not self.lower_bound <= letterset:\n",
    "            if verbose: print(\"lower_bound\")\n",
    "            return False\n",
    "        return True\n",
    "     \n",
    "    def filter_words (self, word_list):\n",
    "        return [wd for wd in word_list if self.matches(wd)]\n",
    "    \n",
    "# A sample instance of a WordInformationState incorporating\n",
    "# the length and position constraints of 4 down in the partially\n",
    "# solved crossword above.\n",
    "wis = WordInformationState (position_dict={0:\"p\",2:\"i\",3:\"o\"}, length=5)\n",
    "wis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "717b69f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prion', 'prior']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis.filter_words(wis.default_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ebfce5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7cb1d",
   "metadata": {},
   "source": [
    "Add the constraint of an upper bound (requiring \"r\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7b4a54af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p*io*"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis2 = WordInformationState (position_dict={0:\"p\",2:\"i\",3:\"o\"}, length=5, upper_bound=\"prio\")\n",
    "wis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1bf0706e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i', 'o', 'p', 'r'}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis2.upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d08d91f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prior']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis2.filter_words(wis.default_corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e57b2",
   "metadata": {},
   "source": [
    "Create an inconsistent word state (position dict contains letter not in upper_bound):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "57347ce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The current constraints are not consistent with the default corpus.  Check for a contradiction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[242], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wis3 \u001b[38;5;241m=\u001b[39m WordInformationState (position_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m2\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m3\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m}, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, upper_bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpri\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m wis3\n",
      "Cell \u001b[0;32mIn[233], line 43\u001b[0m, in \u001b[0;36mWordInformationState.__init__\u001b[0;34m(self, position_dict, length, lower_bound, upper_bound, blank_char)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupper_bound\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlower_bound)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#consistency check\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_words(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_corp)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current constraints are not consistent\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with the default corpus.  Check for a contradiction.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The current constraints are not consistent with the default corpus.  Check for a contradiction."
     ]
    }
   ],
   "source": [
    "wis3 = WordInformationState (position_dict={0:\"p\",2:\"i\",3:\"o\"}, length=5, upper_bound=\"pri\")\n",
    "wis3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f9bb8",
   "metadata": {},
   "source": [
    "Create a word state inconsistent with the facts of English words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "55bb3ab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The current constraints are not consistent with the default corpus.  Check for a contradiction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[340], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wis4 \u001b[38;5;241m=\u001b[39m WordInformationState (position_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m2\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m3\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m}, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      2\u001b[0m wis4\n",
      "Cell \u001b[0;32mIn[339], line 46\u001b[0m, in \u001b[0;36mWordInformationState.__init__\u001b[0;34m(self, position_dict, length, lower_bound, upper_bound, blank_char, default_corp)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupper_bound\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlower_bound)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#consistency check\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_words(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_corp)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current constraints are not consistent\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with the default corpus.  Check for a contradiction.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The current constraints are not consistent with the default corpus.  Check for a contradiction."
     ]
    }
   ],
   "source": [
    "wis4 = WordInformationState (position_dict={0:\"q\",2:\"b\",3:\"o\"}, length=5)\n",
    "wis4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a0570",
   "metadata": {},
   "source": [
    "Create a word state with no constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8cd54806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "..."
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis5 = WordInformationState ()\n",
    "wis5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0a2d1b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236734"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = wis5.filter_words(wis.default_corp)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4a87c6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wis5.default_corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45678c0",
   "metadata": {},
   "source": [
    "The `wis` for the Spelling Bee game above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "925a1765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "..."
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_length = 4\n",
    "default_corpus = [word for word in corp if len(word) >= min_length]\n",
    "upper_bound,lower_bound = \"limgna\",\"u\"\n",
    "wis6 = WordInformationState (lower_bound=lower_bound, upper_bound=upper_bound,\n",
    "                             default_corp = default_corpus)\n",
    "wis6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "48f811ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed = wis6.filter_words(wis6.default_corp)\n",
    "len(allowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5493696",
   "metadata": {},
   "source": [
    "From the Spelling Bee section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "49b33c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1 == allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530434b",
   "metadata": {},
   "source": [
    "## The final wrinkle: solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71b7f5",
   "metadata": {},
   "source": [
    "A more constrained word set with no proper names (Adam Kilgariff's lemma set from the British National Corpus).\n",
    "\n",
    "We'll use this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "113ff790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnd\n",
    "fn=\"https://www.kilgarriff.co.uk/BNClists/all.num.o5\"\n",
    "#word_df = pd.read_csv(fn,index_col=1,sep=\" \", names=[\"Freq\",\"POS\", \"DocFreq\"])\n",
    "word_df = pnd.read_csv(fn,sep=\" \", names=[\"Freq\",\"Word\", \"POS\", \"DocFreq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "540ec065",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = r\"\\?\\+_!\\.@\\$%\\^&\\*\\(\\)=\\[\\]{}#<>`~'\\\",/\\|~:;\"\n",
    "digits = \"01234567890\"\n",
    "\n",
    "\n",
    "def isword (wd):\n",
    "    \"\"\"\n",
    "    Let's filter out a host of nonwords.\n",
    "    \"\"\"\n",
    "    if not isinstance(wd,str):\n",
    "        return False\n",
    "    if wd.startswith(\"-\"):\n",
    "        return False\n",
    "    for char in punct:\n",
    "        if char in wd:\n",
    "            return False\n",
    "    for char in digits:\n",
    "        if char in wd:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "real_words = [word for word in word_df.iloc[1:][\"Word\"].unique() if isword(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "0255b3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "***a*"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "from collections import defaultdict\n",
    "from string import ascii_lowercase\n",
    "\n",
    "corp = words.words()\n",
    "corp = {wd for wd in corp if len(wd)==5}\n",
    "#corp = [wd for wd in real_words if len(wd)==5]\n",
    "\n",
    "class WordInformationState ():\n",
    "    \n",
    "    # self.__position_dict_[idx] is the value at position idx \n",
    "    # in self's character sequence\n",
    "    # We implement it as a dictionary so that there can\n",
    "    # be positions whose letter is unknown.\n",
    "    \n",
    "    # self.__neg_position_dict_[idx] is a set of values that may NOT occur at position idx \n",
    "   \n",
    "    # This one shd be accessible to users\n",
    "    blank_char = \"*\"\n",
    "    default_corp = corp\n",
    "    \n",
    "    def __init__ (self,position_dict=None, neg_position_dict=None, length=None,\n",
    "                  lower_bound=None, upper_bound=None,\n",
    "                  blank_char=None,default_corp=None):\n",
    "      \n",
    "        self.len = length\n",
    "        if blank_char is not None:\n",
    "            self.blank_char = blank_char\n",
    "        # We update the word state with positional info and simultaneously\n",
    "        # check that each position index is a valid index\n",
    "        self._position_dict_ = {}\n",
    "        if position_dict is not None:\n",
    "            for (k,v) in position_dict.items():\n",
    "                self._index_check_(k)\n",
    "                self._position_dict_[k] = v\n",
    "        # create a default dict whose initial default values are empty sets\n",
    "        self._neg_position_dict_ = defaultdict(set)\n",
    "        if neg_position_dict is not None:\n",
    "            for (k,v) in neg_position_dict.items():\n",
    "                self._index_check_(k)\n",
    "                self._neg_position_dict_[k].update(v)\n",
    "        if default_corp is not None:\n",
    "            self.default_corp = default_corp\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        if self.upper_bound is not None:\n",
    "            self.upper_bound = set(upper_bound)\n",
    "        else:\n",
    "            self.upper_bound = set(ascii_lowercase)\n",
    "        if self.lower_bound is not None:\n",
    "            self.lower_bound = set(lower_bound)\n",
    "        else:\n",
    "            self.lower_bound = set()\n",
    "        # what's required must also be allowed\n",
    "        self.upper_bound.update(self.lower_bound)\n",
    "        # enforce constraints on default corpus\n",
    "        self.default_corp = self.filter_words_by_matching(self.default_corp)\n",
    "        try:\n",
    "            assert len(self.default_corp) > 0, \"The current constraints are not consistent\"\\\n",
    "            \" with the default corpus.  Check for a contradiction.\"\n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "          \n",
    "        \n",
    "    def _index_check_(self,idx):\n",
    "        # check that position index idx is a valid index \n",
    "        assert isinstance(idx,int), f\"{idx} is not an integer and therefore not a valid position index\"\n",
    "        if self.len is not None:\n",
    "            assert idx < self.len, f\"{idx} is too large a position index for a word of length {self.len}\"\n",
    "        \n",
    "    def __getitem__ (self, k):\n",
    "        self._index_check_(k)\n",
    "        try:\n",
    "            return self._position_dict_[k]\n",
    "        except:\n",
    "            return self.blank_char\n",
    "        \n",
    "    def __repr__ (self):\n",
    "        #return \"\".join([self._position_dict_[k] if k in self._position_dict_ else \"*\" \n",
    "        #                for k in range(self.len)])\n",
    "        if self.len is not None:\n",
    "            return \"\".join([self[k] for k in range(self.len)])\n",
    "        elif len(self._position_dict_) > 0:\n",
    "            max_pos = max(list(self._position_dict_.keys()))\n",
    "            return \"\".join([self[k] for k in range(max_pos)]) + \"...\"\n",
    "        else:\n",
    "            return \"...\"\n",
    "\n",
    "    def matches (self, word,verbose=False):\n",
    "        if self.len is not None and not len(word)== self.len:\n",
    "            if verbose: print(\"len\")\n",
    "            return False\n",
    "        if self._position_dict_ is not None:\n",
    "            for (idx,let) in self._position_dict_.items():\n",
    "                if not word[idx] == let:\n",
    "                    if verbose: print(\"position\",idx,let)\n",
    "                    return False\n",
    "        if self._neg_position_dict_ is not None:\n",
    "            for (idx,set0) in self._neg_position_dict_.items():\n",
    "                if  word[idx] in set0:\n",
    "                    if verbose: print(\"neg position\",idx,set0)\n",
    "                    return False\n",
    "        letterset = set(word)\n",
    "        if not self.upper_bound >= letterset:\n",
    "            if verbose: print(\"upper_bound\")\n",
    "            return False\n",
    "        if not self.lower_bound <= letterset:\n",
    "            if verbose: print(\"lower_bound\")\n",
    "            return False\n",
    "        return True\n",
    "     \n",
    "    def filter_words_by_matching (self, word_list):\n",
    "        return {wd for wd in word_list if self.matches(wd)}\n",
    "    \n",
    "    def filter_words (self, word_list):\n",
    "        return self.default_corp.intersection(word_list)\n",
    "\n",
    "\n",
    "# A sample instance of a WordInformationState incorporating\n",
    "# the constraints learned in the Wordle game above\n",
    "black_letters = set(\"rtioclshmndpu\")\n",
    "# negative yellow letter info\n",
    "neg_position_dict = {0:set(\"a\"),\n",
    "                     1:set(\"a\"),\n",
    "                     2:set(\"ae\"),\n",
    "                     3:set(),\n",
    "                     4:set(\"e\")}\n",
    "# merge negative yellow and black letter info\n",
    "neg_position_dict = {k:black_letters|s for (k,s) in neg_position_dict.items()}\n",
    "# green letter info\n",
    "position_dict = {\n",
    "                 3:\"a\",\n",
    "                 }\n",
    "\n",
    "# yellow letter info\n",
    "lower_bound = set(\"ae\")\n",
    "\n",
    "wis = WordInformationState (position_dict=position_dict,\n",
    "                            neg_position_dict=neg_position_dict,\n",
    "                            lower_bound=lower_bound,\n",
    "                            length=5)\n",
    "wis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a8600ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113982"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f4b19",
   "metadata": {},
   "source": [
    "The only 5-letter words in `nltk.words` compatible with the constraints (arguably, one of them is not English):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "316dfc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bebay', 'begay', 'kebab']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis.default_corp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662ae4f",
   "metadata": {},
   "source": [
    "So we filter against a set we think is more reliably just English words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e7868f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kebab'}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis.filter_words(real_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a193d4",
   "metadata": {},
   "source": [
    "#### The gleepsite example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "eb4442e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 4\n",
    "default_corpus = [word for word in words.words() if len(word) >= min_length]\n",
    "upper_bound,lower_bound = set(\"gleepsite\"),\"p\"\n",
    "position_dict = {2:\"e\",3:\"e\"}\n",
    "wis9 = WordInformationState (lower_bound=lower_bound, upper_bound=upper_bound,\n",
    "                             default_corp = default_corpus,\n",
    "                             position_dict=position_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "138f05fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epee',\n",
       " 'epeeist',\n",
       " 'sleep',\n",
       " 'sleepless',\n",
       " 'speel',\n",
       " 'speelless',\n",
       " 'steep',\n",
       " 'steeple',\n",
       " 'steepleless'}"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis9.default_corp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9a3d4",
   "metadata": {},
   "source": [
    "The word *gleepsite* is not among the filtered English words so it's not in the intersection with `[\"gleepsite\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "b16212c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis9.filter_words([\"gleepsite\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa7c3ad",
   "metadata": {},
   "source": [
    "But"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "0eac9224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gleepsite'}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis9.filter_words_by_matching([\"gleepsite\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee7fc5",
   "metadata": {},
   "source": [
    "Which tells us that the word *gleepsite* meets the coinstraints on this word state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0b2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
