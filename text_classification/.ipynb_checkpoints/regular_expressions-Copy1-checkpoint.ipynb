{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5EvAXIIhZMW"
   },
   "source": [
    "# Regular Expression Assignment Practice Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to complement the brief introduction to **regular expressions** presented in the appendix to the online Python text [Python for Social Science.](https://gawron.sdsu.edu/python_for_ss/course_core/book_draft/index.html)\n",
    "Python's regular expression package (`re`) provides a language for expressing patterns that \n",
    "match sets of strings.\n",
    "\n",
    "The treatment given in the online text is described as brief because regular expressions are an intricate subject with many thorny side paths; the few pages devoted to the subject there can only begin to scratch the surface. Regular expressions are nevertheless an incredibly useful perhaps even indispensable tool when dealing with datasets containing large strings with patterned data needing extraction or patterned errors needing correction.\n",
    "\n",
    "The power and challenge of using regular expressions are perfectly captured in an XKCD cartoon, \n",
    "linked to below for your viewing pleasure.  Be sure to read the panel before reading the caption,\n",
    "and then, most likely, you will want to read the panel again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=https://imgs.xkcd.com/comics/s_keyboard_leopard.png>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "img_data ='https://imgs.xkcd.com/comics/s_keyboard_leopard.png'\n",
    "HTML(f'<img src={img_data}>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't have to have worked extensively with regular expressions to appreciate this particular XKCD,\n",
    "but I suspect it is funnier if you have.\n",
    "\n",
    "The point:  When regular expressions go wrong, the results are often incomprehensible.  Let's  look\n",
    "at what they can do, and some of the refinement process that nearly  every bit of regular expression\n",
    "code goes through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55iUZaIfhZMX"
   },
   "source": [
    "## How to construct and debug regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zvOPwRphZMY"
   },
   "source": [
    "The cell two cells down defines a large html string that we will use to test some of regular expressions.  When writing a program that is going to depend on accurately extracting instances of certain patterns from text or HTML, you need to create the regular expressions first, testing them on realistic example strings.  You need your expressions to do two things:\n",
    "\n",
    "1. Match the strings you trying to extract, and possibly some context around them, to guarantee you\n",
    "   are extracting the right information;\n",
    "2. If your expression matches context as well as the information you are trying to extract,\n",
    "   (and often it will have to) you need to identify the target part of  the expression.  This is done by placing the target part of \n",
    "   the pattern in parentheses (illustrated below).\n",
    "   \n",
    "The exercise below asks you to extract the baby name year in the html file.  The line containing the relevant information looks like this\n",
    "     \n",
    "     <h3 align=\"center\">Popularity in 1990</h3>\n",
    "     \n",
    "One regular expression that will match the year is the following:\n",
    "\n",
    "       '\\d\\d\\d\\d'\n",
    "\n",
    "This matches any sequence of 4 digits. The code below tries out this idea.  Evaluate it and report on the  success of the idea in the markdown cell below the code cell.  \n",
    "\n",
    "Before looking at the HTML itself, look at how it's suposed to render, in the cell below.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0CZXos-rDso"
   },
   "source": [
    "<head><title>Popular Baby Names</title>\n",
    "<meta name=\"dc.language\" scheme=\"ISO639-2\" content=\"eng\">\n",
    "<meta name=\"dc.creator\" content=\"OACT\">\n",
    "<meta name=\"lead_content_manager\" content=\"JeffK\">\n",
    "<meta name=\"coder\" content=\"JeffK\">\n",
    "<meta name=\"dc.date.reviewed\" scheme=\"ISO8601\" content=\"2005-12-30\">\n",
    "<link rel=\"stylesheet\" href=\"../OACT/templatefiles/master.css\" type=\"text/css\" media=\"screen\">\n",
    "<link rel=\"stylesheet\" href=\"../OACT/templatefiles/custom.css\" type=\"text/css\" media=\"screen\">\n",
    "<link rel=\"stylesheet\" href=\"../OACT/templatefiles/print.css\" type=\"text/css\" media=\"print\">\n",
    "</head>\n",
    "<body bgcolor=\"#ffffff\" text=\"#000000\" topmargin=\"1\" leftmargin=\"0\">\n",
    "<table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"4\">\n",
    "  <tbody>\n",
    "  <tr><td class=\"sstop\" valign=\"bottom\" align=\"left\" width=\"25%\">\n",
    "      Social Security Online\n",
    "    </td><td valign=\"bottom\" class=\"titletext\">\n",
    "      <!-- sitetitle -->Popular Baby Names\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#333366\"><td colspan=\"2\" height=\"2\"></td></tr>\n",
    "  <tr><td class=\"graystars\" width=\"25%\" valign=\"top\">\n",
    "       <a href=\"../OACT/babynames/\">Popular Baby Names</a></td><td valign=\"top\"> \n",
    "      <a href=\"http://www.ssa.gov/\"><img src=\"http://www.ssa.gov/templateimages/tinylogo.gif\"\n",
    "      width=\"52\" height=\"47\" align=\"left\"\n",
    "      alt=\"SSA logo: link to Social Security home page\" border=\"0\"></a><a name=\"content\"></a>\n",
    "      <h1>Popular Names by Birth Year</h1>September 12, 2007</td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#333366\"><td colspan=\"2\" height=\"1\"></td></tr>\n",
    "</tbody></table>\n",
    "<table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"4\" summary=\"formatting\">\n",
    "  <tr valign=\"top\"><td width=\"25%\" class=\"greycell\">\n",
    "      <a href=\"../OACT/babynames/background.html\">Background information</a>\n",
    "      <p><br />\n",
    "      &nbsp; Select another <label for=\"yob\">year of birth</label>?<br />      \n",
    "      <form method=\"post\" action=\"/cgi-bin/popularnames.cgi\">\n",
    "      &nbsp; <input type=\"text\" name=\"year\" id=\"yob\" size=\"4\" value=\"1990\">\n",
    "      <input type=\"hidden\" name=\"top\" value=\"1000\">\n",
    "      <input type=\"hidden\" name=\"number\" value=\"\">\n",
    "      &nbsp; <input type=\"submit\" value=\"   Go  \"></form>\n",
    "    </td><td>\n",
    "<h3 align=\"center\">Popularity in 1990</h3>\n",
    "<p align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following\n",
    "cell, we give the HTML string for generating the cell above and some code for searching it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZR87R4ghZMY",
    "outputId": "6c8464ea-abb4-4957-e6b3-b3065d2c4c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8601\n",
      "2005\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "html_string = \"\"\"\n",
    "<head><title>Popular Baby Names</title>\n",
    "<meta name=\"dc.language\" scheme=\"ISO639-2\" content=\"eng\">\n",
    "<meta name=\"dc.creator\" content=\"OACT\">\n",
    "<meta name=\"lead_content_manager\" content=\"JeffK\">\n",
    "<meta name=\"coder\" content=\"JeffK\">\n",
    "<meta name=\"dc.date.reviewed\" scheme=\"ISO8601\" content=\"2005-12-30\">\n",
    "<link rel=\"stylesheet\" href=\"../OACT/templatefiles/master.css\" type=\"text/css\" media=\"screen\">\n",
    "<link rel=\"stylesheet\" href=\"../OACT/templatefiles/custom.css\" type=\"text/css\" media=\"screen\">\n",
    "<link rel=\"stylesheet\" href=\"../OACT/templatefiles/print.css\" type=\"text/css\" media=\"print\">\n",
    "</head>\n",
    "<body bgcolor=\"#ffffff\" text=\"#000000\" topmargin=\"1\" leftmargin=\"0\">\n",
    "<table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"4\">\n",
    "  <tbody>\n",
    "  <tr><td class=\"sstop\" valign=\"bottom\" align=\"left\" width=\"25%\">\n",
    "      Social Security Online\n",
    "    </td><td valign=\"bottom\" class=\"titletext\">\n",
    "      <!-- sitetitle -->Popular Baby Names\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#333366\"><td colspan=\"2\" height=\"2\"></td></tr>\n",
    "  <tr><td class=\"graystars\" width=\"25%\" valign=\"top\">\n",
    "       <a href=\"../OACT/babynames/\">Popular Baby Names</a></td><td valign=\"top\"> \n",
    "      <a href=\"http://www.ssa.gov/\"><img src=\"/templateimages/tinylogo.gif\"\n",
    "      width=\"52\" height=\"47\" align=\"left\"\n",
    "      alt=\"SSA logo: link to Social Security home page\" border=\"0\"></a><a name=\"content\"></a>\n",
    "      <h1>Popular Names by Birth Year</h1>September 12, 2007</td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#333366\"><td colspan=\"2\" height=\"1\"></td></tr>\n",
    "</tbody></table>\n",
    "<table width=\"100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"4\" summary=\"formatting\">\n",
    "  <tr valign=\"top\"><td width=\"25%\" class=\"greycell\">\n",
    "      <a href=\"../OACT/babynames/background.html\">Background information</a>\n",
    "      <p><br />\n",
    "      &nbsp; Select another <label for=\"yob\">year of birth</label>?<br />      \n",
    "      <form method=\"post\" action=\"/cgi-bin/popularnames.cgi\">\n",
    "      &nbsp; <input type=\"text\" name=\"year\" id=\"yob\" size=\"4\" value=\"1990\">\n",
    "      <input type=\"hidden\" name=\"top\" value=\"1000\">\n",
    "      <input type=\"hidden\" name=\"number\" value=\"\">\n",
    "      &nbsp; <input type=\"submit\" value=\"   Go  \"></form>\n",
    "    </td><td>\n",
    "<h3 align=\"center\">Popularity in 1990</h3>\n",
    "<p align=\"center\">\n",
    "\"\"\"\n",
    "re1 = r'\\d\\d\\d\\d'\n",
    "re1_revised = r'[12]\\d\\d\\d'\n",
    "match = re.search(re1,html_string)\n",
    "match_two = re.search(re1_revised,html_string)\n",
    "# match object tells you positions in string where match begins and ends (match.start() and match.end()).  \n",
    "# Let's look at  this span\n",
    "\n",
    "#match = None\n",
    "#match_two = None\n",
    "if match:\n",
    "   print(html_string[match.start():match.end()])\n",
    "if match_two:\n",
    "   print(html_string[match_two.start():match_two.end()])\n",
    "   #print(match_two.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hmsr3VZhZMd"
   },
   "source": [
    "Discuss how well this regular expression worked at extracting the year \n",
    "the data was last modified. If it failed, explain why.\n",
    "You may edit the cell above.\n",
    "\n",
    "This exercise should have convinced you needed to amend the regular expression to provide some contexts; 4 digits in a row, even if the first is required to be 1 or 2, won't do it.  In the next cell, define and test a new regular expression that does\n",
    "the job. You may want to try some of the exercises in the following sections first, to get some practice with regular expressions.\n",
    "\n",
    "But  here is a hint.  Use look-behind assertion, \n",
    "\n",
    "If a regular expression contains a look-behind assertion, then the matching part of the expression will\n",
    "only count as a match if it is preceded by the expression matching the look-behind assertion.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "r'def'\n",
    "```\n",
    "\n",
    "matches the string `'def'` in any context.  \n",
    "\n",
    "```\n",
    "r'(?<=abc)def'\n",
    "```\n",
    "\n",
    "matches the string `'def'`  only when it is preceded by abc:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_6H5mWKvhZMe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def']\n",
      "['def', 'def']\n"
     ]
    }
   ],
   "source": [
    "test_str = 'abcdefhij defcon 4'\n",
    "\n",
    "print(re.findall(r'(?<=abc)def',test_str))\n",
    "\n",
    "print(re.findall(r'def',test_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the behavior of `findall` in line 3, the lookahead assertion is not\n",
    "part of the match.  It merely constrains what counts as a match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJ70IZgFhZMh"
   },
   "source": [
    "For the next html string, you want to find ALL the triples of the form RANK, MALE NAME, FEMALE NAME.\n",
    "Your output should look like this:\n",
    "\n",
    "   [('1', 'Jacob', 'Emma'), ('2', 'Michael', 'Isabella'), ('3', 'Ethan', 'Emily')]\n",
    "   \n",
    "You can get this using `re.findall`.  The next cell gives you a pretty helpful example of how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41dry_76hZMh",
    "outputId": "a506dbdb-b4c0-426d-8911-101d598dfae7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<tr align=\"right\"><td>1</td>',\n",
       "  '<tr align=\"right\"><td>2</td>',\n",
       "  '<tr align=\"right\"><td>3</td>'],\n",
       " ['1', '2', '3'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "html_str2 = \"\"\"<tr align=\"center\" valign=\"bottom\">\n",
    "  <th scope=\"col\" width=\"12%\" bgcolor=\"#efefef\">Rank</th>\n",
    "  <th scope=\"col\" width=\"41%\" bgcolor=\"#99ccff\">Male name</th>\n",
    "<th scope=\"col\" bgcolor=\"pink\" width=\"41%\">Female name</th></tr>\n",
    "<tr align=\"right\"><td>1</td><td>Jacob</td><td>Emma</td>\n",
    "</tr>\n",
    "<tr align=\"right\"><td>2</td><td>Michael</td><td>Isabella</td>\n",
    "</tr>\n",
    "<tr align=\"right\"><td>3</td><td>Ethan</td><td>Emily</td>\n",
    "</tr>\"\"\"\n",
    "res1 = re.findall(r'<tr\\s+.+><td>\\d+</td>',html_str2)\n",
    "res2 = re.findall(r'<tr\\s+.+><td>(\\d+)</td>',html_str2)\n",
    "\n",
    "(res1, res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKSwyHBshZMk"
   },
   "source": [
    "Notice the very different results you get with very similar `findall` requests.  The function `findall` is written so as to retrieve the **groups** in your regular expression. The groups in your regular expression are defined by parentheses.  If there are no groups (no parentheses), `findall` returns a list of complete matches.  So the first result above is what you get for a regular expression with no groups, and the second is what you get for a regular expression with one group.  If your regular expression contains multiple groups, you get a list of tuples.  Each tuple member corresponds to one group in the pattern.  Since you're being asked for a result that is a list of triples, you want a regular expression with 3 groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_S1smaothZMk"
   },
   "source": [
    "## Solving crosswords (requires NLTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpEoSVBThZMl"
   },
   "source": [
    "The following example is adapted from [the NLTK Book, Ch. 3.](http://www.nltk.org/book/ch03.html)\n",
    "\n",
    "Let's say we're in the midst of doing a cross word puzzle and we need an 8-letter word\n",
    "whose third letter is *j* and whose sixth letter is *t* which means\n",
    "*sad*.   We emphasize any matching word must be **exactly** 8 letters long.\n",
    "For \"majestic\" satisfies the constraints' \"majestically\" does not. \n",
    "Make sure your regular expression respects that requirement.\n",
    "(Your regular expression will need to use \"^\", the beginning of input marker\n",
    "and \"$\", the end of input marker)(,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_iEfiONhZMo",
    "outputId": "74fd562c-3984-4c67-ceba-c3e1a46ee0a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.5\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the correct answer is shown after the cell below.  To preserve it for\n",
    "comparison, you can edit the cell **after** the next one, which is identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lr2MLj6ThZMq",
    "outputId": "dfeab903-8c4f-4eae-b0e5-bcbff5c85395",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abjectly',\n",
       " 'adjuster',\n",
       " 'dejected',\n",
       " 'dejectly',\n",
       " 'injector',\n",
       " 'majestic',\n",
       " 'objectee',\n",
       " 'objector',\n",
       " 'rejecter',\n",
       " 'rejector',\n",
       " 'unjilted',\n",
       " 'unjolted',\n",
       " 'unjustly']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import words\n",
    "wds = words.words()\n",
    "print(len(wds))\n",
    "# Put your regex inplace of xxx in the next line\n",
    "regex = r'xxx'\n",
    "#235786\n",
    "cands = [w for w in wds if re.search(regex,w)]\n",
    "# The correct output is shown below.\n",
    "cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import words\n",
    "wds = words.words()\n",
    "print(len(wds))\n",
    "# Put your regex inplace of xxx in the next line\n",
    "regex = r'xxx'\n",
    "#235786\n",
    "cands = [w for w in wds if re.search(regex,w)]\n",
    "# The correct output is shown below.\n",
    "cands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swk4Jb2thZMs"
   },
   "source": [
    "So looking over the candidates, what is the word we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b54khw00hZMt"
   },
   "source": [
    "## Textonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_rSqda-hZMt"
   },
   "source": [
    "The [NLTK Book, Ch. 3](http://www.nltk.org/book/ch03.html)introduces the following\n",
    "concept of **textonym** with this definition:\n",
    "\n",
    "   The T9 system is used for entering text on mobile phones: Two or more words that are \n",
    "   ent\n",
    "   ered with the same sequence of keystrokes are known as textonyms. For example, \n",
    "   both *hole* and *golf* are entered by pressing the sequence `4653`.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=https://www.nltk.org/images/T9.png width=500>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "img_data = 'https://www.nltk.org/images/T9.png'\n",
    "HTML(f'<img src={img_data} width=500>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_rSqda-hZMt"
   },
   "source": [
    " What other words could be produced with the same sequence? \n",
    "\n",
    "   Here we  could use the regular expression `'^[ghi][mno][jkl][def]$'`.  \n",
    "\n",
    "    >>> [w for w in wds if re.search('^[ghi][mno][jkl][def]$', w)]\n",
    "    ['gold', 'golf', 'hold', 'hole']\n",
    "\n",
    "Try the following.  Find all words that can be spelled out with the sequence\n",
    "`3456`.  Correct output shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8quLB7YWhZMu",
    "outputId": "58d6fca0-a268-4dba-e889-22a78ea98651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'dilo', u'film', u'filo']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your answer in place of xxx in the line bbeflow\n",
    "regex = r'xxx'\n",
    "[w for w in wds if re.search(regex, w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find all words that can be spelled out with the sequence 4653."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1lFhQwzhZMw",
    "outputId": "ef0d5bf0-3ca8-47b0-a47d-88877d9393f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'gold', u'golf', u'hold', u'hole', u'gold', u'hole']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r'xxx'\n",
    "[w for w in wds if re.search(regex, w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqi4xES5hZMy"
   },
   "source": [
    "## Regular expression practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hECvv1mdhZMy",
    "outputId": "36c81113-2c37-4718-b7d9-0e427b77180f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\w\\w\\w\n",
      "\\w\\w\\w\n",
      "\\w\\w\\w\n",
      "<re.Match object; span=(0, 3), match='bcd'>\n",
      "<re.Match object; span=(0, 3), match='1bd'>\n",
      "<re.Match object; span=(0, 3), match='b1d'>\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(0, 3), match='bda'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pat = r'a|b|c'\n",
    "pat2 = r'[abc]'\n",
    "pat3 = r'\\w\\w\\w'\n",
    "print(pat3)\n",
    "pat4 = '\\\\w\\\\w\\\\w'\n",
    "print(pat4)\n",
    "print(re.match(pat3,'bcd'))\n",
    "print(re.match(pat3,'1bd'))\n",
    "print(re.match(pat3,'b1d'))\n",
    "print(re.match(pat3,'b-d'))\n",
    "print(re.match(pat3,'b?d'))\n",
    "print(re.match(pat3,'b d'))\n",
    "print(re.match(pat3,'bda '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LX8EUE7_hZM0"
   },
   "source": [
    "Edit this cell and after each regular expression, describe the class of strings it matches.  Check your answer examining the output of the code cell that follows.\n",
    "\n",
    "1.  [a-zA-Z]+\n",
    "2.  [A-Z][a-z]*\n",
    "3.  \\d+(\\.\\d+)?\n",
    "4.  ([bcdfghjklmnpqrstvwxyz][aeiou][bcdfghjklmnpqrstvwxyz])*\n",
    "5.  \\w+|[^\\w\\s]+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "duu2owuIhZM1",
    "outputId": "d8766ccc-777c-4213-95da-25bb0ea1c694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "re2 [a-zA-Z]+\n",
      "=============\n",
      "\n",
      "   1. abracadabra                                    abracadabra\n",
      "   2. 1billygoat                                     None\n",
      "   3. billygoat1                                     billygoat\n",
      "   4. 43.1789                                        None\n",
      "   5. 43x1789                                        None\n",
      "   6. 43.                                            None\n",
      "   7. 43                                             None\n",
      "   8. road_runner                                    road\n",
      "   9.  road_runner                                   None\n",
      "  10. bathos                                         bathos\n",
      "  11. The little dog laughed to see such a sight.    The\n",
      "  12. socrates                                       socrates\n",
      "  13. Socrates                                       Socrates\n",
      "  14. *&%#!?                                         None\n",
      "  15. IBM                                            IBM\n",
      "\n",
      "re3 [A-Z][a-z]+\n",
      "===============\n",
      "\n",
      "   1. abracadabra                                    None\n",
      "   2. 1billygoat                                     None\n",
      "   3. billygoat1                                     None\n",
      "   4. 43.1789                                        None\n",
      "   5. 43x1789                                        None\n",
      "   6. 43.                                            None\n",
      "   7. 43                                             None\n",
      "   8. road_runner                                    None\n",
      "   9.  road_runner                                   None\n",
      "  10. bathos                                         None\n",
      "  11. The little dog laughed to see such a sight.    The\n",
      "  12. socrates                                       None\n",
      "  13. Socrates                                       Socrates\n",
      "  14. *&%#!?                                         None\n",
      "  15. IBM                                            None\n",
      "\n",
      "re4 \\d+(\\.\\d+)?\n",
      "===============\n",
      "\n",
      "   1. abracadabra                                    None\n",
      "   2. 1billygoat                                     1\n",
      "   3. billygoat1                                     None\n",
      "   4. 43.1789                                        43.1789\n",
      "   5. 43x1789                                        43\n",
      "   6. 43.                                            43\n",
      "   7. 43                                             43\n",
      "   8. road_runner                                    None\n",
      "   9.  road_runner                                   None\n",
      "  10. bathos                                         None\n",
      "  11. The little dog laughed to see such a sight.    None\n",
      "  12. socrates                                       None\n",
      "  13. Socrates                                       None\n",
      "  14. *&%#!?                                         None\n",
      "  15. IBM                                            None\n",
      "\n",
      "re5 ([bcdfghjklmnpqrstvwxyz][aeiou][bcdfghjklmnpqrstvwxyz])*\n",
      "============================================================\n",
      "\n",
      "   1. abracadabra                                    \n",
      "   2. 1billygoat                                     \n",
      "   3. billygoat1                                     bil\n",
      "   4. 43.1789                                        \n",
      "   5. 43x1789                                        \n",
      "   6. 43.                                            \n",
      "   7. 43                                             \n",
      "   8. road_runner                                    \n",
      "   9.  road_runner                                   \n",
      "  10. bathos                                         bathos\n",
      "  11. The little dog laughed to see such a sight.    \n",
      "  12. socrates                                       socrat\n",
      "  13. Socrates                                       \n",
      "  14. *&%#!?                                         \n",
      "  15. IBM                                            \n",
      "\n",
      "re6 \\w+|[^\\w\\s]+\n",
      "================\n",
      "\n",
      "   1. abracadabra                                    abracadabra\n",
      "   2. 1billygoat                                     1billygoat\n",
      "   3. billygoat1                                     billygoat1\n",
      "   4. 43.1789                                        43\n",
      "   5. 43x1789                                        43x1789\n",
      "   6. 43.                                            43\n",
      "   7. 43                                             43\n",
      "   8. road_runner                                    road_runner\n",
      "   9.  road_runner                                   None\n",
      "  10. bathos                                         bathos\n",
      "  11. The little dog laughed to see such a sight.    The\n",
      "  12. socrates                                       socrates\n",
      "  13. Socrates                                       Socrates\n",
      "  14. *&%#!?                                         *&%#!?\n",
      "  15. IBM                                            IBM\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "###     Some regular expressions     ###\n",
    "########################################\n",
    "\n",
    "re2 = r'[a-zA-Z]+'   #Any string consisting of ltters of the alphabet, upper or lower case\n",
    "re3 = r'[A-Z][a-z]+'  \n",
    "re4 = r'\\d+(\\.\\d+)?'\n",
    "re5 = r'([bcdfghjklmnpqrstvwxyz][aeiou][bcdfghjklmnpqrstvwxyz])*'\n",
    "re6 = r'\\w+|[^\\w\\s]+'\n",
    "\n",
    "res = [re2,re3,re4,re5,re6]\n",
    "\n",
    "########################################\n",
    "###     Some example strings         ###\n",
    "########################################\n",
    "\n",
    "example1 = 'abracadabra'\n",
    "example2 = '1billygoat'\n",
    "example3 = 'billygoat1'\n",
    "example4 = '43.1789'\n",
    "example4a = '43x1789'\n",
    "example5 = '43.'\n",
    "example6 = '43'\n",
    "example7 = 'road_runner'\n",
    "example8 = ' road_runner'\n",
    "example9 = 'bathos'\n",
    "example10 = \"The little dog laughed to see such a sight.\"\n",
    "example11 = 'socrates'\n",
    "example12 = 'Socrates'\n",
    "example13 = '*&%#!?'\n",
    "example14 = 'IBM'\n",
    "\n",
    "examples = [example1,example2,example3,example4,example4a,example5,example6,\n",
    "            example7,example8,example9,example10,example11,example12,example13,\n",
    "            example14]\n",
    "\n",
    "########################################\n",
    "###     Trying some matches          ###\n",
    "########################################\n",
    "\n",
    "for i,re_pat in enumerate(res):\n",
    "    banner = 're%d %s' % (i+2,re_pat)\n",
    "    print() \n",
    "    print(banner)\n",
    "    print('=' * len(banner))\n",
    "    print()\n",
    "    for (i,ex) in enumerate(examples):\n",
    "        match = re.match(re_pat,ex)\n",
    "        if match:\n",
    "            print('  %2d. %-45s  %s' % (i+1,ex,ex[match.start():match.end()]))  \n",
    "        else:\n",
    "            print('  %2d. %-45s  %s' %(i+1,ex,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kzxDfCAhZM3"
   },
   "source": [
    "Make sure you can answer the following questions about the results of testing these regular expressions on the examples:\n",
    "\n",
    "1. Why does `re2` succeed on only part  of (8)?\n",
    "1. Why does `re3` only succeed on (11) and (13)?  Be sure to explain why it fails\n",
    "   on (15).\n",
    "1. When 're4' matches (6), why isn't the decimal point part of the match?\n",
    "1. All of the regular expressions except `re5` report a `None` with at least one\n",
    "   one of the examples.  Why doesn't `re5` report any `None`s?\n",
    "1. Why does `re6` match all the characters in (14)?\n",
    "1. Why doesn't `re6` match (9)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcdP69dzhZM3"
   },
   "source": [
    "## An example that requires NLTK to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/gawron/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMnXmijJhZM4"
   },
   "source": [
    "   To run the code for this example, you will use a **balanced corpus**\n",
    "   of English texts, a corpus collected with the purpose of representing\n",
    "   a balanced variety of English text types: fiction, poetry, speech,\n",
    "   non fiction, and so on.  One relatively well-established, free,\n",
    "   and easy-to-get example of such a corpus is the **Brown Corpus.**\n",
    "   Brown is about 1.2 M words. \n",
    "   \n",
    "   You can import the corpus as follows::\n",
    "\n",
    "     >>> from nltk.corpus import brown\n",
    "\n",
    "\n",
    "   If this does not work, it is because you have nltk installed without the accompanying\n",
    "   corpora. You can download any nltk corpus you need through the `nltk.download` function For example,\n",
    "   to get the Brown corpus, do the following in Python::\n",
    "      \n",
    "      >>> import nltk\n",
    "      >>> nltk.download('brown')\n",
    "\n",
    "   You may be told:\n",
    "   \n",
    "   ```\n",
    "   Package brown is already up-to-date!\n",
    "   ```\n",
    "   \n",
    "   or your current nltk install will update `brown`.\n",
    "   You can then import the `brown` corpus as follows:\n",
    "\n",
    "     >>> from nltk.corpus import brown\n",
    "\n",
    "   The following returns a list of all 1.2 M word tokens in Brown:\n",
    "\n",
    "     >>> brown.words()\n",
    "     ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w-izkp1qhZM4",
    "outputId": "d2633c06-42e4-4fd5-c118-a4338fd8c39b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 2787),\n",
       " ('ea', 2249),\n",
       " ('ou', 1855),\n",
       " ('ie', 1799),\n",
       " ('ia', 1400),\n",
       " ('ee', 1289),\n",
       " ('oo', 1174),\n",
       " ('ai', 1145),\n",
       " ('ue', 541),\n",
       " ('au', 540),\n",
       " ('ua', 502),\n",
       " ('ei', 485),\n",
       " ('ui', 483),\n",
       " ('oa', 466),\n",
       " ('oi', 412),\n",
       " ('eo', 250),\n",
       " ('iou', 225),\n",
       " ('eu', 187),\n",
       " ('oe', 181),\n",
       " ('iu', 128),\n",
       " ('ae', 85),\n",
       " ('eau', 54),\n",
       " ('uo', 53),\n",
       " ('eou', 52),\n",
       " ('uou', 37)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From http://www.nltk.org/book/ch03.html\n",
    "#  Find the most common vowel sequences in English.  Note: be patient.  Evaluating this may take a while.\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "bw = sorted(set(brown.words()))\n",
    "# Find every instance of two or more consecutive vowels, and count tokens of each.\n",
    "# Replace the xxx  in the string below to provide your answer (Hint: Use the regex construction\n",
    "# mean 2 or more matches for the preceding expression.)\n",
    "regex = r'xxx'\n",
    "ctr = Counter(vs  for word in bw for vs in re.findall(regex,word))\n",
    "\n",
    "#Correct output shown\n",
    "ctr.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is kind of a surprise (surely \"ea\" and \"ou\" are more natural than \"io\"!), but there is no bug.  The vowel sequence \"io\" occurs in more  English words than any other vowel sequence.  Can you think why?\n",
    "\n",
    "Using the the code above as inspiration, find all the English words containing the vowel sequence \"uou\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KX8CArFchZM7"
   },
   "source": [
    "## Poker examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5cIl0d4hZM7"
   },
   "source": [
    "Suppose you are writing a poker program where a player’s hand is represented as a 5-character string with each character representing a card, “a” for ace, “k” for king, “q” for queen, “j” for jack, “t” for 10, and “2” through “9” representing the card with that value.\n",
    "\n",
    "To see if a given string is a valid hand, one could run the code in t he following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "138N5RlQhZM7",
    "outputId": "b0421c74-dc4e-4279-c078-21173882abf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akt5q      [akt5q]\n",
      "akt5e      None\n",
      "akt        None\n",
      "727ak      [727ak]\n",
      "727aka     None\n",
      "aaaaa      [aaaaa]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def displaymatch(regex,text):\n",
    "    match = regex.match(text)\n",
    "    if match is None:\n",
    "        matchstring = None\n",
    "    else:\n",
    "        matchstring = '%s[%s]%s' % (text[:match.start()],text[match.start():match.end()],text[match.end():])\n",
    "    print('%-10s %s' % (text,matchstring))\n",
    "\n",
    "valid = re.compile(r\"^[a2-9tjqk]{5}$\")\n",
    "\n",
    "## Some examples\n",
    "displaymatch(valid, \"akt5q\")  # Valid.\n",
    "displaymatch(valid, \"akt5e\")  # Invalid.\n",
    "displaymatch(valid, \"akt\")    # Invalid.\n",
    "displaymatch(valid, \"727ak\")  # Valid.\n",
    "displaymatch(valid, \"727aka\")  # Invalid.\n",
    "displaymatch(valid, \"aaaaa\")  # Invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOoX-QzshZM9"
   },
   "source": [
    "The hand \"727ak\" contains a pair, and we would like to recognize such hands as special, so that we can go all in.  We can do this using regular expression groups and register references.  The match for each parenthesized part of a regular expression is called a **group**.  We can refer back to the particular match  associated with a group with \\integer.  Where integer is any integer from 1 through 9.  \\1 refers to the first group, \\2 to the second, and so on.  So to match poker hands with pairs, we do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SckCAlchZM-",
    "outputId": "b7e88536-13c3-4ab7-e68e-b67a6fc001bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727ak      [727ak]\n",
      "723ak      None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = re.compile(r\".*(.).*\\1.*\")\n",
    "displaymatch(pair,\"727ak\")\n",
    "displaymatch(pair,\"723ak\")\n",
    "pair.match(\"727ak\").groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoGfgo3vhZM_",
    "outputId": "f3c0e53c-ae25-4c9d-9630-435565d283aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2aak      [a2aak]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displaymatch(pair,\"a2aak\")\n",
    "pair.match(\"aa2ak\").groups()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlLIFiR1hZNC"
   },
   "source": [
    "Of course, the regex `pair` does not require the text string to be a Poker hand.  We could revise it to do that and if you think about it a little, it would actually make the regex  **a lot** more complicated.  What we could do instead is first apply `valid` to guarantee we've got a valid poker hand and then apply `pair` to find out if it contains a pair. This makes both regexes simple and easy to understand and still enforce all the constraints we want.  Often a good strategy in applying regexes to enforce some complicated constraints is to divide the constraints up into separate categories and apply them **in succession.**.  \n",
    "\n",
    "A problem with `pair` is that it doesnt tell us  what we've got a pair of.  Actually, the match object contains this information.  It has an attribute called `groups` which contains all portions of the string that matched a group.  We can use a revised version of `displaymatch` to print this, when requested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUReunuhhZND",
    "outputId": "a567ba27-9f3a-4d41-fbdf-92fc3337f62e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair\n",
      "723ak      None\n",
      "7a3ak      [7a3a]k ('a',)\n",
      "\n",
      "two pair\n",
      "7a272      [7a272] ('7', '2')\n",
      "722a7      None\n",
      "7722a      None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def displaymatch(regex,text, print_groups=False):\n",
    "    match = regex.match(text)\n",
    "    if match is None:\n",
    "        matchstring = None\n",
    "    else:\n",
    "        matchstring = '%s[%s]%s' % (text[:match.start()],text[match.start():match.end()],text[match.end():])\n",
    "    if print_groups and match:\n",
    "        print('%-10s %s %s' % (text,matchstring,match.groups()))\n",
    "    else:\n",
    "        print('%-10s %s' % (text,matchstring))\n",
    "\n",
    "# Re for recognizing pair hands\n",
    "pair = re.compile(r\".*(.).*\\1\")\n",
    "print(\"pair\")\n",
    "displaymatch(pair,\"723ak\",print_groups=True)\n",
    "displaymatch(pair,\"7a3ak\",print_groups=True)\n",
    "print()\n",
    "## Write your regex for recognizing two pair below. Test\n",
    "## This version is not adequate. Look at the examples to see why.\n",
    "print(\"two pair\")\n",
    "two_pair = re.compile(r\".*(.).*(.).*\\1.*\\2.*\")\n",
    "displaymatch(two_pair,\"7a272\",print_groups=True)\n",
    "displaymatch(two_pair,\"722a7\",print_groups=True)  # shd succeed, does not\n",
    "displaymatch(two_pair,\"7722a\",print_groups=True)  # shd succeed, does not\n",
    "#displaymatch(two_pair,\"7a722\",print_groups=True)\n",
    "#displaymatch(two_pair,\"727a2\",print_groups=True)\n",
    "#displaymatch(two_pair,\"aaaa2\",print_groups=True)  # Will succeed on this one, but that's ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAIyZ1w8hZNF"
   },
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2xpJMIphZNF"
   },
   "source": [
    "1.  Write regexes that match three-of-a-kind hands,  and four-of-a-kind hands.  Follow the model of `pairs` and dont bother to\n",
    "    guarantee that it's a valid Poker hand.\n",
    "2.  It's quite complex to write a regular expression that checks to see if you've got a straight, but you can try the \n",
    "    following strategy.  First, verify you've got a valid poker hand; then verify you havent got a pair, three-of-kind, or\n",
    "    four-of-a-kind.  So you have a valid poker hand with no repetitions and you dont need the regex that checks for straights\n",
    "    to rule those out.\n",
    "    \n",
    "    Now write a regex that will check to see if a valid poker hand \n",
    "    with no repetitions is a straight  beginning with '2'.  It should succeed on `23456` and `25643` and `32654` and it should fail\n",
    "    `24357`.  To deal with all possible straights in this way, how many cases are there to take care of?  Write a single regular\n",
    "    expression that will identify any straight, given that it is a valid poker hand with no repetitions.  Test it on the \n",
    "    straights above and on straights like `akqjt` and on the non-straight `24357`.\n",
    "3.  Write a regex that matches a two pair hand. This is tricky and the most natural answer will also match four-of-a-kind. \n",
    "    Assume we've eliminated that possibility by failing to match the four-of-kind pattern from 1.  You should \n",
    "    test `722a7`, `7a722` and `727a2`.  You will need a pattern that is a big disjunction using `|`, and you will need to\n",
    "    enclose the disjuncts of this big disjunction in parentheses, but for that purpose you will need parentheses that don't\n",
    "    count as defining a retrievable group.  The notation for that is `(?:` instead of `(` [the same right paren is used \n",
    "    in both cases]. See [Python regex docs.](http://docs.python.org/2/library/re.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EW2aah3nhZNF"
   },
   "source": [
    "## How to do extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kydJuzZDhZNG"
   },
   "source": [
    "The following example is from `The weather underground page for San Diego <http://www.wunderground.com/weather-forecast/US/CA/San_Diego.html>`_.  The temperature is regularly given in a page division (HTML tag `div`) with ID (HTML attribute `divID`) `NowTemp`.  If we can find that division and the temperature inside it, we have what we want.  The pattern needs to be compiled with flags that allow it to match across multiple lines, because the context that identifies the temperature does not occur on the same line as the temperature.  Compiling regular expressions also makes them more efficient when reused.  A key point is that we place the actual temperature we want inside parentheses, the `(\\d{1,3}\\.\\d)` part of the pattern.  Portions of a pattern that occur in parentheses and are matched are placed ins the `groups` attribute of  the match object.  The groups attribute is a tuple of all the matched strings in parentheses in the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxgTxaZEhZNG",
    "outputId": "9b4d2c18-4e27-4e01-94f4-d74b06072e8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['55.8']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "html_string = \"\"\"\n",
    "<div class=\"br10\" id=\"stationSelect\">\n",
    "\t\t<a class=\"br10\" id=\"stationselector_button\" href=\"javascript:void(0);\" onclick=\"_gaq.push(['_trackEvent', 'Station Select', 'Opened']);\"><span>Station Select</span></a>\n",
    "\t\t</div>\n",
    "\t\t</div>\n",
    "\t\t<div id=\"conds_dashboard\">\n",
    "\t\t<div id=\"hour00\">\n",
    "\t\t<div id=\"nowCond\">\n",
    "\t\t<div class=\"titleSubtle\">Now</div>\n",
    "\t\t<div id=\"curIcon\"><a href=\"\" class=\"iconSwitchBig\"><img src=\"http://icons-ak.wxug.com/i/c/k/nt_partlycloudy.gif\" width=\"44\" height=\"44\" alt=\"Scattered Clouds\" class=\"condIcon\" /></a></div>\n",
    "\t\t<div id=\"curCond\">Scattered Clouds</div>\n",
    "\t\t</div>\n",
    "\t\t<div id=\"nowTemp\">\n",
    "\t\t<div class=\"titleSubtle\">Temperature</div>\n",
    "\t\t<div id=\"tempActual\"><span id=\"rapidtemp\" class=\"pwsrt\" pwsid=\"KCASANDI123\" pwsunit=\"english\" pwsvariable=\"tempf\" english=\"&deg;F\" metric=\"&deg;C\" value=\"55.8\">\n",
    "  <span class=\"nobr\"><span class=\"b\">55.8</span>&nbsp;&deg;F</span>\n",
    "</span></div>\n",
    "\t\t<div id=\"tempFeel\">Feels Like\n",
    "  <span class=\"nobr\"><span class=\"b\">55.1</span>&nbsp;&deg;F</span>\n",
    "</div>\n",
    "\t\t</div>\n",
    "\"\"\"\n",
    "pattern = r'<div\\s+id\\s*=\\s*\\\"tempActual\\\"\\s*>.*?(\\d{1,3}\\.\\d).*?</div>'\n",
    "pattern_re = re.compile(pattern,re.MULTILINE | re.DOTALL)\n",
    "#m = re.search(pattern_re,html_string)\n",
    "#m.groups()\n",
    "pattern_re.findall(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9JJWNmjhZNI"
   },
   "source": [
    "The pattern in the example above was built up piece by piece.  First we built a regular expression matching the `<div id=\"nowTemp\">` part of the pattern.  That piece looked like this:\n",
    "    \n",
    "     subpattern = r'<div\\s+id\\s*=\\s*\\\"nowTemp\\\"\\s*>\n",
    " \n",
    " The `\\s*` aren't needed for this particular string, but there is considerable variation in how actual HTML is generated, and since\n",
    " white space in the `\\s*` positions wouldn't be meaningful, it is allowed.  Next we tested the core part of the pattern on its own:\n",
    " \n",
    "     corepattern = r'(\\d{1,3}\\.\\d)'\n",
    "  \n",
    "  Finally we tested the last part:\n",
    "  \n",
    "     lastpattern = r`</div>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTIj2KKOhZNJ"
   },
   "source": [
    "## Tokenization  (NLTK assumed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qdnCsZnhZNK"
   },
   "source": [
    "Tokenization is the process of breaking up a text into words.  We have in some cases used `split()` for this purpose, uniformly splitting a text up into words on the spaces, but this doesn't always yield the right results, as the next examples show.\n",
    "\n",
    "There are three tokenizations of `text` string defined in the cell\n",
    "below, `try1`, `try2`, and `try3`; `try1` shows what happens\n",
    "when we just use the Python `split`; `try2` and `try3` use a regular\n",
    "expression that defines different cases of a proper word,\n",
    "such as \n",
    "\n",
    "1. an abbreviation with periods\n",
    "2. an ordinary alphabetic word, with an optional hyphen \n",
    "3. a string of digits, possibly with a decimal, a dollar sign,\n",
    "   or a percent\n",
    " \n",
    "and so on.  We apply this pattern to the example string `text`, \n",
    "using the `re` module function `findall` to find\n",
    "all substrings of `text` that match the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MLXNPuJchZNK"
   },
   "outputs": [],
   "source": [
    "# From http://www.nltk.org/book/ch03.html\n",
    "import re\n",
    "\n",
    "text = \"\"\"\n",
    "\"That,\" said  Fred, \"is what\n",
    "you ... get in the U.S.A. for $5.29.\"\n",
    "\"\"\"\n",
    "try1 = text.split()\n",
    "\n",
    "# Notice the use of special NONCAPTURING parens (?:...)\n",
    "# All parens in the regexp must be non capturing.\n",
    "pattern = r\"\"\" \n",
    "   (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "  |\\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "  |\\$?\\d+(?:\\.\\d+)?%?  # numbers, money and percents, e.g. 3.14, $12.40, 82%\n",
    "  |\\.\\.\\.            # ellipsis\n",
    "  |[][.,;\"'?():-_`]  # keep punctuation, delimiters as separate word tokens\n",
    "\"\"\"\n",
    "re_flags = re.UNICODE | re.MULTILINE | re.DOTALL | re.X\n",
    "pattern_re = re.compile(pattern,re_flags)\n",
    "try2 = pattern_re.findall(text)\n",
    "# Or equivalently, let nltk do some of the work.\n",
    "import nltk\n",
    "try3 = nltk.regexp_tokenize(text,pattern,flags=re_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gC3o8zYbhZNM",
    "outputId": "ce22bfca-10ab-4c08-8937-1b506c89e51f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"That,\"',\n",
       " 'said',\n",
       " 'Fred,',\n",
       " '\"is',\n",
       " 'what',\n",
       " 'you',\n",
       " '...',\n",
       " 'get',\n",
       " 'in',\n",
       " 'the',\n",
       " 'U.S.A.',\n",
       " 'for',\n",
       " '$5.29.\"']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZTCk6kehZNO"
   },
   "source": [
    "The `split` tokenized sentence has some very strange words, for example the 7-character strings `'Fred,',` and `\"That,\"`,  and the 3-character string `\"is`. What's being missed here is that certain characters (like comma and quotation-mark) unambiguously mark a word boundary.  Regular expressions are very good at enforcing this sort of generalization, as we can see by comparing the results of tokenizing the same sentence with a regexp that does not allow words to continue past boundary markers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsk8ei3lhZNO"
   },
   "source": [
    "In the next two tries, we use such a regular expression (defined\n",
    "as `pattern`), compiling it using `re.compile` (for efficiency) and using some compiling flags.  See `re` module docs for a complete description.\n",
    "Here, we'll discuss just the most frequently used one, the `X` flag:\n",
    "\n",
    ">  This flag allows you to write regular expressions \n",
    ">  that look nicer and are more readable by allowing \n",
    ">  you to visually separate logical sections of the pattern\n",
    ">  and add comments. Whitespace within the pattern is ignored, \n",
    ">  except when in a character class, or when preceded by an \n",
    ">  unescaped backslash, or in groups or inisde a few special operators.  \n",
    "\n",
    ">  When a line contains a comment character (#) that is not \n",
    ">  in a character class and is not preceded by an unescaped \n",
    ">  backslash, all characters from the leftmost such # through \n",
    ">  the end of the line are ignored.\n",
    "\n",
    "Next, we call `re.findall(pattern, text)`; `re.findall(pattern, text)` returns a list of all the expressions in `text` that match `pattern`. \n",
    "Since each part (line) of `pattern` is written so as to match\n",
    "a different case of a proper word, `re.findall(pattern, text)`\n",
    "returns a list of the proper words in `text`.\n",
    "Note that all parentheses on `pattern` are what the `re`-module docs call \"non-capturing\".  This means no **groups** are defined by these parens, the\n",
    "matches against expressions in such parens are not put into\n",
    "a register, and they are not returned as separate components\n",
    "in a `findall`.   This is what we want  since the parentheses\n",
    "in `pattern` wrap around parts of words, and we don't want the\n",
    "tokenizer returning word parts, just complete words.\n",
    "\n",
    "The results of using `findall` and the `nltk` tokenizer are equivalent.\n",
    "Basically what the `nltk` tokenizer is compile the regexp using\n",
    "flags and use `findall`.  The `nltk` tokenizer also offers another\n",
    "option, that of writing a tokenizer that matches all word\n",
    "**boundaries** and then using the `re` module method `split`.  That approach\n",
    "has some advantages in some situations, but it is not shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WTyppD5RhZNO",
    "outputId": "47e84388-ebac-4187-a795-593c8733895f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"',\n",
       " 'That',\n",
       " ',',\n",
       " '\"',\n",
       " 'said',\n",
       " 'Fred',\n",
       " ',',\n",
       " '\"',\n",
       " 'is',\n",
       " 'what',\n",
       " 'you',\n",
       " '...',\n",
       " 'get',\n",
       " 'in',\n",
       " 'the',\n",
       " 'U.S.A.',\n",
       " 'for',\n",
       " '$5.29',\n",
       " '.',\n",
       " '\"']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qGgCzxXJhZNR",
    "outputId": "874414a5-47e0-4543-d147-6ca4ead19ff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try2 == try3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2l9V84BhZNT"
   },
   "source": [
    "Python regular expressions use parentheses for two different things, defining retrievable groups, which as we saw, is useful for extraction, and defining the scope of some regular expression operator (like `*` or `+`). Sometimes these two roles get in each other's way.  This is what happens in `pattern` above: Python `findall` handles groups specially and incorrectly treats the parenthesized elements as groups; so we use the regular expression convention of changing `(` to '(?:'.  The \"(?:' functions unambiguously to scope an operator and does not define a retrievable group.  Rather than make this change by hand, we call the convenient NLTK function `convert_regexp_to_nongrouping`.  We then compile the regular expression using various regular expression compiling flags.  `re.MULTILINE` and `re.DOTALL` allow our regular tokenizing `pattern` to match across lines, while `re.UNICODE` allows our definition of word, which depends on the interpretation of `\\w` to apply to UNICODE characters.  Finally, `re.X` is the most directly relevant to this example.  This allows regular expressions that intersperse comments, which makes them much more readable.  See [Python.org re docs](http://docs.python.org/2/library/re.html) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HXiwdTOUhZNT"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\"That,\" said  Fred, \"is what\n",
    "you ... get in the U.S.A. for $5.29.\"\n",
    "\"\"\"\n",
    "# This is illegal, do you know why?\n",
    "#patx = r'\\b\\B+\\b'\n",
    "patx = r'\\w+'\n",
    "re_flags = re.UNICODE | re.MULTILINE | re.DOTALL | re.X\n",
    "patx_re = re.compile(patx,re_flags)\n",
    "try4 = patx_re.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0wXp9OKhZNV"
   },
   "source": [
    "Here is what you get.  Is this a good result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "woM3QfUghZNV",
    "outputId": "1443575b-c71d-4588-d7ea-f582a84325b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That',\n",
       " 'said',\n",
       " 'Fred',\n",
       " 'is',\n",
       " 'what',\n",
       " 'you',\n",
       " 'get',\n",
       " 'in',\n",
       " 'the',\n",
       " 'U',\n",
       " 'S',\n",
       " 'A',\n",
       " 'for',\n",
       " '5',\n",
       " '29']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxz-5LHghZNX"
   },
   "source": [
    "## Sentence boundary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6PLoMA0hZNX"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"\"\"\n",
    "The king rarely saw Marie \n",
    "on Tuesdays, but\n",
    "he did see her  on Wednesdays.  He liked\n",
    "to take long walks\n",
    "in the garden, gazing longingly at the\n",
    "rhododendrons.  She\n",
    "thought this\n",
    "odd.  Me, too.\n",
    "\"\"\"\n",
    "lines = re.split(r'\\s*[!?.]\\s*', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cbxNPTfhZNZ",
    "outputId": "93baa549-562c-4652-b06e-4ca5dcdfc0aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThe king rarely saw Marie \\non Tuesdays, but\\nhe did see her  on Wednesdays',\n",
       " 'He liked\\nto take long walks\\nin the garden, gazing longingly at the\\nrhododendrons',\n",
       " 'She\\nthought this\\nodd',\n",
       " 'Me, too',\n",
       " '']"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ba8y7ichZNb"
   },
   "source": [
    "Now let's clean this up removing unnecessary line breaks and white space.\n",
    "For each element in `lines`, we split it, then put the pieces back together separated \n",
    "by single spaces.  Finally,we remove empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvQL2VPdhZNc",
    "outputId": "10f8492c-2c17-453c-c7b7-324cfa35d174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The king rarely saw Marie on Tuesdays, but he did see her on Wednesdays',\n",
       " 'He liked to take long walks in the garden, gazing longingly at the rhododendrons',\n",
       " 'She thought this odd',\n",
       " 'Me, too']"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences0 = [' '.join(line.split()) for line in lines]\n",
    "sentences = [exp for exp in sentences0 if exp]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuzWG_L4hZNe"
   },
   "source": [
    "We wrap it all up in a function, supplying the above pattern\n",
    "as a default if the user doesn't specify one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDWJ-qiphZNe"
   },
   "outputs": [],
   "source": [
    "def sent_tokenize (text, pat=r'\\s*[!?.]\\s*'):\n",
    "    lines = re.split(pat, text)\n",
    "    sentences0 = [' '.join(line.split()) for line in lines]\n",
    "    return [exp for exp in sentences0 if exp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSrCCEuPhZNg"
   },
   "source": [
    "## Putting it all  together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxMEOYxehZNg"
   },
   "source": [
    "In the next cell we use **negative lookahead**, which allows us \n",
    "to match an instance of one pattern as long as it is not immediately\n",
    "followed by an instance of another.  For example, using `r\"Isaac(?!\\s+Asimov)\"`\n",
    "to define a pattern that matches \"Isaac\" when it is not immediately followed by\n",
    "\" Asimov\", we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovTZJS6hhZNh",
    "outputId": "cbd9aca7-b418-4ee5-e945-abc218fa41df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Isaac', 'Isaac']\n",
      "['Isaac']\n"
     ]
    }
   ],
   "source": [
    "text = 'Isaac Asimov patted Isaac Stern on the back'\n",
    "print(re.findall(r\"Isaac\",text))\n",
    "print(re.findall(r\"Isaac(?!\\s*Asimov)\",text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSVRKkhphZNj"
   },
   "source": [
    "We input a raw text string and first\n",
    "tokenize sentences, then words within sentences,\n",
    "returning a list of tokenized sentences.\n",
    "Each tokenized sentence is  a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yg12AJOShZNj",
    "outputId": "8d7da443-7d4c-44ac-eeaa-315f90a03c6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'king',\n",
       "  'rarely',\n",
       "  'saw',\n",
       "  'Marie',\n",
       "  'on',\n",
       "  'Tuesdays',\n",
       "  ',',\n",
       "  'but',\n",
       "  'he',\n",
       "  'did',\n",
       "  'see',\n",
       "  'her',\n",
       "  'on',\n",
       "  'Wednesdays'],\n",
       " ['He',\n",
       "  'liked',\n",
       "  'to',\n",
       "  'take',\n",
       "  'long',\n",
       "  'walks',\n",
       "  'in',\n",
       "  'the',\n",
       "  'garden',\n",
       "  ',',\n",
       "  'gazing',\n",
       "  'longingly',\n",
       "  'at',\n",
       "  'the',\n",
       "  'rhododendrons'],\n",
       " ['She', 'thought', 'this', 'odd'],\n",
       " ['Me', ',', 'too'],\n",
       " ['\"',\n",
       "  'That',\n",
       "  ',',\n",
       "  '\"',\n",
       "  'said',\n",
       "  'Fred',\n",
       "  ',',\n",
       "  '\"',\n",
       "  'is',\n",
       "  'what',\n",
       "  'you',\n",
       "  '(',\n",
       "  'Texans',\n",
       "  '!',\n",
       "  ')',\n",
       "  'get',\n",
       "  'in',\n",
       "  '1',\n",
       "  '/',\n",
       "  '2',\n",
       "  'the',\n",
       "  'U.S.A.',\n",
       "  'for',\n",
       "  '$5.29',\n",
       "  ',',\n",
       "  '.23%',\n",
       "  'of',\n",
       "  'nothing',\n",
       "  '.',\n",
       "  '\"']]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "pattern = r\"\"\" \n",
    "   (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "  |\\$?\\d+(?:\\.\\d+)?%?  # numbers, money and percents, e.g. 3.14, $12.40, 82% \n",
    "  |\\$?\\.\\d+%?         # numbers, money and percents, e.g. .14, $.40, '/8%     \n",
    "  |\\w+(?:-\\w+)*        # words with optional internal hyphens. NB \\w includes \\d\n",
    "  |\\.\\.\\.            # ellipsis\n",
    "  |[][./,;\"'!?():-_`]  # keep punctuation, delimiters as separate word tokens\n",
    "\"\"\"\n",
    "\n",
    "re_flags = re.UNICODE | re.MULTILINE | re.DOTALL | re.X\n",
    "# Add in to our sentence boundary pattern\n",
    "# that the next letters following the sentence ender\n",
    "# must NOT be a lower case letter (a-z).\n",
    "back_pat = '\\s*[!?.]\\s+(?![a-z])'\n",
    "def sent_tokenize (text, pat = '\\s*[!?.]\\s+'):\n",
    "    lines = re.split(pat, text)\n",
    "    sentences0 = [' '.join(line.split()) for line in lines]\n",
    "    return [exp for exp in sentences0 if exp]\n",
    "\n",
    "text = \"\"\"\n",
    "The king rarely saw Marie \n",
    "on Tuesdays, but\n",
    "he did see her  on Wednesdays.  He liked\n",
    "to take long walks\n",
    "in the garden, gazing longingly at the\n",
    "rhododendrons.  She\n",
    "thought this\n",
    "odd.  Me, too.\n",
    "\"That,\" said  Fred, \"is what\n",
    "you (Texans!) get in 1/2 the U.S.A. for $5.29, .23% of nothing.\"\n",
    "\"\"\"\n",
    "sents = sent_tokenize(text,pat = back_pat)\n",
    "tokenized_sents = [nltk.regexp_tokenize(sent, pattern, flags=re_flags)\n",
    "                   for sent in sents]\n",
    "tokenized_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "IulLoeA4hZNl"
   },
   "source": [
    "## Example of using regular expressions to clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a realistic example of cleaning web data using regular expressions.  It is offered\n",
    "here as a reference, and particularly as  an example using `re.split()`, which is an underutilized tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load recipe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following two commands to either download the data to your machine.  You will need to then move it to your Google Drive if you are using Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified from [*Python Data Science Handbook* Jake VenderPlas.](https://github.com/jakevdp/PythonDataScienceHandbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl https://s3.amazonaws.com/openrecipes/20170107-061401-recipeitems.json.gz --output 20170107-061401-recipeitems.json.gz\n",
    "# !gunzip 20170107-061401-recipeitems.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads the data, does some cleanup and packages it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#  You will need to change the path to whereever the data is, possibly also mounting your Google Drive.\n",
    "path = '/Users/gawron/Desktop/src/sphinx/python_for_ss_extras/colab_notebooks/'\\\n",
    "     'python-for-social-science/pandas/datasets/20170107-061401-recipeitems.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `pandas` has a very good json reading utility, it does not work on this `.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    recipes = pd.read_json(path)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partial solution is to read in the data line by line.  There are still some minor\n",
    "cleanup issues.  The following cell loads the data and deals with those issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JMG A cleanup function for throwing away dictionary wrappers that confuse pd.read_\n",
    "def fix_dd (dd):\n",
    "    to_do = []\n",
    "    for (key,val) in dd.items():\n",
    "        if isinstance(val,dict) and len(val) == 1:\n",
    "            to_do.append((key, val[list(val.keys())[0]]))\n",
    "        elif isinstance(val,dict)and len(val) == 0:\n",
    "            print('***Zero-keyed value found***')\n",
    "        elif isinstance(val,dict):\n",
    "            print('***Multi-keyed value found***')\n",
    "    for (key,new_val) in to_do:\n",
    "        dd[key] = new_val\n",
    "        \n",
    "\n",
    "# JMG Get a list of json dicts\n",
    "import json\n",
    "res = []\n",
    "with open(path) as f:\n",
    "    for line in (f):\n",
    "        res.append(json.loads(line.strip()))\n",
    "\n",
    "for dd in res:\n",
    "    fix_dd(dd)\n",
    "    \n",
    "# JMG Now you can create approximately the DataFrame you want.\n",
    "recipes = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                            5160756b96cc62079cc2db15\n",
       "name                                    Drop Biscuits and Sausage Gravy\n",
       "ingredients           Biscuits\\n3 cups All-purpose Flour\\n2 Tablespo...\n",
       "url                   http://thepioneerwoman.com/cooking/2013/03/dro...\n",
       "image                 http://static.thepioneerwoman.com/cooking/file...\n",
       "ts                                                        1365276011104\n",
       "cookTime                                                          PT30M\n",
       "source                                                  thepioneerwoman\n",
       "recipeYield                                                          12\n",
       "datePublished                                                2013-03-11\n",
       "prepTime                                                          PT10M\n",
       "description           Late Saturday afternoon, after Marlboro Man ha...\n",
       "totalTime                                                           NaN\n",
       "creator                                                             NaN\n",
       "recipeCategory                                                      NaN\n",
       "dateModified                                                        NaN\n",
       "recipeInstructions                                                  NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the recipe with the longest ingredient list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carrot Pineapple Spice &amp; Brownie Layer Cake with Whipped Cream &amp; Cream Cheese Frosting and Marzipan Carrots'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "recipes.name[np.argmax(recipes.ingredients.str.len())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d3fd1",
   "metadata": {},
   "source": [
    "Here's a sample of what the ingredients list (from that one row/recipe) looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e8fa476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 cup carrot juice2 cups (280 g) all purpose flour1/2 cup (65 g) almond meal or almond flour1 tablespoon baking powder1 teaspoon baking soda3/4 teaspo'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.ingredients[test][:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously a lot of distinct ingredients have been concatenated together without spacing,\n",
    "making the whole mess quite hard to read.\n",
    "\n",
    "To clean this up we want\n",
    "\n",
    "```\n",
    "1 cup carrot juice2 cups (280 g) all purpose flour1/2 cup (65 g) almond meal or almond flour\n",
    "```\n",
    "\n",
    "to come out as\n",
    "\n",
    "```\n",
    "1 cup carrot juice\n",
    "2 cups (280 g) all purpose flour\n",
    "1/2 cup (65 g) almond meal or almond flour\n",
    "```\n",
    "So we need to split the string at certain points. \n",
    "Let's try to exploit the fact that an indregient specification tends to start with a number.\n",
    "So we split at the point where a number is concatenated onto a non-number.\n",
    "To define the split points we'll use a **regular expression**.\n",
    "\n",
    "A not-quite-perfect regexp to split the recipe ingredients for this one LONG list\n",
    "of ingredients is given in the next cell as `spl_re`.  It matches a line break\n",
    "or an empty string that is immediately preceded by an alphabetic character (or right parenthesis)\n",
    "and immediately followed by a number; when used by `re.split`\n",
    "it will split the string at all such points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "spl_re_raw = r\"\"\"\n",
    "                 (?<=[a-z\\)])        # Look behind for alphabetic character or right paren\n",
    "                 \\n?                 # Match line break or empty string\n",
    "                 (?=[1-9])           # Look ahead for any digit 1-9\n",
    "\"\"\"\n",
    "re_flags = re.UNICODE | re.MULTILINE | re.DOTALL | re.X\n",
    "spl_re = re.compile(spl_re_raw,re_flags)\n",
    "raw_ingreds= re.split(spl_re,recipes.ingredients[test])\n",
    "#remove dupes!\n",
    "test_ingreds = set(raw_ingreds)\n",
    "#  There were lots of dupes!\n",
    "print(len(raw_ingreds),len(test_ingreds),end='\\n\\n')\n",
    "# print each of the ingredients after splitting and dupe removal, separated by newlines\n",
    "print(*test_ingreds,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this idea to the entire Data Frame and now and clean up all rows of `recipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#spl_re = re.compile(r'(?<=[a-z\\)])\\n?(?=[1-9])')\n",
    "spl_re_raw = r\"\"\"\n",
    "                 (?<=[a-z\\)])        # Look behind for alphabetic character or right paren\n",
    "                 \\n?                 # Match line break or empty string\n",
    "                 (?=[1-9])           # Look ahead for any digit 1-9\n",
    "\"\"\"\n",
    "re_flags = re.UNICODE | re.MULTILINE | re.DOTALL | re.X\n",
    "spl_re = re.compile(spl_re_raw,re_flags)\n",
    "\n",
    "def make_parsable (ingred_str):\n",
    "    # After splitting rejoin with newlines\n",
    "    return '\\n'.join(set(re.split(spl_re,ingred_str)))\n",
    "\n",
    "recipes.ingredients = recipes.ingredients.apply(make_parsable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*recipes.ingredients.iloc[2].split('\\n'),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these changes, the identity of the most complicated recipe has changed (and quite makes sense!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.name[np.argmax(recipes.ingredients.str.len())]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "b54khw00hZMt",
    "Xqi4xES5hZMy",
    "ZcdP69dzhZM3",
    "KX8CArFchZM7",
    "DAIyZ1w8hZNF",
    "EW2aah3nhZNF",
    "pTIj2KKOhZNJ",
    "nxz-5LHghZNX",
    "zSrCCEuPhZNg"
   ],
   "name": "regular_expressions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "226px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
