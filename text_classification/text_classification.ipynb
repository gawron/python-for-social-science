{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Klr4qGXVlqf"
      },
      "source": [
        "# Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oLmUg3WVlqi"
      },
      "source": [
        "## Getting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ohL9bQVlqj"
      },
      "source": [
        "For this notebook you need to have some NLTK `movie reviews` data installed.  First make sure you have nltk installed as a Python module (or the first line in the code block below won't work).  Then install the data as follows:\n",
        "\n",
        "```\n",
        "import nltk\n",
        "nltk.download()\n",
        "```\n",
        "\n",
        "This pops up a separate window.  It has several tabs, one of them labeled `corpora`.  Select that tab and you will see a long alphabetically ordered list of all the corpora `NLTK` supplies.  Scroll down and select `Movie Reviews` and click on `Download`.  This will install that data on your machine, and all the code in this notebook\n",
        "should work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPiox-voVlqj"
      },
      "source": [
        "## Peliminaries:  Code for getting data and extracting features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk9r1NREVlqk"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FB_RsRa6Vlql"
      },
      "outputs": [],
      "source": [
        "\n",
        "def unigram_features (words):\n",
        "    \"\"\" \n",
        "    This is the simplest possible feature representation of a document.\n",
        "    \n",
        "    Each word is a feature.\n",
        "    \"\"\"\n",
        "    return dict((word, True) for word in words)\n",
        "\n",
        "\n",
        "def extract_features (corpus, file_ids, cls, feature_extractor=unigram_features):\n",
        "    \"\"\"\n",
        "    Turn a set of files all belonging to one class into a list\n",
        "    of (feature dictionary, cls) pairs, to be used in testing or training\n",
        "    a classifier.\n",
        "    \"\"\"\n",
        "    return [(feature_extractor(corpus.words(i)), cls) for i in file_ids]\n",
        "\n",
        "\n",
        "def get_words_from_corpus (corpus, file_ids):\n",
        "\n",
        "    for file_id in file_ids:\n",
        "        words = corpus.words(file_id)\n",
        "        for word in words:\n",
        "            yield word\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6s-vcGMVlql"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkmVNxCCVlqm"
      },
      "source": [
        "In line 3  of the next cell, we import the NLTK Bo Pang and Lillian Lee's movie reviews corpus.  Line 5 prints some information about the corpus properties; these appear in the output cell.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "gL-zGdNUVlqm"
      },
      "outputs": [],
      "source": [
        "# Using a corpus of movie review data\n",
        "# 2000 positive and negative reviews, evenly balanced.\n",
        "from nltk.corpus import movie_reviews as mr\n",
        "\n",
        "# If you want to read the corpus collectors' introduction to\n",
        "# this corpus, uncomment the next line.\n",
        "#print mr.readme()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cv3orPmVlqn"
      },
      "source": [
        "The movie review data is packaged up as an NLTK corpus, which \n",
        "gives us access to a number of tools for text handling.  The simplest\n",
        "is that we have two views of the movie review data, word by word and character by character.\n",
        "\n",
        "The character by character view uses the `raw` method, which returns all the data wiht no argument, or just the data from asingle file with a fileid argument:    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erROuZ4jy4_j",
        "outputId": "83b416f3-6033-4f3e-95bb-4151e32db0bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9qg9v05Vlqo",
        "outputId": "c921edde-18a7-4f06-eb54-7fd622917728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "films adapted from comic books have had plenty of success , whether they're about superheroes ( batm\n"
          ]
        }
      ],
      "source": [
        "data = dict(pos = mr.fileids('pos'),\n",
        "            neg = mr.fileids('neg'))\n",
        "print(mr.raw(data['pos'][0])[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDD3zocAVlqo"
      },
      "source": [
        "The word by word character view uses the `words` method::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf1mUkHkVlqp",
        "outputId": "7fce947a-658b-407e-e300-703eacf5dc55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success']\n"
          ]
        }
      ],
      "source": [
        "print(mr.words(data['pos'][0])[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6jq5g_IVlqp"
      },
      "source": [
        "We will be using the word by word view."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generators"
      ],
      "metadata": {
        "id": "KAbHk4rM0m66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_gen = get_words_from_corpus (mr, data['pos'])"
      ],
      "metadata": {
        "id": "6e6cB-xlzzZ8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdlSkRV-0OW6",
        "outputId": "878b43b8-f333-4b91-b50c-2d0b47edbea8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object get_words_from_corpus at 0x7f0752688e50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(pos_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v_9ERFqX0TsS",
        "outputId": "15b44652-e5fd-4e83-c0f8-d86abe54c0c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'films'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(pos_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R-rV3tQh0eUg",
        "outputId": "e8d48f06-5980-4304-b6d3-7d2eab8bb0fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'adapted'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(pos_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-vPvpyBk0i9e",
        "outputId": "a4789ce4-2af7-4a3f-9909-5b9d0725d459"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[next(pos_gen) for i in range(20)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFIC3-Fc0sK8",
        "outputId": "a6f37f37-0287-4319-dc70-2bb661c8508f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comic',\n",
              " 'books',\n",
              " 'have',\n",
              " 'had',\n",
              " 'plenty',\n",
              " 'of',\n",
              " 'success',\n",
              " ',',\n",
              " 'whether',\n",
              " 'they',\n",
              " \"'\",\n",
              " 're',\n",
              " 'about',\n",
              " 'superheroes',\n",
              " '(',\n",
              " 'batman',\n",
              " ',',\n",
              " 'superman',\n",
              " ',',\n",
              " 'spawn']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[next(pos_gen) for i in range(20)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFPQyKpH06Js",
        "outputId": "8fa7de81-77d0-48d7-e2c7-24067c1106ea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[')',\n",
              " ',',\n",
              " 'or',\n",
              " 'geared',\n",
              " 'toward',\n",
              " 'kids',\n",
              " '(',\n",
              " 'casper',\n",
              " ')',\n",
              " 'or',\n",
              " 'the',\n",
              " 'arthouse',\n",
              " 'crowd',\n",
              " '(',\n",
              " 'ghost',\n",
              " 'world',\n",
              " ')',\n",
              " ',',\n",
              " 'but',\n",
              " 'there']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The usage of a generator rather than a function that returns the contents of the files as a block is consistent with the nltk philosophy, which is not to load the entire corpus into memory, but to bring it in as needed."
      ],
      "metadata": {
        "id": "uZahGSCt1GX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_mr = mr.words()\n",
        "print(type(corpus_mr))\n",
        "corpus_mr[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urFh8ITj2yTD",
        "outputId": "4931b8c2-0576-4f20-9fa1-19372c8e0928"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nltk.corpus.reader.util.ConcatenatedCorpusView'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the main ideas of the generator construct\n",
        "is to allow iteration through large structures without loading those large structures into memory.  In text processing, this becomes important when we are dealing with very large copora like the one used in building [Google ngrams.](https://storage.googleapis.com/books/ngrams/books/datasetsv3.html)\n",
        "In that case we are dealing with counts computed from terabytes of data, affording us statistically usable samples of very rare events.  For example, the Google ngrams corpus has \n",
        "\n",
        "circumvallate   1978   335    91\n",
        "\n",
        "Says Google: \"[This] line tells us that in 1978, the word 'circumvallate' (which means 'surround with a rampart or other fortification', in case you were wondering) occurred 335 times overall, in 91 distinct books of our sample.\"  To get a sample that contains this many instances of this very rare English word you have to look at a **lot** of data. But to get that count you don't need to store that data in memory at any point."
      ],
      "metadata": {
        "id": "yo9gVlBN6BJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cNo4UgFP30qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having said this, the nltk corpus viewers give us\n",
        "much the same advantages as a generator, while behaving entirely like the sort of Python containers we're used to."
      ],
      "metadata": {
        "id": "gz-Ev5aq9Erb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3U9cRuZVlqp"
      },
      "source": [
        "## Training a classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jZwEEz4LzRg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "svhKyHZdVlqp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from nltk.corpus import movie_reviews as mr\n",
        "\n",
        "data = dict(pos = mr.fileids('pos'),\n",
        "            neg = mr.fileids('neg'))\n",
        "\n",
        "#######################################################################\n",
        "#\n",
        "#  Dividing up the data\n",
        "#######################################################################\n",
        "\n",
        "# Use 90% of the data for training\n",
        "test_start_index = 900\n",
        "\n",
        "neg_training = extract_features(mr, data['neg'][:test_start_index], 'neg',\n",
        "                                feature_extractor=unigram_features)\n",
        "\n",
        "# Use 10% for testing the classifier on unseen data.\n",
        "neg_test = extract_features(mr, data['neg'][test_start_index:], 'neg',\n",
        "                                feature_extractor=unigram_features)\n",
        "\n",
        "pos_training = extract_features(mr, data['pos'][:test_start_index],'pos',\n",
        "                                feature_extractor=unigram_features)\n",
        "\n",
        "pos_test = extract_features(mr, data['pos'][test_start_index:],'pos',\n",
        "                                feature_extractor=unigram_features)\n",
        "\n",
        "train_set = pos_training + neg_training\n",
        "\n",
        "test_set = pos_test + neg_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q8L1L9EVlqq"
      },
      "source": [
        "Line 2 imports the movie review data from NLTK, and lines 4 and 5 store the two halves of the corpus in a dictionary (positive and negative reviews, 1000 of each).   The commands on \n",
        "the next few lines extract features from the data files, sorting them in pos and negative training and positive and negative test sets.  The training set is 90% of the the data; the test set is 10% of the data.  The feature extractor used is `unigram_features`, the simple feature extractor defined in the first code cell of this notebook.  This feature extractor just uses every word that appears in a document as a feature.  Finally in line 31 the positive and negative training data is combined into a single training set, and in line 36, a Naive Bayes (NB) classifier is trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npKsa72gVlqq"
      },
      "source": [
        "In the next cell, we look at an example representation of a movie review.  It is basically just a set, telling us what words occurred in the review, but not how many times they\n",
        "occurred.  In terms of a Python data structure, it's a dictionary whose keys are the words\n",
        "in the document, and whose values are all `True.`  We're not bothering to represent the words\n",
        "that don't occur in the document, so there are no keys whose value are is `False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wIAmgeVlqq",
        "outputId": "5b16fae4-91ec-4787-df92-e20e04c4d4ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({u'!': True,\n",
              "  u'%': True,\n",
              "  u\"'\": True,\n",
              "  u'(': True,\n",
              "  u')': True,\n",
              "  u',': True,\n",
              "  u'.': True,\n",
              "  u'100': True,\n",
              "  u'13': True,\n",
              "  u'1912': True,\n",
              "  u'3': True,\n",
              "  u':': True,\n",
              "  u'?': True,\n",
              "  u'a': True,\n",
              "  u'about': True,\n",
              "  u'above': True,\n",
              "  u'accomplished': True,\n",
              "  u'accuracy': True,\n",
              "  u'achieve': True,\n",
              "  u'across': True,\n",
              "  u'acting': True,\n",
              "  u'actually': True,\n",
              "  u'adding': True,\n",
              "  u'adds': True,\n",
              "  u'admirably': True,\n",
              "  u'admired': True,\n",
              "  u'aft': True,\n",
              "  u'ago': True,\n",
              "  u'aims': True,\n",
              "  u'aliens': True,\n",
              "  u'all': True,\n",
              "  u'almost': True,\n",
              "  u'alone': True,\n",
              "  u'already': True,\n",
              "  u'also': True,\n",
              "  u'although': True,\n",
              "  u'amaze': True,\n",
              "  u'amazed': True,\n",
              "  u'america': True,\n",
              "  u'an': True,\n",
              "  u'and': True,\n",
              "  u'anew': True,\n",
              "  u'any': True,\n",
              "  u'anything': True,\n",
              "  u'are': True,\n",
              "  u'aren': True,\n",
              "  u'as': True,\n",
              "  u'ask': True,\n",
              "  u'astonishing': True,\n",
              "  u'at': True,\n",
              "  u'atlantic': True,\n",
              "  u'attention': True,\n",
              "  u'backdrop': True,\n",
              "  u'be': True,\n",
              "  u'beautifully': True,\n",
              "  u'because': True,\n",
              "  u'been': True,\n",
              "  u'beginning': True,\n",
              "  u'behind': True,\n",
              "  u'best': True,\n",
              "  u'better': True,\n",
              "  u'bit': True,\n",
              "  u'boats': True,\n",
              "  u'bored': True,\n",
              "  u'both': True,\n",
              "  u'brand': True,\n",
              "  u'brings': True,\n",
              "  u'brining': True,\n",
              "  u'brought': True,\n",
              "  u'build': True,\n",
              "  u'built': True,\n",
              "  u'bukater': True,\n",
              "  u'but': True,\n",
              "  u'by': True,\n",
              "  u'cameron': True,\n",
              "  u'cannot': True,\n",
              "  u'cant': True,\n",
              "  u'captivating': True,\n",
              "  u'cast': True,\n",
              "  u'casting': True,\n",
              "  u'certain': True,\n",
              "  u'chance': True,\n",
              "  u'character': True,\n",
              "  u'characters': True,\n",
              "  u'chemistry': True,\n",
              "  u'class': True,\n",
              "  u'climbs': True,\n",
              "  u'commentary': True,\n",
              "  u'correctly': True,\n",
              "  u'costumes': True,\n",
              "  u'could': True,\n",
              "  u'dawson': True,\n",
              "  u'death': True,\n",
              "  u'degree': True,\n",
              "  u'detail': True,\n",
              "  u'dewitt': True,\n",
              "  u'dicaprip': True,\n",
              "  u'docks': True,\n",
              "  u'does': True,\n",
              "  u'done': True,\n",
              "  u'during': True,\n",
              "  u'effect': True,\n",
              "  u'effective': True,\n",
              "  u'effects': True,\n",
              "  u'either': True,\n",
              "  u'emotional': True,\n",
              "  u'emotions': True,\n",
              "  u'end': True,\n",
              "  u'ending': True,\n",
              "  u'enough': True,\n",
              "  u'even': True,\n",
              "  u'event': True,\n",
              "  u'everything': True,\n",
              "  u'extremely': True,\n",
              "  u'eyes': True,\n",
              "  u'fact': True,\n",
              "  u'fairly': True,\n",
              "  u'feat': True,\n",
              "  u'feats': True,\n",
              "  u'few': True,\n",
              "  u'film': True,\n",
              "  u'finally': True,\n",
              "  u'first': True,\n",
              "  u'flavor': True,\n",
              "  u'footage': True,\n",
              "  u'for': True,\n",
              "  u'forgotten': True,\n",
              "  u'forth': True,\n",
              "  u'frequency': True,\n",
              "  u'from': True,\n",
              "  u'full': True,\n",
              "  u'get': True,\n",
              "  u'getting': True,\n",
              "  u'go': True,\n",
              "  u'good': True,\n",
              "  u'grandiose': True,\n",
              "  u'grasp': True,\n",
              "  u'great': True,\n",
              "  u'had': True,\n",
              "  u'happened': True,\n",
              "  u'happening': True,\n",
              "  u'happens': True,\n",
              "  u'have': True,\n",
              "  u'her': True,\n",
              "  u'high': True,\n",
              "  u'highly': True,\n",
              "  u'historical': True,\n",
              "  u'hollywood': True,\n",
              "  u'home': True,\n",
              "  u'honestly': True,\n",
              "  u'hours': True,\n",
              "  u'house': True,\n",
              "  u'how': True,\n",
              "  u'humans': True,\n",
              "  u'humble': True,\n",
              "  u'i': True,\n",
              "  u'if': True,\n",
              "  u'imagination': True,\n",
              "  u'in': True,\n",
              "  u'interesting': True,\n",
              "  u'intrigue': True,\n",
              "  u'is': True,\n",
              "  u'it': True,\n",
              "  u'its': True,\n",
              "  u'itself': True,\n",
              "  u'jack': True,\n",
              "  u'jumping': True,\n",
              "  u'just': True,\n",
              "  u'kate': True,\n",
              "  u'largest': True,\n",
              "  u'least': True,\n",
              "  u'leave': True,\n",
              "  u'leaving': True,\n",
              "  u'leonardo': True,\n",
              "  u'less': True,\n",
              "  u'life': True,\n",
              "  u'lightly': True,\n",
              "  u'like': True,\n",
              "  u'likely': True,\n",
              "  u'literal': True,\n",
              "  u'looking': True,\n",
              "  u'lucky': True,\n",
              "  u'luxuries': True,\n",
              "  u'luxurious': True,\n",
              "  u'magical': True,\n",
              "  u'maiden': True,\n",
              "  u'main': True,\n",
              "  u'makes': True,\n",
              "  u'many': True,\n",
              "  u'marveled': True,\n",
              "  u'marvelous': True,\n",
              "  u'match': True,\n",
              "  u'maybe': True,\n",
              "  u'memorably': True,\n",
              "  u'men': True,\n",
              "  u'mentioned': True,\n",
              "  u'method': True,\n",
              "  u'might': True,\n",
              "  u'minutes': True,\n",
              "  u'money': True,\n",
              "  u'monsters': True,\n",
              "  u'more': True,\n",
              "  u'most': True,\n",
              "  u'movie': True,\n",
              "  u'movies': True,\n",
              "  u'mr': True,\n",
              "  u'much': True,\n",
              "  u'my': True,\n",
              "  u'new': True,\n",
              "  u'no': True,\n",
              "  u'nominations': True,\n",
              "  u'none': True,\n",
              "  u'nor': True,\n",
              "  u'not': True,\n",
              "  u'now': True,\n",
              "  u'occurred': True,\n",
              "  u'of': True,\n",
              "  u'on': True,\n",
              "  u'one': True,\n",
              "  u'opinion': True,\n",
              "  u'or': True,\n",
              "  u'other': True,\n",
              "  u'out': True,\n",
              "  u'oversized': True,\n",
              "  u'own': True,\n",
              "  u'paid': True,\n",
              "  u'part': True,\n",
              "  u'passenger': True,\n",
              "  u'people': True,\n",
              "  u'performances': True,\n",
              "  u'place': True,\n",
              "  u'played': True,\n",
              "  u'poker': True,\n",
              "  u'premise': True,\n",
              "  u'produce': True,\n",
              "  u'produced': True,\n",
              "  u'production': True,\n",
              "  u'productions': True,\n",
              "  u'project': True,\n",
              "  u'pull': True,\n",
              "  u'punch': True,\n",
              "  u'put': True,\n",
              "  u'quickly': True,\n",
              "  u'quite': True,\n",
              "  u'railings': True,\n",
              "  u'range': True,\n",
              "  u'ranks': True,\n",
              "  u'read': True,\n",
              "  u'realisticaly': True,\n",
              "  u'really': True,\n",
              "  u'receive': True,\n",
              "  u'regardless': True,\n",
              "  u'remarkable': True,\n",
              "  u'rendered': True,\n",
              "  u'respects': True,\n",
              "  u'review': True,\n",
              "  u'right': True,\n",
              "  u'roles': True,\n",
              "  u'romance': True,\n",
              "  u'rose': True,\n",
              "  u's': True,\n",
              "  u'sail': True,\n",
              "  u'sailors': True,\n",
              "  u'sake': True,\n",
              "  u'savings': True,\n",
              "  u'say': True,\n",
              "  u'scenes': True,\n",
              "  u'see': True,\n",
              "  u'seeing': True,\n",
              "  u'seem': True,\n",
              "  u'seems': True,\n",
              "  u'sense': True,\n",
              "  u'serves': True,\n",
              "  u'set': True,\n",
              "  u'she': True,\n",
              "  u'sheer': True,\n",
              "  u'ship': True,\n",
              "  u'ships': True,\n",
              "  u'should': True,\n",
              "  u'showing': True,\n",
              "  u'shows': True,\n",
              "  u'simple': True,\n",
              "  u'simply': True,\n",
              "  u'since': True,\n",
              "  u'sink': True,\n",
              "  u'sinking': True,\n",
              "  u'size': True,\n",
              "  u'smashingly': True,\n",
              "  u'so': True,\n",
              "  u'some': True,\n",
              "  u'something': True,\n",
              "  u'spare': True,\n",
              "  u'special': True,\n",
              "  u'specifications': True,\n",
              "  u'spectacular': True,\n",
              "  u'spent': True,\n",
              "  u'spoil': True,\n",
              "  u'stars': True,\n",
              "  u'start': True,\n",
              "  u'started': True,\n",
              "  u'still': True,\n",
              "  u'story': True,\n",
              "  u'stranger': True,\n",
              "  u'style': True,\n",
              "  u'successful': True,\n",
              "  u'such': True,\n",
              "  u't': True,\n",
              "  u'taken': True,\n",
              "  u'tale': True,\n",
              "  u'tears': True,\n",
              "  u'technical': True,\n",
              "  u'tell': True,\n",
              "  u'telling': True,\n",
              "  u'that': True,\n",
              "  u'the': True,\n",
              "  u'theater': True,\n",
              "  u'their': True,\n",
              "  u'then': True,\n",
              "  u'there': True,\n",
              "  u'they': True,\n",
              "  u'think': True,\n",
              "  u'this': True,\n",
              "  u'thoughts': True,\n",
              "  u'thus': True,\n",
              "  u'ticket': True,\n",
              "  u'time': True,\n",
              "  u'titanic': True,\n",
              "  u'to': True,\n",
              "  u'too': True,\n",
              "  u'took': True,\n",
              "  u'totally': True,\n",
              "  u'tragedy': True,\n",
              "  u'tragic': True,\n",
              "  u'trip': True,\n",
              "  u'trivia': True,\n",
              "  u'undertaken': True,\n",
              "  u'unfortunately': True,\n",
              "  u'unique': True,\n",
              "  u'unsinkable': True,\n",
              "  u'upper': True,\n",
              "  u'value': True,\n",
              "  u'very': True,\n",
              "  u'voyage': True,\n",
              "  u'wane': True,\n",
              "  u'was': True,\n",
              "  u'watched': True,\n",
              "  u'watching': True,\n",
              "  u'way': True,\n",
              "  u'well': True,\n",
              "  u'went': True,\n",
              "  u'were': True,\n",
              "  u'what': True,\n",
              "  u'whole': True,\n",
              "  u'will': True,\n",
              "  u'winslet': True,\n",
              "  u'with': True,\n",
              "  u'wizardry': True,\n",
              "  u'wizards': True,\n",
              "  u'wont': True,\n",
              "  u'world': True,\n",
              "  u'worth': True,\n",
              "  u'wreck': True,\n",
              "  u'years': True,\n",
              "  u'yes': True,\n",
              "  u'you': True,\n",
              "  u'your': True},\n",
              " 'pos')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXyJbyDuVlqr",
        "outputId": "def409e6-fcfe-4aa2-e256-d4a2e1db92fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data['neg'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NL5ceZQVlqr"
      },
      "source": [
        "We have now split the data into two unequal haves, each with positive and negative examples, and called the larger half `train_set` and the smaller half `test_set`.\n",
        "\n",
        "Next we **train** the classifier by giving it the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HjnNwv0Vlqr"
      },
      "outputs": [],
      "source": [
        "# Use a Naive Bayes Classifier\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "\n",
        "#  Train a classifier on our training data.\n",
        "classifier = NaiveBayesClassifier.train(train_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh2irtAdVlqr"
      },
      "source": [
        "## A demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VolqmI4hVlqs"
      },
      "source": [
        "In the next code cell, we demonstrate what the classifier does on the first reviews in the the positive and negative training set.  The output window shows that both reviews are correctly classified by the NB classifier we just trained.\n",
        "\n",
        "First, we pick a review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ryGQoXVhVlqs",
        "outputId": "86694785-b978-4020-8b73-f6f4d362721f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "films adapted from comic books have had plenty of success , whether they ' re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there ' s never really been a comic book like from hell before . for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid ' 80s with a 12 - part series called the watchmen .\n",
            "     . . . . . . \n",
            ", but cinematographer peter deming ( don ' t say a word ) ably captures the dreariness of victorian - era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black - and - white comic . oscar winner martin childs ' ( shakespeare in love ) production design turns the original prague surroundings into one creepy place . even the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent . ians holm ( joe gould ' s secret ) and richardson ( 102 dalmatians ) log in great supporting roles , but the big surprise here is graham . i cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually wasn ' t half bad . the film , however , is all good . 2 : 00 - r for strong violence / gore , sexuality , language and drug content\n"
          ]
        }
      ],
      "source": [
        "def get_review_text (clf,file_id,start=0,end=None):\n",
        "    words = list(mr.words(data[clf][file_id]))\n",
        "    return ' '.join(words[start:end])\n",
        "\n",
        "print get_review_text('pos',0,end=95)\n",
        "\n",
        "print '     . . . . . . '\n",
        "\n",
        "print get_review_text('pos',0,start=-190)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYJcdEgEVlqs"
      },
      "source": [
        "Reading this makes it clear why movie reviews are hard, especially with the approach we're taking;  each word is treated as an independent feature whose presence increases or decreases the probability the review is positive. Overall it's positive review but it's not easy finding single words that might give us good evidence of that,\n",
        "and there are words that probably point the other way as well:\n",
        "\n",
        "```\n",
        "Pos         Neg\n",
        "-----------------\n",
        "ably      dreariness\n",
        "flashy    violence\n",
        "surprise  bad\n",
        "strong    creepy\n",
        "deftly    cringed\n",
        "good\n",
        "oscar\n",
        "winner\n",
        "great\n",
        "```\n",
        "\n",
        "Nevertheless, let's try this out and see how we do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfoLCPXOVlqs",
        "outputId": "9a1ea2d0-e4f7-4b1f-8861-0c9ac025d1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: pos Actual: pos\n"
          ]
        }
      ],
      "source": [
        "predicted_label0 = classifier.classify(pos_test[0][0])\n",
        "\n",
        "print 'Predicted: %s Actual: pos' % (predicted_label0,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lpe2cpPVlqs"
      },
      "source": [
        "We got it right!  Let's try a negative review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf4MrinpVlqt",
        "outputId": "b517e400-03a6-4a5d-b640-46be298c7f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: neg Actual: neg\n"
          ]
        }
      ],
      "source": [
        "predicted_label1 = classifier.classify(neg_test[0][0])\n",
        "\n",
        "print 'Predicted: %s Actual: neg' % (predicted_label1,)\n",
        "\n",
        "# To see the the feature dictionary passed in to the classifier,\n",
        "# uncomment the next line\n",
        "#pos_test[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vGiW9_IVlqt"
      },
      "source": [
        "Right again!\n",
        "\n",
        "Let's try the examples we cooked up before.  We need go to from\n",
        "a string like `\"Inception is the best movie ever\"` to a feature dictionary\n",
        "and pass that to the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WODA33ZrVlqt",
        "outputId": "540e98dd-39be-4767-f869-b3b25c836fc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'pos'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.classify(unigram_features('Inception is the best movie ever'.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiNMHpnQVlqt",
        "outputId": "82705a98-6f39-4802-b85f-ba1de743f543"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'neg'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.classify(unigram_features(\"I don't know how anyone could sit through Inception\".split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bWspKZ4Vlqt"
      },
      "source": [
        "Interesting.  We may get some insight on this one below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBHX51smVlqu"
      },
      "source": [
        "## Most informative features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uebNa6-aVlqu"
      },
      "source": [
        "Heres what our classifier learned.  These are the features for which the ratio of the positive to negative probability (or vice versa) is the highest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQWhdsVzVlqu"
      },
      "source": [
        "We have more features showing up as good indicators of positive, and this is a fairly good indicate or a probl;em with our classifier, as we'll see below.  Actually the classifier is a little too reluctant to classify reviews as negative on the test set.  This suggests that reliable negative indicators are not that common, at least on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9U1amkm7Vlqu",
        "outputId": "9e210501-78ce-4ec7-9e4d-b05a2165a0a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             outstanding = True              pos : neg    =     15.6 : 1.0\n",
            "               ludicrous = True              neg : pos    =     14.2 : 1.0\n",
            "              astounding = True              pos : neg    =     12.3 : 1.0\n",
            "                  avoids = True              pos : neg    =     12.3 : 1.0\n",
            "                 idiotic = True              neg : pos    =     11.8 : 1.0\n",
            "               atrocious = True              neg : pos    =     11.7 : 1.0\n",
            "             fascination = True              pos : neg    =     11.0 : 1.0\n",
            "                 offbeat = True              pos : neg    =     11.0 : 1.0\n",
            "               animators = True              pos : neg    =     10.3 : 1.0\n",
            "                  symbol = True              pos : neg    =     10.3 : 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "classifier.show_most_informative_features()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs0olrAUVlqu"
      },
      "source": [
        "## Serious testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUNTZQ5kVlqu"
      },
      "source": [
        "The next cell takes the first step toward testing a classifier a little more seriously.  It defines some code for evaluating classifier output.  The evaluation metrics defined are precision, recall, and accuracy.  Call the examples the system predicts to be positive (whether correctly or not) ppos and and the examples it predicts to be negative pneg; consider the following performance on 100 examples:\n",
        "\n",
        "$$\\begin{array}[t]{ccc} &  pos &neg\\\\ ppos& 31 & 5\\\\ pneg & 14  & 50 \\end{array}$$\n",
        "\n",
        "The performance of the system has been sorted into 4 classes:\n",
        "\n",
        "$$\\begin{array}[t]{ccc} &  pos &neg\\\\ spos& tp & fp\\\\ sneg & fn & tn \\end{array}$$\n",
        "\n",
        "The $tp$ and $tn$ examples (true positive and true negative) are those the system labeled correctly,\n",
        "while $fp$ and $fn$ (false positive and false negative) are those labeled incorrectly.\n",
        "Let N stand for the total number of examples,\n",
        "100 in our case. \n",
        "\n",
        "The three most important measures of system performance are:\n",
        "  \n",
        "  1. **Accuracy**: Accuracy is the percentage of correct examples out of the total corpus \n",
        "\n",
        "  $$Acc = \\frac{tp+tn}{N} = \\frac{31 +50}{100}$$ \n",
        "  \n",
        "  This is .81 in our case.\n",
        "\n",
        "  2. **Precision**: Precision is the percentage of true positives out of all positive guesses the system made \n",
        "  \n",
        "  $$Prec= \\frac{tp}{tp + fp} = \\frac{31}{31+5}.$$\n",
        "  \n",
        "  This is .86 in our case.\n",
        "  3. **Recall**: Recall is the percentage of true positives out of all positives \n",
        "  \n",
        "  $$Rec = \\frac{tp}{tp + fn} = \\frac{31}{31+14}.$$\n",
        "  \n",
        "  This is .69 in our case.\n",
        "\n",
        "\n",
        "  The function `do_evaluation`, defined in the next cell, computes precision, recall and accuracy for a test set; `do_evaluation` takes as its argument a sequence of pairs of the form (p, a), where p is the system's prediction and a is the actual class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd4jZAHWVlqu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score,accuracy_score\n",
        "\n",
        "def do_evaluation (pairs, pos_label='pos', verbose=True):\n",
        "    predicted, actual = zip(*pairs)\n",
        "    (precision, recall,accuracy) = (precision_score(actual,predicted,pos_label=pos_label), \n",
        "                                    recall_score(actual,predicted,pos_label=pos_label),\n",
        "                                    accuracy_score(actual,predicted))\n",
        "    if verbose:\n",
        "        print_results(precision, recall, accuracy, pos_label)\n",
        "    return (precision, recall,accuracy)\n",
        "\n",
        "def print_results (precision, recall, accuracy, pos_label):\n",
        "    banner =  'Evaluation with pos label = %s' % pos_label\n",
        "    print\n",
        "    print banner\n",
        "    print '=' * len(banner)\n",
        "    print '{0:10s} {1:.1f}'.format('Precision',precision*100)\n",
        "    print '{0:10s} {1:.1f}'.format('Recall',recall*100)\n",
        "    print '{0:10s} {1:.1f}'.format('Accuracy',accuracy*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkEWXFnJVlqv"
      },
      "source": [
        "The code in the next cell actually tests our NB classifier on the entire test set and prints out the result.  Note that precision and recall give different results depending on which  class we think of ourselves as detecting (which class we think of as positive).  We give evaluation numbers with respect to positive and negative reviews.  These show that our classifier actually misses a number of  negative reviews because it misclassifies them as positive (recall of positive high, recall of negative low).  Thus its high recall number when `pos_cls = pos` needs to be taken with a grain of salt.  It achieves this high recall by guessing positive a lot of the time.\n",
        "In fact, it guesses positive 74% of the time, even though it was trained on data that was 50% positive and 50% negative.\n",
        "\n",
        "This fact make it even more interesting that we correctly classified\n",
        "\n",
        "```\n",
        "I don't know how anyone could sit through Inception.\n",
        "```\n",
        "\n",
        "as negative.  In fact it turns out 'sit' is just a pretty good indicator of a negative review. It occurs 79 times in our set of 1000 negative reviews, quite often followed by 'through'.  This tells us something important.  Our intuitions aren't always good at finding good features.\n",
        "\n",
        "So why does our classifier guess positive so often?  Well, probably because it had more success finding strong positive indicators than it did finding strong negative indicators, as our glance at the most informative features suggested.  This is something we might want to worry about as we design good classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSgH0uhlVlqv",
        "outputId": "e99a1256-1274-4d3c-cc64-4db3323e919a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation with pos label = pos\n",
            "===============================\n",
            "Precision  65.5\n",
            "Recall     97.0\n",
            "Accuracy   73.0\n",
            "\n",
            "Evaluation with pos label = neg\n",
            "===============================\n",
            "Precision  94.2\n",
            "Recall     49.0\n",
            "Accuracy   73.0\n",
            "Note that 74.0% of our classifier guesses were positive\n",
            "While 50.0% of the reviews were actually positive\n"
          ]
        }
      ],
      "source": [
        "pairs = [(classifier.classify(example), actual)\n",
        "            for (example, actual) in test_set]\n",
        "\n",
        "do_evaluation (pairs)\n",
        "pos_guesses = [p for (p,a) in pairs if p=='pos']\n",
        "pos_actual = [a for (p,a) in pairs if a=='pos']\n",
        "do_evaluation (pairs, pos_label='neg')\n",
        "print 'Note that {:.1%} of our classifier guesses were positive'.format(float(len(pos_guesses))/len(pairs))\n",
        "print 'While {:.1%} of the reviews were actually positive'.format(float(len(pos_actual))/len(pairs))\n",
        "# to see the actual pairs that came out of the test uncomment the next line\n",
        "#pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5umzXbz9Vlqv"
      },
      "source": [
        "## SVM Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykaRi0UXVlqv"
      },
      "source": [
        "We'll also try a **Support Vector Machine** classifier on the movie review data, both to illustrate a different learning model and to illustrate a somewhat different set of machine learning tools than those in NLTK.\n",
        "\n",
        "Since we're not taking advantage of NLTK's code for handling its own data this time, the script below is a little closer to what you would actually end up doing with \"raw\" labeled data that you had downloaded from the web or some other data source. It still skips an important step called **Tokenization** which we defer for now, because this data has already been tokenized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWs80Qg-Vlqv",
        "outputId": "0a185049-524c-4211-aaa2-1bac43891abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note that 48.5% of our classifier guesses were positive\n",
            "While 50.0% of the reviews were actually positive\n",
            "\n",
            "Evaluation with pos label = pos\n",
            "===============================\n",
            "Precision  90.7\n",
            "Recall     88.0\n",
            "Accuracy   89.5\n",
            "\n",
            "Evaluation with pos label = neg\n",
            "===============================\n",
            "Precision  88.3\n",
            "Recall     91.0\n",
            "Accuracy   89.5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.88349514563106801, 0.91000000000000003, 0.89500000000000002)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "import os.path\n",
        "\n",
        "def add_data_from_files (file_list,data_list):\n",
        "    for f in file_list:\n",
        "        with open(f,'r') as fh:\n",
        "            data_list.append(fh.read())\n",
        "\n",
        "home = os.getenv('HOME')  \n",
        "# This is where MY NLTK data is.  Yours should be in a similar place relative\n",
        "# to what your machine thinks is HOME.\n",
        "data_dir = os.path.join(home,'nltk_data/corpora/movie_reviews/')\n",
        "\n",
        "clses = ['pos','neg']\n",
        "\n",
        "#  The data is in the data_dir, sorted into subdirectories, one for each class.\n",
        "data_dirs = [os.path.join(data_dir,cls) for cls in clses]\n",
        "#  We use a somewhat more traditional feature weights, called TFIDF weights\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                    stop_words='english')\n",
        "\n",
        "# We're going to compute 4 lists training data and labels, test data a nd labels\n",
        "train_labels = []\n",
        "test_labels = []\n",
        "\n",
        "train_data = []\n",
        "test_data = []\n",
        "training_proportion = (9,10)\n",
        "for i,cls  in enumerate(clses):\n",
        "    d_dir = data_dirs[i]\n",
        "    os.chdir(d_dir)\n",
        "    cls_files = os.listdir(d_dir)\n",
        "    num_cls_files = len(cls_files)\n",
        "    training_index = (training_proportion[0] *(num_cls_files/training_proportion[1]))\n",
        "    train_labels.extend(cls for f in cls_files[:training_index])\n",
        "    test_labels.extend(cls for f in cls_files[training_index:])\n",
        "    add_data_from_files (cls_files[:training_index],train_data)\n",
        "    add_data_from_files (cls_files[training_index:],test_data)\n",
        "\n",
        "# Now with data set represented as a list of strings (one from each file),\n",
        "# extract the TFIDF features\n",
        "train_features = vectorizer.fit_transform(train_data)\n",
        "\n",
        "#  We extract features from the test data using the same vectorizer\n",
        "#  trained on training data. The TFIDF feature model has been fit to \n",
        "#  (depends only on) the training data.\n",
        "test_features = vectorizer.transform(test_data)\n",
        "\n",
        "# Create an SVM classifier instance\n",
        "clf = LinearSVC(loss='squared_hinge', penalty=\"l2\",\n",
        "                dual=False, tol=1e-3)\n",
        "\n",
        "# Train (or \"fit\") the model to the training data.\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "# Test the model on the test data.\n",
        "predicted_labels = clf.predict(test_features)\n",
        "\n",
        "# Evaluate the results\n",
        "pos_guesses = [p for p in predicted_labels if p=='pos']\n",
        "pos_actual = [p for p in test_labels if p=='pos']\n",
        "print 'Note that {:.1%} of our classifier guesses were positive'.format(float(len(pos_guesses))/len(test_labels))\n",
        "print 'While {:.1%} of the reviews were actually positive'.format(float(len(pos_actual))/len(test_labels))\n",
        "do_evaluation (zip(predicted_labels,test_labels), pos_label='pos', verbose=True)\n",
        "do_evaluation (zip(predicted_labels,test_labels), pos_label= 'neg', verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr1bhdmaVlqw"
      },
      "source": [
        "Notice our positive label recall actually went down a bit, but as the accuracy shows, it's a much better classifier.  The average of precision and recall is much higher.  And notice the percentage of positive guesses is much closer to the actual percentage in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YszJ9bKjVlqw",
        "outputId": "4277181a-040b-4293-a8dd-3e7ae43bf164"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
              "     verbose=0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y--QdgLvVlqw",
        "outputId": "e1911292-7e7a-4fc9-e3e3-fd8cab0d02af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['C',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__doc__',\n",
              " '__format__',\n",
              " '__getattribute__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__module__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_estimator_type',\n",
              " '_get_param_names',\n",
              " '_predict_proba_lr',\n",
              " 'class_weight',\n",
              " 'classes_',\n",
              " 'coef_',\n",
              " 'decision_function',\n",
              " 'densify',\n",
              " 'dual',\n",
              " 'fit',\n",
              " 'fit_intercept',\n",
              " 'fit_transform',\n",
              " 'get_params',\n",
              " 'intercept_',\n",
              " 'intercept_scaling',\n",
              " 'loss',\n",
              " 'max_iter',\n",
              " 'multi_class',\n",
              " 'n_iter_',\n",
              " 'penalty',\n",
              " 'predict',\n",
              " 'random_state',\n",
              " 'score',\n",
              " 'set_params',\n",
              " 'sparsify',\n",
              " 'tol',\n",
              " 'transform',\n",
              " 'verbose']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wGzJstsVlqw",
        "outputId": "37f8334a-a553-4029-a46d-5e1525410a46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37674"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(clf.coef_[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TRMQI0BfVlqx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "189px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}