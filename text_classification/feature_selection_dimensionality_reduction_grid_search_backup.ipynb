{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhtQXWFRrWSd"
   },
   "source": [
    "# Text Classification:  Insults with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([ 4,  5,  6,  7,  8,  9, 10, 11]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:4],a[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(12)\n",
    "b=np.arange(12,16)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13, 14,  2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp[-1] = 2\n",
    "bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13, 14, 15])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 12,\n",
       "       13, 14, 15])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.concatenate([a,b,b])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MejilF82-rRZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "# Load libraries\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook we dive into the general question of feature selection for classifiers. In the regression\n",
    "and classification module notebook **Dimensionality Reduction** we looked at \n",
    "applying dimensionality reduction to classifiers; here we turn to feature selection, another\n",
    "technique that generally results in more compact representations and hopefully better performing\n",
    "classifiers.\n",
    "\n",
    "The general form of what we're doing\n",
    "in this notebook is to use  some metric\n",
    "to quantify the usefulness of each feature in order to\n",
    "discard all but the top $k$ features.  We'll look at the following feature selection functions in scikit learn.\n",
    "\n",
    "$$\n",
    "\\begin{array}[t]{lll}\n",
    "1. &  \\text{mutual_info_classif} &  \\text{Mutual information for a discrete target.}\\\\\n",
    "2. &  \\text{chi2} & \\text{Chi-squared stat for non-negative features for classification tasks.}\\\\\n",
    "3. &  \\text{fclassif} &  \\text{ANOVA F-value between label/feature for classification tasks.}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Mutual Information, written $\\text{I}$, is defined to be:\n",
    "\n",
    "$$\n",
    "\\text{I}\\,(X;\\,Y) = \\text{D}_{\\text{KL}}\\,(\\, \\text{P}_{X,Y} \\mid\\mid \\text{P}_{X}\\otimes \\text{P}_{Y}\\, )\n",
    "$$\n",
    "\n",
    "\n",
    "where $D_{\\text{KL}}$ is the Kullback-Leibler Divergence (KL-Divergence) of two distributions and\n",
    "$\\text{P}_{X,Y}$ is the joint distribution of X and Y and $\\text{P}_{X}\\otimes \\text{P}_{Y}$ is \n",
    "the distribution that gives $P(X) \\times P(Y)$ as the joint probability of X and Y.\n",
    "KL Divergence is an Information Theoretic measure of the divergence\n",
    "between two distributions, $\\text{I}\\,(X;\\,Y)$ measures the distance between\n",
    "the joint distribution and the distribution that would obtain\n",
    "if X and Y were completely independent.  If X and Y are independent,\n",
    "$\\text{I}\\,(X;\\,Y)$ is 0.  If X conditionally depends on Y, that\n",
    "increases the difference between the joint distribution and independence ($\\text{P}_{X}\\otimes \\text{P}_{Y}$).\n",
    "\n",
    "Thus $\\text{I}\\,(X;\\,Y)$ measures the amount of information you gain about the outcome of $Y$\n",
    "if you know the outcome $X$.  If Y is a class assignment and X is a feature column\n",
    "in our data matrix, $\\text{I}\\,(X;\\,Y)$  measures how much knowing the value of feature $X$ \n",
    "tells us about the class Y.  Hence, it makes sense to use $\\text{I}\\,(F;\\,c)$ to measure how useful\n",
    "feature F is for a classification problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi2 classification function takes the feature matrix and the class labels  as arguments\n",
    "and for each feature and each computes the $\\Xi^{2}@ statistic representing the strength\n",
    "of the feature's association with the class.\n",
    "\n",
    "A note of caution:  The test really only makes sense for categorical variables, but\n",
    "the scikit learn implementation is built in such a way that it can be used for\n",
    "continuous variables.  We will try both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.25415508e+01, 7.35179236e-02, 7.25973700e-02, 1.01320229e-02,\n",
       "       1.08125275e+00, 5.54434465e-02, 1.13279935e-02, 1.09136519e-01,\n",
       "       1.32228682e-01, 1.66505941e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "        n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1, \n",
    "        shuffle=False, random_state=42,shift=5)\n",
    "chi2_stats, p_values = chi2(X, y)\n",
    "chi2_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers show that all but 2 of the 10 features have little connection with the classification\n",
    "problem.  Of course we set it up this way when we created `X, y` with `make_classification`,  by\n",
    "setting the parameter `n_informative` to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the column numbers arranged from least significant to most significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 9, 5, 2, 1, 7, 8, 4, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_stats.argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the following code makes a new feature matrix containing only the two\n",
    "most significant features (the columns indexed 0 and 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X[:, chi2_stats.argsort()[-2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the ANOVA F-value (or `fclassif` in scikit learn) compares the ration of explained\n",
    "variance to the unexaplined variance. If the null hypothesis is true, you expect F to have a value close to 1.0 most of the time. A large F ratio means that the variation among group means is more than you'd expect to see by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qildTjvw-rRb"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28jZSTW_-rRb"
   },
   "source": [
    "Let's open the CSV file with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MtGQlB1q-rRc"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "site = 'https://raw.githubusercontent.com/gawron/python-for-social-science/master/'\\\n",
    "'text_classification/'\n",
    "#site = 'https://gawron.sdsu.edu/python_for_ss/course_core/book_draft/_static/'\n",
    "df = pd.read_csv(os.path.join(site,\"troll.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3ncLUYx-rRc"
   },
   "source": [
    "Each row is a comment  taken from a blog or online forum. There are three columns: whether the comment is insulting (1) or not (0), the data, and the unicode-encoded contents of the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pFeNaW-m-rRd",
    "outputId": "0d5e5e36-697f-4fd8-ff00-ef8d164a3c35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment\n",
       "3942       1  \"you are both morons and that is never happening\"\n",
       "3943       0  \"Many toolbars include spell check, like Yahoo...\n",
       "3944       0  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...\n",
       "3945       0  \"How about Felix? He is sure turning into one ...\n",
       "3946       0  \"You're all upset, defending this hipster band..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Insult', 'Comment']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "H-fPVjYV-rRl"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets FIRST\n",
    "T_train,T_test, y_train,y_test = train_test_split(df['Comment'],df['Insult'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demoing $\\chi^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported the `chi2` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.feature_selection._univariate_selection.chi2(X, y)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's ine way to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "4JLT1QylrWSn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2960 13829\n"
     ]
    }
   ],
   "source": [
    "#tf = text.TfidfVectorizer(min_df=2,max_df=.8)\n",
    "sublinear_tf = True\n",
    "#subliner_tf = False\n",
    "tf = text.TfidfVectorizer(sublinear_tf=sublinear_tf)\n",
    "# Train your vectorizer oNLY on the trainingh data.\n",
    "X_train = tf.fit_transform(T_train)\n",
    "print(*X_train.shape)\n",
    "# N features with highest chi-squared statistics are selected\n",
    "# chi2 is a functiomported above\n",
    "chi2_features = SelectKBest(chi2, k = 10_000)\n",
    "X_train_chi = chi2_features.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IO9ykCgdrWSn"
   },
   "source": [
    "`X-train` is our **term-document** matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUihdpHIgA7e",
    "outputId": "3a69016d-c65e-4994-e021-3451880e8b00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2960, 13829), (2960, 10000))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_train_chi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0wp6RbS-rRo"
   },
   "source": [
    "## Preliminary experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88mG_1C0-rRo"
   },
   "source": [
    "Now, we are going to train a classifier as usual. We\n",
    "have already split the data and labels into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf-3XQDN-rRo"
   },
   "source": [
    "We use an **SVM classifier** and try it out on the two representations of our\n",
    "data,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "uj7vvTS--rRo",
    "outputId": "c3be5d3a-7801-4311-d8da-45c6a267b36e"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf_chi = LinearSVC()\n",
    "\n",
    "# Unreduced\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "uj7vvTS--rRo",
    "outputId": "c3be5d3a-7801-4311-d8da-45c6a267b36e"
   },
   "outputs": [],
   "source": [
    "# Reduced\n",
    "clf_chi.fit(X_train_chi, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMWe6ZCDrWSo"
   },
   "source": [
    "And we're done.  How'd we do?  Now we  test on the test set.  Before we can do that we need to\n",
    "vectorize the test set.  But don't just copy what we did with the training data:\n",
    "\n",
    "```\n",
    "X_test = tf.fit_transform(T_test)\n",
    "```\n",
    "\n",
    "That would retrain the vectorizer from scratch.  Any words that occurred in the training texts\n",
    "but not in the test texts would be forgotten!  Plus training the vectorizer\n",
    "is part of the classifier training pipeline.  If we let the vectorizer see\n",
    "the test data during its training phase, we'd be compromising the whole\n",
    "idea of splitting training and test data.  So what we want to do\n",
    "with the test data is just apply the transform part of vectorizing:\n",
    "\n",
    "```\n",
    "X_test = tf.transform(T_test)\n",
    "```\n",
    "\n",
    "That is, build a representation of the test data using only the vocabulary you learned\n",
    "about in training.  Ignore any new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rewbP2vT-rRp",
    "outputId": "fa1e71c6-3712-443d-a90f-49faa0d4f013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8358662613981763, 0.8297872340425532)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tf.transform(T_test)\n",
    "X_test_chi = chi2_features.transform(X_test)\n",
    "clf.score(X_test, y_test),clf_chi.score(X_test_chi, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, not a reliable result.  But at least trimming down the model didn't seem to hurt it.\n",
    "\n",
    "Let's clean this all up a bit by putting everything in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8409321175278622, 0.5478927203065134, 0.7857142857142857)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "\n",
    "#from sklearn import decomposition as dec\n",
    "#from pipeline import make_pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#poly = preprocessing.PolynomialFeatures(degree=20, include_bias=True)\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#lin_reg2 = linear_model.LinearRegression()\n",
    "\n",
    "X,y = df['Comment'].values,df['Insult'].values\n",
    "\n",
    "def make_tf_feat_selection_clf_pipeline (selection_function=None, k=5_000,\n",
    "                                         selector = SelectKBest,sublinear_tf=False):\n",
    "    tf = text.TfidfVectorizer(sublinear_tf=sublinear_tf)\n",
    "    #chi2_features = SelectKBest(selector, k)\n",
    "    if selection_function is not None:\n",
    "        k_best_features = selector(selection_function, k=k)\n",
    "    else:\n",
    "        k_best_features = selector(k=k)\n",
    "    svm_clf = LinearSVC()\n",
    "    return pipeline.Pipeline([('vect', tf), ('feat_selector', k_best_features), ('svm', svm_clf)])\n",
    "\n",
    "\n",
    "pipeline_reg = make_tf_feat_selection_clf_pipeline (selection_function=f_classif, k=5_000,sublinear_tf=True)\n",
    "\n",
    "# Train\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "pipeline_reg.fit(T_train, y_train)\n",
    "predicted = pipeline_reg.predict(T_test)\n",
    "\n",
    "accuracy_score(predicted, y_test),\\\n",
    "precision_score(predicted, y_test),\\\n",
    "recall_score(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_classif\n",
      "===================\n",
      "k= 3_000 a=0.840 p=0.554 r=0.770\n",
      "k= 5_000 a=0.834 p=0.541 r=0.762\n",
      "k=10_000 a=0.832 p=0.586 r=0.731\n"
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "stats = np.zeros((num_runs,3))\n",
    "#selection_function = chi2\n",
    "selection_function = f_classif\n",
    "sublinear_tf=True\n",
    "print(selection_function.__name__,end=\"\\n===================\\n\")\n",
    "for k in (3_000,5_000, 10_000):\n",
    "    for test_run in range(num_runs):\n",
    "        pipeline_reg = make_tf_feat_selection_clf_pipeline (selection_function = selection_function,k=k,\n",
    "                                                           sublinear_tf=sublinear_tf)\n",
    "        T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "         \n",
    "        # Train\n",
    "        pipeline_reg.fit(T_train, y_train)\n",
    "        # Test\n",
    "        predicted = pipeline_reg.predict(T_test)\n",
    "        stats[test_run] = accuracy_score(predicted, y_test),\\\n",
    "                            precision_score(predicted, y_test),\\\n",
    "                             recall_score(predicted, y_test)\n",
    "\n",
    "    stats_mn = stats.mean(axis=0)\n",
    "    a,p,r = stats_mn\n",
    "\n",
    "    print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2\n",
      "===================\n",
      "k= 3_000 a=0.837 p=0.555 r=0.774\n",
      "k= 5_000 a=0.836 p=0.568 r=0.759\n",
      "k=10_000 a=0.837 p=0.592 r=0.744\n"
     ]
    }
   ],
   "source": [
    "num_runs = 10\n",
    "stats = np.zeros((num_runs,3))\n",
    "selection_function = chi2\n",
    "#selection_function = f_classif\n",
    "sublinear_tf=True\n",
    "\n",
    "print(selection_function.__name__,end=\"\\n===================\\n\")\n",
    "for k in (3_000,5_000, 10_000):\n",
    "    for test_run in range(num_runs):\n",
    "        pipeline_reg = make_tf_feat_selection_clf_pipeline (selection_function = selection_function,k=k)\n",
    "        T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "        # Train\n",
    "        pipeline_reg.fit(T_train, y_train)\n",
    "        # Test\n",
    "        predicted = pipeline_reg.predict(T_test)\n",
    "        stats[test_run] = accuracy_score(predicted, y_test),\\\n",
    "                            precision_score(predicted, y_test),\\\n",
    "                             recall_score(predicted, y_test)\n",
    "\n",
    "    stats_mn = stats.mean(axis=0)\n",
    "    a,p,r = stats_mn\n",
    "\n",
    "    print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual information can work like the others but used in the context of select KBest\n",
    "it requires discrete-valued features, so we need a slightly different pipeline.\n",
    "\n",
    "We will CountVectorize our doc set to give a term document matrix (TDM) filled with\n",
    "counts, run mutual information on that to feature reduce, and then classify in\n",
    "the usual way.  Note we use a TfidfTransformer rather than a TfidfVectorizer.  This\n",
    "is because the docs have already been vectorized so we nbeed a transformer that\n",
    "maps from a TDM with counts to a TDM with TFIDF values; TfidfTransformer fits\n",
    "the bill.\n",
    "\n",
    "The following code also gives us  a chance to try out chi2 on counts, which\n",
    "it was always intended for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3_000 a=0.806 p=0.789 r=0.350\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "k = 500\n",
    "kb= SelectKBest(mutual_info_classif,k=k)\n",
    "# You can try these others with this pipeline as well.\n",
    "# chi2 and f_classif work better with numbers over 3K\n",
    "#kb= SelectKBest(f_classif,k=k)\n",
    "#kb= SelectKBest(chi2, k=k)\n",
    "\n",
    "\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "         \n",
    "svm_clf = LinearSVC()\n",
    "\n",
    "cv = CountVectorizer()\n",
    "tf = text.TfidfTransformer(sublinear_tf=True)\n",
    "\n",
    "pipeline_reg=pipeline.Pipeline([('vect', cv), ('feat_selector', kb),\n",
    "                                ('tfidf',tf), ('svm', svm_clf)])\n",
    "# Train\n",
    "pipeline_reg.fit(T_train, y_train)\n",
    "# Test\n",
    "predicted = pipeline_reg.predict(T_test)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "a,p,r = accuracy_score(y_test,predicted,),\\\n",
    "        precision_score(y_test, predicted),\\\n",
    "            recall_score(y_test, predicted)\n",
    "\n",
    "# MI k= 3_000 a=0.806 p=0.789 r=0.350\n",
    "# chi k= 3_000 a=0.806 p=0.789 r=0.350\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A Mutual Information transformer\n",
    "\n",
    "Let's implement a Mutual Information Transformer.\n",
    "\n",
    "Assumption:\n",
    "The Mutual Information Transformer.**always** accepts a Term Doc (as a 2D numpuy array) and alwys outputs \n",
    "a 2D numpy array with fewer columns.\n",
    "\n",
    "We will use Mutual Information two ways\n",
    "\n",
    "1.  Pass in a sequence of strings add select a vocab using word counts (operating on a Count Vectorized representation of the docs like we did above)\n",
    "2.  Operate on a TFIDF TDM to do feature selection.\n",
    "\n",
    "\n",
    "Model A\n",
    "----------\n",
    "\n",
    "To do feature selection on the base of counts, we pass in a count vectorizer \n",
    "TDM and pass back a truncated feat vectorizer.  We then pass that to a TFIDFTransformer.\n",
    "(which accepts a CountVectorized TDM).\n",
    "\n",
    "\n",
    "T_Train, T_Test, y_Train, y_Test\n",
    "\n",
    "vec_pipe = [CountVectorizer =>  Mutual Info => TFIDFTransformer => LinearSVC]\n",
    "\n",
    "X_Train = vec_pipe.fit_transform(T_Train)\n",
    "predicted = vec_pipe.transform(T_test)\n",
    "\n",
    "\n",
    "Model B\n",
    "-----------\n",
    "\n",
    "Operate on a TFIDF TDM to do feature selection.\n",
    "\n",
    "```python\n",
    "T_Train, T_Test, y_Train, y_Test\n",
    "```\n",
    "\n",
    "vec_pipe = [TFIDFVectorizer =>  Mutual Info => LinearSVC]\n",
    "\n",
    "\n",
    "```python\n",
    "X_Train = vec_pipe.fit_transform(T_Train)\n",
    "predicted = vec_pipe.transform(T_test)\n",
    "```\n",
    "\n",
    "Note we switch from the TFIDFTransformer to the TFIDF Vectorizer,  The former acceots a count\n",
    "vectorized TD as input.  The latter wants a sequence of document strin gs.  Both\n",
    "out a TDM with TFIDF values.  \n",
    "\n",
    "CountVectorizer => TFIDFTransformer\n",
    "\n",
    "is equivalent  to\n",
    "\n",
    "TFIDFVectorizer\n",
    "\n",
    "The motivation for resorting to the  Transformer is so that we could interpose\n",
    "Mutual Information feature selection between Count Vectorizing and converting the\n",
    "counts to TFIDF values.  This allows MI selection to work on probabilities based on counts,\n",
    "more or less its original intent, and avoids averaging based on nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "class MutualInfo:\n",
    "    \n",
    "    def  __init__(self,k,discrete_features=True):\n",
    "        self.k =k\n",
    "        self.discrete_features = discrete_features\n",
    "        \n",
    "    def fit_transform(self,X,y):\n",
    "        \"\"\"\n",
    "        If self.use_counts create  cv, a count vectorized version of X,\n",
    "        and assign feature ranks based mutual info of cv[:,feat_i] and y\n",
    "        Use the feature ranks to choose a vocab of size self.k.\n",
    "        \n",
    "        Otherwise assign feature ranks based mutual info of X[:,feat_i] and y\n",
    "        Use the feature ranks to choose a vocab of size self.k.\n",
    "        \"\"\"\n",
    "        \n",
    "        if hasattr(X,'toarray'):\n",
    "            X = X.toarray()\n",
    "    \n",
    "        ranks = mutual_info_classif(X, y,discrete_features=self.discrete_features)\n",
    "        self.idxs = ranks.argsort()[-self.k:]\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform (self, X):\n",
    "        if X.ndim == 2:\n",
    "            return X[:,self.idxs]\n",
    "        else:\n",
    "            return X[self.idxs]\n",
    "\n",
    "\n",
    "sublinear_tf,k=True,3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3_000 a=0.817 p=0.765 r=0.533\n"
     ]
    }
   ],
   "source": [
    "### Model A\n",
    "\n",
    "def make_model_A ():\n",
    "    cv = CountVectorizer()\n",
    "    mi = MutualInfo(k=k,discrete_features=True)\n",
    "    tf = text.TfidfTransformer(sublinear_tf=sublinear_tf)\n",
    "    svm_clf = LinearSVC()\n",
    "\n",
    "    return pipeline.Pipeline([('vect', cv), \n",
    "                              ('feat_selector', mi), \n",
    "                              ('tfidf_vect',tf), \n",
    "                              ('svm', svm_clf)])\n",
    "\n",
    "# Data \n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "#Train\n",
    "vec_pipe = make_model_A ()\n",
    "vec_pipe.fit(T_train, y_train)\n",
    "#Test\n",
    "predicted = vec_pipe.predict(T_test)\n",
    "\n",
    "a,p, r = accuracy_score(y_test,predicted),\\\n",
    "           precision_score(y_test, predicted),\\\n",
    "              recall_score(y_test, predicted)\n",
    "\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3_000 a=0.785 p=0.678 r=0.482\n"
     ]
    }
   ],
   "source": [
    "# Model B\n",
    "\n",
    "def make_model_B():\n",
    "    mi = MutualInfo(k=k, discrete_features=False)\n",
    "    tf = text.TfidfVectorizer(sublinear_tf=sublinear_tf)\n",
    "    svm_clf = LinearSVC()\n",
    "\n",
    "    return pipeline.Pipeline([('tfidf_vect',tf),  ('feat_selector', mi), ('svm', svm_clf)])\n",
    "\n",
    "# Data \n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "#Train\n",
    "vec_pipe =  make_model_B()\n",
    "vec_pipe.fit(T_train, y_train)\n",
    "#Test\n",
    "predicted = vec_pipe.predict(T_test)\n",
    "\n",
    "a,p, r = accuracy_score(y_test, predicted),\\\n",
    "           precision_score(y_test, predicted),\\\n",
    "              recall_score(y_test, predicted)\n",
    "\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of dimensionality reduction\n",
    "\n",
    "Model\n",
    "\n",
    "[TFDIF -> TruncatedSVD -> SVM]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Truncated SVD for reduction\n",
      "Beginning reduction fit print 2024-04-20 12:35:57.324080 \n",
      "Reduction fit completed 2024-04-20 12:36:39.164440 \n",
      "k= 3_000 a=0.830 p=0.750 r=0.600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD\n",
    "# Avoiding SparsePCA which seems ill-behaved\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "## Data \n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "## Reduction params\n",
    "#k,sparse_pca=500,False\n",
    "k,sparse_pca=3_000,False\n",
    "#red = TruncatedSVD(n_components=k)\n",
    "#red = NMF(n_components=k)\n",
    "\n",
    "if sparse_pca:\n",
    "    print(\"Using sparse PCA for reduction\")\n",
    "    red = SparsePCA(n_components=k)\n",
    "else:\n",
    "    print(\"Using Truncated SVD for reduction\")\n",
    "    red = TruncatedSVD(n_components=k)\n",
    "# Data \n",
    "\n",
    "#TSVD k= 500 a=0.823 p=0.716 r=0.580\n",
    "\n",
    "######  Text -> TFIDF\n",
    "vectorizer = text.TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(T_train)\n",
    "X_test = vectorizer.transform(T_test)\n",
    "\n",
    "if sparse_pca:\n",
    "    X_train = X_train.toarray()\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "#########\n",
    "\n",
    "###### TFIDF -> reduced\n",
    "print(f\"Beginning reduction fit print {datetime.now()} \")\n",
    "X_train_red = red.fit_transform(X_train)\n",
    "print(f\"Reduction fit completed {datetime.now()} \")\n",
    "X_test_red = red.transform(X_test)\n",
    "############\n",
    "\n",
    "### Reduced =>  Class\n",
    "\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_red,y_train)\n",
    "predicted = svm_clf.predict(X_test_red)\n",
    "\n",
    "### Eval\n",
    "a,p, r = accuracy_score(y_test, predicted),\\\n",
    "           precision_score(y_test, predicted),\\\n",
    "              recall_score(y_test, predicted)\n",
    "\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:32:33.001275 \n",
    "Reduction fit completed 2024-04-20 12:33:17.055381 \n",
    "k= 3_000 a=0.843 p=0.761 r=0.630\n",
    "\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:33:51.944394 \n",
    "Reduction fit completed 2024-04-20 12:34:34.503089 \n",
    "k= 3_000 a=0.818 p=0.702 r=0.600\n",
    "\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:34:54.958394 \n",
    "Reduction fit completed 2024-04-20 12:35:37.068576 \n",
    "k= 3_000 a=0.848 p=0.791 r=0.579\n",
    "\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:35:57.324080 \n",
    "Reduction fit completed 2024-04-20 12:36:39.164440 \n",
    "k= 3_000 a=0.830 p=0.750 r=0.600\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Putting it all together:  The Grid Search\n",
    "\n",
    "We have two sets of different techniques for reducing the size of document representations\n",
    "and hopefully improving classifier performance: dimensionality redction and feature selection.\n",
    "But which reduction technique should we use, and how many features should we keep?\n",
    "\n",
    "Answering questions like these is what the scikit learn grid search package was designed for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saturday 20. April 2024 12:38:39\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3; 1/8] START classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=500\n",
      "[CV 1/3; 1/8] END classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=500;, score=0.656 total time=   0.1s\n",
      "[CV 2/3; 1/8] START classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=500\n",
      "[CV 2/3; 1/8] END classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=500;, score=0.667 total time=   0.1s\n",
      "[CV 3/3; 1/8] START classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=500\n",
      "[CV 3/3; 1/8] END classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=500;, score=0.660 total time=   0.1s\n",
      "[CV 1/3; 2/8] START classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=3000\n",
      "[CV 1/3; 2/8] END classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=3000;, score=0.656 total time=   0.1s\n",
      "[CV 2/3; 2/8] START classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=3000\n",
      "[CV 2/3; 2/8] END classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=3000;, score=0.667 total time=   0.1s\n",
      "[CV 3/3; 2/8] START classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=3000\n",
      "[CV 3/3; 2/8] END classify__C=1.0, reduce_dim=IdentityTransformer(), reduce_dim__n_components=3000;, score=0.660 total time=   0.1s\n",
      "[CV 1/3; 3/8] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV,ShuffleSplit\n",
    "\n",
    "\n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "\n",
    "pipe = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", text.TfidfVectorizer()),\n",
    "        # the reduce_dim stage is populated by the param_grid\n",
    "        (\"reduce_dim\", \"passthrough\"),\n",
    "        (\"classify\", LinearSVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#N_FEATURES_OPTIONS = [5_000, 3_000, 500]\n",
    "N_FEATURES_OPTIONS = [500, 3_000]\n",
    "#C_OPTIONS = np.logspace(0,2,3)\n",
    "C_OPTIONS = np.logspace(0,1,2)\n",
    "#DIM_REDUCERS = [TruncatedSVD(), NMF(max_iter=1_000)]\n",
    "DIM_REDUCERS = [TruncatedSVD()]\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=0):\n",
    "        self.n_components=n_components\n",
    "        pass\n",
    "    \n",
    "    def fit(self, input_array, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        return input_array*1\n",
    "\n",
    "#DIM_REDUCERS = [TruncatedSVD(), NMF(max_iter=1_000)]\n",
    "DIM_REDUCERS = [IdentityTransformer(), TruncatedSVD()]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"reduce_dim\": DIM_REDUCERS,\n",
    "        \"reduce_dim__n_components\": N_FEATURES_OPTIONS,\n",
    "        \"classify__C\": C_OPTIONS,\n",
    "    },\n",
    "#    {\n",
    "#        \"reduce_dim\": [SelectKBest(chi2),SelectKBest(f_classif)],\n",
    "#        \"reduce_dim__k\": N_FEATURES_OPTIONS,\n",
    "#        \"classify__C\": C_OPTIONS,\n",
    "#    },\n",
    "]\n",
    "\n",
    "# The default is 5-fold cross validation\n",
    "#cv=3\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "t0 = time.time()\n",
    "print(datetime.now().strftime(\"%A %d. %B %Y %H:%M:%S\"))\n",
    "\n",
    "# If a grid search is too costly\n",
    "#grid = RandomizedSearchCV(\n",
    "#    estimator=pipe,\n",
    "#    param_distributions=param_grid,\n",
    "#    n_iter=10,\n",
    "#    random_state=0,\n",
    "#    scoring = \"f1\"\n",
    "#    n_jobs=1,\n",
    "#    verbose=10,\n",
    "#    cv = cv\n",
    "#)\n",
    "\n",
    "from joblib import parallel_backend\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"f1\", n_jobs=1, cv=cv, verbose=10)\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    grid.fit(X, y)\n",
    "datetime.now().strftime(\"%A %d. %B %Y %H:%M:%S\")\n",
    "secs = time.time() - t0\n",
    "hrs,mins = secs//3600,(secs%3600)//60\n",
    "print(f\"{hrs} hours {mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%A %d. %B %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reduce_dim': [TruncatedSVD()],\n",
       " 'reduce_dim__n_components': [3000, 500],\n",
       " 'classify__C': array([ 1., 10.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "classify__C: 1.0\n",
      "reduce_dim: SelectKBest(k=3000)\n",
      "reduce_dim__n_components: Not found\n",
      "classify__C: 1.0\n",
      "reduce_dim: SelectKBest(k=3000)\n",
      "reduce_dim__k: 3000\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters combination found:\")\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for subgrid in param_grid:\n",
    "    for param_name in sorted(subgrid.keys()):\n",
    "        try:\n",
    "            print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "        except KeyError:\n",
    "            print(f\"{param_name}: Not found\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reducer_labels = [\"SVD\", \"KBest(chi2)\",\"KBest(f_classif)\"]\n",
    "\n",
    "mean_scores = np.array(grid.cv_results_[\"mean_test_score\"])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "# create a dataframe to ease plotting\n",
    "mean_scores = pd.DataFrame(\n",
    "    mean_scores.T, index=N_FEATURES_OPTIONS, columns=reducer_labels\n",
    ")\n",
    "\n",
    "ax = mean_scores.plot.bar()\n",
    "ax.set_title(\"Comparing feature reduction techniques\")\n",
    "ax.set_xlabel(\"Reduced number of features\")\n",
    "ax.set_ylabel(\"F-Score\")\n",
    "ax.set_ylim((0, 1))\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion questions\n",
    "-------------------------\n",
    "\n",
    "1. Call all the features with variable values in the code above\n",
    "   our **grid features**. And call one particular\n",
    "   assignment of values to **all** our grid features a **grid point**.  How many\n",
    "   distinct grid points are there in our grid?\n",
    "2. How many experiments did the grid search run?  Note this depends \n",
    "   both on the number of grid points and the number of \"folds\". in the cross validation strategy.\n",
    "3. What grid points have been left out of our plot? \n",
    "4. What is the best combination of features?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Insults_with_Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "94px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
