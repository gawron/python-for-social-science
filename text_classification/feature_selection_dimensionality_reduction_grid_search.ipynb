{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhtQXWFRrWSd"
   },
   "source": [
    "# Text Classification:  Insults with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys;print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MejilF82-rRZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "# Load libraries\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook we dive into the general question of feature selection for classifiers. In the regression\n",
    "and classification module notebook **Dimensionality Reduction** we looked at \n",
    "applying dimensionality reduction to classifie4rs; here we turn to feature selection, another\n",
    "technique that generally results in more compact representations and hopefully better performing\n",
    "classifiers.\n",
    "\n",
    "The general form of what we're doing\n",
    "in this notebook is to use  some metric\n",
    "to quantify the usefulness of each feature in order to\n",
    "discard all but the top $k$ features.  We'll look at the following feature selection functions in scikit learn.\n",
    "\n",
    "$$\n",
    "\\begin{array}[t]{lll}\n",
    "1. &  \\text{mutual_info_classif} &  \\text{Mutual information for a discrete target.}\\\\\n",
    "2. &  \\text{chi2} & \\chi^2 \\text{ stat for non-negative features for classification tasks.}\\\\\n",
    "3. &  \\text{fclassif} &  \\text{ANOVA F-value between label/feature for classification tasks.}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Mutual Information, written $\\text{I}$, is defined to be:\n",
    "\n",
    "$$\n",
    "\\text{I}\\,(X;\\,Y) = \\text{D}_{\\text{KL}}\\,(\\, \\text{P}_{X,Y} \\mid\\mid \\text{P}_{X}\\otimes \\text{P}_{Y}\\, )\n",
    "$$\n",
    "\n",
    "\n",
    "where $D_{\\text{KL}}$ is the Kullback-Leibler Divergence (KL-Divergence) of two distributions and\n",
    "$\\text{P}_{X,Y}$ is the joint distribution of X and Y and $\\text{P}_{X}\\otimes \\text{P}_{Y}$ is \n",
    "the distribution that gives $P(X) \\times P(Y)$ as the joint probability of X and Y.\n",
    "KL Divergence is an Information Theoretic measure of the divergence\n",
    "between two distributions, $\\text{I}\\,(X;\\,Y)$ measures the distance between\n",
    "the joint distribution and the distribution that would obtain\n",
    "if X and Y were completely independent.  If X and Y are independent,\n",
    "$\\text{I}\\,(X;\\,Y)$ is 0.  If X conditionally depends on Y, that\n",
    "increases the difference between the joint distribution and independence ($\\text{P}_{X}\\otimes \\text{P}_{Y}$).\n",
    "\n",
    "Thus $\\text{I}\\,(X;\\,Y)$ measures the amount of information you gain about the outcome of $Y$\n",
    "if you know the outcome $X$.  If Y is a class assignment and X is a feature column\n",
    "in our data matrix, $\\text{I}\\,(X;\\,Y)$  measures how much knowing the value of feature $X$ \n",
    "tells us about the class Y.  Hence, it makes sense to use $\\text{I}\\,(F;\\,c)$ to measure how useful\n",
    "feature F is for a classification problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi2 classification function takes the feature matrix and the class labels  as arguments\n",
    "and for each feature and each computes the $\\Xi^{2}@ statistic representing the strength\n",
    "of the feature's association with the class.\n",
    "\n",
    "A note of caution:  The test really only makes sense for categorical variables, but\n",
    "the scikit learn implementation is built in such a way that it can be used for\n",
    "continuous variables.  We will try both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.25415508e+01, 7.35179236e-02, 7.25973700e-02, 1.01320229e-02,\n",
       "       1.08125275e+00, 5.54434465e-02, 1.13279935e-02, 1.09136519e-01,\n",
       "       1.32228682e-01, 1.66505941e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "        n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1, \n",
    "        shuffle=False, random_state=42,shift=5)\n",
    "chi2_stats, p_values = chi2(X, y)\n",
    "chi2_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers show that all but 2 of the 10 features have little connection with the classification\n",
    "problem.  Of course we set it up this way when we created `X, y` with `make_classification`,  by\n",
    "setting the parameter `n_informative` to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the column numbers arranged from least significant to most significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 9, 5, 2, 1, 7, 8, 4, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_stats.argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the following code makes a new feature matrix containing only the two\n",
    "most significant features (the columns indexed 0 and 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X[:, chi2_stats.argsort()[-2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the ANOVA F-value (or `fclassif` in scikit learn) compares the ration of explained\n",
    "variance to the unexaplined variance. If the null hypothesis is true, you expect F to have a value close to 1.0 most of the time. A large F ratio means that the variation among group means is more than you'd expect to see by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qildTjvw-rRb"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28jZSTW_-rRb"
   },
   "source": [
    "Let's open the CSV file with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MtGQlB1q-rRc"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "site = 'https://raw.githubusercontent.com/gawron/python-for-social-science/master/'\\\n",
    "'text_classification/'\n",
    "#site = 'https://gawron.sdsu.edu/python_for_ss/course_core/book_draft/_static/'\n",
    "df = pd.read_csv(os.path.join(site,\"troll.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3ncLUYx-rRc"
   },
   "source": [
    "Each row is a comment  taken from a blog or online forum. There are three columns: whether the comment is insulting (1) or not (0), the data, and the unicode-encoded contents of the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pFeNaW-m-rRd",
    "outputId": "0d5e5e36-697f-4fd8-ff00-ef8d164a3c35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment\n",
       "3942       1  \"you are both morons and that is never happening\"\n",
       "3943       0  \"Many toolbars include spell check, like Yahoo...\n",
       "3944       0  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...\n",
       "3945       0  \"How about Felix? He is sure turning into one ...\n",
       "3946       0  \"You're all upset, defending this hipster band..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Insult', 'Comment']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H-fPVjYV-rRl"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets FIRST\n",
    "T_train,T_test, y_train,y_test = train_test_split(df['Comment'],df['Insult'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demoing $\\chi^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported the `chi2` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.feature_selection._univariate_selection.chi2(X, y)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's ine way to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5193816927044406"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()[0,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4JLT1QylrWSn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2960 14053\n"
     ]
    }
   ],
   "source": [
    "#tf = text.TfidfVectorizer(min_df=2,max_df=.8)\n",
    "sublinear_tf = True\n",
    "#subliner_tf = False\n",
    "tf = text.TfidfVectorizer(sublinear_tf=sublinear_tf)\n",
    "# Train your vectorizer oNLY on the trainingh data.\n",
    "X_train = tf.fit_transform(T_train)\n",
    "print(*X_train.shape)\n",
    "# N features with highest chi-squared statistics are selected\n",
    "# chi2 is a functiomported above\n",
    "chi2_features = SelectKBest(chi2, k = 10_000)\n",
    "X_train_chi = chi2_features.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IO9ykCgdrWSn"
   },
   "source": [
    "`X-train` is our **term-document** matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUihdpHIgA7e",
    "outputId": "3a69016d-c65e-4994-e021-3451880e8b00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2960, 14053), (2960, 10000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_train_chi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0wp6RbS-rRo"
   },
   "source": [
    "## Preliminary experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88mG_1C0-rRo"
   },
   "source": [
    "Now, we are going to train a classifier as usual. We\n",
    "have already split the data and labels into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf-3XQDN-rRo"
   },
   "source": [
    "We use an **SVM classifier** and try it out on the two representations of our\n",
    "data,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "uj7vvTS--rRo",
    "outputId": "c3be5d3a-7801-4311-d8da-45c6a267b36e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf_chi = LinearSVC()\n",
    "\n",
    "# Unreduced\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "uj7vvTS--rRo",
    "outputId": "c3be5d3a-7801-4311-d8da-45c6a267b36e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduced\n",
    "clf_chi.fit(X_train_chi, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMWe6ZCDrWSo"
   },
   "source": [
    "And we're done.  How'd we do?  Now we  test on the test set.  Before we can do that we need to\n",
    "vectorize the test set.  But don't just copy what we did with the training data:\n",
    "\n",
    "```\n",
    "X_test = tf.fit_transform(T_test)\n",
    "```\n",
    "\n",
    "That would retrain the vectorizer from scratch.  Any words that occurred in the training texts\n",
    "but not in the test texts would be forgotten!  Plus training the vectorizer\n",
    "is part of the classifier training pipeline.  If we let the vectorizer see\n",
    "the test data during its training phase, we'd be compromising the whole\n",
    "idea of splitting training and test data.  So what we want to do\n",
    "with the test data is just apply the transform part of vectorizing:\n",
    "\n",
    "```\n",
    "X_test = tf.transform(T_test)\n",
    "```\n",
    "\n",
    "That is, build a representation of the test data using only the vocabulary you learned\n",
    "about in training.  Ignore any new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rewbP2vT-rRp",
    "outputId": "fa1e71c6-3712-443d-a90f-49faa0d4f013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8267477203647416, 0.8358662613981763)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tf.transform(T_test)\n",
    "X_test_chi = chi2_features.transform(X_test)\n",
    "clf.score(X_test, y_test),clf_chi.score(X_test_chi, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea one:  Use a pipeline\n",
    "\n",
    "Well, not a reliable result.  But at least trimming down the model didn't seem to hurt it.\n",
    "\n",
    "Let's clean this all up a bit by putting everything in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8389057750759878, 0.5490909090909091, 0.8118279569892473)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "\n",
    "#from sklearn import decomposition as dec\n",
    "#from pipeline import make_pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#poly = preprocessing.PolynomialFeatures(degree=20, include_bias=True)\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#lin_reg2 = linear_model.LinearRegression()\n",
    "\n",
    "X,y = df['Comment'].values,df['Insult'].values\n",
    "\n",
    "def make_tfidf_feat_selection_clf_pipeline (selection_function=None, k=5_000,\n",
    "                                         selector = SelectKBest,sublinear_tf=False):\n",
    "    tf = text.TfidfVectorizer(sublinear_tf=sublinear_tf)\n",
    "    #chi2_features = SelectKBest(selector, k)\n",
    "    if selection_function is not None:\n",
    "        k_best_features = selector(selection_function, k=k)\n",
    "    else:\n",
    "        k_best_features = selector(k=k)\n",
    "    svm_clf = LinearSVC()\n",
    "    return pipeline.Pipeline([('vect', tf), ('feat_selector', k_best_features), ('svm', svm_clf)])\n",
    "\n",
    "\n",
    "pipeline_reg = make_tfidf_feat_selection_clf_pipeline (selection_function=f_classif, k=5_000,sublinear_tf=True)\n",
    "\n",
    "# Train\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "pipeline_reg.fit(T_train, y_train)\n",
    "predicted = pipeline_reg.predict(T_test)\n",
    "\n",
    "accuracy_score(predicted, y_test),\\\n",
    "precision_score(predicted, y_test),\\\n",
    "recall_score(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 2:  Evaluate over multiple train text splits; report means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: f_classif\n",
      "Split 0: chi2\n",
      "\n",
      "Split 1: f_classif\n",
      "Split 1: chi2\n",
      "\n",
      "Split 2: f_classif\n",
      "Split 2: chi2\n",
      "\n",
      "Split 3: f_classif\n",
      "Split 3: chi2\n",
      "\n",
      "Split 4: f_classif\n",
      "Split 4: chi2\n",
      "\n",
      "Split 5: f_classif\n",
      "Split 5: chi2\n",
      "\n",
      "Split 6: f_classif\n",
      "Split 6: chi2\n",
      "\n",
      "Split 7: f_classif\n",
      "Split 7: chi2\n",
      "\n",
      "Split 8: f_classif\n",
      "Split 8: chi2\n",
      "\n",
      "Split 9: f_classif\n",
      "Split 9: chi2\n",
      "\n",
      "f_classif   a      p     r\n",
      "===============================\n",
      "  3_000 | 0.836 0.553 0.766\n",
      "  5_000 | 0.838 0.566 0.764\n",
      " 10_000 | 0.836 0.585 0.745\n",
      "\n",
      "chi2       a      p     r\n",
      "===============================\n",
      "  3_000 | 0.838 0.559 0.769\n",
      "  5_000 | 0.838 0.578 0.757\n",
      " 10_000 | 0.835 0.592 0.738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_stats(stats_means):\n",
    "    \"\"\"\n",
    "    means is an i x j x 3 array.\n",
    "    i: number of selection fns\n",
    "    j: number of dimension values\n",
    "    \"\"\"\n",
    "    for (i,fn) in enumerate(selection_functions):\n",
    "        fstring = fn.__name__\n",
    "        print(f\"{fstring:<8}   a      p     r\",end=\"\\n\" + \"=\"*31 + \"\\n\")\n",
    "        fn_scores = stats_mean[i]\n",
    "        for (j,k) in enumerate(dimension_vals):\n",
    "            a,p,r = fn_scores[j]\n",
    "            print(f\" {k:>6_d} | {a:.3f} {p:.3f} {r:.3f}\")\n",
    "        print()\n",
    "\n",
    "num_splits = 10\n",
    "\n",
    "selection_functions = [f_classif, chi2]\n",
    "dimension_vals = (3_000, 5_000, 10_000)\n",
    "#accuracy, precision, recall\n",
    "num_metrics = 3\n",
    "# a 10x2x3x3 array (=120 fits)\n",
    "stats = np.zeros((num_splits, len(selection_functions), len(dimension_vals), num_metrics))\n",
    "sublinear_tf=True\n",
    "X,y = df['Comment'].values,df['Insult'].values\n",
    "\n",
    "for test_run in range(num_splits):\n",
    "    # Each candidate system in theinner loops runs on the same train/test split\n",
    "    T_train, T_test, y_train,y_test = train_test_split(X,y)\n",
    "    scores = stats[test_run]\n",
    "    for (j, selection_function) in enumerate(selection_functions):\n",
    "        print(f\"Split {test_run}: {selection_function.__name__}\",)#end=\"\\n===================\\n\")\n",
    "        j_scores = scores[j]\n",
    "        for (i,k) in enumerate(dimension_vals):\n",
    "            pipeline_reg = make_tfidf_feat_selection_clf_pipeline (selection_function = selection_function,k=k,\n",
    "                                                               sublinear_tf=sublinear_tf)\n",
    "        \n",
    "            # Train\n",
    "            pipeline_reg.fit(T_train, y_train)\n",
    "            # Test\n",
    "            predicted = pipeline_reg.predict(T_test)\n",
    "            j_scores[i] = accuracy_score(predicted, y_test),\\\n",
    "                                    precision_score(predicted, y_test),\\\n",
    "                                     recall_score(predicted, y_test)\n",
    "    print()\n",
    "\n",
    "stats_means = stats.mean(axis=0)\n",
    "print_stats(stats_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner is?  Mostly chi2, although note if you go for the highest precision value (.592)m\n",
    "you end up with a lower recall value then if you did the same with chi2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poking around our 4d score array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from the first of 10 splits (a 2x3x3 array):\n",
    "3 scores for each of  6 candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.82674772, 0.51601423, 0.80555556],\n",
       "        [0.83181358, 0.54092527, 0.8042328 ],\n",
       "        [0.82877406, 0.5658363 , 0.77184466]],\n",
       "\n",
       "       [[0.82877406, 0.52313167, 0.80769231],\n",
       "        [0.83383992, 0.56227758, 0.79396985],\n",
       "        [0.83282675, 0.57651246, 0.77884615]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stats.shape is (10, 2, 3, 3)\n",
    "# 1 of 10 splits a 2x3x3 array (3 scores for each of  6 candidates)\n",
    "test0 = stats[0]\n",
    "test0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi2 scores for the first split: 3 scores each of 3 candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83080041, 0.53584906, 0.76344086],\n",
       "       [0.83282675, 0.5509434 , 0.76041667],\n",
       "       [0.83383992, 0.58113208, 0.74396135]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.83282675, 0.54345891, 0.76623743],\n",
       "        [0.83505572, 0.55936573, 0.76309436],\n",
       "        [0.83444782, 0.58042296, 0.74624624]],\n",
       "\n",
       "       [[0.83485309, 0.55161653, 0.76786067],\n",
       "        [0.8337386 , 0.5653802 , 0.75364553],\n",
       "        [0.83454914, 0.59130789, 0.73986455]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the means across the 10 splits\n",
    "stats_means = stats.mean(axis=0)\n",
    "#stats_means.shape (3,2,3)  18 means (3 scores for each of 6 systems)\n",
    "stats_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83282675, 0.54345891, 0.76623743])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats_mean[0,0,:]  is selection_function=f_classif,k=3000,  apr scores\n",
    "stats_means[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83454914, 0.59130789, 0.73986455])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats_mean[1,2,:]  is selection_function=chi2, k=10_000, apr scores \n",
    "stats_means[1,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_classif   a      p     r\n",
      "===============================\n",
      "  3_000 | 0.836 0.553 0.766\n",
      "  5_000 | 0.838 0.566 0.764\n",
      " 10_000 | 0.836 0.585 0.745\n",
      "\n",
      "chi2       a      p     r\n",
      "===============================\n",
      "  3_000 | 0.838 0.559 0.769\n",
      "  5_000 | 0.838 0.578 0.757\n",
      " 10_000 | 0.835 0.592 0.738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is defined and called above\n",
    "\n",
    "def print_stats(means):\n",
    "    \"\"\"\n",
    "    means is an i x j x 3 array.\n",
    "    i: number of selection fns\n",
    "    j: number of dimension values\n",
    "    \"\"\"\n",
    "    for (i,fn) in enumerate(selection_functions):\n",
    "        fstring = fn.__name__\n",
    "        print(f\"{fstring:<8}   a      p     r\",end=\"\\n\" + \"=\"*31 + \"\\n\")\n",
    "        fn_scores = stats_mean[i]\n",
    "        for (j,k) in enumerate(dimension_vals):\n",
    "            a,p,r = fn_scores[j]\n",
    "            print(f\" {k:>6_d} | {a:.3f} {p:.3f} {r:.3f}\")\n",
    "        print()\n",
    "\n",
    "print_stats(stats_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Mutrual Information\n",
    "\n",
    "Mutual information can work like the others but used in the context of select KBest\n",
    "it requires discrete-valued features, so we need a slightly different pipeline.\n",
    "\n",
    "We will CountVectorize our doc set to give a term document matrix (TDM) filled with\n",
    "counts, run mutual information on that to feature reduce, and then classify in\n",
    "the usual way.  Note we use a TfidfTransformer rather than a TfidfVectorizer.  This\n",
    "is because the docs have already been vectorized so we need a transformer that\n",
    "maps from a TDM with counts to a TDM with TFIDF values; TfidfTransformer fits\n",
    "the bill.\n",
    "\n",
    "The following code also gives us  a chance to try out chi2 on counts, which\n",
    "it was always intended for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=   500 a=0.853 p=0.766 r=0.580\n"
     ]
    }
   ],
   "source": [
    "def make_count_feat_selection_pipeline (selection_function=None, k=500,\n",
    "                                       selector = SelectKBest,sublinear_tf=False):\n",
    "\n",
    "    cv = text.CountVectorizer()\n",
    "    tf = text.TfidfTransformer(sublinear_tf=sublinear_tf)\n",
    "    \n",
    "    if selection_function is None:\n",
    "        kb = selector(k=k)\n",
    "    else:\n",
    "        kb = selector(selection_function,k=k)\n",
    "    \n",
    "    svm_clf = LinearSVC()\n",
    "    \n",
    "    pipeline_reg=pipeline.Pipeline([('vect', cv), \n",
    "                                    ('feat_selector', kb),\n",
    "                                    ('tfidf',tf), \n",
    "                                    ('svm', svm_clf)])\n",
    "    return pipeline_reg\n",
    "\n",
    "# Mutual info works  with select Kbest on discretely vectorized data\n",
    "# You can also try these others with this pipeline as well.\n",
    "# chi2 and f_classif work better with k>3K\n",
    "# selection_function = f_classif,k=k\n",
    "# selection_function = chi2, k=k\n",
    "k=500\n",
    "pipeline_reg = make_count_feat_selection_pipeline (selection_function=mutual_info_classif, k=k)\n",
    "\n",
    "# split\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "# Train\n",
    "pipeline_reg.fit(T_train, y_train)\n",
    "# Test\n",
    "predicted = pipeline_reg.predict(T_test)\n",
    "\n",
    "# Evaluate\n",
    "a,p,r = accuracy_score(y_test,predicted,),\\\n",
    "        precision_score(y_test, predicted),\\\n",
    "            recall_score(y_test, predicted)\n",
    "\n",
    "# MI k= 3_000 a=0.806 p=0.789 r=0.350\n",
    "# chi k= 3_000 a=0.806 p=0.789 r=0.350\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A Mutual Information transformer\n",
    "\n",
    "We've done feature selection two different ways, on term document\n",
    "matrices representing word counts, created by the CountVectorizer,\n",
    "and on continuously-valued term document matrices representing\n",
    "word-in-document TFIDF values.\n",
    "\n",
    "To systematize this,\n",
    "let's implement a Mutual Information-Transformer (MI-Xformer), using the scikit learn interface.\n",
    "\n",
    "Assumption:\n",
    "The MIT **always** accepts a Term Doc Matrix (= a TDM, a 2D numpy array) and always outputs  a 2D numpy array with fewer columns.\n",
    "\n",
    "We will use the MI X-former two ways\n",
    "\n",
    "1.  Pass in a sequence of strings and select a vocab using word counts (operating on a Count Vectorized TDM like we did above)\n",
    "2.  Operate on a TFIDF-valued TDM to do feature selection.\n",
    "\n",
    "\n",
    "Model A\n",
    "----------\n",
    "\n",
    "To do feature selection on the base of counts, we pass the MI X-former a count vectorizer \n",
    "TDM and pass back a truncated TDM.  We then pass that to a TFIDFTransformer.\n",
    "(which accepts a CountVectorized TDM).\n",
    "\n",
    "\n",
    "T_Train, T_Test, y_Train, y_Test\n",
    "\n",
    "vec_pipe = [CountVectorizer =>  Mutual Info => TFIDFTransformer => LinearSVC]\n",
    "\n",
    "X_Train = vec_pipe.fit_transform(T_Train)\n",
    "predicted = vec_pipe.transform(T_test)\n",
    "\n",
    "\n",
    "Model B\n",
    "-----------\n",
    "\n",
    "To do feature selection on the base of continuous TFIDF values, \n",
    "we pass the MI X-former a TFIDF TDM to do feature selection.\n",
    "\n",
    "```python\n",
    "T_Train, T_Test, y_Train, y_Test\n",
    "```\n",
    "\n",
    "vec_pipe = [TFIDFVectorizer =>  Mutual Info => LinearSVC]\n",
    "\n",
    "\n",
    "```python\n",
    "X_Train = vec_pipe.fit_transform(T_Train)\n",
    "predicted = vec_pipe.transform(T_test)\n",
    "```\n",
    "\n",
    "Note we switch from the TFIDFTransformer to the TFIDF Vectorizer,  The former accepts a TDM \n",
    "with discrete count values as input.  The latter wants a sequence of document strings.  Both\n",
    "output a TDM with TFIDF values.  \n",
    "\n",
    "CountVectorizer => TFIDFTransformer\n",
    "\n",
    "is equivalent  to\n",
    "\n",
    "TFIDFVectorizer\n",
    "\n",
    "The motivation for resorting to the  Transformer is so that we could interpose\n",
    "Mutual Information feature selection between Count Vectorizing and converting the\n",
    "counts to TFIDF values.  This allows MI selection to work on probabilities based on counts,\n",
    "more or less its original intent, and avoids averaging based on nearest neighbors.\n",
    "\n",
    "In the implementation below, we use the parameter `discrete_features` to switch \n",
    "between Model A and Model B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "class MutualInfo:\n",
    "    \n",
    "    def  __init__(self,k,discrete_features=True):\n",
    "        self.k =k\n",
    "        self.discrete_features = discrete_features\n",
    "        \n",
    "    def fit_transform(self,X,y,make_sparse=True):\n",
    "        \"\"\"\n",
    "        If self.use_counts create  cv, a count vectorized version of X,\n",
    "        and assign feature ranks based mutual info of cv[:,feat_i] and y\n",
    "        Use the feature ranks to choose a vocab of size self.k.\n",
    "        \n",
    "        Otherwise assign feature ranks based mutual info of X[:,feat_i] and y\n",
    "        Use the feature ranks to choose a vocab of size self.k.\n",
    "        \"\"\"\n",
    "        \n",
    "        if make_sparse and hasattr(X,'toarray'):\n",
    "            X = X.toarray()\n",
    "    \n",
    "        ranks = mutual_info_classif(X, y,discrete_features=self.discrete_features)\n",
    "        self.idxs = ranks.argsort()[-self.k:]\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform (self, X):\n",
    "        if X.ndim == 2:\n",
    "            return X[:,self.idxs]\n",
    "        else:\n",
    "            return X[self.idxs]\n",
    "\n",
    "\n",
    "sublinear_tf,k=True,3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3_000 a=0.817 p=0.765 r=0.533\n"
     ]
    }
   ],
   "source": [
    "### Model A\n",
    "\n",
    "def make_model_A ():\n",
    "    cv = CountVectorizer()\n",
    "    mi = MutualInfo(k=k,discrete_features=True)\n",
    "    tf = text.TfidfTransformer(sublinear_tf=sublinear_tf)\n",
    "    svm_clf = LinearSVC()\n",
    "\n",
    "    return pipeline.Pipeline([('vect', cv), \n",
    "                              ('feat_selector', mi), \n",
    "                              ('tfidf_vect',tf), \n",
    "                              ('svm', svm_clf)])\n",
    "\n",
    "# Data \n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "#Train\n",
    "vec_pipe = make_model_A ()\n",
    "vec_pipe.fit(T_train, y_train)\n",
    "#Test\n",
    "predicted = vec_pipe.predict(T_test)\n",
    "\n",
    "a,p, r = accuracy_score(y_test,predicted),\\\n",
    "           precision_score(y_test, predicted),\\\n",
    "              recall_score(y_test, predicted)\n",
    "\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3_000 a=0.785 p=0.678 r=0.482\n"
     ]
    }
   ],
   "source": [
    "# Model B\n",
    "\n",
    "def make_model_B():\n",
    "    mi = MutualInfo(k=k, discrete_features=False)\n",
    "    tf = text.TfidfVectorizer(sublinear_tf=sublinear_tf)\n",
    "    svm_clf = LinearSVC()\n",
    "\n",
    "    return pipeline.Pipeline([('tfidf_vect',tf),  ('feat_selector', mi), ('svm', svm_clf)])\n",
    "\n",
    "# Data \n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "#Train\n",
    "vec_pipe =  make_model_B()\n",
    "vec_pipe.fit(T_train, y_train)\n",
    "#Test\n",
    "predicted = vec_pipe.predict(T_test)\n",
    "\n",
    "a,p, r = accuracy_score(y_test, predicted),\\\n",
    "           precision_score(y_test, predicted),\\\n",
    "              recall_score(y_test, predicted)\n",
    "\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction (Latent Semantic Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of dimensionality reduction to be explored below.\n",
    "\n",
    "Model\n",
    "\n",
    "[TFDIF -> TruncatedSVD -> SVM]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scikit learn docs:  \n",
    "\n",
    ">In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).\n",
    "\n",
    "It might look appealing to use PCA in this context, especially since it has such nice mathematical properties, and appear so close computationally.  But close is often not good enough in computational contexts.  The centering operation that PCA starts with cannot currently be performed on sparse arrays (CSR or compressed sparse row arrays in numpy).  The cost of expanding the arrays to center them is computationally prohibitive; most importantly, it can blow up memory.  \n",
    "\n",
    "> Note: see [this github numpy patch](https://rasbt.github.io/mlxtend/user_guide/preprocessing/MeanCenterer/) intended to solve the problem.\n",
    "\n",
    "The scikit learn folks have addressed the problem in principle and offer a Sparse PCA implementation,\n",
    "but as noted in the code below, it seems not to be behaving well on this data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3_000 a=0.847 p=0.721 r=0.630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD #, NMF, PCA, \n",
    "# Avoiding SparsePCA which seems ill-behaved\n",
    "# NMF seems to be too costly for this data.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "## Data \n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "pipe = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", text.TfidfVectorizer()),\n",
    "        # the reduce_dim stage is populated by the param_grid\n",
    "        (\"reduce_dim\", TruncatedSVD(n_components=k)),\n",
    "        (\"classify\", LinearSVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(T_train,y_train)\n",
    "predicted = pipe.predict(T_test)\n",
    "\n",
    "### Eval\n",
    "a,p, r = accuracy_score(y_test, predicted),\\\n",
    "           precision_score(y_test, predicted),\\\n",
    "              recall_score(y_test, predicted)\n",
    "\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Truncated SVD for reduction\n",
      "Beginning reduction fit print 2024-04-21 09:24:58.187237 \n",
      "Reduction fit completed 2024-04-21 09:25:40.401928 \n",
      "k= 3_000 a=0.825 p=0.717 r=0.593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD\n",
    "\n",
    "# Avoiding SparsePCA which seems ill-behaved\n",
    "# NMF seems to be too costly for this data.\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "## Data \n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "T_train,T_test, y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "## Reduction params\n",
    "#k,sparse_pca=500,False\n",
    "k,sparse_pca=3_000,False\n",
    "#red = TruncatedSVD(n_components=k)\n",
    "#red = NMF(n_components=k)\n",
    "\n",
    "if sparse_pca:\n",
    "    print(\"Using sparse PCA for reduction\")\n",
    "    red = SparsePCA(n_components=k)\n",
    "else:\n",
    "    print(\"Using Truncated SVD for reduction\")\n",
    "    red = TruncatedSVD(n_components=k)\n",
    "# Data \n",
    "\n",
    "#TSVD k= 500 a=0.823 p=0.716 r=0.580\n",
    "\n",
    "######  Text -> TFIDF\n",
    "vectorizer = text.TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(T_train)\n",
    "X_test = vectorizer.transform(T_test)\n",
    "\n",
    "if sparse_pca:\n",
    "    X_train = X_train.toarray()\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "#########\n",
    "\n",
    "###### TFIDF -> reduced\n",
    "print(f\"Beginning reduction fit print {datetime.now()} \")\n",
    "X_train_red = red.fit_transform(X_train)\n",
    "print(f\"Reduction fit completed {datetime.now()} \")\n",
    "X_test_red = red.transform(X_test)\n",
    "############\n",
    "\n",
    "### Reduced =>  Class\n",
    "\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_red,y_train)\n",
    "predicted = svm_clf.predict(X_test_red)\n",
    "\n",
    "### Eval\n",
    "a,p, r = accuracy_score(y_test, predicted),\\\n",
    "           precision_score(y_test, predicted),\\\n",
    "              recall_score(y_test, predicted)\n",
    "\n",
    "print(f\"{k=:>6_d} {a=:.3f} {p=:.3f} {r=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:32:33.001275 \n",
    "Reduction fit completed 2024-04-20 12:33:17.055381 \n",
    "k= 3_000 a=0.843 p=0.761 r=0.630\n",
    "\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:33:51.944394 \n",
    "Reduction fit completed 2024-04-20 12:34:34.503089 \n",
    "k= 3_000 a=0.818 p=0.702 r=0.600\n",
    "\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:34:54.958394 \n",
    "Reduction fit completed 2024-04-20 12:35:37.068576 \n",
    "k= 3_000 a=0.848 p=0.791 r=0.579\n",
    "\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-20 12:35:57.324080 \n",
    "Reduction fit completed 2024-04-20 12:36:39.164440 \n",
    "k= 3_000 a=0.830 p=0.750 r=0.600\n",
    "\n",
    "Using Truncated SVD for reduction\n",
    "Beginning reduction fit print 2024-04-21 09:20:12.280890 \n",
    "Reduction fit completed 2024-04-21 09:20:54.727115 \n",
    "k= 3_000 a=0.819 p=0.745 r=0.607\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Putting it all together:  The Grid Search\n",
    "\n",
    "We have two sets of different techniques for reducing the size of document representations\n",
    "and hopefully improving classifier performance: dimensionality redction and feature selection.\n",
    "But which reduction technique should we use, and how many features should we keep?\n",
    "\n",
    "Answering questions like these is what the scikit learn grid search package was designed for.\n",
    "\n",
    "But a note of <font color=\"red\" size=8>warning.<font>\n",
    "    \n",
    "This is a computationally costly experiment.\n",
    "    \n",
    "1.  The setup below involves taking the cross-product of 3 experiment parameters, which ends up\n",
    "    creating 20 system candidates (details in the code).  In addition we are doing 3-fold cross\n",
    "    validation, which means a total of 60 fits.\n",
    "2.  That will of course raise issues of **time**. Time effects will be multiplicative. For example.\n",
    "    the computation time for most expensive component (TruncatedSVD below) will be multiplied by\n",
    "    the number of components it combines.   To complete the phase using SVD below we have\n",
    "    to explore a parameter space with 2x3 settings, \n",
    "    2 values for the C-parameter of the SVM times 3 values for \n",
    "    the number of dimensions in  the SVD-reduction.  The same is true for the two feature selection\n",
    "    techniques, $\\chi^{2}$ (`chi2`) and ANOVA f-value (`fclassif`).\n",
    "3.  Everything just said about time may apply to memory, but in somewhat more unpredictable ways.  It turns\n",
    "    out memory was the killer in the example below.  The experiment hung for hours on an Apple M1 Pro with\n",
    "    16 GB of memory. It ran to completion in 8 minutes on a PC with 32 GB of meory and a GPU (which I'm\n",
    "    not sure was used). The interesting thing is that the memory issue only arise in the pipeline.  The   \n",
    "    Truncated SVD runs in under 1 minute on the Mac using teh code in the previous section, as illu\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three dimensions of variation:\n",
    "\n",
    "\n",
    "1. Reducer (4 values):  SVD, Identity, Chi2, ANOVA F-Value.  \n",
    "2. C-value (2 values); 1 and 10.   This is the slack variable that controls how expanding the \n",
    "   geometric margin of the classifier is traded off for misclassifying a few points.\n",
    "3. N of features in reduction (3 values: 500, 3_000, 5_000).\n",
    "\n",
    "\n",
    "in that order.  In other words, the triples defining a parameter setting are generated like this:\n",
    "\n",
    "```\n",
    "(SVD,   1,     500)\n",
    "(SVD,   1,   3,000)\n",
    "(SVD,   1,   5,000)\n",
    "(SVD,  10,     500)\n",
    "(SVD,  10,   3,000)\n",
    "(SVD,  10,   5,000)\n",
    "(ChiSq  1,     500)\n",
    "(ChiSq  1,   3,000)\n",
    "  ...\n",
    "```\n",
    "That's a 4x2x3 grid.  That's 24 grid points. So each reducer should define a 2x3 grid of values,\n",
    "which shows up as expected for SVD above,\n",
    "\n",
    "But with the defective reducer Ident we only get a grid of shape (2,) the two\n",
    "C-values,  It doesn't make sense to vary the number of dimensions in the\n",
    "reduction when there is no reduction, which mean we end up with only 20 candidates\n",
    "instead of 24 (3x2x3 plus 1x2x1). So we \"broadcast out\"  the Ident Transformer numbers \n",
    "into a (3x2x4) grid in the code below to make manipulating, reading and visualizing the data easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These could be used but are not ucrrently being used.\n",
    "#from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "X,y = df[\"Comment\"].values,df[\"Insult\"].values\n",
    "\n",
    "pipe = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", text.TfidfVectorizer()),\n",
    "        # the reduce_dim stage is populated by the param_grid\n",
    "        (\"reduce_dim\", \"passthrough\"),\n",
    "        (\"classify\", LinearSVC()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#N_FEATURES_OPTIONS = [5_000, 3_000, 500]\n",
    "N_FEATURES_OPTIONS = [500, 3_000, 5_000]\n",
    "#C_OPTIONS = np.logspace(0,2,3)\n",
    "C_OPTIONS = np.logspace(0,1,2)\n",
    "#DIM_REDUCERS = [TruncatedSVD(), NMF(max_iter=1_000)]\n",
    "#DIM_REDUCERS = [TruncatedSVD()]\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=0):\n",
    "        self.n_components=n_components\n",
    "        pass\n",
    "    \n",
    "    def fit(self, input_array, y=None):\n",
    "        print(self.n_components)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        return input_array*1\n",
    "\n",
    "#DIM_REDUCERS = [TruncatedSVD(), NMF(max_iter=1_000)]\n",
    "#DIM_REDUCERS = [IdentityTransformer(), TruncatedSVD()]\n",
    "DIM_REDUCERS = [TruncatedSVD()]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"reduce_dim\": DIM_REDUCERS,\n",
    "        \"reduce_dim__n_components\": N_FEATURES_OPTIONS,\n",
    "        \"classify__C\": C_OPTIONS,\n",
    "    },\n",
    "    {\n",
    "        \"reduce_dim\": [IdentityTransformer()],\n",
    "        \"classify__C\": C_OPTIONS,\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"reduce_dim\": [SelectKBest(chi2),SelectKBest(f_classif)],\n",
    "        \"reduce_dim__k\": N_FEATURES_OPTIONS,\n",
    "        \"classify__C\": C_OPTIONS,\n",
    "    },\n",
    "]\n",
    "\n",
    "# The default is 5-fold cross validation\n",
    "#cv=3\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For code that is going to go away for a long time before returning, it is a good idea to\n",
    "\n",
    "1.  Print out messages indicating progress, which may later provide clues to where the bottlenecks are.  In\n",
    "    the code below, that's achieved by setting  `verbose = 10`  when\n",
    "    creating the `GridSearchCV` instance (line 19).\n",
    "2.  Include code that reports timing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wednesday 24. April 2024 10:23:13\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3; 1/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500\n",
      "[CV 1/3; 1/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500;, score=0.704 total time=   2.5s\n",
      "[CV 2/3; 1/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500\n",
      "[CV 2/3; 1/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500;, score=0.670 total time=   2.3s\n",
      "[CV 3/3; 1/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500\n",
      "[CV 3/3; 1/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500;, score=0.655 total time=   2.4s\n",
      "[CV 1/3; 2/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000\n",
      "[CV 1/3; 2/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000;, score=0.705 total time=  37.7s\n",
      "[CV 2/3; 2/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000\n",
      "[CV 2/3; 2/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000;, score=0.668 total time=  39.9s\n",
      "[CV 3/3; 2/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000\n",
      "[CV 3/3; 2/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000;, score=0.638 total time=  39.0s\n",
      "[CV 1/3; 3/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000\n",
      "[CV 1/3; 3/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000;, score=0.705 total time=  43.6s\n",
      "[CV 2/3; 3/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000\n",
      "[CV 2/3; 3/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000;, score=0.663 total time=  41.2s\n",
      "[CV 3/3; 3/20] START classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000\n",
      "[CV 3/3; 3/20] END classify__C=1.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000;, score=0.653 total time=  41.1s\n",
      "[CV 1/3; 4/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500\n",
      "[CV 1/3; 4/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500;, score=0.703 total time=   3.3s\n",
      "[CV 2/3; 4/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500\n",
      "[CV 2/3; 4/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500;, score=0.685 total time=   3.7s\n",
      "[CV 3/3; 4/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500\n",
      "[CV 3/3; 4/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=500;, score=0.653 total time=   3.2s\n",
      "[CV 1/3; 5/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000\n",
      "[CV 1/3; 5/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000;, score=0.692 total time=  43.1s\n",
      "[CV 2/3; 5/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000\n",
      "[CV 2/3; 5/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000;, score=0.647 total time=  42.0s\n",
      "[CV 3/3; 5/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000\n",
      "[CV 3/3; 5/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=3000;, score=0.642 total time=  42.0s\n",
      "[CV 1/3; 6/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000\n",
      "[CV 1/3; 6/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000;, score=0.681 total time=  46.2s\n",
      "[CV 2/3; 6/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000\n",
      "[CV 2/3; 6/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000;, score=0.650 total time=  44.0s\n",
      "[CV 3/3; 6/20] START classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000\n",
      "[CV 3/3; 6/20] END classify__C=10.0, reduce_dim=TruncatedSVD(), reduce_dim__n_components=5000;, score=0.623 total time=  45.4s\n",
      "[CV 1/3; 7/20] START classify__C=1.0, reduce_dim=IdentityTransformer()..........\n",
      "0\n",
      "[CV 1/3; 7/20] END classify__C=1.0, reduce_dim=IdentityTransformer();, score=0.705 total time=   0.1s\n",
      "[CV 2/3; 7/20] START classify__C=1.0, reduce_dim=IdentityTransformer()..........\n",
      "0\n",
      "[CV 2/3; 7/20] END classify__C=1.0, reduce_dim=IdentityTransformer();, score=0.663 total time=   0.1s\n",
      "[CV 3/3; 7/20] START classify__C=1.0, reduce_dim=IdentityTransformer()..........\n",
      "0\n",
      "[CV 3/3; 7/20] END classify__C=1.0, reduce_dim=IdentityTransformer();, score=0.653 total time=   0.1s\n",
      "[CV 1/3; 8/20] START classify__C=10.0, reduce_dim=IdentityTransformer().........\n",
      "0\n",
      "[CV 1/3; 8/20] END classify__C=10.0, reduce_dim=IdentityTransformer();, score=0.681 total time=   0.2s\n",
      "[CV 2/3; 8/20] START classify__C=10.0, reduce_dim=IdentityTransformer().........\n",
      "0\n",
      "[CV 2/3; 8/20] END classify__C=10.0, reduce_dim=IdentityTransformer();, score=0.650 total time=   0.1s\n",
      "[CV 3/3; 8/20] START classify__C=10.0, reduce_dim=IdentityTransformer().........\n",
      "0\n",
      "[CV 3/3; 8/20] END classify__C=10.0, reduce_dim=IdentityTransformer();, score=0.623 total time=   0.1s\n",
      "[CV 1/3; 9/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500\n",
      "[CV 1/3; 9/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500;, score=0.703 total time=   0.1s\n",
      "[CV 2/3; 9/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500\n",
      "[CV 2/3; 9/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500;, score=0.633 total time=   0.1s\n",
      "[CV 3/3; 9/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500\n",
      "[CV 3/3; 9/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500;, score=0.624 total time=   0.1s\n",
      "[CV 1/3; 10/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000\n",
      "[CV 1/3; 10/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000;, score=0.688 total time=   0.1s\n",
      "[CV 2/3; 10/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000\n",
      "[CV 2/3; 10/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000;, score=0.648 total time=   0.1s\n",
      "[CV 3/3; 10/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000\n",
      "[CV 3/3; 10/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000;, score=0.609 total time=   0.1s\n",
      "[CV 1/3; 11/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000\n",
      "[CV 1/3; 11/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000;, score=0.667 total time=   0.1s\n",
      "[CV 2/3; 11/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000\n",
      "[CV 2/3; 11/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000;, score=0.652 total time=   0.1s\n",
      "[CV 3/3; 11/20] START classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000\n",
      "[CV 3/3; 11/20] END classify__C=1.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000;, score=0.605 total time=   0.1s\n",
      "[CV 1/3; 12/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=500\n",
      "[CV 1/3; 12/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=500;, score=0.706 total time=   0.1s\n",
      "[CV 2/3; 12/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=500\n",
      "[CV 2/3; 12/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=500;, score=0.663 total time=   0.1s\n",
      "[CV 3/3; 12/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=500\n",
      "[CV 3/3; 12/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=500;, score=0.631 total time=   0.1s\n",
      "[CV 1/3; 13/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=3000\n",
      "[CV 1/3; 13/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=3000;, score=0.683 total time=   0.1s\n",
      "[CV 2/3; 13/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=3000\n",
      "[CV 2/3; 13/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=3000;, score=0.645 total time=   0.1s\n",
      "[CV 3/3; 13/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=3000\n",
      "[CV 3/3; 13/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=3000;, score=0.629 total time=   0.1s\n",
      "[CV 1/3; 14/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=5000\n",
      "[CV 1/3; 14/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=5000;, score=0.667 total time=   0.1s\n",
      "[CV 2/3; 14/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=5000\n",
      "[CV 2/3; 14/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=5000;, score=0.652 total time=   0.1s\n",
      "[CV 3/3; 14/20] START classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=5000\n",
      "[CV 3/3; 14/20] END classify__C=1.0, reduce_dim=SelectKBest(), reduce_dim__k=5000;, score=0.608 total time=   0.1s\n",
      "[CV 1/3; 15/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500\n",
      "[CV 1/3; 15/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500;, score=0.658 total time=   0.1s\n",
      "[CV 2/3; 15/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500\n",
      "[CV 2/3; 15/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500;, score=0.642 total time=   0.1s\n",
      "[CV 3/3; 15/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500\n",
      "[CV 3/3; 15/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=500;, score=0.615 total time=   0.1s\n",
      "[CV 1/3; 16/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000\n",
      "[CV 1/3; 16/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000;, score=0.651 total time=   0.1s\n",
      "[CV 2/3; 16/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000\n",
      "[CV 2/3; 16/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000;, score=0.629 total time=   0.1s\n",
      "[CV 3/3; 16/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000\n",
      "[CV 3/3; 16/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=3000;, score=0.593 total time=   0.1s\n",
      "[CV 1/3; 17/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000\n",
      "[CV 1/3; 17/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000;, score=0.628 total time=   0.1s\n",
      "[CV 2/3; 17/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000\n",
      "[CV 2/3; 17/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000;, score=0.615 total time=   0.1s\n",
      "[CV 3/3; 17/20] START classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000\n",
      "[CV 3/3; 17/20] END classify__C=10.0, reduce_dim=SelectKBest(score_func=<function chi2 at 0x7fe6702c4360>), reduce_dim__k=5000;, score=0.600 total time=   0.1s\n",
      "[CV 1/3; 18/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=500\n",
      "[CV 1/3; 18/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=500;, score=0.685 total time=   0.1s\n",
      "[CV 2/3; 18/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=500\n",
      "[CV 2/3; 18/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=500;, score=0.660 total time=   0.1s\n",
      "[CV 3/3; 18/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=500\n",
      "[CV 3/3; 18/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=500;, score=0.638 total time=   0.2s\n",
      "[CV 1/3; 19/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=3000\n",
      "[CV 1/3; 19/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=3000;, score=0.619 total time=   0.1s\n",
      "[CV 2/3; 19/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=3000\n",
      "[CV 2/3; 19/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=3000;, score=0.641 total time=   0.1s\n",
      "[CV 3/3; 19/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=3000\n",
      "[CV 3/3; 19/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=3000;, score=0.613 total time=   0.1s\n",
      "[CV 1/3; 20/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=5000\n",
      "[CV 1/3; 20/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=5000;, score=0.637 total time=   0.1s\n",
      "[CV 2/3; 20/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=5000\n",
      "[CV 2/3; 20/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=5000;, score=0.609 total time=   0.1s\n",
      "[CV 3/3; 20/20] START classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=5000\n",
      "[CV 3/3; 20/20] END classify__C=10.0, reduce_dim=SelectKBest(), reduce_dim__k=5000;, score=0.620 total time=   0.1s\n",
      "0.0 hours 8.0 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "print(datetime.now().strftime(\"%A %d. %B %Y %H:%M:%S\"))\n",
    "\n",
    "\n",
    "# If a grid search is too costly\n",
    "#grid = RandomizedSearchCV(\n",
    "#    estimator=pipe,\n",
    "#    param_distributions=param_grid,\n",
    "#    n_iter=10,\n",
    "#    random_state=0,\n",
    "#    scoring = \"f1\"\n",
    "#    n_jobs=1,\n",
    "#    verbose=10,\n",
    "#    cv = cv\n",
    "#)\n",
    "\n",
    "# For customizing parallelism\n",
    "#from joblib import parallel_backend\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"f1\", n_jobs=1, cv=cv, verbose=10)\n",
    "\n",
    "#with parallel_backend('threading'):\n",
    "#    grid.fit(X, y)\n",
    "grid.fit(X, y)\n",
    "datetime.now().strftime(\"%A %d. %B %Y %H:%M:%S\")\n",
    "secs = time.time() - t0\n",
    "hrs,mins = secs//3600,(secs%3600)//60\n",
    "print(f\"{hrs} hours {mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_grid(grid):\n",
    "    return np.array([grid.cv_results_['split0_test_score'],\n",
    "                     grid.cv_results_['split1_test_score'],\n",
    "                     grid.cv_results_['split2_test_score']])\n",
    "score_grid = get_score_grid(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which split was the hardest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67754299, 0.64859768, 0.62631263])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_grid.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score grid is 3x20 (cv times number of candidates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69      , 0.70528967, 0.70528967, 0.70892019, 0.68421053,\n",
       "        0.68075117, 0.70528967, 0.68075117, 0.70341207, 0.68783069,\n",
       "        0.66666667, 0.70588235, 0.68266667, 0.66666667, 0.65809769,\n",
       "        0.65053763, 0.6278481 , 0.68472906, 0.61917808, 0.63684211],\n",
       "       [0.672     , 0.67179487, 0.66323907, 0.66666667, 0.64631043,\n",
       "        0.64974619, 0.66323907, 0.64974619, 0.63276836, 0.64835165,\n",
       "        0.65240642, 0.6630137 , 0.64480874, 0.65229111, 0.64150943,\n",
       "        0.62921348, 0.61538462, 0.65963061, 0.64066852, 0.60916442],\n",
       "       [0.6529563 , 0.64267352, 0.65306122, 0.65686275, 0.63809524,\n",
       "        0.62287105, 0.65306122, 0.62287105, 0.62359551, 0.60869565,\n",
       "        0.60540541, 0.63129973, 0.62903226, 0.60752688, 0.61458333,\n",
       "        0.59299191, 0.6       , 0.63797468, 0.61290323, 0.61979167]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which parameter setting performed the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6716521 , 0.67325269, 0.67386332, 0.6774832 , 0.6562054 ,\n",
       "       0.6511228 , 0.67386332, 0.6511228 , 0.65325865, 0.64829266,\n",
       "       0.64149283, 0.66673193, 0.65216922, 0.64216155, 0.63806348,\n",
       "       0.62424768, 0.61441091, 0.66077812, 0.62424994, 0.62193273])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_grid.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 19, 15, 18, 14, 10, 13,  9,  5,  7, 12,  8,  4, 17, 11,  0,  1,\n",
       "        6,  2,  3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_grid.mean(axis=0).argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameter setting found was the one at index 3.  And here it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid.best_estimator_.get_params()\n",
    "#best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer', TfidfVectorizer()),\n",
       "  ('reduce_dim', TruncatedSVD(n_components=500)),\n",
       "  ('classify', LinearSVC(C=10.0))],\n",
       " 'verbose': False,\n",
       " 'vectorizer': TfidfVectorizer(),\n",
       " 'reduce_dim': TruncatedSVD(n_components=500),\n",
       " 'classify': LinearSVC(C=10.0),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.float64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__norm': 'l2',\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__smooth_idf': True,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__sublinear_tf': False,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': None,\n",
       " 'vectorizer__use_idf': True,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'reduce_dim__algorithm': 'randomized',\n",
       " 'reduce_dim__n_components': 500,\n",
       " 'reduce_dim__n_iter': 5,\n",
       " 'reduce_dim__n_oversamples': 10,\n",
       " 'reduce_dim__power_iteration_normalizer': 'auto',\n",
       " 'reduce_dim__random_state': None,\n",
       " 'reduce_dim__tol': 0.0,\n",
       " 'classify__C': 10.0,\n",
       " 'classify__class_weight': None,\n",
       " 'classify__dual': True,\n",
       " 'classify__fit_intercept': True,\n",
       " 'classify__intercept_scaling': 1,\n",
       " 'classify__loss': 'squared_hinge',\n",
       " 'classify__max_iter': 1000,\n",
       " 'classify__multi_class': 'ovr',\n",
       " 'classify__penalty': 'l2',\n",
       " 'classify__random_state': None,\n",
       " 'classify__tol': 0.0001,\n",
       " 'classify__verbose': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters combination found:\n",
      "classify__C: 10.0\n",
      "reduce_dim: TruncatedSVD(n_components=500)\n",
      "reduce_dim__n_components: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters combination found:\")\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(param_grid[0].keys()):\n",
    "    try:\n",
    "        print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "    except KeyError:\n",
    "        print(f\"{param_name}: Not found\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#reducer_labels = [\"SVD\", \"KBest(chi2)\",\"KBest(f_classif)\"]\n",
    "reducer_labels = [\"SVD\",\"Ident\",\"Chi2\",\"ANOVA f-val\"]\n",
    "mean_scores = np.array(grid.cv_results_[\"mean_test_score\"])\n",
    "# The other transformers define a 2x3 grid ; Ident defines one of shape (2,)\n",
    "# Pretend like it were otherwise\n",
    "i_score1,i_score2 = mean_scores[6],mean_scores[7]\n",
    "new_mean_scores = np.concatenate([mean_scores[:6], [i_score1,i_score1,i_score1], [i_score2,i_score2,i_score2], mean_scores[8:]])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "new_mean_scores = new_mean_scores.reshape( -1, len(C_OPTIONS), len(N_FEATURES_OPTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mean_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVD</th>\n",
       "      <th>Ident</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>fclassif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.677483</td>\n",
       "      <td>0.673863</td>\n",
       "      <td>0.666732</td>\n",
       "      <td>0.660778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.673253</td>\n",
       "      <td>0.673863</td>\n",
       "      <td>0.652169</td>\n",
       "      <td>0.624250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.673863</td>\n",
       "      <td>0.673863</td>\n",
       "      <td>0.642162</td>\n",
       "      <td>0.621933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SVD     Ident      Chi2  fclassif\n",
       "500   0.677483  0.673863  0.666732  0.660778\n",
       "3000  0.673253  0.673863  0.652169  0.624250\n",
       "5000  0.673863  0.673863  0.642162  0.621933"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f27df007c10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select score for best C\n",
    "#mean_scores = mean_scores.max(axis=0)\n",
    "new_mean_scores_f = new_mean_scores.max(axis=1)\n",
    "# create a dataframe to ease plotting\n",
    "mean_scores_df = pd.DataFrame(\n",
    "    new_mean_scores_f.T, index=N_FEATURES_OPTIONS, columns=reducer_labels\n",
    ")\n",
    "\n",
    "ax = mean_scores_df.plot.bar()\n",
    "ax.set_title(\"Comparing feature reduction techniques\")\n",
    "ax.set_xlabel(\"Reduced number of features\")\n",
    "ax.set_ylim([.5,.75])\n",
    "ax.set_ylabel(\"F-Score\")\n",
    "#ax.set_ylim((0, 1))\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion questions\n",
    "-------------------------\n",
    "\n",
    "1. Call all the features with variable values in `param_gride` **grid features**. And call one particular\n",
    "   assignment of values to **all** our grid features a **candidate** .  How many\n",
    "   distinct candidate are there in our grid?\n",
    "2. How many fittings did the grid search actually maker?  Note this depends \n",
    "   both on the number of candidates and the number of \"folds\". in the cross validation strategy.\n",
    "3. Specifying a candidate by a complete assignment of gride features, whicg candidates are in out plot? Which have been left out of our plot? How do we know the omitted candidates might not be the best?\n",
    "4. What is the best candidate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclass exercise\n",
    "-------------------\n",
    "\n",
    "I had planned to end class with a much simpler grid construction exercise.  Using a Model A type architecture, construct a complete GridSearch CV system using the following feature dimensions\n",
    "\n",
    "1.  chi2 vs fclassif, (optionally TruncatedSVD)\n",
    "2.  3000, 5000, 1000 (number of features)\n",
    "3.  C-value for the classifier (1, 10,100).\n",
    "\n",
    "That's a total of 18 candidates. However, because Trincated SVD has been left out, this will run fairly quickly and give you a result.  If you're willing to try this out, I will stick around and help you debug your code, as well as interpret the results (which is perhaps the hardest part).  \n",
    "\n",
    "If you'd rather not we can end class now.  No harm no foul.  In that case, I will begin class next week with this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook content ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of an earlier simpler system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f27df4ed290>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select score for best C\n",
    "#mean_scores = mean_scores.max(axis=0)\n",
    "new_mean_scores_f = new_mean_scores.max(axis=1)\n",
    "# create a dataframe to ease plotting\n",
    "mean_scores_df = pd.DataFrame(\n",
    "    new_mean_scores_f.T, index=N_FEATURES_OPTIONS, columns=reducer_labels\n",
    ")\n",
    "\n",
    "ax = mean_scores_df.plot.bar()\n",
    "ax.set_title(\"Comparing feature reduction techniques\")\n",
    "ax.set_xlabel(\"Reduced number of features\")\n",
    "ax.set_ylim([.5,.75])\n",
    "ax.set_ylabel(\"F-Score\")\n",
    "#ax.set_ylim((0, 1))\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Insults_with_Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "94px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
