{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a08a0c4",
   "metadata": {},
   "source": [
    "## Retired logistic Regression code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(vocab) = 258\n",
    "#len(triggers) = 108\n",
    "#a context has dimensionality 125 + 258\n",
    "#context_vec\n",
    "#wd_idx1, wd_idx2, wd_idx3, vocab_idx_1, dots vocab_idx_258, trigger_idx_1, ... trigger_idx_258\n",
    "\n",
    "#training data\n",
    "#25614 (= 90% of num_events = num sentences in brown after filtering)\n",
    "#test data\n",
    "#2854 (= 10% of num_events = num sentences in brown after filtering)\n",
    "\n",
    "\n",
    "ngram_offset = V\n",
    "num_triggers = len(triggers)\n",
    "dim = ngram_offset + num_triggers\n",
    "encoder = {wd:i for (i,wd) in enumerate(vocab)}\n",
    "trig_encoder = {wd:ti for (ti, wd) in enumerate(triggers)}\n",
    "\n",
    "def process_corpus (sents,V,encoder,trig_encoder,batch_sz = 10_000):\n",
    "    corpus = np.zeros((V,dim))\n",
    "    #corpus = np.zeros((V,dim))\n",
    "    token_ct,next_milestone = 0, batch_sz\n",
    "    for sent in sents:\n",
    "        token_ct = process_sent (sent,token_ct, corpus,encoder,trig_encoder)\n",
    "        if token_ct > next_milestone:\n",
    "            print(f\"{token_ct} words processed\")\n",
    "            next_milestone += batch_sz\n",
    "    return corpus\n",
    "\n",
    "def process_sent (sent,token_ct,corpus,encoder,trig_encoder):\n",
    "    triggers_in = []\n",
    "    for i in range(len(sent)):\n",
    "        wd_idx = encoder[sent[i]]\n",
    "        corpus[wd_idx,:] += add_context_vector(sent[:i],sent[i], triggers_in,\n",
    "                                                 encoder,trig_encoder)\n",
    "    return token_ct + len(sent) \n",
    "\n",
    "def update_bigram_context (context,prev,encoder):\n",
    "    if prev is not None:\n",
    "        context[encoder[prev]] += 1\n",
    "\n",
    "def update_trigger_context (context,t,trig_encoder):\n",
    "    # Use trigger encoding plus ngram_offset\n",
    "    context[trig_encoder[t]+ngram_offset] += 1\n",
    "    \n",
    "def add_context_vector (hist, w, triggers_in,encoder,trig_encoder):\n",
    "    \"\"\"\n",
    "    For the first word of sent (hist = []) the values of the trigram feats wd_idx1, wd_idx2, wd_idx3,\n",
    "    are -3,-2,-1, For secon d word of sent  -2,-1,idx where idx is the word idx of the first word\n",
    "    in the sent.  For third word of sent: -1,idx1,idx2 where idx1 and isdx2 are the word \n",
    "    indexes of the first two words of sent.  Obvious\n",
    "    \"\"\"\n",
    "    global dim\n",
    "    context = np.zeros((dim,))\n",
    "    if hist:\n",
    "        prev = hist[-1] \n",
    "    else:\n",
    "        prev = None\n",
    "    if prev in triggers:\n",
    "        triggers_in.append(hist[-1])\n",
    "    for t in triggers_in:\n",
    "        update_trigger_context(context,t,trig_encoder)\n",
    "    update_bigram_context(context,prev,encoder)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = process_corpus (sents,V,encoder,trig_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e0bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return numpy.allclose(a, a.T, rtol=rtol, atol=atol)\n",
    "\n",
    "class Triangular2DArray ():\n",
    "    \n",
    "    print_width = 8\n",
    "    lbrack = \"|\"\n",
    "    rbrack = \"|\"\n",
    "    \n",
    "    def __init__ (self, A, verbose = False):\n",
    "        self.m,self.n = A.shape\n",
    "        assert self.m == self.n, \"Only square arrays may be converted to Triangular2DArray\"\n",
    "        if verbose:\n",
    "            zeroed_A = np.triu(A)\n",
    "            print(zeroed_A)\n",
    "        self.size = int((self.m*(self.m+1))/2)\n",
    "        #print(self.size)\n",
    "        self._a = np.zeros((self.size,),dtype=A.dtype) #np.ndarray.flatten(zeroed_A)\n",
    "        ctr = 0\n",
    "        for i in range(self.m):\n",
    "            for j in range(i,self.m):\n",
    "                #d = zeroed_A[i,j]\n",
    "                #assert d>0,\"zeroed data error\"\n",
    "                #print(i,j,d,i*self.n + j)\n",
    "                if j>=i:\n",
    "                    self._a[ctr] =  A[i,j]   #d\n",
    "                    ctr += 1\n",
    "        self.shape = A.shape\n",
    "        #del A\n",
    "        \n",
    "    def __getitem__ (self,pair):\n",
    "        i,j = pair\n",
    "        assert j >= i, f\"{i=} {j=} not appropriate for upper triangular array.\"\n",
    "        assert i < self.m and j < self.n, f\"{i=} {j=} not appropriate for {m}x{n} array.\"\n",
    "        return self._a[self.get_idx(i,j)]\n",
    "         \n",
    "    def __setitem__ (self,pair,data):\n",
    "        i,j = pair\n",
    "        assert j <= i, f\"{i=} {j=} not appropriate for upper triangular array.\"\n",
    "        assert i < self.m and j < self.n, f\"{i=} {j=} not appropriate for {m}x{n} array.\"\n",
    "        self._a[self.get_idx(i,j)] = data\n",
    "\n",
    "            \n",
    "    def __repr__ (self):\n",
    "        str_list = []\n",
    "        for i in range(self.m):\n",
    "            row = [self.lbrack]\n",
    "            for j in range(self.n):\n",
    "                if i > j:\n",
    "                    d = 0\n",
    "                else:\n",
    "                    d = self.__getitem__((i,j))\n",
    "                row.append (self.make_print_rep (d))\n",
    "            row.append(self.rbrack)\n",
    "            str_list.append(\"\".join(row))\n",
    "        return \"\\n\".join(str_list)\n",
    "            \n",
    "    def make_print_rep (self, d):\n",
    "        return str(d).rjust(self.print_width,\" \")\n",
    "    \n",
    "    def idx_ct_row (self, j):\n",
    "        return sum(self.n-i for i in range(j+1))\n",
    "    \n",
    "    def get_idx (self, i,j):\n",
    "        #i*self.n + j\n",
    "        #print(i,j,self.idx_ct_row (i-1), self.idx_ct_row (i-1) +j\n",
    "        #    )\n",
    "        return self.idx_ct_row (i-1) +(j-i)\n",
    "\n",
    "#A = np.arange(1,26).reshape((5,5))\n",
    "#ta = Triangular2DArray(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c4f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
