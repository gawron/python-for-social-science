{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b95e841",
   "metadata": {},
   "source": [
    "## Problem 0: Wordle Solution (Plus code introducing WordNet!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746fd5d",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d851bc7",
   "metadata": {},
   "source": [
    "First learn about the new word game **Wordle** that is taking the internet by storm.\n",
    "\n",
    "Read about the phenomenon [here.](https://ktla.com/morning-news/technology/what-is-wordle-game-everyone-playing-explained-tips-to-win/)\n",
    "\n",
    "Play a game [here.](https://www.powerlanguage.co.uk/wordle/)\n",
    "\n",
    "Here's a quick summary of the idea.\n",
    "\n",
    "   1. The game consists of one puzzle a day where you have six chances to guess a five-letter word. Let's call that the target. Each of your guesses must be an English word. Sounds pretty hard so far. There are lots of 5-ltter words!\n",
    "\n",
    "   2. But here's the thing.  After you type in your guess, correct letters are highlighted: green means a letter is in the right spot, yellow means the letter is in the target, but it’s not in the right spot. Remaining means the letter does not occur in the target.\n",
    "   \n",
    "So as you work through your six guesses, you acquire information\n",
    "about the target.  Say your guess produces a green *n* in the second\n",
    "position. You know the target has an *n* in the second position (so, based on what we know about English spelling, it likely has a vowel or an *s* in the first position).  Say you also have a yellow *r* in the fifth position; then you know there's an *r* somewhere in the word, but not in fifth position, and not in first position, because English words can't start with *rn*, and not in second position, because that's filled.  So in fact you know the *r* is in third or fourth position.  Suppose the other three letters in your guess turned black.  You file away the information that none of these letters should show up in your future guesses. And so on, combining simple logic with knowledge of facts \n",
    "about English.  Fun game.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d24e2",
   "metadata": {},
   "source": [
    "### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91868a",
   "metadata": {},
   "source": [
    "Write a function **color_guess** that takes a Wordle target and a Wordle guess as inputs (so both are 5-letter words), and returns the **coloring** for the guess.\n",
    "\n",
    "A coloring is a sequence of colors (represented as the characters 'g', 'y' or 'k' [for black]) that contains the correct colors for the letters of the guess, where correct means correct according to the coloring rules of Wordle. \n",
    "\n",
    "The first question you should answer is what the data type of a coloring is.\n",
    "\n",
    "The definition of the function should be just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa48bbf",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_guess (target, guess):\n",
    "    coloring = list('k'*5)\n",
    "    for i in range(5):\n",
    "        if target[i] == guess[i]:\n",
    "            color[i] = 'g'\n",
    "        elif guess[i] in target:\n",
    "            color[i] = 'y'\n",
    "    return coloring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d294e0",
   "metadata": {},
   "source": [
    "### Extra credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f544350",
   "metadata": {},
   "source": [
    "For extra credit use an English word list to return the set of words compatible with the coloring and the guess. For example you can iterate through\n",
    "`nltk.corpus.words.words()`.\n",
    "\n",
    "```\n",
    "from nltk.corpus import words\n",
    "\n",
    "def find_compatible_words (guess, coloring):\n",
    "    result = []\n",
    "    for wd in words.words():\n",
    "       <do some cool stuff>\n",
    "    return result\n",
    "```\n",
    "\n",
    "Needless to say you should just return 5-letter words and don't forget to use negative information (for most colorings, you know some letters that can't be in the target).\n",
    "\n",
    "In the solution below, we use a more complkete lexical resource **WordNet**, instead of\n",
    "`nltk.corpus.words`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2270b668",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9ae9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "# FRor a more natural list of wo\n",
    "from string import ascii_lowercase,digits\n",
    "digits = set(digits)\n",
    "\n",
    "def get_active_words_wn (lang='eng',length=5):\n",
    "    \"\"\"\n",
    "    This accesses the multilingual wordnet resource for an english wordlist\n",
    "    \"\"\"\n",
    "    return {ln for w in wn.all_synsets() for ln in w.lemma_names(lang=lang) \n",
    "                 if len(ln) == length and  '_' not in ln and ln.lower() == ln \n",
    "                 and digits.intersection(ln) == set()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4fa519",
   "metadata": {},
   "source": [
    "Wordnet is a large multilingual database pairinhg words and meanings.\n",
    "\n",
    "Wordnet implements two key ideas.  The **senses** (or meanings) of a word are language\n",
    "independent concepts represented in a **very large** concept graph,\n",
    "'\n",
    "What we want for Wordle purposes are **lemmas** (pairings of a sense and a spelling),\n",
    "which are language particular, and of course we want English lemmas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e83acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog')[0].lemmas(lang='eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924f1b5",
   "metadata": {},
   "source": [
    "Below, just for fun, we implement a more general function than we need, `get_active_words` which\n",
    "collects all five letter words in a given language (if it's in WordNet!).\n",
    "\n",
    "For example, let's collect all 5-letter French words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd731256",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_wds = get_active_words_wn (lang='fra')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a2c25",
   "metadata": {},
   "source": [
    "\n",
    "Since `f_wds` is a set, we can't just look at the first 20 elements, so instead we look at a random sample.\n",
    "\n",
    "```\n",
    "from random import choice,sample\n",
    "from string import ascii_lowercase\n",
    "\n",
    "\n",
    ">>> sample(f_wds,20)\n",
    "['reine',\n",
    " 'mikvé',\n",
    " 'geste',\n",
    " 'orgue',\n",
    " 'luire',\n",
    " 'anode',\n",
    " 'éluer',\n",
    " 'jaune',\n",
    " 'kobus',\n",
    " 'hindi',\n",
    " 'dingo',\n",
    " 'osier',\n",
    " 'lupin',\n",
    " 'gruau',\n",
    " 'ajuga',\n",
    " 'rumen',\n",
    " 'prise',\n",
    " 'unix™',\n",
    " 'axial',\n",
    " 'gecko']\n",
    "```\n",
    "\n",
    "If you know French the set contains some pretty oddball words.\n",
    "\n",
    "Notice that \"Unix\" with the trademark symbol counts as a 5-letter word.  Just one of many\n",
    "surprises you will experience once you start working with Unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2bf1ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reine',\n",
       " 'mikvé',\n",
       " 'geste',\n",
       " 'orgue',\n",
       " 'luire',\n",
       " 'anode',\n",
       " 'éluer',\n",
       " 'jaune',\n",
       " 'kobus',\n",
       " 'hindi',\n",
       " 'dingo',\n",
       " 'osier',\n",
       " 'lupin',\n",
       " 'gruau',\n",
       " 'ajuga',\n",
       " 'rumen',\n",
       " 'prise',\n",
       " 'unix™',\n",
       " 'axial',\n",
       " 'gecko']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice,sample\n",
    "from string import ascii_lowercase\n",
    "sample(f_wds,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f172910f",
   "metadata": {},
   "source": [
    "Here's code for implementing our solution, discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1107e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess=tires coloring = kkykk  205 words found\n",
      "guess=drone coloring = kggkk   35 words found\n",
      "guess=proud coloring = gggkk   13 words found\n",
      "guess=proxy coloring = ggggg    1 words found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['apery', 'apart']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_wordnet = True\n",
    "\n",
    "\n",
    "if use_wordnet:\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    # For a more natural list of words than nltk.words()\n",
    "    from string import ascii_lowercase,digits\n",
    "    digits = set(digits)\n",
    "\n",
    "    def get_active_words_wn ():\n",
    "        return {ln for w in wn.all_synsets() for ln in w.lemma_names() \n",
    "                     if len(ln) == 5 and  '_' not in ln and ln.lower() == ln \n",
    "                     and digits.intersection(ln) == set()}\n",
    "\n",
    "    active_words = get_active_words_wn()\n",
    "else:\n",
    "    from nltk.corpus import words\n",
    "    # Use only 5-letter words; avoid capitalized words (names)\n",
    "    active_words = {w for w in words.words() if len(w) == 5 and w.title() != w}\n",
    "    # Missing word that turned uop in a recent NYT Wordle\n",
    "    # active_words.add('caulk')\n",
    "\n",
    "\n",
    "def find_compatible_words (guess, coloring,verbose=False):\n",
    "    result = [wd for wd in active_words\\\n",
    "              if test_word(guess,coloring,wd)]\n",
    "    if verbose:\n",
    "        print(f'guess={guess} coloring = {coloring} {len(result):>4,} words found')\n",
    "    return result\n",
    "\n",
    "def test_word(guess, coloring, wd):\n",
    "    \"\"\"\n",
    "    Limitation: This version does not work right\n",
    "    with guesses that contain repeated letters.\n",
    "    \"\"\"\n",
    "    for (w, g, c) in zip(wd, guess, coloring):\n",
    "        if c == 'k' and g in wd:\n",
    "                return False\n",
    "        elif c == 'y':\n",
    "            # 'y' means g is in the word but not at this position\n",
    "            if w==g or g not in wd:\n",
    "                return False\n",
    "        elif c=='g':\n",
    "            if w != g:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# A case like the one discussed above target must have n in 2nd position,\n",
    "# last letter of guess [= \"r\"] in the word, i\n",
    "L1 = find_compatible_words('tires','kkykk', verbose = True)\n",
    "L2 = find_compatible_words('drone','kggkk', verbose = True)\n",
    "L3 = find_compatible_words('proud','gggkk', verbose = True)\n",
    "L4 = find_compatible_words('proxy','ggggg', verbose = True)\n",
    "#len(L),'proxy' in L\n",
    " \n",
    "# last letter of guess [= \"r\"] in the word, i\n",
    "# A case like the one discussed above target must have n in 2nd position,\n",
    "L5 = find_compatible_words('spoor','kgkky')\n",
    "L5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d838a553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(active_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574678f",
   "metadata": {},
   "source": [
    "`active_words` is a set so we can't just look at the first 20 elements. \n",
    "\n",
    "Let's look at a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64e032f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gourd',\n",
       " 'needs',\n",
       " 'buddy',\n",
       " 'class',\n",
       " 'nylon',\n",
       " 'drawl',\n",
       " 'slain',\n",
       " 'radar',\n",
       " 'shirt',\n",
       " 'guava',\n",
       " 'imply',\n",
       " 'ileum',\n",
       " 'liver',\n",
       " 'sherd',\n",
       " 'honey',\n",
       " 'combo',\n",
       " 'esker',\n",
       " 'haven',\n",
       " 'peril',\n",
       " 'crypt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "sample(active_words,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d759d496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0 = set(find_compatible_words('broad', 'kkkkk'))\n",
    "len(S0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15fd64e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1 = set(find_compatible_words('fight', 'kykyk'))\n",
    "len(S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed5c63",
   "metadata": {},
   "source": [
    "### Finding a good first guess word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13af41e",
   "metadata": {},
   "source": [
    "'earth' is a good initial guess.  Here's one reason why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ca575e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_compatible_words('earth', 'kkkkk'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8c1c0",
   "metadata": {},
   "source": [
    "Striking out leaves a relatively small set of candidate words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6522929c",
   "metadata": {},
   "source": [
    "Find the perfect starting guess?\n",
    "\n",
    "We want a word which, if it strikes out, is compatible with a very small set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08e97585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aloes 285\n"
     ]
    }
   ],
   "source": [
    "best_wd, wd_set_sz = 'earth', 482\n",
    "\n",
    "for this_wd in active_words:\n",
    "    fail_set = find_compatible_words(this_wd, 'kkkkk')\n",
    "    this_wd_set_sz = len(fail_set)\n",
    "    if this_wd_set_sz < wd_set_sz:\n",
    "        best_wd,wd_set_sz = this_wd, this_wd_set_sz\n",
    "        \n",
    "print(best_wd,wd_set_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43f2c9",
   "metadata": {},
   "source": [
    "### Extra credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c96d9",
   "metadata": {},
   "source": [
    "This is for the extra extra credit, a version with an excluded letters argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "020662d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apery', 'apart']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Version II with optional excluded letters argument\n",
    "\n",
    "def find_compatible_words2 (guess, coloring, excluded_letters = ''):\n",
    "    return [wd for wd in active_words \\\n",
    "              if test_word2(guess,coloring,wd, excluded_letters)]\n",
    "\n",
    "\n",
    "def test_word2(guess, coloring, wd, excluded_letters):\n",
    "    for (w, g, c) in zip(wd, guess, coloring):\n",
    "        if w in excluded_letters:\n",
    "            return False\n",
    "        if c == 'k' and g in wd:\n",
    "                return False\n",
    "        elif c == 'y':\n",
    "            if w==g or g not in wd:\n",
    "                return False\n",
    "        elif c=='g':\n",
    "            if w != g:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# A case like the one discussed above target must have n in 2nd position,\n",
    "# last letter of guess [= \"r\"] in the word, i\n",
    "#L = find_compatible_words('tires','kkykk')\n",
    "#L = find_compatible_words('drone','kggkk')\n",
    "#L = find_compatible_words('proud','gggkk')\n",
    "#L = find_compatible_words('proxy','ggggg')\n",
    "#len(L),'proxy' in L\n",
    " \n",
    "# last letter of guess [= \"r\"] in the word, i\n",
    "# A case like the one discussed above target must have n in 2nd position,\n",
    "find_compatible_words('spoor','kgkky')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d072aa",
   "metadata": {},
   "source": [
    "Let's check out the version that implements an `eliminated_words` argument.\n",
    "\n",
    "The guess in the second Wordl game was quite insightful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf0535e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pricy', 'prick']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coloring0 = 'gykgk'\n",
    "find_compatible_words2('pinch', coloring0, excluded_letters = \"stealnh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d447617",
   "metadata": {},
   "source": [
    "WordNet does much more than look up possible word forms.\n",
    "\n",
    "Here's a brief demo for using it as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de8d8ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helix\n",
      "1. a curve that lies on the surface of a cylinder or cone and cuts the element at a constant angle.  \n",
      "2. a structure consisting of something wound in a continuous series of loops.  \n",
      "3. type genus of the family Helicidae.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_definitions(word_set,language = None):\n",
    "    \"\"\"\n",
    "    Need to check that synset has at least one lemma in the given langugae.\n",
    "    \"\"\"\n",
    "    for wd in word_set:\n",
    "        print(wd)\n",
    "        for (i,ss) in enumerate(wn.synsets(wd)):\n",
    "            print(f'{i+1}. {ss.definition()}.',end= '  ')\n",
    "            print()\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "get_definitions({'helix'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
