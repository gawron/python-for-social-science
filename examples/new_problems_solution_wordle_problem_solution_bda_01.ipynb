{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b95e841",
      "metadata": {
        "id": "0b95e841"
      },
      "source": [
        "## Problem 0: Wordle Solution (Plus code introducing WordNet!)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2746fd5d",
      "metadata": {
        "id": "2746fd5d"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d851bc7",
      "metadata": {
        "id": "4d851bc7"
      },
      "source": [
        "First learn about the new word game **Wordle** that is taking the internet by storm.\n",
        "\n",
        "Read about the phenomenon [here.](https://ktla.com/morning-news/technology/what-is-wordle-game-everyone-playing-explained-tips-to-win/)\n",
        "\n",
        "Play a game [here.](https://www.powerlanguage.co.uk/wordle/)\n",
        "\n",
        "Here's a quick summary of the idea.\n",
        "\n",
        "   1. The game consists of one puzzle a day where you have six chances to guess a five-letter word. Let's call that the target. Each of your guesses must be an English word. Sounds pretty hard so far. There are lots of 5-ltter words!\n",
        "\n",
        "   2. But here's the thing.  After you type in your guess, correct letters are highlighted: green means a letter is in the right spot, yellow means the letter is in the target, but it’s not in the right spot. Remaining means the letter does not occur in the target.\n",
        "   \n",
        "So as you work through your six guesses, you acquire information\n",
        "about the target.  Say your guess produces a green *n* in the second\n",
        "position. You know the target has an *n* in the second position (so, based on what we know about English spelling, it likely has a vowel or an *s* in the first position).  Say you also have a yellow *r* in the fifth position; then you know there's an *r* somewhere in the word, but not in fifth position, and not in first position, because English words can't start with *rn*, and not in second position, because that's filled.  So in fact you know the *r* is in third or fourth position.  Suppose the other three letters in your guess turned black.  You file away the information that none of these letters should show up in your future guesses. And so on, combining simple logic with knowledge of facts \n",
        "about English.  Fun game.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93d24e2",
      "metadata": {
        "id": "c93d24e2"
      },
      "source": [
        "### Problem statement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc91868a",
      "metadata": {
        "id": "fc91868a"
      },
      "source": [
        "Write a function **color_guess** that takes a Wordle target and a Wordle guess as inputs (so both are 5-letter words), and returns the **coloring** for the guess.\n",
        "\n",
        "A coloring is a sequence of colors (represented as the characters 'g', 'y' or 'k' [for black]) that contains the correct colors for the letters of the guess, where correct means correct according to the coloring rules of Wordle. \n",
        "\n",
        "The first question you should answer is what the data type of a coloring is.\n",
        "\n",
        "The definition of the function should be just a few lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa48bbf",
      "metadata": {
        "id": "8fa48bbf"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd93e1a4",
      "metadata": {
        "id": "cd93e1a4"
      },
      "outputs": [],
      "source": [
        "def color_guess (target, guess):\n",
        "    coloring = list('k'*5)\n",
        "    for i in range(5):\n",
        "        if target[i] == guess[i]:\n",
        "            color[i] = 'g'\n",
        "        elif guess[i] in target:\n",
        "            color[i] = 'y'\n",
        "    return coloring"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90d294e0",
      "metadata": {
        "id": "90d294e0"
      },
      "source": [
        "### Extra credit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f544350",
      "metadata": {
        "id": "8f544350"
      },
      "source": [
        "For extra credit use an English word list to return the set of words compatible with the coloring and the guess. For example you can iterate through\n",
        "`nltk.corpus.words.words()`.\n",
        "\n",
        "```\n",
        "from nltk.corpus import words\n",
        "\n",
        "def find_compatible_words (guess, coloring):\n",
        "    result = []\n",
        "    for wd in words.words():\n",
        "       <do some cool stuff>\n",
        "    return result\n",
        "```\n",
        "\n",
        "Needless to say you should just return 5-letter words and don't forget to use negative information (for most colorings, you know some letters that can't be in the target).\n",
        "\n",
        "In the solution below, we use a more complkete lexical resource **WordNet**, instead of\n",
        "`nltk.corpus.words`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2270b668",
      "metadata": {
        "id": "2270b668"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "x6BfpR84KVJx",
        "outputId": "55fbd2b4-7400-4e3d-c6da-bbfa06f2c04e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "x6BfpR84KVJx",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1d9ae9eb",
      "metadata": {
        "id": "1d9ae9eb"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "# FRor a more natural list of wo\n",
        "from string import ascii_lowercase,digits\n",
        "digits = set(digits)\n",
        "\n",
        "def get_active_words_wn (lang='eng',length=5):\n",
        "    \"\"\"\n",
        "    This accesses the multilingual wordnet resource for an english wordlist\n",
        "    \"\"\"\n",
        "    return {ln for w in wn.all_synsets() for ln in w.lemma_names(lang=lang) \n",
        "                 if len(ln) == length and  '_' not in ln and ln.lower() == ln \n",
        "                 and digits.intersection(ln) == set()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f926d93e",
      "metadata": {
        "id": "f926d93e"
      },
      "source": [
        "Wordnet is a large multilingual database pairinhg words and meanings.\n",
        "\n",
        "Wordnet implements two key ideas.  The **senses** (or meanings) of a word are language\n",
        "independent concepts represented in a **very large** concept graph,\n",
        "'\n",
        "What we want for Wordle purposes are **lemma names** (spellings that are paired with a sense); these are language particular, and of course the language we want is English."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d776d93c",
      "metadata": {
        "id": "d776d93c"
      },
      "source": [
        "There are three different ways of spelling (expressing in writing) the first (most imprtant) sense of the word *dog*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "584d7b74",
      "metadata": {
        "id": "584d7b74",
        "outputId": "00cb490e-bc92-4b66-8fba-aadb13687fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog', 'domestic_dog', 'Canis_familiaris']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "[ln for ln in wn.synsets('dog')[0].lemma_names(lang='eng')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0924f1b5",
      "metadata": {
        "id": "0924f1b5"
      },
      "source": [
        "Below, just for fun, we implement a more general function than we need, `get_active_words` which\n",
        "collects all five letter words in a given language (if it's in WordNet!).\n",
        "\n",
        "For example, let's collect all 5-letter French words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw')"
      ],
      "metadata": {
        "id": "JeprTVMgKjRt",
        "outputId": "75b58a83-50fd-4ef4-8076-046b1dfeedb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JeprTVMgKjRt",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bd731256",
      "metadata": {
        "id": "bd731256"
      },
      "outputs": [],
      "source": [
        "f_wds = get_active_words_wn (lang='fra')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "561a2c25",
      "metadata": {
        "id": "561a2c25"
      },
      "source": [
        "\n",
        "Since `f_wds` is a set, we can't just look at the first 20 elements, so instead we look at a random sample.\n",
        "\n",
        "```\n",
        "from random import choice,sample\n",
        "from string import ascii_lowercase\n",
        "\n",
        "\n",
        ">>> sample(f_wds,20)\n",
        "['reine',\n",
        " 'mikvé',\n",
        " 'geste',\n",
        " 'orgue',\n",
        " 'luire',\n",
        " 'anode',\n",
        " 'éluer',\n",
        " 'jaune',\n",
        " 'kobus',\n",
        " 'hindi',\n",
        " 'dingo',\n",
        " 'osier',\n",
        " 'lupin',\n",
        " 'gruau',\n",
        " 'ajuga',\n",
        " 'rumen',\n",
        " 'prise',\n",
        " 'unix™',\n",
        " 'axial',\n",
        " 'gecko']\n",
        "```\n",
        "\n",
        "If you know French the set contains some pretty oddball words.\n",
        "\n",
        "Notice that \"Unix\" with the trademark symbol counts as a 5-letter word.  Just one of many\n",
        "surprises you will experience once you start working with Unicode."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab37bef",
      "metadata": {
        "id": "3ab37bef"
      },
      "source": [
        "It's a set so we can't grab the first 20 elements.  \n",
        "We'll just randomly sample 20 words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d2bf1ef1",
      "metadata": {
        "id": "d2bf1ef1",
        "outputId": "02fabdd8-5fb3-43b2-fc83-a409e5131a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['morve',\n",
              " 'lueur',\n",
              " 'futur',\n",
              " 'chaos',\n",
              " 'apnée',\n",
              " 'essai',\n",
              " 'crâne',\n",
              " 'biche',\n",
              " 'fatwa',\n",
              " 'orgie',\n",
              " 'irena',\n",
              " 'chape',\n",
              " 'sprat',\n",
              " 'gigue',\n",
              " 'sosie',\n",
              " 'panse',\n",
              " 'gamut',\n",
              " 'cæcal',\n",
              " 'batis',\n",
              " 'fiole',\n",
              " 'unix™']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from random import sample\n",
        "\n",
        "add_on = [w for w in f_wds if w.startswith('unix')]\n",
        "sample(f_wds,20) + add_on"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a72bd56",
      "metadata": {
        "id": "7a72bd56"
      },
      "source": [
        "Here's code for implementing our solution, discussed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b2271dac",
      "metadata": {
        "scrolled": true,
        "id": "b2271dac",
        "outputId": "949a338d-4041-4909-f289-7edf5a14b248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "guess=tires coloring = kkykk  205 words found\n",
            "guess=drone coloring = kggkk   35 words found\n",
            "guess=proud coloring = gggkk   13 words found\n",
            "guess=proxy coloring = ggggg    1 words found\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apery', 'apart']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "use_wordnet = True\n",
        "\n",
        "if use_wordnet:\n",
        "    from nltk.corpus import wordnet as wn\n",
        "    # For a more natural list of words than nltk.words()\n",
        "    from string import ascii_lowercase,digits\n",
        "    digits = set(digits)\n",
        "\n",
        "    def get_active_words_wn (lang='eng'):\n",
        "        return {ln for w in wn.all_synsets() for ln in w.lemma_names(lang=lang) \n",
        "                     if ln.islower()  and len(ln) == 5 and  '_' not in ln\n",
        "                     and digits.intersection(ln) == set()}\n",
        "\n",
        "    active_words = get_active_words_wn()\n",
        "else:\n",
        "    from nltk.corpus import words\n",
        "    # Use only 5-letter words; avoid capitalized words (names)\n",
        "    active_words = {w for w in words.words() if len(w) == 5 and w.title() != w}\n",
        "    # Missing word that turned uop in a recent NYT Wordle\n",
        "    # active_words.add('caulk')\n",
        "\n",
        "\n",
        "def find_compatible_words (guess, coloring,verbose=False):\n",
        "    result = [wd for wd in active_words\\\n",
        "              if test_word(guess,coloring,wd)]\n",
        "    if verbose:\n",
        "        print(f'guess={guess} coloring = {coloring} {len(result):>4,} words found')\n",
        "    return result\n",
        "\n",
        "def test_word(guess, coloring, wd):\n",
        "    \"\"\"\n",
        "    Limitation: This version does not work right\n",
        "    with guesses that contain repeated letters.\n",
        "    \"\"\"\n",
        "    for (w, g, c) in zip(wd, guess, coloring):\n",
        "        if c == 'k' and g in wd:\n",
        "                return False\n",
        "        elif c == 'y':\n",
        "            # 'y' means g is in the word but not at this position\n",
        "            if w==g or g not in wd:\n",
        "                return False\n",
        "        elif c=='g':\n",
        "            if w != g:\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "# A case like the one discussed above target must have n in 2nd position,\n",
        "# last letter of guess [= \"r\"] in the word, i\n",
        "L1 = find_compatible_words('tires','kkykk', verbose = True)\n",
        "L2 = find_compatible_words('drone','kggkk', verbose = True)\n",
        "L3 = find_compatible_words('proud','gggkk', verbose = True)\n",
        "L4 = find_compatible_words('proxy','ggggg', verbose = True)\n",
        "#len(L),'proxy' in L\n",
        " \n",
        "# last letter of guess [= \"r\"] in the word, i\n",
        "# A case like the one discussed above target must have n in 2nd position,\n",
        "L5 = find_compatible_words('spoor','kgkky')\n",
        "L5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "632e84a7",
      "metadata": {
        "id": "632e84a7",
        "outputId": "6cf002a5-03b8-4f25-836e-64758b4cb331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4158"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(active_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23060fae",
      "metadata": {
        "id": "23060fae"
      },
      "source": [
        "`active_words` is a set so we can't just look at the first 20 elements. \n",
        "\n",
        "Let's look at a random sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bcc77f9a",
      "metadata": {
        "scrolled": true,
        "id": "bcc77f9a",
        "outputId": "a29822f5-4fda-450a-f639-a244fb8929be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['strut',\n",
              " 'plonk',\n",
              " 'fesse',\n",
              " 'dryer',\n",
              " 'duchy',\n",
              " 'frill',\n",
              " 'gigot',\n",
              " 'laden',\n",
              " 'nomad',\n",
              " 'debug',\n",
              " 'sonic',\n",
              " 'gruel',\n",
              " 'stomp',\n",
              " 'hawse',\n",
              " 'gonzo',\n",
              " 'crash',\n",
              " 'croak',\n",
              " 'botch',\n",
              " 'saber',\n",
              " 'below']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from random import sample\n",
        "sample(active_words,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8f15a93f",
      "metadata": {
        "id": "8f15a93f",
        "outputId": "3645df74-e48d-4bb5-bc16-a084d16c171a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drama', 'diazo', 'diary', 'drain', 'draba', 'drawn', 'drawl', 'dwarf']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "find_compatible_words('death', 'gkgkk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eba868bc",
      "metadata": {
        "id": "eba868bc",
        "outputId": "30cb37d2-71c2-4099-80bc-35c876609996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "701"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "S0 = set(find_compatible_words('broad', 'kkkkk'))\n",
        "len(S0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15fd64e7",
      "metadata": {
        "id": "15fd64e7",
        "outputId": "9579a475-450a-4687-ca06-6e073862c4f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "S1 = set(find_compatible_words('fight', 'kykyk'))\n",
        "len(S1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c15add6",
      "metadata": {
        "id": "9c15add6",
        "outputId": "ed245dbf-0a6f-47c8-c667-26bd98aea2e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "S2 = set(find_compatible_words('agent', 'gkgkk'))\n",
        "len(S2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "be49ba15",
      "metadata": {
        "id": "be49ba15",
        "outputId": "a09f9334-1fc7-48ec-f459-e2c8dbceab1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rhino', 'roily'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "set(find_compatible_words('raise', 'gkgkk'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1352e1b",
      "metadata": {
        "id": "f1352e1b",
        "outputId": "47394e64-8cc7-491a-f6b0-4895b49a786c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'abeam',\n",
              " 'abele',\n",
              " 'acerb',\n",
              " 'ahead',\n",
              " 'aleph',\n",
              " 'ameba',\n",
              " 'ameer',\n",
              " 'apery',\n",
              " 'areal',\n",
              " 'areca',\n",
              " 'arere'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "S2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "306f9b97",
      "metadata": {
        "id": "306f9b97"
      },
      "source": [
        "Code for `get_definitions` defined at end of NB."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b165ed",
      "metadata": {
        "id": "b2b165ed"
      },
      "source": [
        "### Finding a good first guess word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e3fdb1",
      "metadata": {
        "id": "78e3fdb1"
      },
      "source": [
        "'earth' is a good initial guess.  Here's one reason why."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd66fedd",
      "metadata": {
        "id": "cd66fedd"
      },
      "source": [
        "Striking out leaves a relatively small set of candidate words.\n",
        "\n",
        "While positive info (it starts with \"a\") can be enormousl;y helpful\n",
        "at helping you think of eligible words, negative is also extremely\n",
        "useful.  If noithing else it helps keep you from wasting guesses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f7ea345",
      "metadata": {
        "id": "2f7ea345"
      },
      "source": [
        "Find the perfect starting guess?\n",
        "\n",
        "One idea:  We want a word which, if it strikes out, is compatible with a very small set of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "98d7357b",
      "metadata": {
        "id": "98d7357b",
        "outputId": "ff5dc1a3-6a75-4f2a-ae89-8e2c0075c9ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aloes 285\n"
          ]
        }
      ],
      "source": [
        "best_wd, wd_set_sz = 'earth', 482\n",
        "\n",
        "def compatibility_score(wd):\n",
        "    return len(find_compatible_words(this_wd, 'kkkkk'))\n",
        "\n",
        "# Compute this once and for all in advance.\n",
        "no_rep_active_words = [wd for wd in active_words if len(set(wd)) == 5]\n",
        "\n",
        "for this_wd in no_rep_active_words:\n",
        "    this_wd_set_sz = compatibility_score(this_wd)\n",
        "    if this_wd_set_sz < wd_set_sz:\n",
        "        best_wd,wd_set_sz = this_wd, this_wd_set_sz\n",
        "        \n",
        "print(best_wd,wd_set_sz)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff24205",
      "metadata": {
        "id": "1ff24205"
      },
      "source": [
        "Another possible criterion is that it has the best chance of getting greens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "98ace6ae",
      "metadata": {
        "id": "98ace6ae",
        "outputId": "e83b0ac4-a8a6-48a0-9838-1ce28bb60424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coney 2445\n"
          ]
        }
      ],
      "source": [
        "def compute_hits0(this_wd):\n",
        "    hits = 0\n",
        "    for other in active_words:\n",
        "        for i in range(5):\n",
        "            if other[i] == this_wd[i]:\n",
        "                hits += 1\n",
        "    return hits\n",
        "\n",
        "def compute_hits (this_wd):\n",
        "    return sum(1 for other in active_words \\\n",
        "               for i in range(5) if other[i] == this_wd[i])\n",
        "\n",
        "# use best wd by last criterion as first guess\n",
        "best_wd, best_hits = 'earth', compute_hits('earth')\n",
        "\n",
        "for this_wd in no_rep_active_words:\n",
        "    this_wd_hits = compute_hits(this_wd)\n",
        "    if this_wd_hits > best_hits:\n",
        "        best_wd, best_hits = this_wd, this_wd_hits\n",
        "        \n",
        "# No repeated letter constraint: saree 2812\n",
        "# coney 2445\n",
        "print(best_wd,best_hits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0e68c9",
      "metadata": {
        "id": "7b0e68c9"
      },
      "source": [
        "Another idea is maximize the number of yellows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7b0586eb",
      "metadata": {
        "id": "7b0586eb",
        "outputId": "df9e858a-9c33-43d3-a87e-5806905af9fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raise 7292\n"
          ]
        }
      ],
      "source": [
        "# Guess the best word from the last criterion\n",
        "best_wd, best_hits = 'coney', 5526\n",
        "\n",
        "def compute_overlaps(this_wd):\n",
        "    hits = 0\n",
        "    this_set = set(this_wd)\n",
        "    for other in active_words:\n",
        "        hits+= len(this_set.intersection(other))\n",
        "    return hits\n",
        "\n",
        "for this_wd in no_rep_active_words:\n",
        "    this_wd_hits = compute_overlaps(this_wd)\n",
        "    if this_wd_hits > best_hits:\n",
        "        best_wd, best_hits = this_wd, this_wd_hits\n",
        "        \n",
        "print(best_wd,best_hits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "365074fb",
      "metadata": {
        "id": "365074fb"
      },
      "source": [
        "Do well at all three?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c531b49a",
      "metadata": {
        "id": "c531b49a",
        "outputId": "d7563cbc-2f69-473e-81d1-fe4edd4258d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raise 9167\n"
          ]
        }
      ],
      "source": [
        "def aggregate_score(wd):\n",
        "    return compute_hits(wd) + compute_overlaps(wd) - compatibility_score(wd)\n",
        "\n",
        "# Guess the best word from the last criterion\n",
        "best_wd, best_score = 'arise', aggregate_score('arise')\n",
        "\n",
        "for this_wd in no_rep_active_words:\n",
        "    this_wd_score = aggregate_score(this_wd)\n",
        "    if this_wd_score > best_score:\n",
        "        best_wd, best_score = this_wd, this_wd_score\n",
        "\n",
        "print(best_wd,best_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36f75c4e",
      "metadata": {
        "id": "36f75c4e"
      },
      "source": [
        "### Extra credit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f953aba",
      "metadata": {
        "id": "9f953aba"
      },
      "source": [
        "This is for the extra extra credit, a version with an excluded letters argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "020662d7",
      "metadata": {
        "id": "020662d7",
        "outputId": "bf31923f-1f2e-4724-9b4f-f58ccd44c7a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apery', 'apart']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "## Version II with optional excluded letters argument\n",
        "\n",
        "def find_compatible_words2 (guess, coloring, excluded_letters = ''):\n",
        "    return [wd for wd in active_words \\\n",
        "              if test_word2(guess,coloring,wd, excluded_letters)]\n",
        "\n",
        "\n",
        "def test_word2(guess, coloring, wd, excluded_letters):\n",
        "    for (w, g, c) in zip(wd, guess, coloring):\n",
        "        if w in excluded_letters:\n",
        "            return False\n",
        "        if c == 'k' and g in wd:\n",
        "                return False\n",
        "        elif c == 'y':\n",
        "            if w==g or g not in wd:\n",
        "                return False\n",
        "        elif c=='g':\n",
        "            if w != g:\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "# A case like the one discussed above target must have n in 2nd position,\n",
        "# last letter of guess [= \"r\"] in the word, i\n",
        "#L = find_compatible_words('tires','kkykk')\n",
        "#L = find_compatible_words('drone','kggkk')\n",
        "#L = find_compatible_words('proud','gggkk')\n",
        "#L = find_compatible_words('proxy','ggggg')\n",
        "#len(L),'proxy' in L\n",
        " \n",
        "# last letter of guess [= \"r\"] in the word, i\n",
        "# A case like the one discussed above target must have n in 2nd position,\n",
        "find_compatible_words('spoor','kgkky')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568f7b7d",
      "metadata": {
        "id": "568f7b7d",
        "outputId": "93dee610-95b3-4a7e-d9c7-5d082716d919"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "482"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(find_compatible_words('earth', 'kkkkk'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02d072aa",
      "metadata": {
        "id": "02d072aa"
      },
      "source": [
        "Let's check out the version that implements an `eliminated_words` argument.\n",
        "\n",
        "The guess in the second Wordl game was quite insightful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf0535e",
      "metadata": {
        "id": "caf0535e",
        "outputId": "5b88f3b2-3a69-4eea-e146-1a5d778f617c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pricy', 'prick']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coloring0 = 'gykgk'\n",
        "find_compatible_words2('pinch', coloring0, excluded_letters = \"stealnh\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coloring0 = 'gkgkg'\n",
        "find_compatible_words2('olive', coloring0, excluded_letters = \"rastwcpn\")"
      ],
      "metadata": {
        "id": "ym1p-SAgLhpE",
        "outputId": "23dda320-715c-462f-bf72-9a10e4896bc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ym1p-SAgLhpE",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oxime', 'oxide']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa84c3f",
      "metadata": {
        "id": "5aa84c3f"
      },
      "source": [
        "WordNet does much more than look up possible word forms.\n",
        "\n",
        "Here's a brief demo for using it as a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e9fe090f",
      "metadata": {
        "id": "e9fe090f",
        "outputId": "1d22b3a3-862d-4193-a018-fad76b2fe874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helix\n",
            "1. a curve that lies on the surface of a cylinder or cone and cuts the element at a constant angle.  \n",
            "2. a structure consisting of something wound in a continuous series of loops.  \n",
            "3. type genus of the family Helicidae.  \n",
            "\n",
            "\n",
            "record\n",
            "1. anything (such as a document or a phonograph record or a photograph) providing permanent evidence of or information about past events.  \n",
            "2. sound recording consisting of a disk with a continuous groove; used to reproduce music by rotating while a phonograph needle tracks in the groove.  \n",
            "3. the number of wins versus losses and ties a team has had.  \n",
            "4. the sum of recognized accomplishments.  \n",
            "5. a compilation of the known facts regarding something or someone.  \n",
            "6. an extreme attainment; the best (or worst) performance ever attested (as in a sport).  \n",
            "7. a document that can serve as legal evidence of a transaction.  \n",
            "8. a list of crimes for which an accused person has been previously convicted.  \n",
            "9. make a record of; set down in permanent form.  \n",
            "10. register electronically.  \n",
            "11. indicate a certain reading; of gauges and instruments.  \n",
            "12. be aware of.  \n",
            "13. be or provide a memorial to a person or an event.  \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_definitions(word_set,language = None):\n",
        "    \"\"\"\n",
        "    Need to check that synset has at least one lemma in the given langugae.\n",
        "    \"\"\"\n",
        "    for wd in word_set:\n",
        "        print(wd)\n",
        "        for (i,ss) in enumerate(wn.synsets(wd)):\n",
        "            print(f'{i+1}. {ss.definition()}.',end= '  ')\n",
        "            print()\n",
        "        print()\n",
        "        print()\n",
        "\n",
        "get_definitions({'helix','record'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef5913b6",
      "metadata": {
        "id": "ef5913b6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "new_problems_solution_wordle_problem_solution_bda_01.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}