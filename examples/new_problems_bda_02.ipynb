{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b95e841",
   "metadata": {},
   "source": [
    "## Problem 0: Wordle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746fd5d",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d851bc7",
   "metadata": {},
   "source": [
    "First learn about the new word game **Wordle** that is taking the internet by storm.\n",
    "\n",
    "Read about the phenomenon [here.](https://ktla.com/morning-news/technology/what-is-wordle-game-everyone-playing-explained-tips-to-win/)\n",
    "\n",
    "Play a game [here.](https://www.powerlanguage.co.uk/wordle/)\n",
    "\n",
    "Here's a quick summary of the idea.\n",
    "\n",
    "   1. The game consists of one puzzle a day where you have six chances to guess a five-letter word. Let's call that the target. Each of your guesses must be an English word. Sounds pretty hard so far. There are lots of 5-letter words!\n",
    "\n",
    "   2. But here's the thing.  After you type in your guess, correct letters are highlighted: green means a letter is in the right spot, yellow means the letter is in the target, but itâ€™s not in the right spot. Remaining means the letter does not occur in the target.\n",
    "   \n",
    "So as you work through your six guesses, you acquire information\n",
    "about the target.  Say your guess produces a green *n* in the second\n",
    "position. You know the target has an *n* in the second position (so, based on what we know about English spelling, it likely has a vowel or an *s* in the first position).  Say you also have a yellow *r* in the fifth position; then you know there's an *r* somewhere in the word, but not in fifth position, and not in first position, because English words can't start with *rn*, and not in second position, because that's filled.  So in fact you know the *r* is in third or fourth position.  Suppose the other three letters in your guess turned black.  You file away the information that none of these letters should show up in your future guesses. And so on, combining simple logic with knowledge of facts \n",
    "about English.  Fun game.\n",
    "\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://gawron.sdsu.edu/python_for_ss/course_core/book_draft/_static/sample_wordle_game.png ' />\n",
    "<figcaption>A sample Wordle Game (not particularly well-played)</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb64f49",
   "metadata": {},
   "source": [
    "Here's another slightly more interesting game we'll use below.  Think about whether that last guess\n",
    "is incredibly lucky, or just represents a good play.  We'll try to answer that question below.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://gawron.sdsu.edu/python_for_ss/course_core/book_draft/_static/sample_wordle_game_2.png ' />\n",
    "<figcaption>A better Wordle Game</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d24e2",
   "metadata": {},
   "source": [
    "### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91868a",
   "metadata": {},
   "source": [
    "Write a function **color_guess** that takes a Wordle target and a Wordle guess as inputs (so both are 5-letter words), and returns the **coloring** for the guess.\n",
    "\n",
    "A coloring is a sequence of colors (represented as the characters 'g', 'y' or 'k' [for black]) that contains the correct colors for the letters of the guess, where correct means correct according to the coloring rules of Wordle. \n",
    "\n",
    "The first question you should answer is what the data type of a coloring is.\n",
    "\n",
    "The definition of the function should be just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d294e0",
   "metadata": {},
   "source": [
    "### Extra credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f544350",
   "metadata": {},
   "source": [
    "For extra credit use an English word list to return the set of words compatible with the coloring and the guess. For example you can iterate through\n",
    "`nltk.corpus.words.words()`.\n",
    "\n",
    "```\n",
    "from nltk.corpus import words\n",
    "\n",
    "def find_compatible_words (guess, coloring):\n",
    "    result = []\n",
    "    for wd in words.words():\n",
    "       <do some cool stuff>\n",
    "    return result\n",
    "```\n",
    "\n",
    "Needless to say you should just return 5-letter words and don't forget to use negative information (for most colorings, you know some letters that can't be in the target).\n",
    "\n",
    "Note you should try this function out on the second-to-last guess in the second Wordle \n",
    "game above, to answer the question whether the last guess is lucky (there are many\n",
    "open possibilities) or insightful (there are few). \n",
    "\n",
    "Also, to sharpen the answer your function gives you, modify `find_compatible_words`  by adding another (optional) argument for excluded letters.  The meaning is that the excluded letters\n",
    "shouldn't occur in any of the words returned by the function.  Then assuming `coloring0` is the right coloring\n",
    "for the second-to-last guess, the words left as possibilities after that guess \n",
    "would be given by:\n",
    "\n",
    "```\n",
    "find_compatible_words('pinch', coloring0, excluded_letters = \"stealnh\")\n",
    "```\n",
    "\n",
    "because the letters in \"stealnh\" are the ones eliminated earlier in the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd50e3",
   "metadata": {},
   "source": [
    "### Extra special extra credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ed125",
   "metadata": {},
   "source": [
    "For extra special extra credit,  redo everything that we've thought about so far\n",
    "to use wordle **information states**.  A wordle information state represents\n",
    "all the information from all the guesses so far. \n",
    "\n",
    "You would write two functions.  One called **update_information_state** that inputs an information state (the current information state), a target word, and a guess, and returns the updated information state,  Another called **find_compatible_words** that takes an information state and returns the 5-letter words compatible with it.\n",
    "\n",
    "Note that a wordle information state **can't** just be a guess and a coloring.  After one unlucky\n",
    "guess we might know exactly 5 letters that aren't in the target.  After\n",
    "two unlucky guesses we might know 10, and that can't be represented by\n",
    "one guess and one coloring sequence with only 5 positions.  So the first thing you need\n",
    "to think about, before writing any code, is how to represent an information\n",
    "state.  If you find a good answer, it should be obvious how to represent the\n",
    "initial information state (before any guesses have been made).  Note that the result\n",
    "of applying **find_compatible_words** to the initial information state should be the set of all\n",
    "English 5-letter words.  And the result of applying **find_compatible_words** to the final information state of a winning game (all green letters) should be a set containing a single 5-letter word. \n",
    "\n",
    "Important point:  Don't try to make the information states reflect facts about\n",
    "English. For instance, knowing there's an *n* in second position tells you a lot about\n",
    "what letters can occur in first position, **if you know some facts about\n",
    "English words**.  Don't get into that.  It's a rabbit hole from which there is no return.\n",
    "Just try to represent the fact that you know the information that comes from\n",
    "the sequence of  colored guesses, e.g., there's an *n* in second position, there is no *i*,\n",
    "there is an *e* somewhere, but not in fourth position: the **logical** information you know.\n",
    "\n",
    "Second important point:  Making the information state be elegant in the sense that no piece\n",
    "of information is represented twice is not essential. For example, you might choose to represent\n",
    "information states in such a way that the following can happen:  One part of\n",
    "one of your information states captures the fact that there is an *e* in the target, and\n",
    "another part captures the fact that an *e* occurs in second position of the target.\n",
    "The first fact follows logically from the second. That doesn't mean your way of representing information states is incorrect.\n",
    "\n",
    "The notion information state\n",
    "has a rich history in computation and in computational psychology. Solving this\n",
    "problem does not require any acquaintance with that history.  But it will probably be\n",
    "easier to solve it in an elegant way for those who've had some experience thinking\n",
    "about information states. \n",
    "\n",
    "Summing up: Our notion of information state is  a representation of what our guess thus far\n",
    "have told us.  It should determine the set\n",
    "of English words compatible with the guesses and their colorings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ee9ad",
   "metadata": {},
   "source": [
    "## Problem 1:  Bigram counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc20c85",
   "metadata": {},
   "source": [
    "### Introduction: Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8770c",
   "metadata": {},
   "source": [
    "A bigram is a pair of words occurring together in running text.  For example, in the sentence\n",
    "\n",
    "```\n",
    "the old man loved the old woman\n",
    "```\n",
    "\n",
    "the bigrams are\n",
    "\n",
    "```\n",
    "[('the', 'old'), ('old', 'man'), ('man', 'loved'), ('loved', 'the'), ('the', 'old'), ('old', 'woman')]\n",
    "```\n",
    "\n",
    "Bigrams arise in the study of the sequential statistical properties of language,\n",
    "in other words, when we are trying to answer questions like, \"Given that the current word is \n",
    "*the* what is the probability that the next word is *old*?\"  So we might\n",
    "also write down the bigrams of the example sentence as\n",
    "\n",
    "```\n",
    "[('the', 'old'), ('old', 'man'), ('man', 'loved'), ('loved', 'the'), ('the', 'old'), ('old', 'woman'),\n",
    "('woman', 'END')]\n",
    "```\n",
    "\n",
    "in order to model the probability that there is no next word, that\n",
    "is, that the current word is the last word in a sentence. We might even write the bigrams as:\n",
    "\n",
    "```\n",
    "[('START', 'the'), ('the', 'old'), ('old', 'man'), ('man', 'loved'), ('loved', 'the'), ('the', 'old'), ('old', 'woman'),  ('woman', 'END')]\n",
    "```\n",
    "\n",
    "in order to get counts for being a first word as well.  In this way, just by counting\n",
    "bigrams, we would discover that *the* is a very common way of starting a sentence.\n",
    "\n",
    "It's useful to know that bigrams are a special case of the general concept of **ngrams**. An\n",
    "ngram is a sequence of *n* words occurring in running text. The unigrams (or 1-grams) in a text\n",
    "are just the words, so the unigrams in the text above are\n",
    "\n",
    "```\n",
    "['the', 'old', 'man', 'loved', 'the', 'old', 'woman']\n",
    "```\n",
    "\n",
    "while the trigrams are:\n",
    "\n",
    "```\n",
    "[('START1', 'START2','the'), ('START2', 'the', 'old'), ('the', 'old','man'), ('old', 'man','loved'), ('man', 'loved','the'), ('loved', 'the','old'), ('the', 'old','woman'), ('old', 'woman', 'END1'), ('woman', 'END1', 'END2')]\n",
    "```\n",
    "\n",
    "We count ngrams the same way we count words. The bigram ('old', 'woman') occurs once\n",
    "in our example sentence.  The bigram ('the', 'old') occurs twice.  In this problem we are\n",
    "going to write some of the utility code for counting bigrams.  First step: list them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6da9e",
   "metadata": {},
   "source": [
    "###  Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b7010",
   "metadata": {},
   "source": [
    "Write a function `find_bigrams` that finds the **bigrams** in a string of words.  You can include `'START'`\n",
    "and `'END'` symbols or not.  Or you can write your function with optional Boolean parameters `start` and `end`,\n",
    "which give the user the option of including `'START'` and `'END'` symbols.  Your choice.\n",
    "\n",
    "Write another function `get_bigram_counts` that takes a string of words as its argument, calls `find_bigrams`,\n",
    "and returns a `FreqDist` with the bigram counts from the input string.  This should be a one-liner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01293a76",
   "metadata": {},
   "source": [
    "The functions should work like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6c9cb542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'old'), ('old', 'man'), ('man', 'loved'), ('loved', 'the'), ('the', 'old'), ('old', 'woman')]\n"
     ]
    }
   ],
   "source": [
    "bgrs = find_bigrams('the old man loved the old woman')\n",
    "print(bgrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284577d6",
   "metadata": {},
   "source": [
    "As observed above, the bigram *the old* occurs twice in this sentence, while the bigram *old man* occurs only once. We can capture this fact using a `Counter` (a specialized dictionary for keeping counts of the elements\n",
    "in a sequence). \n",
    "\n",
    "The standard Python module `collections` provides a class called `Counter` for this purpose, but we get a counter with a few more bells and whistles if we import the class `FreqDist` from  the `nltk` (Natural Language Tool Kit) module, and pass it the sequence we want to get counts for.  \n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2451dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rain in spain falls mainly on the plain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({' ': 8, 'n': 6, 'a': 5, 'i': 5, 'l': 4, 't': 2, 'h': 2, 'e': 2, 's': 2, 'p': 2, ...})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "text = 'the rain in spain falls mainly on the plain'\n",
    "print(text)\n",
    "FreqDist(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c38338",
   "metadata": {},
   "source": [
    "A string is a sequence of characters, so given a string, a `FreqDist` counts characters.\n",
    "\n",
    "If we want to count words, we need to pass in a sequence of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd9a2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'rain', 'in', 'spain', 'falls', 'mainly', 'on', 'the', 'plain']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 2, 'rain': 1, 'in': 1, 'spain': 1, 'falls': 1, 'mainly': 1, 'on': 1, 'plain': 1})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text.split())\n",
    "FreqDist(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca56f4",
   "metadata": {},
   "source": [
    "Now we see that our `find_bigrams`  function returns just the right thing for counting bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d06ba2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('the', 'old'): 2, ('old', 'man'): 1, ('man', 'loved'): 1, ('loved', 'the'): 1, ('old', 'woman'): 1})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "bgrs = find_bigrams('the old man loved the old woman')\n",
    "print(bgrs)\n",
    "FreqDist(bgrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b285533",
   "metadata": {},
   "source": [
    "We count bigrams just like we count words.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba4752",
   "metadata": {},
   "source": [
    "### Implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55328452",
   "metadata": {},
   "source": [
    "Now there's a fine point here to pay attention to when you implement\n",
    "`find_bigrams`.  In order for `FreqDist` to work with your bigrams, the bigrams\n",
    "have to be **hashable**, which means they have to be **immutable**.  That's why the bigrams are tuples\n",
    "not lists.\n",
    "\n",
    "Watch what happens if a bigram is represented as a **list** of two words instead of as a **tuple**\n",
    "of two words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "241c1599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'old'], ['old', 'man'], ['man', 'loved'], ['loved', 'the'], ['the', 'old'], ['old', 'woman']]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-b967c958152c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbad_bgrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbad_find_bigrams\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'the old man loved the old woman'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_bgrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_bgrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/probability.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mCounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Cached number of samples in this FreqDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/probability.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \"\"\"\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "bad_bgrs = bad_find_bigrams ('the old man loved the old woman')\n",
    "print(bad_bgrs)\n",
    "FreqDist(bad_bgrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7add1",
   "metadata": {},
   "source": [
    "Here we called `bad_find_bigrams`, a version of `find_bigrams` which represented each bigram as a two-word list.  That caused the error.  Pay attention to the **last line** of the Error (good practice in general, not just here).\n",
    "\n",
    "```\n",
    "TypeError: unhashable type: 'list'\n",
    "```\n",
    "\n",
    "A `FreqDist` is a `Counter` which in turn is just a specialized Python dictionary.  Our\n",
    "ngrams are the keys in the dictionary and \n",
    "the keys in a dictionary must be **hashable**.  This means they must be immutable.  Tuples\n",
    "are immutable and lists are not.  Hence when we represent our bigrams as 2-element lists\n",
    "we get this **unhashable type** error.\n",
    "\n",
    "Summing up: bigrams must be hashable in order to be keys in a count dictionary.  Hence bigrams\n",
    "should be tuples, not lists, and bigram sequences should be lists of tuples.  Bear this in mind\n",
    "when you write `find_bigrams`.\n",
    "\n",
    "For a discussion of **why** hashable types must be immutable look [here.](https://gawron.sdsu.edu/python_for_ss/course_core/book_draft/Python_introduction/mutability.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff711c8e",
   "metadata": {},
   "source": [
    "## Problem 2:  Finding Rhymes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598bdea",
   "metadata": {},
   "source": [
    "### Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1c6e6",
   "metadata": {},
   "source": [
    "Consider a description of a Python program used to construct the Jan 12, 2022\n",
    "NYT crossword puzzle, as written by its constructor, Adam Aaronson:\n",
    "\n",
    "\"Then I made a Python program that mined the CMU Pronouncing Dictionary for every word that rhymes with a single digit and searched my word list for every entry consisting of two of those words back to back.\"\n",
    "\n",
    "Hmmm. Interesting piece of programming.  Let's consider writing a function \n",
    "that finds English rhymes (as part of, let's say, \n",
    "our **Poet's Workbench**, a software package we hope to make\n",
    "millions on).\n",
    "\n",
    "Let's make one thing clear.  The use of a pronunciation dictionary is critical for\n",
    "finding English rhymes.  We are stuck dealing with gazillions of special\n",
    "cases if we have to deal with English orthography.  Think of bite\n",
    "and flight, fix and ticks, load and code and owed and furloughed;\n",
    "think of non-rhymes like cough and tough and bough and dough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dacc7",
   "metadata": {},
   "source": [
    "So let's start by bringing in the CMU pronouncing dictionary, and looking at a word's pronounciations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e23a361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AE1', 'K', 'CH', 'AH0', 'W', 'EH2', 'R', 'IY0']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "pron_dict = cmudict.dict()\n",
    "pron_dict['actuary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547898c",
   "metadata": {},
   "source": [
    "A **pronunciation** in the  CMU pronunciation dictionary is a **list of sounds**. Since words can have more than one pronunciation, a word is associated with a **list** of pronunciations.\n",
    "\n",
    "The word *actuary* has one pronunciation; hence the dictionary gives it a list with one element, and that element is a list of 8 sounds (or phonemes or phones). Next let's look at *human*, a word with two pronunciations. See if you can say them aloud.  In trying to read the pronunciation representation, it's helpful to know that the numbers represent stress information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0efbf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HH', 'Y', 'UW1', 'M', 'AH0', 'N'], ['Y', 'UW1', 'M', 'AH0', 'N']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pron_dict['human']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3fe3da",
   "metadata": {},
   "source": [
    "For the purposes of this problem you don't really need to think about what each sound symbol\n",
    "means, but if you're interested, there's a set of examples illustrating each\n",
    "of the phonemes [here.](http://www.speech.cs.cmu.edu/cgi-bin/cmudict?stress=-s&in=SYLLABLE)\n",
    "\n",
    "Let's look at some rhyming words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1dc89720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['S', 'P', 'AE1', 'M']],\n",
       " [['HH', 'AE1', 'M']],\n",
       " [['SH', 'AE1', 'M']],\n",
       " [['K', 'L', 'AE1', 'M']])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pron_dict['spam'], pron_dict['ham'], pron_dict['sham'], pron_dict['clam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919c629",
   "metadata": {},
   "source": [
    "So clearly, the last part of the pronunication has to match.\n",
    "\n",
    "Let's try this.  Grab the first, preferred pronunciation of a target word and look for end-matches with that.\n",
    "\n",
    "We'll do the word *ham*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a91e7ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bahm ['B', 'AE1', 'M']\n",
      "bam ['B', 'AE1', 'M']\n",
      "cam ['K', 'AE1', 'M']\n",
      "camm ['K', 'AE1', 'M']\n",
      "cham ['CH', 'AE1', 'M']\n",
      "dahm ['D', 'AE1', 'M']\n",
      "dam ['D', 'AE1', 'M']\n",
      "damm ['D', 'AE1', 'M']\n",
      "damme ['D', 'AE1', 'M']\n",
      "damn ['D', 'AE1', 'M']\n",
      "gahm ['G', 'AE1', 'M']\n",
      "gamm ['G', 'AE1', 'M']\n",
      "hahm ['HH', 'AE1', 'M']\n",
      "ham ['HH', 'AE1', 'M']\n",
      "hamm ['HH', 'AE1', 'M']\n",
      "hamme ['HH', 'AE1', 'M']\n",
      "jam ['JH', 'AE1', 'M']\n",
      "jamb ['JH', 'AE1', 'M']\n",
      "kam ['K', 'AE1', 'M']\n",
      "kamm ['K', 'AE1', 'M']\n",
      "lahm ['L', 'AE1', 'M']\n",
      "lam ['L', 'AE1', 'M']\n",
      "lamb ['L', 'AE1', 'M']\n",
      "lambe ['L', 'AE1', 'M']\n",
      "lamm ['L', 'AE1', 'M']\n",
      "lamme ['L', 'AE1', 'M']\n",
      "ma'am ['M', 'AE1', 'M']\n",
      "nahm ['N', 'AE1', 'M']\n",
      "nam ['N', 'AE1', 'M']\n",
      "pam ['P', 'AE1', 'M']\n",
      "pham ['F', 'AE1', 'M']\n",
      "rahm ['R', 'AE1', 'M']\n",
      "ram ['R', 'AE1', 'M']\n",
      "ramm ['R', 'AE1', 'M']\n",
      "sahm ['S', 'AE1', 'M']\n",
      "sam ['S', 'AE1', 'M']\n",
      "sham ['SH', 'AE1', 'M']\n",
      "tam ['T', 'AE1', 'M']\n",
      "tamm ['T', 'AE1', 'M']\n",
      "tham ['TH', 'AE1', 'M']\n",
      "wham ['W', 'AE1', 'M']\n",
      "yam ['Y', 'AE1', 'M']\n",
      "zahm ['Z', 'AE1', 'M']\n"
     ]
    }
   ],
   "source": [
    "tgt = pron_dict['ham'][0]\n",
    "for (wd,ps) in pron_dict.items():\n",
    "    for p in ps:\n",
    "       if p[1:] == tgt[1:]: \n",
    "          print(wd, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740a8e3",
   "metadata": {},
   "source": [
    "There are lots of non words in CMU, in part because this was built for use in early speech recognition\n",
    "systems, and coverage of proper names was desirable.  But we do see real words like *yam, dam, lamb*, and\n",
    "*damn*, some of which depart from a simple orthographic match, so this is a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45794b",
   "metadata": {},
   "source": [
    "So something roughly along these lines will work a lot of the time.\n",
    "\n",
    "Let's call this version of the program **version A**.\n",
    "\n",
    "Here's another example that works, using a two syllable rhyme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ba79c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cabot ['K', 'AE1', 'B', 'AH0', 'T']\n",
      "habit ['HH', 'AE1', 'B', 'AH0', 'T']\n",
      "kabat ['K', 'AE1', 'B', 'AH0', 'T']\n",
      "rabbit ['R', 'AE1', 'B', 'AH0', 'T']\n"
     ]
    }
   ],
   "source": [
    "tgt = pron_dict['rabbit'][0]\n",
    "for (wd,ps) in dd.items():\n",
    "    for p in ps:\n",
    "       if p[1:] == tgt[1:]: \n",
    "          print(wd, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc7ff9f",
   "metadata": {},
   "source": [
    "There are problems with version A, \n",
    "illustrated by the target word *kicked*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "567979a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kicked ['K', 'IH1', 'K', 'T']\n",
      "licht ['L', 'IH1', 'K', 'T']\n",
      "licked ['L', 'IH1', 'K', 'T']\n",
      "nicked ['N', 'IH1', 'K', 'T']\n",
      "picht ['P', 'IH1', 'K', 'T']\n",
      "picked ['P', 'IH1', 'K', 'T']\n",
      "ticked ['T', 'IH1', 'K', 'T']\n"
     ]
    }
   ],
   "source": [
    "tgt = pron_dict['kicked'][0]\n",
    "for (wd,ps) in dd.items():\n",
    "    for p in ps:\n",
    "       if p[1:] == tgt[1:]: \n",
    "          print(wd, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88617115",
   "metadata": {},
   "source": [
    "An impressive list but notice some missing words.\n",
    "\n",
    "```\n",
    "clicked\n",
    "tricked\n",
    "strict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa45d8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'L', 'IH1', 'K', 'T']\n",
      "['T', 'R', 'IH1', 'K', 'T']\n",
      "['S', 'T', 'R', 'IH1', 'K', 'T']\n"
     ]
    }
   ],
   "source": [
    "print(pron_dict['clicked'][0])\n",
    "print(pron_dict['tricked'][0])\n",
    "print(pron_dict['strict'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac967331",
   "metadata": {},
   "source": [
    "These words are in fact in the dictionary and they are easily discoverable rhymes.\n",
    "The problem is that our current code for finding rhymes doesn't catch these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd6a08",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "The sample code above prints out rhymes.  Instead of writing\n",
    "code that **prints out** the rhymes, write a **function** called `find_rhymes`\n",
    "that takes one argument, an English word, and uses the CMU pronunciation\n",
    "dictionary to return the set of all its\n",
    "rhymes.  It should work roughly like this:\n",
    "\n",
    "```\n",
    ">>> find_rhymes('kicked')\n",
    "{'kicked', 'licht', 'licked', 'nicked', 'picht', 'picked', 'ticked','clicked', 'tricked', 'strict'}\n",
    "```\n",
    "\n",
    "Note: your program may not return these results in this order and may find other rhymes as well,\n",
    "but it should return at least these rhymes for *kicked*.   Also to make life a tad\n",
    "easier, just find rhymes for the preferred pronunciation of the target\n",
    "word (The first pronunciation in the pronunciation list of a word is its **preferred**\n",
    "pronunciation).\n",
    "\n",
    "Let's spell this out in a list of program **specs**.\n",
    "\n",
    "1.  Figure out why the last three rhymes for *kicked* are missed by version A.\n",
    "\n",
    "    The function `find_rhymes` should fix the problem of the three missing rhymes for *kicked*.  So getting 'kicked' right means finding all the rhymes for *kicked* found by version A of the program **plus** at least the three new ones listed above, *clicked*, *tricked* and *strict*.\n",
    "\n",
    "2.  Make sure that if A is a rhyme of B, B is also a rhyme of B.\n",
    "\n",
    "    So we also want the following behavior:\n",
    "    \n",
    "    ```\n",
    "    >>> find_rhymes('strict')\n",
    "    ['kicked', 'licht', 'licked', 'nicked', 'picht', 'picked', 'ticked','clicked', 'tricked', 'strict']\n",
    "     ```\n",
    "    \n",
    "3.  Getting it right **also** means not getting the following false rhymes.\n",
    "\n",
    "    ```\n",
    "    bellowed billowed\n",
    "    bellowed furloughed\n",
    "    bellowed vetoed\n",
    "    ```\n",
    "    In brief, the only rhyme for *bellowed* should be *mellowed*.\n",
    "\n",
    "4.  It will be useful to write an auxiliary function `xx`, which is called by `find_rhyme`. The function `xx` inputs a word pronunciation and returns the part of the pronunciation which has to be matched by a rhyme.\n",
    "\n",
    "5.  The output from the examples above does have what might be called a bug.  A word is considered a rhyme of itself.  You do not have to worry about fixing this.\n",
    "\n",
    "6.  In order to solve this,  it will be useful to distinguish between consonants and vowels.  The CMU pronunciation dictionary represents stress information in the form of numbers attached to the vowels. Since only vowels come with stress numbers, the presence of a stress number is a  reliable test for vowelhood:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5bbea8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70 sounds\n",
      "{'AH1', 'K', 'IY0', 'UW1', 'AA2', 'IH0', 'N', 'OY0', 'AY1', 'EH1', 'AO2', 'SH', 'IY2', 'IY1', 'B', 'UH1', 'OW0', 'F', 'OW2', 'DH', 'AW1', 'W', 'EY2', 'ZH', 'EH0', 'ER2', 'IH2', 'ER1', 'AE2', 'P', 'HH', 'AY2', 'EY1', 'AH0', 'EH2', 'M', 'V', 'AE1', 'AO0', 'AA1', 'ER0', 'UW2', 'UH2', 'L', 'NG', 'R', 'T', 'AW2', 'Y', 'CH', 'OY1', 'EY0', 'AY0', 'G', 'OW1', 'AO1', 'TH', 'UH0', 'Z', 'IH1', 'UW', 'S', 'JH', 'OY2', 'AH2', 'AW0', 'UW0', 'AA0', 'AE0', 'D'}\n",
      "vowels\n",
      "{'AH1', 'IY0', 'UW1', 'AA2', 'IH0', 'OY0', 'AY1', 'EH1', 'AO2', 'IY1', 'IY2', 'UH1', 'OW0', 'OW2', 'AW1', 'EY2', 'ER2', 'EH0', 'IH2', 'ER1', 'AE2', 'AY2', 'EY1', 'AH0', 'EH2', 'AE1', 'AO0', 'AA1', 'ER0', 'UW2', 'UH2', 'AW2', 'OY1', 'EY0', 'AY0', 'OW1', 'AO1', 'UH0', 'IH1', 'OY2', 'AH2', 'AW0', 'UW0', 'AA0', 'AE0'}\n",
      "consonants\n",
      "{'K', 'N', 'SH', 'B', 'F', 'DH', 'W', 'ZH', 'P', 'HH', 'M', 'V', 'L', 'NG', 'R', 'CH', 'T', 'Y', 'G', 'TH', 'Z', 'UW', 'S', 'JH', 'D'}\n"
     ]
    }
   ],
   "source": [
    "# Collect all the sound representations used in the dictionary\n",
    "sounds = {s for ps in pron_dict.values() for p in ps for s in p}\n",
    "print(f'There are {len(sounds)} sounds')\n",
    "print(sounds)\n",
    "vowels = {s for s in sounds if s[-1] in '012'}\n",
    "print('vowels')\n",
    "print(vowels)\n",
    "consonants = sounds - vowels\n",
    "print('consonants')\n",
    "print(consonants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff257c",
   "metadata": {},
   "source": [
    "NB:  For nitpickers.  There appears to be a bug because 'UW', which phonetically is the vowel\n",
    "in `food`, shows up among the consonants.  \n",
    "\n",
    "Bottom line:  Ability to bear stress is a very useful operational definition of vowel, arguably the right one for the present problem.  Don't worry about this \"exception\"-al consonant.  There is exactly one occurrence of the symbol `UW` (as opposed to `UW0`, `UW1` and `UW2`) in the entire pronunciation dictionary, and it's a very peculiar case\n",
    "which you can find yourself (by looping through all pronunications of all words), if interested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5320a",
   "metadata": {},
   "source": [
    "### Extra credit problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d73bd",
   "metadata": {},
   "source": [
    "The remarks above lead in a fruitful direction but they do not really solve the problem of rhyme.\n",
    "\n",
    "Here are some examples which are harder to get and require going a little deeper into the\n",
    "linguistics.  Arguably the following are rhymes and merely implementing the ideas above will not\n",
    "find them.\n",
    "\n",
    "```\n",
    "incredible inedible\n",
    "astounding  resounding\n",
    "```\n",
    "\n",
    "To get these right, you need an additional idea, stress.  The key idea is\n",
    "stated in the Wikipedia definition of rhyme:\n",
    "\n",
    "  **A rhyme is a repetition of similar sounds (usually, exactly the same sound) in the final stressed syllables and any following syllables of two or more words.** \n",
    "\n",
    "So there has to be a match on the stressed syllable and all that follows, but that allows \n",
    "mismatches **before** the first stressed syllable, as with *astounding* and *resounding*.\n",
    "The number 1 on a vowel means it receives primary stress, 0 means unstressed, and 2 means\n",
    "secondary stress ( which falls between primary and unstressed in prominence).\n",
    "\n",
    "For extra credit, write the code so that it finds *inedble* and *incredible* as\n",
    "rhymes, as well as *astounding* and *resounding*.  Make sure you keep getting all the\n",
    "previous examples right, including avoiding false rhymes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "27576ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['F', 'AH0', 'S', 'IH2', 'L', 'AH0', 'T', 'EY1', 'SH', 'AH0', 'N']],\n",
       " [['IH0', 'N', 'K', 'R', 'EH1', 'D', 'AH0', 'B', 'AH0', 'L']],\n",
       " [['IH0', 'N', 'EH1', 'D', 'AH0', 'B', 'AH0', 'L']],\n",
       " [['AH0', 'S', 'T', 'AW1', 'N', 'D', 'IH0', 'NG']],\n",
       " [['R', 'IY0', 'S', 'AW1', 'N', 'D', 'IH0', 'NG']])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pron_dict['facilitation'],pron_dict['incredible'],pron_dict['inedible'],\\\n",
    "  pron_dict['astounding'],pron_dict['resounding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3cc542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
