{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91997c1",
   "metadata": {},
   "source": [
    "### Motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b0f2b",
   "metadata": {},
   "source": [
    "The first reason to write a function is to avoid repeating code.\n",
    "\n",
    "The next two code cells contain code snippets that do the same thing to slightly different data.  First, see if you can explain what that thing is.\n",
    "\n",
    "The third code cell abstracts the shared code into a function.  See if you can\n",
    "guess what the function will look like before you get to the third cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495a02c",
   "metadata": {},
   "source": [
    "### snippet #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e13cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# This is the Iliad\n",
    "with urlopen('https://www.gutenberg.org/cache/epub/6130/pg6130.txt') as iliad_page:\n",
    "    iliad_bytes = iliad_page.read()\n",
    "\n",
    "iliad = iliad_bytes.decode('utf-8')\n",
    "iliad_words = iliad.split()\n",
    "iliad_vocab = set(iliad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99673609",
   "metadata": {},
   "source": [
    "### snippet #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294ec4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# This is the odyssey\n",
    "with urlopen('https://www.gutenberg.org/cache/epub/1727/pg1727.txt') as odyssey_page:\n",
    "    odyssey_bytes = odyssey_page.read()\n",
    "    \n",
    "odyssey = odyssey_bytes.decode('utf-8')\n",
    "odyssey_words = odyssey.split()\n",
    "odyssey_vocab = set(odyssey_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e491a",
   "metadata": {},
   "source": [
    "Next try to articulate to the task that both these code snippers perform.  The answer is in a markup (text) cell a few cells down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c8c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc055063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4d20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a95dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2a422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef3981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a72f6622",
   "metadata": {},
   "source": [
    "Description A: **The code snippets extract the vocabulary from a url. If we wanted to write a function that performs that task, the function would take a url string as its input and it would return a set of words.**\n",
    "\n",
    "Note that the page at that url address needs to contain text encoded in UTF-8 in order for\n",
    "the code to give the expected result.  This is why pages on `gutenberg.org` were\n",
    "chosen.\n",
    "\n",
    "There are other possible answers you could have come up with.  You might have said.\n",
    "\n",
    "Description B:  **The code snippets extract the vocabulary from a gutenberg.org book. If we wanted to write a function that performed that task, it could take a gutenberg\n",
    "document number as its input and return a set of words.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f9ed5",
   "metadata": {},
   "source": [
    "Next try to write a function that does what the code snippets do, consistent\n",
    "with the description in Description A.\n",
    "\n",
    "You can start by copying and pasting one of the snippets and indenting it\n",
    "under:\n",
    "\n",
    "```\n",
    "def <function_name> (<parameters>):\n",
    "```\n",
    "\n",
    "but you will have to chose a legal function name, supply the parameters for the function,\n",
    "and change the code snippet.\n",
    "\n",
    "There are two things to think about:\n",
    "\n",
    "1.  What the parameters (input) of the function will be.\n",
    "2.  What the function returns\n",
    "\n",
    "The answer is a few cells down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce5c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a32a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26aa61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648ce05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524eba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c970b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a5216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "252494c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "def extract_vocab_from_text_url(url):\n",
    "    with urlopen(url) as page:\n",
    "        page_bytes = page.read()\n",
    "    page_text = page_bytes.decode('utf-8')\n",
    "    words = page_text.split()\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykVI0zHrOj-o"
   },
   "source": [
    "## Extracting Names:  Try #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbC-0kb5Oj-p"
   },
   "source": [
    "Let's try to extract all proper names from a large body of text.  As a first approximation, use the string method \"is_title\" which tells us, by returning `True` or `False`, whether a string is capitalized or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhSAPQraOj-p",
    "outputId": "a020cbe0-368b-4228-d229-6d16f6195750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('Fred'.istitle())\n",
    "print('tablespoon'.istitle())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NF-WjB-XOj-q"
   },
   "source": [
    "We need to open a file, loop through every line, loop through every word in the line, and collect the ones that are capitalized into some sort of container.  Let's assume we don't want to know how many times a name occurs, just that it occurs.  So we want a container that can't contain duplicates.  To that end we want a `Set`.  As our example text, let's use Jane Austen's *Pride and Prejudice*, downloaded for free from Project Gutenberg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Jane Austen's novel *Pride and Prejudice* from Project Gutenberg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yiPvt7uwOj-q",
    "outputId": "022979fd-280a-48cc-fc3e-eead9e85146d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'“Well,”', 'Mary?', 'Carter,', 'Kitty,--', 'J.', 'Kitty;', 'F.;', 'Lydia,”', 'Pray,', 'Spectator,”', '“As', 'Hill,', 'Lucases', '“Certainly,', '“_My_', 'Happiness', '“Lizzy', '_Monday,', '1.E.1.', 'Michael', 'Lakes.”', '_Chap', 'Words', '“Mrs.', 'Collins.', 'In', '“Hearing', 'Fitzwilliam,', 'There', '“Read', '“Pray', 'Does', 'Convinced', 'Sally', '“_I_', 'Jane.', 'Updated', 'William,', 'Darcy!”', 'Vain', 'Argemone', 'Fixed', 'Sir,', '1.F.5.', 'Jane,', 'God', 'Attention,', 'Other', 'Wednesday.', 'Burney,', 'Charlotte.', '“Ay,', 'Why,', 'Longbourn.”', 'Ring', 'Feb', 'Gardiner;', 'Must', 'There,', 'Younger', 'Adieu', 'Catherine,)', 'Two', 'Bennet,', '“Upon', 'However', 'Scott', 'Take', 'Teasing,', 'Saturday:', 'Wickham!', '“Implacable', '“No--I', '“Their', 'Fielding,', 'This', 'For,', 'Bingley:', 'Hursts', 'Release', 'Lodge.', 'Some', '“Why', 'Younge', 'Five', 'Breakfast', 'No', 'Bingley,”', '“Was', 'Sections', 'But', 'Fairfax', 'Whitman', 'Lakes.', '“What', 'Great', 'Monday,', 'Party', 'Since', 'Foundation.\"', 'Rosings', '“Is', 'Rendered', 'Catherine,', '“But', 'Allow', 'Addison', 'Gutenberg\"', '“Ten', 'Lydia;', 'Park,', 'Oh', 'But,”', '“Something', 'Long,”', '“By', 'Soon', 'Abbey,', 'Gretna', 'Fanny', 'Colonel', '“Both,”', '“May', '“Oh!', 'Good', 'England;', 'Don', '“Wickham,', '\"Information', 'Esq.,', 'British', 'Another', 'First', '1.F.1.', '“Tell', '_I', 'Long.', '_I_', 'Edward', 'Perhaps,', 'Respect,', '“Though', 'Rosings,', 'Wollstonecraft', 'Christmas.', 'Fitzwilliam', 'Newcastle.', '“Blame', 'After', '“One', 'Whenever', 'Dear,', 'Rosings.”', 'Upon', 'Meryton.”', 'Bountiful)', 'Tuesday.', 'Austen', 'Scarborough', 'Has', '_Reading', '“Certainly,”', 'Bourgh.”', 'Forsters', '[Illustration:', 'Christmas.”', '“Nay,', 'Meryton?”', '“No,”', 'Foundation,', 'Hertfordshire.', 'Volunteers', 'Having', '“Dining', 'Conversation', 'Hertfordshire', 'Reynolds,', 'Women', 'King,', 'Under', 'Saturday?”', 'Conjectures', 'Impossible!', 'Others', 'Indeed', 'Allowing', 'Bourgh,”', 'States', '“Pray,', '“My', 'Elizabeth._', '_You_', 'Lambton,', 'F.', 'Jane:', '“Protested', 'London,', 'Bingleys.', 'Irish', 'Against', 'London!', 'Lucas', '1.E.7.', 'Unfortunately', '“Very,', 'Nay,', 'Philips', 'Royalty', '“Or,', 'Consoled', 'Commerce,', 'Charlotte,', 'Tuesday,', 'Now', '“Hate', '“_That_', 'Internal', '“When', 'Leigh', 'Though', 'House.', 'Rosings?”', 'Scotland', 'V.', 'Lane,', '\\ufeffThe', 'Edmund', 'Kenilworth,', 'Gutenberg:', '“How', '“Very', '“So', 'Beatrix', 'Its', 'Distributed', 'Sermons.”', '1.E.4.', 'Poor,', 'Choose', '“At', 'Nearly', '“Unable', 'Scarcely', 'Every', 'Derbyshire.', '(I', '“Lizzy,', 'Longbourn', 'Long', '_Boulanger_----”', 'H.T', 'March,”', 'Lakes', 'Darcy_,', 'Cheerful', '“Let', 'Dawson', 'Newcastle', '“Jane,', '“Yours', 'Charles.”', '“With', 'He', 'One', '“Your', 'September', '“_Her_', 'Prejudice;', '“Go', 'Parsonage,', 'Terms', 'Most', 'Rosings.', 'Pursuing', '“She', '_Still,', 'Thackeray,', 'Ever', 'Forster.', 'Coleridge', 'At', 'Illustrations.]', 'Frontispiece', 'Collins,”', 'I.]', 'Service.', 'Darcy,', 'Nobody', '“Nothing', '“He', 'Pemberley.', 'Honourable', 'Without', 'Right', 'Denny', '“There', 'Charlotte,”', 'Heaven', 'Haggerston', '1.A.', 'Accept', 'Have', 'Saturday.”', 'However,', 'Accordingly,', 'Did', 'Sarah,', 'Matlock', 'Rushworth,', 'Italian', '“Dear', '1.E.8', '“Insolent', 'Caroline.', 'Find', 'Generous,', '“Compared', 'Family', 'Christian', 'Presuming,', 'Eastbourne,', '_Walt', 'Gardiner', 'My', 'Gracechurch', 'Hugh', 'Hope', 'Norris', 'Lucas;', '“Poor', 'Scotch', 'Meryton!”', '_In', 'Collinses', 'Elizabeth!', 'Bennet:', '“Colonel', 'What,', 'Never,', 'Something,', 'F.,', 'London;', '“Now,', 'Kent?”', '“Caroline', 'Cross', 'North', '“Yes,', 'Console', 'Bath;', 'Now,', 'Change', 'Jane?”', 'January', 'Thursday', 'Pride', 'Philipses,', 'May', 'Come', '_And,', 'Mrs.', 'Wickham,', 'Engaged', 'Bingleys’', 'Brighton!”', 'So', 'Theatre', 'Archbishop', 'Team', 'Lucas,”', 'Netherfield.”', '“Had', 'King?', 'And,', '“Much', 'Scotland.', 'Preface', '_She_', '“You', 'Society,', '“Good', 'Spectator,', 'Goulding', 'Elizabeth:--', 'Lizzy.”', 'From', 'Bingley),', 'Interested', '“‘When', 'As', '“Come,', 'Caroline', 'Thomson', 'Catherine,”', 'Persuaded', 'November,', 'Nothing,', 'Thursday,', '1.E.3.', 'Into', 'Wickham;', 'Carr', 'Yet', 'Lizzy,”', '“Except,”', 'Caroline,', 'Astonishment,', '“You,', '“Already', 'Lizzy!', 'Can', 'Wickham?”', 'Also', 'Bennet.', 'Eliza,', 'Darcy,--', 'Saturday', 'Fitzwilliam;', 'What', 'Wickham”', 'Oh,', '“True;', 'If', 'Derbyshire;', 'Maria.', 'Bennet!”', '“Yet', 'City,', 'Gardiner,', 'Redistribution', 'Nonsense,', '“Mr.', 'Many', 'Charles', 'Anne', '“Sir,', '_To', 'Elizabeth', 'Allen.', 'Widely', 'When,', '\"Project', 'Stone.', 'England,', '“Take', 'Oh!', 'Pratt', 'Diana', 'Contributions', 'Lodge,', '“Perhaps', '“Come', 'Hunsford', '“Complied', '_Hugh', '“Nearly', 'Everything', 'Spectators', 'Why', '“Pardon', 'End', 'Lucases,', 'The', 'Wednesday;', '“Yours,', 'Think', 'Harriet', 'Eliza,”', 'Bennet?', 'Title:', 'Collinses’', 'Cambridge;', 'Thackeray', 'Pemberley?”', '\"Right', 'Recovering', 'Risk', 'Indeed,', 'Daughters', '“Indeed,”', 'Meryton?', 'House,', '_Darcy', 'She', 'Louisa.', '_This', 'Then,', 'List', 'Netherfield.', 'Yours', 'Memling', 'Balls', 'Between', 'Reynolds’', '“Nonsense,', 'Collins!”', 'About', 'Lucases’', 'Excellent', 'Collins', 'Observing', '“Yours,”', 'I', '“Such', 'Jane;', 'Darcy?', 'Lodge', 'Salt', 'Tuesday;', 'London', 'And', 'Language:', '“Neglect!', 'They', 'Michaelmas;', '“La!”', '1.C.', 'Lizzy?”', 'Longbourn,', 'April,', 'Eliza', 'May,', 'Stop', 'Neither', '“Do', 'Robinson:', 'Forster', 'Chamberlayne', 'Emma,', 'Hill', 'Use', 'Bennet;', '“That', '“Nothing,', '_But', '“Really,', 'Netherfield', '“No,', 'Mr.', 'Forster;', 'Besides,', '“For', '“Unhappy', 'I.”', 'Bromley,', 'Nor', 'Pemberley.”', 'Smith', 'Very', 'Darcy;', 'Lizzy,', '“Indeed!”', 'Spectator', '“After', 'Collins!', '“Oh,”', '1.D.', '‘I', 'Stupid', 'Wholly', '“Will', 'Clapham,', '“Speak', '“Undoubtedly,”', 'Elizabeth;', 'Meryton,', 'Only', '[Most', 'Church', 'Annesley,', 'Frenchman,', 'London?”', 'Emma.', 'Pratt,', '“Certainly', 'Denny,', 'Jane,”', '“Walked', 'Detection', 'Regulars.', 'All', 'Lewis', 'Lydia!', 'Who', 'Author:', '1.F.', '1.E.8.', 'Towards', 'Jenkinson', 'This,', 'June,', 'Anxiety', 'Heaven!', 'Sunday', '“’Tis', 'Clapham.', 'Where', 'Wherever', '“Perfectly', 'Special', 'X.', 'Brighton', 'January.', 'Little', 'Maria,', 'Hurst.”', '“Shall', '_My_', 'Parsonage', '“What,', 'Austenians', 'Do', 'Town”', 'Dovedale,', '1.E.5.', 'Assistance', '“Never,', 'Human', 'Lord', '“Are', '“In', '1.F.3.', 'Mary', 'Regulars;', '“Not', 'Epsom.', '“Have', 'General', 'Derbyshire,', 'Eliza?', 'Whilst', '‘Mr.', 'Niece,', '“Say', 'Sense', 'Lizzie,', 'Birmingham,', 'Had', 'Everything,', 'Produced', 'Kitty!', 'February', 'Meryton;', 'Mission', 'Thorpe,', 'States.', 'Gardiner.', 'Additional', '1.C', 'Although', 'Catherine', '“Miss', 'Brighton.', 'Perhaps', 'Westerham,', '_Their_', 'No,', 'That', 'Refund\"', 'Jenkinson,', 'Seriously,', 'Hertfordshire.”', 'Chuck', 'Lucas.', 'Is', 'Wretched,', 'Come,', 'Contact', 'Letters', 'Eliza.”', '“Another', 'Netherfield,”', 'Among', 'Internet', 'Oakham', '“Our', 'For', 'Street', 'Within', 'West,', 'Tailpiece', 'Would', '“Delighted', 'George', 'Younge,', 'Bennet,’', '_They_', 'Bingleys', '_He_', 'There--I', 'During', 'Juanish', '“Yes:', '“Money!', 'Newcastle,', 'Creating', '“Go,', 'Supposing', 'Professor', '“Haye', 'King', 'Yours,', 'These', '\"Defects,\"', 'August', 'Green,', 'Mamma', 'London,”', '“Accompanied', 'Much', 'Stay,', '“Now,”', 'Forster,”', '_Mr.', 'Easter', 'Replacement', 'Unless', 'Bennet”', '“They', 'I,”', 'Lakes;', 'Netherfield;', '“Certainly.', '“But,', '“Far', '“Laugh', '“No', 'Lambton!', '“Well,', 'Society', 'Consider', 'Poor', 'Collinses,', '“But,”', 'July,', 'Forster?', 'Blenheim,', 'Adieu!', 'Fielding;', 'Tell', 'Street,', 'November', 'Grosvenor', 'Kitty.', 'Lydia:', 'Darcy.', 'De', 'By', 'Lake', 'If,', 'Tease', 'Meryton,”', '“Her', 'Swiftian', '‘Courier,’', 'Maria', 'Longbourn;', '“We', 'To', 'Cheapside,”', 'Excuse', 'A', 'Chawton', '“His', 'Meissonier', 'Jane?', '“If', 'Elizabeth.”', '“Mary', 'Cosway', 'Lady,', '“Lydia', 'Darcy?”', 'Imprudence', 'Carter', 'Jones', 'Eager', 'Lambton', 'Here', '“Excuse', 'Date:', '“Unless', 'I.', '“E.', 'Gutenberg', 'Scotland.”', 'Fatigued', 'Next', '_The', '’Tis', 'Darcy', 'June', 'Della', 'Henry', 'Miss', '“Who', '“O', 'Whatever', 'Darcy,”', 'Webbs', '“Just', '“To', 'Could', 'Well,', 'Thus,', 'Even', 'Steady', 'Charlotte!', 'Lavington,', 'L.', '“Tenderly', 'Project', 'German', '1.F.4.', 'Anxious', 'Elizabeth,', 'Sensibility', 'Gardiners,', 'April', 'Woods', 'Ladyship,', 'Hunsford.”', 'U.S.', 'First,', 'Foundation.', 'Lord!', '1.E.6.', 'S.', 'Things', 'Georgiana', 'Bingley!', 'Parsonage.', 'Epsom,', 'Darcy!', 'Make', 'Wickham?', '“A', 'Pope', 'Put', 'Let', 'Barnet', 'Hertfordshire:', '“I', 'Darcy.”', '“Dawson”', 'Georgiana,', '1.F.6.', '“Lady', 'Philistinism,', '“Jane', 'Lydia,', 'Lucases.', 'Parsonage;', '“Probably', '“Charles', 'Absence', 'Hart', 'Lydia?”', 'Be', 'Hunsford.', '“Ah,”', 'Pen', '‘Bingley,', 'Elizabeth.', 'Illustrations', 'Church”', 'Send', '“Would', '1.F.2.', '_That_', 'Before', 'Vanilla', 'Putting', '\"Plain', 'Catherine.', '(Lady', '“Yes,”', 'Caroline,”', 'Regard', 'Bingley.', 'Yours,”', 'Pemberley', 'Northanger', 'Painful', 'England.', '“It', 'Howsoever', 'Kitty', 'Remember', 'Thus', '“‘After', '“Neither', 'Forgive', 'Through', 'Elizabeth,”', 'Catherine;', '“Offended', 'Darcy:', '[Illustration]', 'Not', 'Are', 'P.', 'Harriet,', 'Both', 'Jane!', 'Hill?', '“Lizzy,”', 'It', 'Street.', 'York,', 'Thomson_', 'People', 'Maupassant,', 'Smiles', '“Whenever', '‘Times’', 'Away', 'Bourgh,', 'Goldwin', 'Elizabeth,----', 'United', 'War', 'Brighton,', 'Charlotte', '“Louisa,', '“Eliza', '“What!', 'Charles,', 'But,', '1.B.', '“Lord,', 'November;', 'Thank', '“Bingley.”', 'Brighton!', '“Beyond', '(This', 'Netherfield?”', 'October_.', 'Churchill', 'Conceal', '“Be', 'Forster,', 'Anne,', 'Give', '[_Copyright', '“Can', 'Girls,', 'Mississippi', '‘Had', '“Believe', 'Netherfield,', 'Surprise', '“Elizabeth,', 'Mary,', 'Lizzy.', '“Sure', 'Occupied', '“Ah,', '“Hunsford,', 'Section', 'Bennet', '“Care', 'George,', 'Louisa,”', 'Lydia.”', '“Did', '“Meeting', 'Hertfordshire,', 'His', 'Eliza!', '‘Lady', 'Foundation', 'Lodge;', 'Elizabeth:', '“Which', 'Well!', '“The', 'Shapely,', 'Fitzwilliam.', 'Wednesday', 'Greif', 'French', 'Pray', 'Norris,', 'Bingley', 'Vanity', '_It', 'Kitty,”', '“Indeed,', 'States,', '“New', 'Here,', 'Hunsford,', 'Derbyshire', 'Swift,', 'Richard?', 'Cruscans', 'Bingley.”', 'Allen.]]', 'Woman”', 'London.”', 'Lambton;', 'Bingley?”', 'Thursday.', '“_Whenever', 'Four', 'Netherfield?', 'Importance', '“Impossible,', '“Most', '“These', 'Meryton.', 'Pemberley;', 'Bingley,--', 'Till', 'Full', 'Kent,', '“Has', 'Saturday.', 'Please', 'Anything', '1.E.7', 'London.', 'Gardiners', 'Dearest', '‘My', 'Such', '1.E.1', 'Vernon,', 'Tilney,', 'Saintsbury', '“Next', '_Too', 'Dashwood.', 'B.,', 'Any', 'Philips,', 'Copyright', '“Cheerful', 'Of', 'Apothecary', '“Obstinate,', 'Online', '_His_', 'Kympton?”', 'Collins;', 'When', 'Allen._]]', 'Gardiner?', 'Captain', '“Sometimes.', 'Christian,', 'With', 'Court', '“Now', 'Bingley;', '1.F.3,', 'Rosings;', 'Chapter', 'Lydia', 'Charing', 'Street.”', 'Email', 'How', '“All!', 'Promise', 'Brighton;', 'Despite', 'Saturday,', 'Kent', 'Frank', '“I,', 'Spanish', 'Friday,', 'Lucas,', 'Hatfield,', '“Gracechurch', 'King.', '“Exceedingly', 'Christmas', 'Were', '“On', 'Epsom', '“Heaven', 'International', 'No;', 'License', 'Never', '“Of', 'Nicholls', '“An', 'Certain', 'Ramsgate;', '“True,”', '‘Oh,', '“Merely', 'Affectation', 'House', '“While', 'Philips.', 'Kitty?”', 'Was', 'Young', '“All', 'Smollett,', 'Gutenberg\"),', '“Does', 'Bell,', 'Not,', 'Revenue', 'Mount,', 'Day', '“Thank', '“Exceed', 'Then', 'Argemone;', 'Bates,', 'Gouldings', 'Venus.', 'Three', 'Heading', 'Information', 'Thoughtlessness,', 'Grant.', '“From', '“Dearest', 'Once', 'Almost', 'Resignation', '“If,', 'See', 'Lydia.', 'Compliance', '“Since', '“John', '(By', '“Only', 'Ladyship.', 'Your', 'Bennet.”', '“Conjecturing', 'Wilfully', 'Eltons,', '“Then', 'Sir', 'Monday:', '“Because', 'Post', 'Lizzy!”', 'Lucas.”', 'Powerful', 'Janites,', 'Lizzy;', 'Amazed', 'June.', '“Whatever', '1.E.2.', '1.E', 'Lydia!”', 'Wickham', 'Lakes,', 'Nothing', 'Bakewell,', 'Say', 'Scotland:', '_Mrs.', 'Lizzy', 'Each', 'Britain', '“About', 'Bennet,”', 'Instead', 'Happy', 'Stoke,', 'Fielding', '“Kitty', 'Longbourn.', 'Elizabeth,--', '“Without', 'English', 'Collins,', 'Esmond,', 'On', 'Persuasion,', 'Mr,', '“Pride,”', 'Austen,', '“And', 'God!', '_We_', 'Louisa', 'William,--', '“Nor', 'Office,', 'Far', 'March', 'Pleased', 'Again', 'Dedication', 'M.', '“Oh,', 'Scotland,', 'Their', '“Surely', 'Everybody', '“_You_', '“This', '“None', 'Crawford', 'Stairs”', 'Yet,', 'Foundation\"', 'Rosings’', 'Donations', 'Brighton?”', 'Bennet!', 'Literary', 'Wednesday,', 'Amongst', 'We', '“Could', '“Piling', '“Why,', '“Write', 'Her', 'Kent.', 'Morris', '“Undoubtedly.', 'He,', 'Imprudent', 'Barbara.', 'Imagine', 'Bourgh?', 'Our', 'Ruskin', 'Darcy.)', 'Sunday,', 'Unwilling', '“Oh', 'Charlotte;', 'Defect', '‘This', '“Design?', 'Fitzwilliam?', 'Bennet?”', 'Calling', 'Road.', 'You', '“Then,”', 'I,', 'Lady', '_Her_', 'William', 'Michaelmas,', 'Bennet.’--“My', 'Hill.', '‘Yes,’', '“Removed!”', 'Mentor', 'Lucas)', 'Sometimes', 'Vain,', 'Purvis', 'Chatsworth,', 'Sunday;', 'Lucases’,', 'Barbara', 'England', 'Mansfield', 'Thoughtless', '1.E.9.', 'Ashworth', '[Copyright', 'Pardon', 'Peak.', 'Bennets', 'Redistributing', 'Last', 'Hurst', 'Meryton', 'Easter,', 'Collins.”', '“Covering', 'An', '‘_She_', '_Your_', 'License.', '“Some', '“Engaged', 'Prejudice', 'Those', 'Harringtons', 'Follies', 'Ramsgate.”', 'While', '“Yes;', 'O', 'Will', '‘Ah!', 'Robinson.”', 'Hunsford;', 'W.', '“Hunsford,”', 'Bourgh', 'Comyns', '“Then,', '“No;', '“Wickham', 'Archive', 'Lambton?”', '1.E.', '“La!', 'Philipses', 'Annesley', 'Hertfordshire;', 'Maria;', 'Dovedale', 'Shall', 'Liverpool;', '“Sir', 'Kitty,', 'Lambton?', 'Derbyshire.”', 'Ramsgate', '‘Lately,', '“Mamma,”', '“Perhaps,”', 'St.', 'Dear', 'Whether', '“Were', '“M.', 'Monday', 'Ladyship', 'Compliments', 'Swift', '“If!', 'Intimate', 'Brother,', 'Hurst,', 'Except', 'Bingley,', 'Lucases;', 'Matlock,', 'Reflection', '“True.', 'Tuesday', '“Indeed', 'Warwick,', 'Proofreading', 'Twice', 'Letters._', 'Pemberley,', 'Nichols', 'Ten', 'Reynolds', '_Sept.', 'Jane', 'Yes,', 'Mary,”', 'Catherine,’', '“Remember,', 'Arguments', 'Cheapside.”', 'John', 'More', 'Bourgh.', '_For', '“Depend', 'Park', '“Nay,”', '“Two', 'Emma', 'Unfeeling,', 'Archive)', '“Where', 'Hear', '“So,', 'Wickham.', 'Forster?”', 'Mount'}\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"\n",
    "with urllib.request.urlopen(url) as req:\n",
    "    # Web text gets downloaded as raw bytes.  Need an encoding to make it a string\n",
    "    text = req.read().decode(\"utf-8\")\n",
    "\n",
    "cap_words = set()\n",
    "## Loop through each line and in each line loop\n",
    "## through each word\n",
    "for line in text.splitlines():\n",
    "     # Now split into words\n",
    "     line_list = line.split()\n",
    "     for word in line_list:\n",
    "         if word.istitle():\n",
    "            cap_words.add(word)\n",
    "print(cap_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQMGm2xAOj-q"
   },
   "source": [
    "Now let's for the moment ignore the flaws in what we've done (Many, if not most, of the things collected are not proper names).  Suppose we want to do the same thing to another Jane Austen novel, *Emma*. Here's code for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jI4TkjTWOj-r",
    "outputId": "762ed985-9502-4dda-9b0c-aaba6e28fbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'“Well,”', '“Ill,', 'Wakefield.', '“Me!”', 'Richardson,', '“Nonsense!', 'Highbury.', 'Walk', 'Kings', '“Emma,”', 'Philip', 'Happily,', '‘No’', 'Pray,', 'Randalls.—But', '“As', 'Gratifying,', 'Richard?—I', 'Hill,', '“Certainly,', '“_My_', 'Square,', '1.E.1.', 'Welch', '‘But,’', 'Michael', 'Nature', '“Mrs.', 'In', 'There', '“Read', 'Serle', '“Pray', 'Perry?—Has', 'John,', 'Does', 'Men', '“Emma!”', 'Donwell?—He', '“_I_', 'Jane.', 'Taylor,', 'Updated', 'William,', 'Picture,', 'Sir,', '1.F.5.', 'Jane,', 'God', 'Other', 'Small', '‘Not', '“—Mrs.', '“Very.”', 'Dixon.', 'Must', 'There,', 'Weston!—Astonished', '“Low,', 'Two', '“‘Smallridge!’—What', '“Upon', 'Maple', 'Take', 'Bateses,', 'Goddard.', 'Barnes,', 'Hall;', 'Perrys,', 'Windsor?”', 'This', 'Perry,”', 'Release', 'Some', 'Sucklings,', 'Knightley!—I', '“Why', 'Five', 'Braithwaites,', 'Frank.', '“Till', 'Eltons?—Here', 'No', '“Better', '“Was', 'Bella,', 'Sections', 'But', '“No—Mrs.', 'Fairfax', 'August,', '“What', 'Bragge,', 'Since', 'Adelaide', 'Quite', '“Is', 'Campbell,', 'Churchills.', 'Perry.”', 'Wallis', 'Enscombe,”', '“But', 'Pass', 'Alderneys,', '‘No,’', 'Park,', 'Larkins;', 'Oh', '“Something', 'Martin.”', '“By', 'Soon', '_May_', 'Isabella;', 'Abbey,', '‘How', 'Colonel', '“May', '“Oh!', 'Bates', 'Contents', 'Good', 'Bates,)', 'Common', 'Elton?—That', 'Invite', 'Woodhouse!”', 'Christmas,', 'Knightley.—It', 'Dixon)', 'Another', '1.F.1.', 'Dixon.”', '“Elegant,', '_I_', 'Think,', '“‘Mr.', 'Harriet,”', '“Harriet,', 'Christmas.', 'Ireland;', 'After', '“One', 'Whenever', 'Dear,', 'Upon', 'Bless', 'James', 'Tuesday.', 'Nash', 'Coles.—Upon', 'Austen', '“Dreadful!—Exactly', 'Bates.”', 'Has', 'Madame', 'Yorkshire?”', 'Worse', '“Certainly,”', 'Abbots', 'Bought', 'No!', '‘If', 'Emma.—You', 'Highbury!', 'March?', '“Exactly', 'Weston?—Judge', 'Donwell;', '“News!', '“Nay,', 'November.', '“No,”', 'Grove,', 'Foundation,', '‘Oh!’', '“Should', 'George.', 'Volunteers', 'Harriet,)', 'Hitherto', 'Having', 'Ambition,', 'Fairfax!—Well', 'Richmond,', 'Harry', 'Bates.', 'I?”', 'Soup', 'Under', '“Great', 'Fairfax.—And', 'W.”', 'Woodhouse),', 'Churchills.”', 'E.,’', 'Though,', 'Indeed', 'Hartfield!', 'States', '“Pray,', 'Hartfield:', 'Fortunately', '“My', 'February.', '_You_', 'F.', 'Smith.', 'Shortly', 'Harriet!”—Those', 'Intimacy', 'London,', 'Irish', 'Yes.', 'Westons', '(Miss', 'December.', 'Something', '1.E.7.', 'Nay,', 'E.', 'Royalty', 'Knightleys', 'Cox;', '_What_', 'Tuesday,', 'Now', '“Aye,', 'Internal', '“When', 'Though', 'Windsor;', 'V.', 'Abbey;', 'Enscombe', 'Knightley;', 'Martin', 'Lane,', 'Rev.', 'Bates?”', '—“The', '‘No?’”', 'Dixons', 'Ford.', 'Once,', 'Read', 'Gutenberg:', 'Fairfax?', '“How', 'Gutenberg”),', '“Very', '“So', 'Its', 'Knightley.—Every', '1.E.4.', 'Quick', 'Might', '“At', 'Madeira', 'Farm;', 'Nearly', 'Every', 'Waiving', 'Forest', '(I', 'Emma.—Offended,', 'Long', 'Genlis’', 'Lane.”', 'Dorking', 'That,', '(Emma', '“_She_', '“Those', '“Let', 'Harriet.—They', 'Campbells.”', '“Jane,', '“Yours', '“With', 'He', 'Nash,', 'One', '“Your', 'Cannot', '(Mr.', 'Like', 'September', 'Ireland.', '“Three', 'Emma?”', 'Churchill,”', 'Knightley.—Neither', 'Terms', 'Most', '“Whom', 'Certainly', 'Campbells,”', 'Perry;', '“She', 'Jane.)', 'Ever', 'Dining', 'Emma.—“I', 'Square.', 'At', '“Emma,', 'Otway;', 'Ceremonies’', 'Service.', 'Knightley.—This', 'Nobody', 'Abbey-Mill', 'Highbury;—Mr.', '“Nothing', 'End.”', '“Beg', '“He', 'Escape,', 'Enscombe;', 'Without', 'Coxe—Oh!', 'Hawkins,—I', 'Ladies', 'Bath,', 'Sucklings’', 'God!—Mr.', 'Fairfax;', '“York', 'Too', '“There', 'Bates?', 'Selina,', 'Heaven', 'Contrary', '1.A.', 'Have', 'Saturday.”', 'However,', '“Emma', 'Accordingly,', 'Did', '‘Woman,', '_Mrs_.', 'Italian', '“Dear', '1.E.8', 'Emma—”', 'Woodhouse.—Dear', 'Enscombe.', 'Weymouth;', 'Find', 'Weston?', 'Behold', 'Sixteen', 'Tea', 'Christian', '“Having', 'Short', 'Campbell.', 'My', 'Donwell?—Oh!', 'Hartfield,”', 'Enscombe,', 'Altogether', 'Elton.”', '“Poor', 'They,', 'Coxes', 'Broadwood', 'Thy', '_Woodhouse_', '“Colonel', 'Weston,”', '(Harriet,', 'Place,', 'F.,', 'London;', '‘Can', 'Eltons.', '“Now,', 'Goddard,', 'Randalls!', 'North', 'Hawkins', 'Crown,', '“Yes,', 'Larkins,”', 'Bath;', 'English.', 'Now,', 'Fairfax.—She', 'Emma;', 'Elton!—The', 'Mistresses', 'Fairfax?”', 'Serious', 'K.—But', 'Presently', 'May', 'Fairfax!”', 'Come', '_Now_,', '“Women', '_There_,', 'Mrs.', 'Knightley.—“Emma,', 'So', 'Hughes', '“Imprudent,', 'Seldom,', '“Ungrateful!—What', 'Campbells,', '“Had', 'And,', '“Ah!—Indeed', 'Taylor!', '“Much', '_She_', '“You', 'Beyond', 'Elton!—‘Jane', '“Good', 'Larkins.', 'Voices', '‘Bless', 'Real,', 'Hartfield.”', 'N.', 'Ford?', 'From', 'As', '“Come,', 'Ford.”', 'Cole', 'Look!', 'November,', 'Nothing,', 'Ireland', '1.E.3.', 'Bath?—Indeed', '“Well!', 'Campbells.—The', '“Almost', 'Emma!”', 'Emma!—Emma', '“Ever', 'Kingston', 'Yet', '‘Well,', '_Dixon_.', '“You,', 'Bath.', 'Knightley.”', 'French,', 'Kingston.”', 'Can', 'Donwell,)', 'Smith!—I', '“Harriet', 'Coles', 'Ireland.”', 'Martin!”', 'Living', '‘Even', 'Master', 'Just', 'Dr.', 'Saturday', '‘Full', 'What', 'Oh,', 'Gutenberg™', 'Isabella,', 'Observe', 'Wingfield,', 'Either', '“Quite', 'If', 'Vicarage.—There,', 'Frank;', 'City,', 'Churchill;', '_Now_', 'Redistribution', '“Myself', '“Mr.', 'Many', 'Brunswick', 'Anne', 'Charming', 'Wrapt', 'Absolute', 'Elizabeth', 'Happily', 'Square', 'Hannah', 'England,', '“There,', 'Perry.', '“Take', 'Dixon!', 'Day,', 'Oh!', 'Isabella”', 'Windsor.—Oh!', 'Weymouth.', 'Contributions', 'Vanity,', '“Perhaps', '“Come', 'Wiltshire,', 'Weston;', 'Often', '“Might', '“Think', 'Martins', 'Such,', 'Why', 'End', 'Bristol—Maple', 'Bragge;', 'Papa,', 'Churchills', 'The', 'Knightley!—How', 'Hill;', 'Respect', 'Stokes', 'Harriet', 'Think', '_May_,', 'Cox', 'Title:', 'English,', '“Cannot', 'Comtesse', 'Late', 'Indeed,', 'Gilberts,', 'Ah!', 'Windsor', 'She', 'Bates,”', 'Apologies', 'Then,', 'Disingenuousness', 'Woodhouse?—Till', '“No—I', '“Perfectly,', 'Between', 'December,', 'Cole?', 'Church!', 'Frank.—Go', '“Nonsense,', 'Woodhouse:', 'About', 'Excellent', 'Sighs', 'Sometimes,', 'I', 'Harriet!—It', 'Woodhouses', '“Such', '“Henry', 'Jane;', 'Salt', 'Sucklings.', 'London', 'And', 'Language:', 'Misses', 'They', 'Nobody,', 'Fourteen', 'October', 'Vigorous,', 'Knightley!—Mr.', '1.C.', 'Hazle', 'April,', 'Elton.—She', 'Besides', 'Hartfield', '“_He_', 'Woodhouse)', 'Neither', 'Otway', '“Do', 'Frank?', 'Emma,', 'E.,', 'Suckling,', 'Hill', 'Fairfax.’', 'Depend', 'Keep', 'Use', '“Rather', 'Plain', 'Swisserland,', '“That', '“No,', 'Hawkins!—Good', 'Mr.', 'Madam,’', '“Here,”', 'Fairfax?—I', 'Isabella:', 'Besides,', '“For', 'Harriet.”', 'Alas!', 'Grandmama', 'Romance', 'Angry', 'C.', '_Chaperon_', 'Martin!', 'Grove.', 'Hodges', 'Smith', 'Very', 'Otway,', 'Philippics', '“Indeed!”', 'Henry;', '“Four', 'Knightley—“I', 'Bristol', 'Dinner', 'Mill', '1.D.', '‘I', 'Extracts,', '“Will', 'Perry,', 'Harriet:', 'Churchills,', 'Dublin,', 'Only', 'Hawkins.”', 'What!', 'Highbury;', 'Emma.', 'True,', 'Cobham,', '“What!”', 'Hawkins,', 'Hetty,', 'Woodhouse.—I', 'Tan”', 'All', 'Weston,', 'Abbey.”', 'Who', 'Author:', '_Perfection_', '1.F.', '“Information', '1.E.8.', 'Towards', '“Oh!”', 'This,', 'June,', 'Heaven!', 'Emma,”', 'Sunday', 'Baronne', '“’Tis', 'Where', '‘But', 'Special', 'X.', 'Fairfax.”', 'Forest,', 'Augusta,', 'September:', 'Dixon.—Emma', 'Little', 'January.', 'Bates?—I', 'Much,', 'Richmond', '“Shall', '“Impropriety!', 'Do', 'Randalls.”', '1.E.5.', 'Actually', 'Clayton', '“Never,', 'Goddard?', 'Hawkins.', 'Extracts.', 'Considering', 'Human', 'Elton,”', 'Lord', 'Receive', '“Are', 'Churchill?—Ah!', 'Tom', '“In', '‘George,’', '1.F.3.', 'Bateses', 'Oxford', '‘And', 'Martins.', 'Richmond.”', '“Not', 'Highbury,', '‘No,', 'Patty,', '“Have', 'End,', 'Hetty', 'General', 'Emma!', 'Campbells', 'High', '“Part', 'Martin,”', 'Weston?—To', 'Harriet!”', '‘Mr.', '“Say', 'Saunders', 'Kingston?’', 'Birmingham,', 'Had', 'Ford', 'Otways.—Not', 'John.—He', 'Inn,', 'Later', 'Cromer,', '‘Three', 'February', 'Woodhouse—I', 'Mission', 'Jane,—There', 'Windsor,', 'States.', 'Hawkins—”', 'Wingfield', 'Fairfax.—', '_Adair_', 'Gone', 'Additional', '1.C', 'Forcing', 'Although', 'Catherine', 'Langham,', '“A.', '“Miss', 'Perhaps', '“Frank,”', 'Dancing', '“Come,”', 'No,', '“Must', 'That', 'Goddard;', 'Encouragement', 'Fairfax,”', 'Jane?—Do', 'Is', 'Wright', 'Come,', 'Donwell.', 'Contact', 'True', 'Letters', 'February.”', 'Randalls.—“Well,', '‘Miss', 'Warmth', 'Farm,', '“Another', '“Handsome!', 'Weston_.]', '“Our', 'For', 'James;', 'Within', 'West,', 'Would', 'La', 'George', 'Day;', 'Churchill.', 'Knightleys,', '“Project', 'Woodhouse.”', 'Perrys', 'Richmond;', '“Ah!”', '_He_', 'Churchill—‘Every', 'Woodhouse,', 'During', 'Or,', '“Yes:', 'Tupmans,', 'Creating', 'Professor', 'Fortune', 'Woodhouse?—I', 'Fairfax!', '“Leave', 'According', 'These', 'Weymouth', 'Heavens!', 'August', 'Emma.—“You', '“Here', 'Mine,', 'John.', '‘No;’', 'Much', 'Eltons;', 'Jane!”—And', 'Heavens!—What', '“Now,”', '‘It', 'I?—Yes,', 'South', 'September,', 'Replacement', 'Unless', 'Campbell', '“They', 'I,”', '‘George’', '“Certainly.', '“But,', 'Skilful', '“No', 'Smith!—Such', '“Well,', '_Miss_', 'Delighted', 'Donwell,', 'Consider', 'Poor', 'Weymouth.”', 'Caroline.—Such', 'July,', 'West', 'Tell', 'Martin.”—She', 'Arthur!—How', 'November', '‘Dearer,', 'Elton.', 'Or', '“Service!', 'Elegant', 'By', 'Lake', 'Still,', 'Square;', '“Isabella', 'Harriet.—“Do', 'Go,', 'England.”', '“Her', 'Instances', '“We', 'To', 'Grove!', 'Kingston.', 'A', 'Churchill,', 'Ours', '“Ah!', '“His', '“Increase!”', 'Abbey!—Oh!', '_Robin_', '“If', 'October,', 'Surprizes', 'Wickedness', 'Cole,', 'Witness', 'Pembroke,', 'Here', '“Excuse', '‘Well,’', 'Taylor.—But', '“Happy', 'Harriet!', 'Chuse', 'I.', 'Gutenberg', '“Me,', 'Cox,', 'Lords', 'I!”—But', 'Compare', 'Part', '_The', '’Tis', 'Refund”', '“Hum!', 'Mickleham', 'Hawkins;', 'June', 'Knightley.’', 'Partridge', 'Undoubtedly', 'Agricultural', 'Henry', 'George?”', 'Miss', '“Who', 'Churchill?', 'Enscombe:', 'How,', 'Whatever', 'Smith,', '“Ha!', 'Eltons!', '“Just', '“To', 'Martin;', 'Elton!”', 'Knightley,)', 'Could', 'Well,', 'Thus,', 'Even', 'Time,', 'Bragge', 'Project', 'Smith!—No,', 'Hartfield!—No,', '1.F.4.', 'Anxious', 'Elizabeth,', 'Lively', 'Composure', '‘Do', 'April', 'December)', 'Used', 'Knightley?', 'U.S.', 'Manners', 'Clifton?”', 'Foundation.', 'Lane', 'Knightley.—Were', '1.E.6.', '“Certainly;', 'S.', '“Mermaids', 'Knightley.—“Robert', 'Things', '[_To', 'Dixon.—Very', 'Augusta?”', 'Uncle', '“A', 'Put', '‘Have', 'Let', 'Understanding', 'Highbury?”', 'John?”', '‘Exactly', '_Most_', 'Circumstances', '“I', 'Box', 'Anna', '1.F.6.', 'Knightley', 'I?—Anne,', '“Jane', 'Hart', 'Donwell,”', 'Be', 'Highbury', 'Which', 'Dixons,', '#158]Most', '‘F.', '“Would', '1.F.2.', 'Henceforward', '“Knightley!”', 'Christmas;', 'Before', 'Dixon,', 'Vanilla', 'Churchill.—I', '“Yes,”', '“Cautious,', 'Taylor.', 'Children', '“Indifferent!', 'Excepting', 'England.', '“It', 'Remember', 'Fetch', '“No—It', 'Elton;', 'Beavers”', 'Not', 'Abbey.', 'Are', 'Martins;', 'Fairfax—”', 'Being', 'Farmer', 'Harriet!—A', 'Harriet,', 'Referring', 'Cole.”', 'Both', 'Martin,', 'Fairfax,', 'Elton', 'Six', 'It', 'People', 'Smiles', '“Whenever', 'Bath_,', 'Weymouth,', 'Bristol;', 'Yorkshire.', 'Early,', 'Yorkshire', 'Grove;', 'Donwell!—You', 'Suppose', 'Jeffereys—Clara', 'Randalls,”', 'United', 'Goldsmith', 'Aunt', '“What!', 'But,', '1.B.', 'Martin.', 'Randalls?”', 'Elton—', 'Cox.’', '“True,', 'Books', '_Dixons_.', '“Or', 'Thank', '“Between', 'Crown.', 'Cox.', 'Stilton', '‘Augusta.’', 'Aye,', 'Milmans,', 'Surry.”', 'Smiths', 'Churchill', 'Disputable,', 'Bateses—I', '“Be', 'Smith!—What', 'Give', 'Michaelmas!', '“Can', 'Hawkins!—Well,', 'Mississippi', 'Hartfield.', 'Taylor', 'Weston', 'December', 'Ireland,', 'Richard?—Oh!', 'Knightley’', 'Randalls,', 'Bateses.', 'Am', '“Ah,', 'Gutenberg”', 'Stokes.—Every', 'Eltons’;', 'V', 'Bath!', 'Section', 'Believe', 'Foundation.”', 'Venice,', 'Latterly,', '“Did', 'Certainly,', 'Churchill.’—I', 'Elton.—This', 'His', 'She,', 'Foundation', 'Surry;', 'Perry!', '“Which', 'Well!', '“The', 'Randalls;', 'Wednesday', 'Bates—I', 'Birmingham.', 'Emma:”', 'Pray', '_Elton_', 'Vanity', '“Indeed,', 'God!”', 'Churchills’', 'Crown!”', 'Campbell.’”', 'Knightley.’—You', 'Fortunately,', 'States,', '“Six', 'Patroness,', 'Here,', 'F—,', 'Remember.”', 'Should', 'Midsummer,', 'Knightley!—There', 'Knightley,', 'Hughes.', 'Smallridge,', 'Foundation”', 'Harriet!—I', 'Papa', '“Plain', 'Taylor—It', 'May.', 'Neptune?', 'Campbell.”', 'Taylor.”', 'Go', 'Isabella,”', '“Most', 'Selina', 'Impossible', '“These', 'Campbell;', 'Tupman,', 'Campbell,”', 'Emma)', 'Bird', 'Till', 'Fairfax!—Good', 'Unwelcome', 'Martins,', 'Full', 'Compressed', 'Woodhouse.', '“Has', 'Saturday.', 'Weymouth?', 'Please', '1.E.7', 'London.', 'Bates;', '‘My', 'Such', '1.E.1', '“Sir,”', '“Especially', 'Enscombe.”', 'Vicarage.”', 'Jane.”', 'Name', '“Right', 'Anywhere,', 'Any', 'Copyright', 'Married', 'Gilbert', 'Robert', 'I.—I', 'Of', 'Elton?”', 'Smith!—Miss', '“Robert', 'Woodhouse', 'Nonsense!', '“Kitty,', '“Humph!', 'Knightley;’', 'When', 'Adopt', 'January,', 'Cooper;', 'Captain', '“Oftentimes', '“Wrong!', 'Seats', 'With', '“Now', '“Frank', 'Isabella.', '“Pretty!', 'Gilbert.”', '1.F.3,', 'Approve', 'Highbury.”', 'Harriet.—Does', 'Churchill.”', '“Me!', 'Churchill.—At', '“Never', 'Highbury:', '“Insufferable', 'Natural', 'Going', 'Email', 'How', '“Dating', 'Despite', 'Saturday,', '_Taylor_', '“Much,', 'Consider,', 'Frank', 'Always', 'Elton,', 'Taylor!—I', 'You,', '_Mrs._', 'Hodges,', 'Smith.”', 'Randalls.', '“Both', 'Christmas', 'Were', 'Perrys—I', 'Dixon!”', 'Highbury.—“He', '“Open', 'Absence,', '“Business,', '“On', '“And,', 'August.”', 'Sorrow', 'Sept.', 'International', 'No;', 'License', 'Never', '“Of', 'Windsor—July.', 'Certain', 'Goddard', 'Peculiarly', 'Isabella', 'Square.—Isabella', '“Worse', 'Shakespeare', 'Mill,', '“Indeed!', '“Trouble!', '“While', 'Was', 'Young', 'Augusta', 'Knightley.—“It', '“Does', 'Revenue', 'Emma—“A', 'Kindled', '“Thank', 'Inn?”', 'Perry.—I', 'Then', '“_His_', 'Bates,', 'Three', 'Supper', 'Surry', 'Poverty', 'Information', 'Grove.”', '‘Uncle', 'Harriet?', 'I?', '“From', 'Smith!—Very', 'Wednesday.”', '‘The', 'See', '“Harriet!”', '“Difference!', 'Compliance', '“John', '“Only', 'Your', 'Coles.', 'Eltons,', 'Theodore,', '“Then', 'Wallises,', '“Middling,', 'Woodhouse!', 'Patty', 'Suckling', 'Smith;', 'Taylor.’', '“Me!—I', 'Weston.—“Very', 'Knightley!—Can', 'Busy', 'Eltons’', 'Emma,)', 'Seven', 'Gutenberg™.', 'Miss——', 'June.', '“Whatever', '1.E.2.', '1.E', 'Nothing', '“Yes—I', 'Smallridge', 'Say', 'Saturday;', 'Dixon?”', 'Bates!”', 'January;', '“About', '“Dirty,', 'Call', 'Instead', 'Happy', 'Lieut.', 'Harriet.—It', 'Half', 'Elton?', 'Westons.', 'English', 'Knightley,”', 'Conceive', 'Emma.)', 'On', 'Richmond.', 'Weston.—So', '“Prejudiced!', 'Leave', '“Charming', '“And', 'God!', '_We_', 'Trust', 'Cole,’', 'Eltons,”', 'S.—_My_', 'Miniatures,', '‘Grandpapa,', '“Agreed,', '“Highbury', 'Resentment', 'M.', 'Highbury!”', 'Understanding.', 'Perfectly', 'Emma.—She', '“Oh,', 'End.', 'Bristol,', 'Yorkshire,', 'Scotland,', 'Friday', 'Their', 'Harriet?”', 'Taylor,’', 'Weston!', 'Dixon', 'Woodhouse;', 'January.”', 'Blessed', '“_You_', 'Crown;', '“This', '“Time,', 'Former', 'Knightley!', 'Reports,', '“Nor,', 'Grove', '“Brother', 'Fairfax.—A', 'Soft', '“Defects,”', 'Donations', 'Delightful,', 'Compliments,', 'Bickerton', 'Vicar', 'Literary', 'Matrimony,', '“Lord', 'Decidedly,', 'We', '“Why,', 'Bates!', '‘You', 'Abbey-Mill.”', 'Hartfield,', 'Cowper', 'Cromer', 'Better', '“Yes.', 'Emma.”', 'Her', 'Look', 'Woodhouse,”', 'Knightley?”', 'Knightleys;', '“Being', 'Farm.', 'Imagine', 'X', 'Our', 'Sunday,', 'Emma.”—', '“Yes.”', '“Oh', 'Jane?—‘So', 'Weston.', 'February,', '“Never!', 'Weston;—Mrs.', 'Vicarage,', 'Defect', 'Pain', 'Weston.”', '“Nonsensical', 'July', 'You', 'I,', 'Lady', '_Her_', 'Emma),', 'William', '“Break', '“Ought', 'Hill.', 'Fairfax.', '‘Yes,’', 'White-Hart,', 'Larkins', 'Sometimes', '“Success', 'Knightley.', 'Coles,', 'Abbey', '“Encouragement!—I', 'Selina;', '“None;', 'Randalls', 'England', '“Yes', 'Smith.”—She', '1.E.9.', 'Pardon', 'Bates.—He', 'Redistributing', 'Easter,', 'Exactly', 'Abbey-Mill,', '“Impossible!—I', 'An', 'Command', 'Harriet.', 'License.', 'Prince,', '“John,', 'Churchill!', '“Some', '“Engaged', 'Broadway', 'Henry,', 'Those', 'Holyhead', '“Pretty', 'Churchill.—He', 'While', '“Proof', 'Somebody', 'Bragges,', '“Yes;', 'Knightley.—They', 'Will', 'Harriet;', 'W.', 'Bath', '“Christmas', 'Sucklings', 'Crown.”', '“Well', '“Then,', 'Donwell?—_There_', '“No;', 'Archive', 'Smith!—It', 'Fairfax.—I', '‘Upon', '1.E.', '‘Shall', 'Farm!—_You_', 'Fairfax!—Harriet', '“Nobody', 'Eltons', 'Weather', 'Shall', '_Mr_.', 'W.,', 'Martin?', 'Kitty,', 'Knightley?—Who', 'Frank,', '“How?—They', 'James,', '“Donwell!”', '“Perry!”', 'Perfect', 'St.', 'Gutenberg™,', 'Dear', 'Heaven!”', 'Whether', '“Were', '“More', '_Some_', '“Men', 'Monday', 'Churchill?”', '“Whoever', 'Perry', 'Smith?—Very', 'Except', 'Smith—I', 'Acquit', '“Knightley', '“True.', 'Elton!', 'Time', 'Donwell', 'Tuesday', 'Proportions,', '“Indeed', 'Emma’', 'Bickerton,', 'Concession', 'Ten', 'Jane', 'Yes,', 'Hartfield;', 'Swisserland.', 'Partridge,', 'Son,', 'Exquisite,', 'Vicarage', 'Cole.', 'Fairfax.—Then,', 'John', 'Absolutely', 'Campbells.', 'More', '“Depend', 'Crown', 'Surry,', 'Emma', 'Martin?”', '“Where', '‘Nobody', 'Stokes,’', '‘Oh!', 'Ford,'}\n"
     ]
    }
   ],
   "source": [
    "url2 = \"https://www.gutenberg.org/cache/epub/158/pg158.txt\"\n",
    "with urllib.request.urlopen(url2) as req:\n",
    "    # Web text gets downloaded as raw bytes.  Need an encoding to make it a string\n",
    "    text2 = req.read().decode(\"utf-8\")\n",
    "\n",
    "cap_words2 = set()\n",
    "## Loop through each line and in each line loop\n",
    "## through each word\n",
    "for line in text2.splitlines():\n",
    "    line_list = line.split()\n",
    "    for word in line_list:\n",
    "        if word.istitle():\n",
    "            cap_words2.add(word)\n",
    "print(cap_words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-3bQ4NaOj-r"
   },
   "source": [
    "So now we have two code cells above which are practically identical.  But what I want to focus on here is not the redundancy.  After all, the way I created the second cell was by cutting, pasting, and doing a small edit.  Not by laboriously retyping all the same things.  What I want to focus on is what it's going to be like to read this notebook three months from now.  We're going to see two cells that look nearly identical, and it's going to take some work to see where they differ.  That's unnecessary.  There are  really three complaints about the copy and paste method of reusing code (which you will do a lot):\n",
    "\n",
    "  1.  There's no explicit, easy-to-read statement, of what's different in the two uses.\n",
    "  2.  Closely related, but not entirely identical, There's no explicit statement of what the code *depends on*, \n",
    "      that is, on what names have to be defined in order for the code to work.  This makes it hard to fit the \n",
    "      code into a large data pipeline (which is another thing you'll be doing).\n",
    "  3.  There isn't any explcit easy-to-read statement of what the code **does**.  In a very practical sense\n",
    "      it inputs a filename and outputs a set of capitalized words. Now those facts happen to be related to the           first and last lines of the code cell, so they're not hard to figure out, but in many cases the code flow\n",
    "      will be more complicated and it won't be so easy to read the purpose off the order in the cell.\n",
    "      \n",
    "I made the second issue more difficult because I renamed more than one variable when I copied\n",
    "and pasted the code.\n",
    "\n",
    "```python\n",
    "url\n",
    "text\n",
    "cap_words\n",
    "```\n",
    "\n",
    "So there were three differences to find.  I could certainly have gotten the same\n",
    "basic functionality by just changing `url`, but what if I wanted to keep both sets\n",
    "`cap_words` around for comparison?  What if I had other things I wanted to do \n",
    "to `text` and `text2`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXIZrXA8Oj-s"
   },
   "source": [
    "But suppose we revised the code sp that the code only needed the name `url` to be defined to work properly.  Easy enough to see since I put it right at beginning of the cell, but  it could just as easily have been defined several cells earlier, if I'd needed that URL for other purposes.  Then it would take some careful reading to see that the cell needs the name `url` to be defined.  This is what I meant by problem 2 above. The dependency on that name is inexplicit, and needs to be dug out by doing work.  So both complaints fall under the broad heading of *code readability*.  But we can go a bit further.  Both complaints 1 and 2 go to code **reusability**.  In order to cut and paste the code to use it on a third file, I have to have these kinds of issues settled.  Moreover, the reusability issues get worse as the context dependency of the code gets worse.  Suppose the above code depended both on a file name and a website URL, and that I generally (maybe not always) changed both at the same time.  That's not explicit either, and that kind of inexplicitness is responsible for many, many bugs when code is reused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyZmc_ETOj-s"
   },
   "source": [
    "## Functions are the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gbld27YjOj-s"
   },
   "source": [
    "The solution is to encapsulate what you've done as a function definition.   This solves all three of our problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "def find_cap_words0(filename):\n",
    "    with urllib.request.urlopen(filename) as req:\n",
    "        # Web text gets downloaded as raw bytes.  Need an encoding to make it a string\n",
    "        text = req.read().decode(\"utf-8\")\n",
    "    cap_words = set()\n",
    "    for line in text.splitlines():\n",
    "        line_list = line.split()\n",
    "        for word in line_list:\n",
    "            if word.istitle():\n",
    "                cap_words.add(word)\n",
    "    return cap_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUjnkAjvOj-s"
   },
   "source": [
    "`filename`  is our input; `cap_words` is our output (what is **returned**).  What's different from use to use is the exact value of `filename` .  What the code depends on is also the exact value of `filename`.  Moreover suppose we want there to be another optional dependency (the website the file can be found on).  Now the code looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mu3ac_KVOj-s"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "def find_cap_words(filename, site = None):\n",
    "    if site is not None:\n",
    "        filename = os.path.join(site, filename)\n",
    "    with urllib.request.urlopen(filename) as req:\n",
    "        # Web text gets downloaded as raw bytes.  Need an encoding to make it a string\n",
    "        text = req.read().decode(\"utf-8\")\n",
    "    cap_words = set()\n",
    "    for line in text.splitlines():\n",
    "        line_list = line.split()\n",
    "        for word in line_list:\n",
    "            if word.istitle():\n",
    "                cap_words.add(word)\n",
    "    return cap_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsEVu7crOj-t"
   },
   "source": [
    "The names in parentheses after the function name are called the **parameters** or **arguments** of the function.  Notice that in this case only one of the parameters is obligatory (No `= Value` after `filename`, so no default value supplied).  In the case of the `site` parameter in `find_cap_words`, there was a fairly natural answer as to what to do when `site` wasn't supplied.  Just  assume `filename` includes the site URL.  But if  `filename` isn't supplied, where are we to look? There's no natural default, so we make that parameter obligatory.  The decision as to whether a parameter is optional or obligatory is an important thing to think about when defining a function.\n",
    "\n",
    "Demonstrating `find_cap_words`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oi-iJqVaOj-t",
    "outputId": "8e4bee9e-5a34-4e8a-abaf-4a89835d7429",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382 ['“Well,”', 'Mary?', 'Carter,', 'Kitty,--', 'J.', 'Kitty;', 'F.;', 'Lydia,”', 'Pray,', 'Spectator,”', '“As', 'Hill,', 'Lucases', '“Certainly,', '“_My_', 'Happiness', '“Lizzy', '_Monday,', '1.E.1.', 'Michael', 'Lakes.”', '_Chap', 'Words', '“Mrs.', 'Collins.', 'In', '“Hearing', 'Fitzwilliam,', 'There', '“Read', '“Pray', 'Does', 'Convinced', 'Sally', '“_I_', 'Jane.', 'Updated', 'William,', 'Darcy!”', 'Vain', 'Argemone', 'Fixed', 'Sir,', '1.F.5.', 'Jane,', 'God', 'Attention,', 'Other', 'Wednesday.', 'Burney,', 'Charlotte.', '“Ay,', 'Why,', 'Longbourn.”', 'Ring', 'Feb', 'Gardiner;', 'Must', 'There,', 'Younger', 'Adieu', 'Catherine,)', 'Two', 'Bennet,', '“Upon', 'However', 'Scott', 'Take', 'Teasing,', 'Saturday:', 'Wickham!', '“Implacable', '“No--I', '“Their', 'Fielding,', 'This', 'For,', 'Bingley:', 'Hursts', 'Release', 'Lodge.', 'Some', '“Why', 'Younge', 'Five', 'Breakfast', 'No', 'Bingley,”', '“Was', 'Sections', 'But', 'Fairfax', 'Whitman', 'Lakes.', '“What', 'Great', 'Monday,', 'Party', 'Since', 'Foundation.\"']\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"\n",
    "cap_words = find_cap_words(url)\n",
    "print(len(cap_words), list(cap_words)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRwdLJrBOj-t"
   },
   "source": [
    "And here we are using it on another file.  See?  Quite easy to see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UDV7AHwUOj-t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592 ['“Well,”', '“Ill,', 'Wakefield.', '“Me!”', 'Richardson,', '“Nonsense!', 'Highbury.', 'Walk', 'Kings', '“Emma,”', 'Philip', 'Happily,', '‘No’', 'Pray,', 'Randalls.—But', '“As', 'Gratifying,', 'Richard?—I', 'Hill,', '“Certainly,', '“_My_', 'Square,', '1.E.1.', 'Welch', '‘But,’', 'Michael', 'Nature', '“Mrs.', 'In', 'There', '“Read', 'Serle', '“Pray', 'Perry?—Has', 'John,', 'Does', 'Men', '“Emma!”', 'Donwell?—He', '“_I_', 'Jane.', 'Taylor,', 'Updated', 'William,', 'Picture,', 'Sir,', '1.F.5.', 'Jane,', 'God', 'Other', 'Small', '‘Not', '“—Mrs.', '“Very.”', 'Dixon.', 'Must', 'There,', 'Weston!—Astonished', '“Low,', 'Two', '“‘Smallridge!’—What', '“Upon', 'Maple', 'Take', 'Bateses,', 'Goddard.', 'Barnes,', 'Hall;', 'Perrys,', 'Windsor?”', 'This', 'Perry,”', 'Release', 'Some', 'Sucklings,', 'Knightley!—I', '“Why', 'Five', 'Braithwaites,', 'Frank.', '“Till', 'Eltons?—Here', 'No', '“Better', '“Was', 'Bella,', 'Sections', 'But', '“No—Mrs.', 'Fairfax', 'August,', '“What', 'Bragge,', 'Since', 'Adelaide', 'Quite', '“Is', 'Campbell,', 'Churchills.', 'Perry.”']\n"
     ]
    }
   ],
   "source": [
    "url2 = \"https://www.gutenberg.org/cache/epub/158/pg158.txt\"\n",
    "cap_words = find_cap_words(url2)\n",
    "print(len(cap_words), list(cap_words)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa9kI_vVOj-t"
   },
   "source": [
    "## Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytaY8blZOj-t"
   },
   "source": [
    "So here's the new plan, now that we know about functions.  Write the code once encapsulated as a function.\n",
    "Reuse it as many times as you like varying the **arguments** of the function  (the part that changes from use to use, the information the code explicitly depends on): in this case what changes is the `filename` value.  In one case it's `\"pride_and_prejudice.txt\"`.  In another it's `\"emma.txt\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcv3oStdOj-t"
   },
   "source": [
    "## Problem 1: Parameters and Return values (input/output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN89IWZBOj-t"
   },
   "source": [
    "We tackle the problem of breaking `find_cap_words` into two more natural pieces, each\n",
    "a function, increasing the re-usability and (hopefully) the readability.\n",
    "\n",
    "Eyeballing `find_cap_words` as currently written, it really does two things\n",
    "in sequence, easily separated by looking at the biggest blocks of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cap_words(filename, site = None):\n",
    "    if site is not None:\n",
    "        filename = os.path.join(site, filename)\n",
    "    with urllib.request.urlopen(filename) as req:\n",
    "        # Web text gets downloaded as raw bytes.  Need an encoding to make it a string\n",
    "        text = req.read().decode(\"utf-8\")\n",
    "    cap_words = set()\n",
    "    for line in text.splitlines():\n",
    "        line_list = line.split()\n",
    "        for word in line_list:\n",
    "            if word.istitle():\n",
    "                cap_words.add(word)\n",
    "    return cap_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN89IWZBOj-t"
   },
   "source": [
    "It downloads a file from the web, decoding it, then extracts caps.  Let's write two functions,\n",
    "`download_text_file` and `extract_caps`.\n",
    "\n",
    "Here are the first drafts of those functions.  The parameters of the functions have been left out.\n",
    "It's your job to:\n",
    "\n",
    "1.  Add the parameters (arguments) to be functions, deciding which should be optional\n",
    "2.  Determine what each function should return.\n",
    "3.  Write some code demonstrating how the functions should be called\n",
    "    to download *Pride and Prejudice* and *Emma*.\n",
    "    \n",
    "Here's something to bear in mind as you edit the functions:  You want them to be usable beyond just\n",
    "these two cases, and not every text file on the web will be encoded in UTF8 (although\n",
    "most will).\n",
    "\n",
    "Some blank code cells have been provided for your answers.  Reasonable answers have been supplied\n",
    "a few more cells down.  Be aware that this problem has more than one answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_text_file():\n",
    "    if site is not None:\n",
    "        filename = os.path.join(site, filename)\n",
    "    with urllib.request.urlopen(filename) as req:\n",
    "        # Web text gets downloaded as raw bytes.  Need an encoding to make it a string\n",
    "        text = req.read().decode(\"utf-8\")\n",
    "\n",
    "def extract_caps ():\n",
    "    cap_words = set()\n",
    "    for line in text.splitlines():\n",
    "        line_list = line.split()\n",
    "        for word in line_list:\n",
    "            if word.istitle():\n",
    "                cap_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### A reasonable answer to the question\n",
    "import os.path\n",
    "\n",
    "def download_text_file(filename, site = None, encoding=\"utf8\"):\n",
    "    if site is not None:\n",
    "        filename = os.path.join(site, filename)\n",
    "    with urllib.request.urlopen(filename) as req:\n",
    "        # Web text gets downloaded as raw bytes.  Need an encoding to make it a string\n",
    "        return req.read().decode(encoding)\n",
    "\n",
    "def extract_caps (text):\n",
    "    cap_words = set()\n",
    "    for line in text.splitlines():\n",
    "        line_list = line.split()\n",
    "        for word in line_list:\n",
    "            if word.istitle():\n",
    "                cap_words.add(word)\n",
    "    return cap_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"https://www.gutenberg.org\"\n",
    "\n",
    "#  Run pipeline once\n",
    "filename1 = \"files/1342/1342-0.txt\"\n",
    "text1 = download_text_file(filename1, site = site)\n",
    "caps1 = extract_caps (text1)\n",
    "\n",
    "#  Run pipeline a second time\n",
    "filename2 = \"cache/epub/158/pg158.txt\"\n",
    "text2 = download_text_file(filename2, site = site)\n",
    "caps2 = extract_caps (text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWiDmlbcOj-t"
   },
   "source": [
    "So now we have the above natural sequence of two commands whenever we get a new URL to extract information from.\n",
    "\n",
    "1. download_text_file\n",
    "2. extract_caps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgjy5UPdOj-u"
   },
   "source": [
    "This, like many of the pieces of code we will write in this course, is a **pipeline**.   We take in one piece of data, a filename, use it to extract some information, a text string, and pass those on for further processing,  A simple pipeline has the following structure:\n",
    "\n",
    "```\n",
    "output_1 = Function_1(input)\n",
    "output_2 = Function_2(output_1, ... [other parameters])\n",
    "output_3 = Function_3(output_2, ... [other parameters])\n",
    "...\n",
    "Function_n(output_{n-1}, ... [other paramters])\n",
    "```\n",
    "\n",
    "We are assuming here that Funtion_n is a function that saves the data to a disk, so there is not output_n in the program.  In a simple variant, there is an output_n, because the pipeline is part of some larger program, which will do further processing on output_n.\n",
    "\n",
    "Our simple pipeline has only two functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2wzJicEOj-u"
   },
   "source": [
    "## Appendix:  Regular expression-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYMVEV4COj-u"
   },
   "source": [
    "Another good reason for encapsulating code in a function, is that it's easy to change all uses of the function in a large body of code, and experiment with a new method, as we will frequently do in this course.  For example here's an entirely new approach to the extract names problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "0TjQC9bvOj-u"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cap_word_re = r'\\b([A-Z][a-z]+)\\b'\n",
    "x = set(re.findall(cap_word_re, text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_mTcTc2Oj-u"
   },
   "source": [
    "Here we use a pattern-matching Python module called `re` (for **regular expression**)  to try to extract all capitalized words that are at least two characters long.  The pattern is the string that's given the name `cap_word_re`, which is then used as the first argument of `re.findall`.  The part in the first pair of square breackets of the pattern says the first character must be a capitalized letter (`A-Z`) and then there must be one or more following characters of the sort that can occur in words (`\\w+`).  All of this must begin and end with a word boundary (`\\b`). \n",
    "\n",
    "Applying this pattern to a simple string we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "NTSK9YmsOj-u",
    "outputId": "8567d533-776b-43c5-c643-89f9c31661e9",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beethoven']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(cap_word_re,'F3 I 22 love Beethoven')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kyd8WRXGOj-u"
   },
   "source": [
    "Notice that this excludes `I`and `F3` , which our previous attempt didn't.  There are more powerful things one can say with regular expressions, and when we learn more about regular expressions, we'll return to this problem and come up with a still more satisfactory solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YCAEfKFOj-u"
   },
   "source": [
    "Here we use a pattern-matching Python module called `re` (for **regular expression**)  to try to extract all capitalized words that are at least two characters long.  The pattern is the string that's the first argument of `re.findall`.  The part in the first pair of square breackets of the pattern says the first character must be a capitalized letter (`A-Z`) and then there must be one or more following lower case characters (`[a-z]+`).  All of this must begin and end with a word boundary (`\\b`).  Notice that this excludes single-charactereize capitalized word like `I`, which our previous attempt didn't.  There are more powerful things one can say with regular expressions, and if you learn more about regular expressions, you might want to return to this problem and come up with a still more satisfactory solution.\n",
    "\n",
    "For now, your task is to redefine `extract_caps` to use a regular expression approach.   Be sure to try out your new function on one of the examples  done above, to see if you can reproduce that functionality, or do better.  Check how many words end up in `caps` for both approaches.  Eyeball some of the answers. See which words are excluded by one approach and not the otehr (the `.difference()` method on sets might be of help).   Is the regular expressions approach an improvement?  Hint:  The regular expressions approach does have some issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "0oda3sJqOj-u"
   },
   "outputs": [],
   "source": [
    "def extract_caps2 (text):\n",
    "    cap_word_re = r'\\b([A-Z][a-z]+)\\b'\n",
    "    return set(re.findall(cap_word_re, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1pNqx8jOj-u"
   },
   "source": [
    "To try this out we'd just re-execute any of the cells above that call `cownload_text_file`\n",
    "to provide us with some text.  And plug in our new function.  For example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "cM2-CbfsOj-u",
    "outputId": "d36804bf-8553-4204-a383-b6cb9fbfe858"
   },
   "outputs": [],
   "source": [
    "#  Run pipeline once\n",
    "filename1 = \"files/1342/1342-0.txt\"\n",
    "text1 = download_text_file(filename1, site = site)\n",
    "caps3 = extract_caps2 (text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "cM2-CbfsOj-u",
    "outputId": "d36804bf-8553-4204-a383-b6cb9fbfe858",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691 ['Goulding', 'Charing', 'Nay', 'Compared', 'Robinson', 'Much', 'From', 'Email', 'Interested', 'How', 'Promise', 'As', 'Caroline', 'Despite', 'Easter', 'Kent', 'Replacement', 'Commerce', 'Thomson', 'Frank', 'Unless', 'Persuaded', 'Ah', 'Spanish', 'Lucases', 'Road', 'Birmingham', 'Into', 'Happiness', 'Society', 'Christmas', 'Delighted', 'Carr', 'Consider', 'Were', 'Michael', 'Yet', 'Poor', 'Words', 'Regulars', 'Epsom', 'In', 'There', 'West', 'Does', 'Tell', 'International', 'Convinced', 'Can', 'Sally', 'November', 'Grosvenor', 'Covering', 'Also', 'License', 'Never', 'Cambridge', 'Nicholls', 'Smollett', 'Updated', 'Vain', 'Argemone', 'Certain', 'Fixed', 'Or', 'Implacable', 'Write', 'Vingt', 'God', 'De', 'By', 'Other', 'Stone', 'Lake', 'Protested', 'House', 'Affectation', 'Just', 'Ring', 'Feb', 'Saturday', 'Tease', 'Vernon', 'Piling', 'What', 'Philistinism', 'Swiftian', 'Maria', 'Must', 'Was', 'Younger', 'Insolent', 'Young', 'To', 'Adieu', 'Revenue', 'Excuse', 'Niece', 'Chawton', 'Two']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(caps3), list(caps3)[:100])\n",
    "'Darcy' in caps3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how different the two results from *Pride and Prejudice* are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Zi9KZ11pOj-u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382, 691)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caps1), len(caps3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've actually improved performance considerably  Here's why. \n",
    "\n",
    "A number of \"names\" containing punctuation as part of the word have been eliminated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But all is not sunshine and roses.  Our solution has bugs.  \n",
    "\n",
    "Here are names that have **not** been discovered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "CIWjMdmGOj-u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abbey',\n",
       " 'Accompanied',\n",
       " 'Accordingly',\n",
       " 'Ah',\n",
       " 'Allen',\n",
       " 'Already',\n",
       " 'Astonishment',\n",
       " 'Attention',\n",
       " 'Author',\n",
       " 'Ay',\n",
       " 'Bakewell',\n",
       " 'Bates',\n",
       " 'Bath',\n",
       " 'Because',\n",
       " 'Believe',\n",
       " 'Bell',\n",
       " 'Besides',\n",
       " 'Beyond',\n",
       " 'Birmingham',\n",
       " 'Blame',\n",
       " 'Blenheim',\n",
       " 'Books',\n",
       " 'Bountiful',\n",
       " 'Bromley',\n",
       " 'Brother',\n",
       " 'Burney',\n",
       " 'Cambridge',\n",
       " 'Care',\n",
       " 'Certainly',\n",
       " 'Chatsworth',\n",
       " 'Cheapside',\n",
       " 'City',\n",
       " 'Clapham',\n",
       " 'Clarke',\n",
       " 'Clement',\n",
       " 'Commerce',\n",
       " 'Compared',\n",
       " 'Complied',\n",
       " 'Conjecturing',\n",
       " 'Courier',\n",
       " 'Covering',\n",
       " 'Dashwood',\n",
       " 'Date',\n",
       " 'Defects',\n",
       " 'Delighted',\n",
       " 'Depend',\n",
       " 'Design',\n",
       " 'Dining',\n",
       " 'Eastbourne',\n",
       " 'Eltons',\n",
       " 'Esmond',\n",
       " 'Esq',\n",
       " 'Exceed',\n",
       " 'Exceedingly',\n",
       " 'Fordyce',\n",
       " 'Frenchman',\n",
       " 'Friday',\n",
       " 'Generous',\n",
       " 'Girls',\n",
       " 'Go',\n",
       " 'Grant',\n",
       " 'Grantley',\n",
       " 'Green',\n",
       " 'Hate',\n",
       " 'Hatfield',\n",
       " 'Haye',\n",
       " 'Hearing',\n",
       " 'Illustration',\n",
       " 'Implacable',\n",
       " 'Impossible',\n",
       " 'Insolent',\n",
       " 'James',\n",
       " 'Janites',\n",
       " 'July',\n",
       " 'Just',\n",
       " 'Keep',\n",
       " 'Kenilworth',\n",
       " 'Kympton',\n",
       " 'La',\n",
       " 'Lane',\n",
       " 'Language',\n",
       " 'Lately',\n",
       " 'Laugh',\n",
       " 'Lavington',\n",
       " 'Liverpool',\n",
       " 'Lizzie',\n",
       " 'Look',\n",
       " 'Maupassant',\n",
       " 'Meeting',\n",
       " 'Merely',\n",
       " 'Metcalfe',\n",
       " 'Michaelmas',\n",
       " 'Miller',\n",
       " 'Money',\n",
       " 'Mr',\n",
       " 'Mrs',\n",
       " 'Musgrove',\n",
       " 'Nay',\n",
       " 'Neglect',\n",
       " 'New',\n",
       " 'Niece',\n",
       " 'None',\n",
       " 'Nonsense',\n",
       " 'Obstinate',\n",
       " 'Offended',\n",
       " 'Office',\n",
       " 'Or',\n",
       " 'Oxford',\n",
       " 'Peak',\n",
       " 'Perfectly',\n",
       " 'Persuasion',\n",
       " 'Philistinism',\n",
       " 'Piling',\n",
       " 'Plain',\n",
       " 'Presuming',\n",
       " 'Probably',\n",
       " 'Protested',\n",
       " 'Read',\n",
       " 'Really',\n",
       " 'Refund',\n",
       " 'Regulars',\n",
       " 'Removed',\n",
       " 'Respect',\n",
       " 'Richard',\n",
       " 'Road',\n",
       " 'Robinson',\n",
       " 'Rushworth',\n",
       " 'Sarah',\n",
       " 'Seriously',\n",
       " 'Sermons',\n",
       " 'Service',\n",
       " 'Shapely',\n",
       " 'Smollett',\n",
       " 'Something',\n",
       " 'Speak',\n",
       " 'St',\n",
       " 'Stairs',\n",
       " 'Stay',\n",
       " 'Stoke',\n",
       " 'Stone',\n",
       " 'Sure',\n",
       " 'Surely',\n",
       " 'Teasing',\n",
       " 'Tenderly',\n",
       " 'Thorpe',\n",
       " 'Thoughtlessness',\n",
       " 'Tilney',\n",
       " 'Times',\n",
       " 'Tis',\n",
       " 'Title',\n",
       " 'Town',\n",
       " 'True',\n",
       " 'Unable',\n",
       " 'Undoubtedly',\n",
       " 'Unfeeling',\n",
       " 'Unhappy',\n",
       " 'Venus',\n",
       " 'Vernon',\n",
       " 'Vingt',\n",
       " 'Walked',\n",
       " 'Warwick',\n",
       " 'Watson',\n",
       " 'Well',\n",
       " 'West',\n",
       " 'Westerham',\n",
       " 'Which',\n",
       " 'Woman',\n",
       " 'Won',\n",
       " 'Wretched',\n",
       " 'Write',\n",
       " 'Yes',\n",
       " 'York'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = set(caps3).difference(caps1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see, it's not really a matter of the shape of these names themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abbey',\n",
       " 'Accompanied',\n",
       " 'Accordingly',\n",
       " 'Ah',\n",
       " 'Allen',\n",
       " 'Already',\n",
       " 'Astonishment',\n",
       " 'Attention',\n",
       " 'Author',\n",
       " 'Ay',\n",
       " 'Bakewell',\n",
       " 'Bates',\n",
       " 'Bath',\n",
       " 'Because',\n",
       " 'Believe',\n",
       " 'Bell',\n",
       " 'Besides',\n",
       " 'Beyond',\n",
       " 'Birmingham',\n",
       " 'Blame',\n",
       " 'Blenheim',\n",
       " 'Books',\n",
       " 'Bountiful',\n",
       " 'Bromley',\n",
       " 'Brother',\n",
       " 'Burney',\n",
       " 'Cambridge',\n",
       " 'Care',\n",
       " 'Certainly',\n",
       " 'Chatsworth',\n",
       " 'Cheapside',\n",
       " 'City',\n",
       " 'Clapham',\n",
       " 'Clarke',\n",
       " 'Clement',\n",
       " 'Commerce',\n",
       " 'Compared',\n",
       " 'Complied',\n",
       " 'Conjecturing',\n",
       " 'Courier',\n",
       " 'Covering',\n",
       " 'Dashwood',\n",
       " 'Date',\n",
       " 'Defects',\n",
       " 'Delighted',\n",
       " 'Depend',\n",
       " 'Design',\n",
       " 'Dining',\n",
       " 'Eastbourne',\n",
       " 'Eltons',\n",
       " 'Esmond',\n",
       " 'Esq',\n",
       " 'Exceed',\n",
       " 'Exceedingly',\n",
       " 'Fordyce',\n",
       " 'Frenchman',\n",
       " 'Friday',\n",
       " 'Generous',\n",
       " 'Girls',\n",
       " 'Go',\n",
       " 'Grant',\n",
       " 'Grantley',\n",
       " 'Green',\n",
       " 'Hate',\n",
       " 'Hatfield',\n",
       " 'Haye',\n",
       " 'Hearing',\n",
       " 'Illustration',\n",
       " 'Implacable',\n",
       " 'Impossible',\n",
       " 'Insolent',\n",
       " 'James',\n",
       " 'Janites',\n",
       " 'July',\n",
       " 'Just',\n",
       " 'Keep',\n",
       " 'Kenilworth',\n",
       " 'Kympton',\n",
       " 'La',\n",
       " 'Lane',\n",
       " 'Language',\n",
       " 'Lately',\n",
       " 'Laugh',\n",
       " 'Lavington',\n",
       " 'Liverpool',\n",
       " 'Lizzie',\n",
       " 'Look',\n",
       " 'Maupassant',\n",
       " 'Meeting',\n",
       " 'Merely',\n",
       " 'Metcalfe',\n",
       " 'Michaelmas',\n",
       " 'Miller',\n",
       " 'Money',\n",
       " 'Mr',\n",
       " 'Mrs',\n",
       " 'Musgrove',\n",
       " 'Nay',\n",
       " 'Neglect',\n",
       " 'New',\n",
       " 'Niece',\n",
       " 'None',\n",
       " 'Nonsense',\n",
       " 'Obstinate',\n",
       " 'Offended',\n",
       " 'Office',\n",
       " 'Or',\n",
       " 'Oxford',\n",
       " 'Peak',\n",
       " 'Perfectly',\n",
       " 'Persuasion',\n",
       " 'Philistinism',\n",
       " 'Piling',\n",
       " 'Plain',\n",
       " 'Presuming',\n",
       " 'Probably',\n",
       " 'Protested',\n",
       " 'Read',\n",
       " 'Really',\n",
       " 'Refund',\n",
       " 'Regulars',\n",
       " 'Removed',\n",
       " 'Respect',\n",
       " 'Richard',\n",
       " 'Road',\n",
       " 'Robinson',\n",
       " 'Rushworth',\n",
       " 'Sarah',\n",
       " 'Seriously',\n",
       " 'Sermons',\n",
       " 'Service',\n",
       " 'Shapely',\n",
       " 'Smollett',\n",
       " 'Something',\n",
       " 'Speak',\n",
       " 'St',\n",
       " 'Stairs',\n",
       " 'Stay',\n",
       " 'Stoke',\n",
       " 'Stone',\n",
       " 'Sure',\n",
       " 'Surely',\n",
       " 'Teasing',\n",
       " 'Tenderly',\n",
       " 'Thorpe',\n",
       " 'Thoughtlessness',\n",
       " 'Tilney',\n",
       " 'Times',\n",
       " 'Tis',\n",
       " 'Title',\n",
       " 'Town',\n",
       " 'True',\n",
       " 'Unable',\n",
       " 'Undoubtedly',\n",
       " 'Unfeeling',\n",
       " 'Unhappy',\n",
       " 'Venus',\n",
       " 'Vernon',\n",
       " 'Vingt',\n",
       " 'Walked',\n",
       " 'Warwick',\n",
       " 'Watson',\n",
       " 'Well',\n",
       " 'West',\n",
       " 'Westerham',\n",
       " 'Which',\n",
       " 'Woman',\n",
       " 'Won',\n",
       " 'Wretched',\n",
       " 'Write',\n",
       " 'Yes',\n",
       " 'York'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_str = ' '.join(ds)\n",
    "extract_caps2 (d_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, all the names on their own match our capitalized name reg exp. So it's something about the context in\n",
    "which they occur in the text of *Pride and Prejudice*.\n",
    "\n",
    "Here's your clue, using one of the words from the above list and a slightly looser regexp which allows\n",
    "any single character before and after \"Merely\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Merely ']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\".Merely.\",text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be fixed.  You are welcome to try to fix `extract_caps2`.  Answer supplied on request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
