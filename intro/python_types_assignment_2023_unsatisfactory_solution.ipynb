{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIBX7u_RW74U"
   },
   "source": [
    "# Python Types Assignment 2023 Unsatisfactory Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWYWYfMiW74W"
   },
   "source": [
    "This notebook contains only a subset of `Python Types Assignment 2023` exercises.  It\n",
    "is intended to illustrate common mistakes made in submitted solutions.\n",
    "\n",
    "For the problems in this assignment, assume all the definitions in the next cell, and check your answers by evaluating the next cell and verifying that your answers give the required results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19mvC4k2W74X"
   },
   "outputs": [],
   "source": [
    "# Note: the interpretation we will work with for city distances is that it is a weighted graph representing \n",
    "# city distances.  The weights represent the distance between the cities. \n",
    "city_distances = {'New York': {'Chicago': 790, 'Boston': 215, 'St. Louis': 953, 'Baltimore':188},\n",
    "                   'Chicago': {'Denver': 1_002, 'Omaha': 467, 'Salt Lake City':1_397},\n",
    "                   'Denver': {'Phoenix': 865, 'Salt Lake City': 528, },\n",
    "                   'Phoenix': { 'Albuquerque': 419,  'Reno': 739, 'San Diego': 355},\n",
    "                   'Dallas' : {'Houston': 241}\n",
    "                  }\n",
    "capitals = [ ('France', 'Paris'), ('Italy', 'Rome'), ('Germany', 'Berlin'),  ('England', 'London'),\n",
    "                          ('Sweden', 'Stockholm'), ('Norway', 'Oslo'), ('Poland', 'Warsaw')]\n",
    "country2capital = dict(capitals)\n",
    "dwarves = ('Sneezy', 'Doc', 'Sleepy','Happy','Dopey','Grumpy', 'Bashful')\n",
    "secret_word = \"sesame bagel\"\n",
    "historical_records = [{'name':'Fred Flinstone',\n",
    "                     'spouse': 'Wilma',\n",
    "                       'favorite_tv_shows': ['The Honeymooners', 'The Jetsons'],\n",
    "                      'town of residence': 'Bedrock'},\n",
    "                    {'name':'Barney Rubble',\n",
    "                     'spouse': 'Elizabeth',\n",
    "                     'favorite_tv_shows': ['The Crown', 'Bridgerton'],\n",
    "                      'town of residence': 'Bedrock'},\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3Sm1M10W74W"
   },
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SdNV4DNW74i"
   },
   "source": [
    "## Exercise One\n",
    "\n",
    "In the next cell, write expression that accesses `dwarves` and returns the value `\"Bashful\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sneezy', 'Doc', 'Sleepy', 'Happy', 'Dopey', 'Grumpy', 'Bashful')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwarves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 1**: \n",
    "\n",
    "Note that this solution has a typo.  But that isn't the **real** problem.  The cell hasn't been evaluated\n",
    "so the student hasn't tested whether their solution works.  If they had, they would have found out about their typo. The telltale sign that the cell hasn't been evaluated is that there is no output under the cell.  There are some python sentences that produce no output (we'll discuss the most important example below).  But there are fixes for that problem.  This is all illustrated below.\n",
    "\n",
    "This solution would receive **no** credit, even though it's quite close to the correct solutioon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ic5AnNKuW74j"
   },
   "outputs": [],
   "source": [
    "dwavres[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 2**: \n",
    "\n",
    "Note that the solution still has a typo. But this time the cell has been evaluated.  That's much better.\n",
    "Tested solutions that are still wrong will often get partial credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dwavres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_83452/1153119232.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdwavres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dwavres' is not defined"
     ]
    }
   ],
   "source": [
    "dwavres[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point of information.  After the first week, I would expect even beginning programmers to be able to fix this problem on their own.  This is a `NameError` and the **first** thing you should suspect when you get a `NameError` is a typo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 3**: \n",
    "\n",
    "What's going on in teh cell below?  This solution looks right!  Why is it getting a `NameError`?  The problem\n",
    "is that the first code cell in the notebook hadn't been evaluated when\n",
    "I evaluated the cell below. But evaluating the first cell in the notebook is how the name `dwarves`\n",
    "comes to be defined.\n",
    "\n",
    "The **second** thing you should suspect when you get a `NameError` is that there is a code cell\n",
    "**earlier in the notebook** that this cell depends on, in particular because the earlier cell defines a name that this cell uses.  So that earlier cell should have been evaluated before this one.\n",
    "\n",
    "This happens all the time and it is easy to fix.  If you are working with this notebook now you\n",
    "should try the fix.  Execute the first code cell in the notebook.  Then re-execute the code\n",
    "cell below.  Presto!  The `NameError` will be gone.  \n",
    "\n",
    "The erroneous solution below will still get partial credit, because it is essentially correct, but\n",
    "after the first week you will be expected to fix `NameError`s that can be resolved by executing earlier cells on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dwarves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_83452/3914608235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdwarves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dwarves' is not defined"
     ]
    }
   ],
   "source": [
    "dwarves[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 4**: \n",
    "\n",
    "The problem in the next cell is again, no output, but the output is missing for a new reason.\n",
    "\n",
    "The code assigns a value to the variable `X`.  When a value is assigned to a variable,\n",
    "no output is generated. Python  just quietly updates the value of the variable `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dwarves[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fix for this issue is shown in the next cell.  Just put the variable on a line of\n",
    "its own.  Python understands this to mean it is supposed to evaluate the variable\n",
    "and output will generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bashful'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dwarves[-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course in this case the variable `X` wasn't needed at all, \n",
    "\n",
    "```python\n",
    "dwarves[-1]\n",
    "```\n",
    "\n",
    "is a fine answer all on its own.  But there is nothing wrong with introducing a variable\n",
    "(in some problems you will need to do that) as long you correctly show its value when\n",
    "needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 5**: \n",
    "\n",
    "The problem in the next cell is again, no output; and this\n",
    "example is here to complete our discussion\n",
    "of when notebooks output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwarves[-1]\n",
    "X = dwarves[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line\n",
    "\n",
    "```python\n",
    "dwarves[-1]\n",
    "```\n",
    "generates a value all on its own, as we've seen before, but the notebook will only display that value\n",
    "when `dwarves[-1]` is the last value in a cell and the cell is evaluated.\n",
    "\n",
    "I did evaluate the cell above, but since `dwarves[-1]`  is not on the last line,\n",
    "there was no output.\n",
    "\n",
    "**Moral**:  Try to put the expressions with relevant output on the last line.  If you ever\n",
    "need to show more than one output value, use `print(...)` for the expressions that aren't on\n",
    "the last line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrb4FrpQW74m"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyonsXZjW74m"
   },
   "source": [
    "## Exercise Two\n",
    "\n",
    "In the next cell, write an expression that accesses `secret_word` and returns the value `\"m\"`.\n",
    "`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sesame bagel'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 1**:  The output isn't the output I requested.  So the code is not performing the requested task.  This is called **not meeting specifications** or **not meeting specs**.\n",
    "\n",
    "Always inspect your output carefully to make sure it is the output that was requested.  \n",
    "\n",
    "This is a partial credit solution because it is very close  to the correct solution. The fix is just\n",
    "to change from the index `3` to the index `4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLKwzgMKW74n",
    "outputId": "110e6599-5bd7-47af-e9cd-072fe25d06c4",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret_word[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 2**:  This is the same incorrect solution as the previous one, but I've included a description that says  I know the output is incorrect.  That always gets more credit than a solution that fails to meet specs without any acknowledgement.  Not including an acknowledgement that the solution fails\n",
    "suggests that the student doesn't know that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret_word[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that the solution above generates the wrong output, but I couldn't figure out how to get the requested output, even though I tried everything I could think of, including making the index smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:  Of course it's a little odd that the student being role-played above didn't also try making the index larger, but this example is for illustrative purposes only.  In general,  I know students don't have infinite time, and they can't try everything.  That's why solutions that don't meet specs will usually get partial credit (see below for some exceptions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqgeJc1jW74p"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFmMMNrVW74q"
   },
   "source": [
    "## Exercise Three\n",
    "\n",
    "In the next cell, write an expression that accesses `dwarves` and produces an `IndexError`.  Try to make the index you use to access `dwarves` as small as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sneezy', 'Doc', 'Sleepy', 'Happy', 'Dopey', 'Grumpy', 'Bashful')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwarves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bashful'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwarves[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directions say to cause an error, and they say what kind of error to cause.\n",
    "\n",
    "This mythical student did not read the instructions.  This is probably a No Credit Answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRhYiXRJW74t"
   },
   "source": [
    "## Exercise Four\n",
    "\n",
    "In the next cell, write an expression that accesses `dwarves` and returns `\"ope\"`.  There is more than one answer.  See if you can find two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sneezy', 'Doc', 'Sleepy', 'Happy', 'Dopey', 'Grumpy', 'Bashful')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwarves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 1:**  This is a `Type Error`.  It's not that far from the correct solution\n",
    "so it's a partial credit unsatisfactory solution.\n",
    "\n",
    "Please see the posted solution for this notebook (Use the \"Sample Student Work\" link  or the \"M1 Python Types Workbook\" Link), if it isn't clear to you how to fix this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sb81tMbDW74u",
    "outputId": "071b430e-a70d-4e89-b892-f8429f3f7c47",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_83452/3637009598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdwarves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "dwarves[4][1,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution 2:** This is a `SyntaxError`.  A `SyntaxError` is generally worse than any other kind of error because it means that you haven't even produced a legal sentence in the Python language.  That means Python never starts **evaluating** the expressions in your code to see if it does the right thing.  A syntax error masks all other errors.  After Module 1, I will start deducting more points for submitted assignments that contain `SyntaxError`s.  \n",
    "\n",
    "When you get a `SyntaxError` you need to start scanning your code character by character to see what caused\n",
    "the problem.  If you look at the output below you can see that Python is trying to help.  The `^` in the output is pointing directly at the character that caused the problem.  Now sometimes the problem will be bigger than\n",
    "that (see the example below), but the `^` still gives you a clue as the where to start.  Look left and right of there to try to find the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4180921599.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_83452/4180921599.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dwarves[4][1;4]\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dwarves[4][1;4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains a very common `SyntaxError`, even among non-beginners.  Notice that the `^` comes right the beginning of the code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(...)? (2419407535.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_83452/2419407535.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print \"Hi\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(...)?\n"
     ]
    }
   ],
   "source": [
    "print \"Hi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the fix to see what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parentheses were missing.  So what Python sees is two expressions in a row, a name `print`  and a string `\"Hi\"` with no way to connect them, so it places the `^` where the two expressions start because that's where the oroblem starts. \n",
    "\n",
    "This particular error is really common because Python `print` used to not require parentheses, so longtime\n",
    "Python programmers like myself make this error all the time.  As a result, Python has included a **very** special purpose error message for this one.\n",
    "\n",
    "```python\n",
    "Missing parentheses in call to 'print'. Did you mean print(...)?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yd_mC2AHW74w"
   },
   "source": [
    " ## Exercise Five\n",
    " \n",
    " In the next cell, write **a single Python expression** that accesses `secret_word` and returns\n",
    " \n",
    " ```\n",
    " ['sesame','bagel']\n",
    " ```\n",
    " \n",
    " You will need to use a string **method**, that is, a function called with the syntax `secret_word.function(...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sesame bagel'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRmFvB_8W74x",
    "outputId": "a6465e2f-f441-4180-af3a-2fcc595b62a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sesame bagel']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[secret_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look carefully at the requested output and this output. They don't match.  One is a liut of length 2.  The other is a list of length 1.  This is an example of an answer that doesn't meet specs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0c5-_POaW74z"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyoTDs0_W740"
   },
   "source": [
    "## Exercise Six\n",
    "\n",
    "Explain what happens  when the following expression is evaluated.  Edit it to be an expression that returns `\"h\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_53108/4232992233.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdwarves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "dwarves[6]['h']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explain what happens when the ... expression is evaluated.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwarves[6][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:  The code is completely right, but an explanation was requested for the error and no explanation was\n",
    "given.  Missing the explanation or description when an explanation or description is\n",
    "requested is an error.\n",
    "\n",
    "This is a case where either a markup cell needs to be added (so that can type your explanation into it)\n",
    "or you need to double-click on the cell containing the words\n",
    "\n",
    "> (Explain what happens when the ... expression is evaluated.)\n",
    "\n",
    "so that you can edit it and add the explanation there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VabiRPzPW743"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyNmzb8iW743"
   },
   "source": [
    "## Exercise Seven - Twelve Skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbtVOFMCW75S"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiSCfU1BW75T"
   },
   "source": [
    "## Exercise Thirteen\n",
    "\n",
    "Can you write an expression that sets the first element of `dwarves` to be `\"Thorin\"`.  If not, why not?\n",
    "\n",
    "You may use the next cell to illustrate your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell has not been evaluated.  In fact it generates an error and a correct solution\n",
    "would show the error and explain it, as requested in the directions (**If not, why not?**)\n",
    "\n",
    "This is a no credit solution because the code is not being adequately tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwarves[0] = 'Thorin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7lDWVTTW75X"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rehiuvcXW75Y"
   },
   "source": [
    "## Exercise Fourteen - Sixteen (Skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Seventeen\n",
    "\n",
    "The next cell raises a `TypeError`.  Explain why. Be sure to say what string is causing the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_46533/3696662505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistorical_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spouse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m'V'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "historical_records[0]['spouse'][0]  = 'V'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a type error because strings are **immutable**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  The solution above is unsatisfactory because an explanation has been requested and\n",
    "is missing.  There is no attempt to identify what string the code attempts to change:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Eighteen\n",
    "\n",
    "In this problem, your task is to write an assignment statement that changes the distance from\n",
    "Chicago to New York in `city_distances` from 790 to 789."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer, which should be an assignment, in the next cell.\n",
    "\n",
    "Be sure to check your answer as well by accessing the updated data value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution**:\n",
    "\n",
    "Doing the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_distances['New York']['Chicago'] = 789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution above is unsatisfactory because the dictionary is not checked to see if the update worked.\n",
    "\n",
    "The following cell illustrates the missing check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_distances['New York']['Chicago']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwn17TUFW75h"
   },
   "source": [
    "##       Part Two  Skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problems in Part Two have not been done.  \n",
    "\n",
    "The full point values wil be deducted fro skipped problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZMgB6DRW75t"
   },
   "source": [
    "## Part Three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0LjtauVW75t",
    "outputId": "08d92e1d-a903-45f4-9282-5fb7184b112e"
   },
   "source": [
    "The `city_distances` dictionary provides information about distances between U. S. city pairs.  It does not cover all U.S. city pairs; in fact it only covers  13 city pairs.  Besides its incompleteness, there is a significant problem with how the information is represented.  In this problem you will reoorganize the data and represent it in a way\n",
    "that fixes this problem.\n",
    "\n",
    "Here is a hint as to what the problem is. Even though `city_distances` contains information about the distance between Chicago and New York, the following is an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'New York'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/bx4mylnd27g_kqqgn5hrn2x40000gr/T/ipykernel_60197/824707247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcity_distances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Chicago'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'New York'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'New York'"
     ]
    }
   ],
   "source": [
    "city_distances['Chicago']['New York']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it's not that the data is being looked up in a way inconsistent with the dictionary's design.  The following is fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_distances['Phoenix']['Albuquerque']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that the typical user can't look at the definition of the dictionary.  They know how to use it\n",
    "and they know the city pairs that it covers. Explain the problem and why this puts an undue burden on the user. Hint: How **do** you look up the distance between Chicago and New York? Come up with a different way of representing the same data that solves this problem. Note:  Your solution should not introduce redundancy into the representation.  Don't store the same piece of information twice.  Your solution  should give the user one fairly natural way of looking up any of the 13 distances available in the data.  And it should not require the user to know any arbitrary facts about how any indvidual city distance is stored. \n",
    "\n",
    "This problem is about designing a a good way to represent some information. You can illustrate your \n",
    "design idea without typing in all 13 city pairs.  How about just doing three, one of which should\n",
    "be Chicago and New York?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'New York': {'Chicago': 790,\n",
       "  'Boston': 215,\n",
       "  'St. Louis': 953,\n",
       "  'Baltimore': 188},\n",
       " 'Chicago': {'Denver': 1002, 'Omaha': 467, 'Salt Lake City': 1397},\n",
       " 'Denver': {'Phoenix': 865, 'Salt Lake City': 528},\n",
       " 'Phoenix': {'Albuquerque': 419, 'Reno': 739, 'San Diego': 355},\n",
       " 'Dallas': {'Houston': 241}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsatisfactory Solution**\n",
    "\n",
    "The solution given below ignores the direction not to store the same piece of information\n",
    "twice, so it will only get partial credit.  But it is a high partial credit solution\n",
    "because it diagnoses the problem and restructures the data in a way that meets almost all the specifications.\n",
    "\n",
    "There is also testing after the solution that addresses the main point of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unsatisfactory solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "city_distances = {\n",
    "                  ['New York','Chicago']: 790, \n",
    "                  ['Chicago','New York']: 790, \n",
    "                  ['New York','Boston']: 215, \n",
    "                  ['Boston','New York']: 215, \n",
    "                  ['New York','St. Louis']: 953, \n",
    "                  ['St. Louis','New York']: 953, \n",
    "                  ['New York','Baltimore']:188,\n",
    "                  ['Baltimore','New York']:188,\n",
    "                  ['Chicago','Denver']: 1_002,\n",
    "                  ['Denver','Chicago']: 1_002,\n",
    "                  ['Chicago','Omaha']: 467,\n",
    "                  ['Omaha','Chicagi']: 467,\n",
    "                  ['Chicago','Salt Lake City']:1_397,\n",
    "                  ['Salt Lake City','Chicago']:1_397,\n",
    "                  ['Denver', 'Phoenix']: 865,\n",
    "                  ['Phoenix','Denver']: 865,\n",
    "                  ['Salt Lake City','Denver']: 528, \n",
    "                  ['Denver', 'Salt Lake City']: 528, \n",
    "                  ['Phoenix', 'Albuquerque']: 419, \n",
    "                  ['Albuquerque','Phoenix']: 419, \n",
    "                  ['Phoenix', 'Reno']: 739, \n",
    "                  ['Reno','Phoenix']: 739, \n",
    "                  ['Phoenix', 'San Diego']: 355,\n",
    "                  ['San Diego','Phoenix']: 355,\n",
    "                  ['Dallas','Houston']: 241,\n",
    "                  ['Houston', 'Dallas']: 241\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_distances[fz(['New York','Chicago'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_distances[fz(['Chicago','New York'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJQo1KOhW75w"
   },
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "python_types_assignment_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
