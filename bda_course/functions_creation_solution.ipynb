{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94dfad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ebf26b",
   "metadata": {},
   "source": [
    "# Function Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e00ea",
   "metadata": {},
   "source": [
    "### Motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c1358f",
   "metadata": {},
   "source": [
    "The first reason to write a function is to avoid repeating code.\n",
    "\n",
    "The next two code cells contain code snippets that do the same thing to slightly different data.  First, see if you can explain what that thing is.\n",
    "\n",
    "The third code cell abstracts the shared code into a function.  See if you can\n",
    "guess what the function will look like before you get to the third cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c257fc9",
   "metadata": {},
   "source": [
    "### snippet #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d703d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# This is the Iliad\n",
    "with urlopen('https://www.gutenberg.org/cache/epub/6130/pg6130.txt') as iliad_page:\n",
    "    iliad_bytes = iliad_page.read()\n",
    "\n",
    "iliad = iliad_bytes.decode('utf-8')\n",
    "iliad_words = iliad.split()\n",
    "iliad_vocab = set(iliad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1f81a",
   "metadata": {},
   "source": [
    "### snippet #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabe3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# This is the odyssey\n",
    "with urlopen('https://www.gutenberg.org/cache/epub/1727/pg1727.txt') as odyssey_page:\n",
    "    odyssey_bytes = odyssey_page.read()\n",
    "    \n",
    "odyssey = odyssey_bytes.decode('utf-8')\n",
    "odyssey_words = odyssey.split()\n",
    "odyssey_vocab = set(odyssey_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737eadd",
   "metadata": {},
   "source": [
    "Next try to articulate to the task that both these code snippers perform.  The answer is in a markup (text) cell a few cells down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5197d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a528fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853a15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5b890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2490750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec5393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f9512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8db56562",
   "metadata": {},
   "source": [
    "Description A: **The code snippets extract the vocabulary from a url. If we wanted to write a function that performs that task, the function would take a url string as its input and it would return a set of words.**\n",
    "\n",
    "Note that the page at that url address needs to contain text encoded in UTF-8 in order for\n",
    "the code to give the expected result.  This is why pages on `gutenberg.org` were\n",
    "chosen.\n",
    "\n",
    "There are other possible answers you could have come up with.  You might have said.\n",
    "\n",
    "Description B:  **The code snippets extract the vocabulary from a gutenberg.org book. If we wanted to write a function that performed that task, it could take a gutenberg\n",
    "document number as its input and return a set of words.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f8506d",
   "metadata": {},
   "source": [
    "Next try to write a function that does what the code snippets do, consistent\n",
    "with the description in Description A.\n",
    "\n",
    "You can start by copying and pasting one of the snippets and indenting it\n",
    "under:\n",
    "\n",
    "```\n",
    "def <function_name> (<parameters>):\n",
    "```\n",
    "\n",
    "but you will have to chose a legal function name, supply the parameters for the function,\n",
    "and change the code snippet.\n",
    "\n",
    "There are two things to think about:\n",
    "\n",
    "1.  What the parameters (input) of the function will be.\n",
    "2.  What the function returns\n",
    "\n",
    "The answer is a few cells down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa63e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd941d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae60f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562317a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540ccd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffd083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0416c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "94e4b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "def extract_vocab_from_text_url(url):\n",
    "    with urlopen(url) as page:\n",
    "        page_bytes = page.read()\n",
    "    page_text = page_bytes.decode('utf-8')\n",
    "    words = page_text.split()\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90931af",
   "metadata": {},
   "source": [
    "We decided the function would input a url string and output the vocabulary set found\n",
    "at that url. The snippet the above function definition evolved from is:\n",
    "\n",
    "```\n",
    "with urlopen('https://www.gutenberg.org/cache/epub/1727/pg1727.txt') as odyssey_page:\n",
    "    odyssey_bytes = odyssey_page.read()\n",
    "odyssey = odyssey_bytes.decode('utf-8')\n",
    "odyssey_words = odyssey.split()\n",
    "odyssey_vocab = set(odyssey_words)\n",
    "```\n",
    "\n",
    "Note all the name changes in the code and make sure you understand them. Make sure\n",
    "you understand the need to use `return` in the last line. Notice\n",
    "the necessary import statement was included in the cell defining\n",
    "the function.  It is good practice when defining functions to declare\n",
    "all its dependencies explicitly and place them nearby the function definition.\n",
    "\n",
    "Let's apply this function to our previous examples to show the benefits of our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1e8a93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "odyssey_vocab = \\\n",
    "   extract_vocab_from_text_url('https://www.gutenberg.org/cache/epub/1727/pg1727.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "05718041",
   "metadata": {},
   "outputs": [],
   "source": [
    "iliad_vocab = \\\n",
    "   extract_vocab_from_text_url('https://www.gutenberg.org/cache/epub/6130/pg6130.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed018b",
   "metadata": {},
   "source": [
    "We demonstrate the function gets different results with different arguments (this is a good way of checking you made all the necessary name changes when you defined the function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "58a9018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14214, 27070)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(odyssey_vocab),len(iliad_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d7f66",
   "metadata": {},
   "source": [
    "Note: This is kind of a noteworthy result.  *The Iliad* is about 16K lines,\n",
    "and and *The Odyssey* about 12K lines,  so it's interesting that the vocabulary size\n",
    "of *The Iliad* is so much greater.  If you know anything about the stories,\n",
    "you might be able think of some story-specific reasons for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d192e7",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486565a",
   "metadata": {},
   "source": [
    "Here are two code snippets. \n",
    "\n",
    "1.  Write a description of what they do.\n",
    "2.  Write a function that does what the code snippets do, consistent with your description of what they do.\n",
    "3.  Test it by calling it on the appropriate arguments to reproduce what snippet #1\n",
    "and snippet #2 do.  Check to see the results are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67378e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'johnson,fred      fjohnson@gmail.com',\n",
       " 'clark,kenneth     kclark223@gmail.com',\n",
       " 'rotsler,elaine    er337@apple.com',\n",
       " 'smith,howard      hgs@yahoo.com',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bdd8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 1\n",
    "\n",
    "emails = \\\n",
    "\"\"\"\n",
    "johnson,fred      fjohnson@gmail.com\n",
    "clark,kenneth     kclark223@gmail.com\n",
    "rotsler,elaine    er337@apple.com\n",
    "smith,howard      hgs@yahoo.com\n",
    "\"\"\"\n",
    "\n",
    "email_dict = dict()\n",
    "for line in emails.split(\"\\n\"):\n",
    "    if line.strip():\n",
    "        name,email = line.strip().split()\n",
    "        email_dict[name] = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4375d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'johnson,fred': 'fjohnson@gmail.com',\n",
       " 'clark,kenneth': 'kclark223@gmail.com',\n",
       " 'rotsler,elaine': 'er337@apple.com',\n",
       " 'smith,howard': 'hgs@yahoo.com'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af972a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 2\n",
    "\n",
    "tel_nums = \\\n",
    "\"\"\"\n",
    "johnson,fred      619-564-7789\n",
    "clark,kenneth     858-915-5460\n",
    "rotsler,elaine    858-276-1990\n",
    "smith,howard      619-352-9911\n",
    "\"\"\"\n",
    "\n",
    "dd = dict()\n",
    "for pair in tel_nums.split(\"\\n\"):\n",
    "    if pair.strip():\n",
    "        name,num = pair.strip().split()\n",
    "        dd[name] = num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a8ff8f",
   "metadata": {},
   "source": [
    "Put your description of the function in the cell below.  Be sure to say what the input of the function is and what it returns.  And be sure to write a function consistent with your\n",
    "description.  Remember: You have to double click on a text (markup) cell to edit it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a925f2",
   "metadata": {},
   "source": [
    "#### Description goes here\n",
    "\n",
    "The snippets take lines of data with whitespace-separated items and create a dictionary.  The\n",
    "string before the white space is the key and the string after the white-space is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a74a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your definition of the function here\n",
    "\n",
    "def string2dict (str):\n",
    "    dd = dict()\n",
    "    for pair in str.split(\"\\n\"):\n",
    "        if pair.strip().split():\n",
    "            name,num = pair.split()\n",
    "            dd[name] = num\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "972f9811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'johnson,fred': '619-564-7789',\n",
       " 'clark,kenneth': '858-915-5460',\n",
       " 'rotsler,elaine': '858-276-1990',\n",
       " 'smith,howard': '619-352-9911'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test your function on the email data and the telephone number data.\n",
    "string2dict (tel_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050e235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'johnson,fred': 'fjohnson@gmail.com',\n",
       " 'clark,kenneth': 'kclark223@gmail.com',\n",
       " 'rotsler,elaine': 'er337@apple.com',\n",
       " 'smith,howard': 'hgs@yahoo.com'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2dict (emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35214d3f",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f95630",
   "metadata": {},
   "source": [
    "Here are two more code snippets. \n",
    "\n",
    "1.  Write a description of what they do.\n",
    "2.  Write a function that does what the code snippets do, consistent with your description of what they do.\n",
    "3.  Test it by calling it on the appropriate arguments to reproduce what snippet #1\n",
    "and snippet #2 do.  Check to see the results are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2dbb1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'bib',\n",
       " 'demon',\n",
       " 'dint',\n",
       " 'hoard',\n",
       " 'lapel',\n",
       " 'mongoose',\n",
       " 'navel',\n",
       " 'ram',\n",
       " 'slake',\n",
       " 'yolk']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snippet #1\n",
    "\n",
    "L1 = \"demon navel hoard ram bib apple\".split()\n",
    "L2 = \"yolk lapel dint mongoose slake\".split()\n",
    "\n",
    "sorted(L1 + L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5743dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demon navel hoard ram bib apple'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2061a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['April',\n",
       " 'February',\n",
       " 'January',\n",
       " 'March',\n",
       " 'May',\n",
       " 'apple',\n",
       " 'banana',\n",
       " 'cherry',\n",
       " 'mango',\n",
       " 'orange']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snippet # 2\n",
    "\n",
    "fruits = ['cherry', 'banana', 'apple', 'orange','mango']\n",
    "months = ['January', 'February', 'March', 'April','May']\n",
    "\n",
    "sorted(fruits + months)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53962eb9",
   "metadata": {},
   "source": [
    "Put your description of the function in the cell below.  Be sure to say what the input of the function is and what it returns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2cd65c",
   "metadata": {},
   "source": [
    "#### Description goes here\n",
    "\n",
    "The function joins two sequences of words into a single sequence of words, returning a list.  If the inputs\n",
    "are strings they are converted into lists with `.split()`.  Otherwise they are assumed to already be lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78cea121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition goes after this line.\n",
    "def join_word_sequences (seq1,seq2):\n",
    "    if isinstance(seq1,str):\n",
    "        seq1 = seq1.split()\n",
    "    if isinstance(seq2,str):\n",
    "        seq1 = seq2.split()\n",
    "    return seq1 + seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c51af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demon',\n",
       " 'navel',\n",
       " 'hoard',\n",
       " 'ram',\n",
       " 'bib',\n",
       " 'apple',\n",
       " 'yolk',\n",
       " 'lapel',\n",
       " 'dint',\n",
       " 'mongoose',\n",
       " 'slake']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_word_sequences (L1,L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b56c826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cherry',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'orange',\n",
       " 'mango',\n",
       " 'January',\n",
       " 'February',\n",
       " 'March',\n",
       " 'April',\n",
       " 'May']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test your function on the fruits data and the months data.\n",
    "join_word_sequences (fruits,months)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10658c8",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280609e",
   "metadata": {},
   "source": [
    "Go back to the motivating example.  Now write and test a function consistent\n",
    "with description B of what the code snippets do. The new function should take a Gutenberg document number as its input and return a set of words. Call it `extract_vocab_from_gutenberg_doc`.\n",
    "\n",
    "Hint:  Use an f-string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88a640",
   "metadata": {},
   "source": [
    "Put your description of the function in the cell below.  Be sure to say what the input of the function is and what it returns.  And be sure to write a function consistent with your\n",
    "description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b494b0b",
   "metadata": {},
   "source": [
    "#### Function description\n",
    "\n",
    "The function `extract_vocab_from_gutenberg_doc` takes a Gutenberg document number as its input and returns the vocabulary of the document as a set of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a48e155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defintion goes after this line\n",
    "def extract_vocab_from_gutenberg_doc(doc_number):\n",
    "    url = f'https://www.gutenberg.org/cache/epub/{doc_number}/pg{doc_number}.txt'\n",
    "    with urlopen(url) as page:\n",
    "        page_bytes = page.read()\n",
    "    page_text = page_bytes.decode('utf-8')\n",
    "    words = page_text.split()\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "448853ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function on the appropriate arguments using \n",
    "doc_number = 6130\n",
    "iliad_vocab2 = extract_vocab_from_gutenberg_doc(doc_number)\n",
    "# iliad vocab was computed in the Motivating Example section of this NB\n",
    "iliad_vocab2 == iliad_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0c46225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function on the appropriate arguments using \n",
    "doc_number2 = 1727\n",
    "odyssey_vocab2 = extract_vocab_from_gutenberg_doc(doc_number2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725107ac",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5e3cd",
   "metadata": {},
   "source": [
    "Write function that takes as its arguments two url strings and returns the vocabulary set common to both urls.\n",
    "\n",
    "As an example, suppose we have two URLs containing the following very short texts:\n",
    "\n",
    "```\n",
    "url1: cats dogs urchin\n",
    "url2: dogs my trail\n",
    "```\n",
    "\n",
    "Then this is the behavior we want:\n",
    "\n",
    "```\n",
    ">>> extract_shared_vocab_from_text_urls(url1,url2)\n",
    "{'dogs'}\n",
    "```\n",
    "\n",
    "The point of this exercise is not to start from scratch.  Your function\n",
    "should make use of the function `extract_vocab_from_text_url` already defined\n",
    "in the motivating example.  If you do that, this should be very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08c8e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shared_vocab_from_text_urls(url1,url2):\n",
    "    return extract_vocab_from_text_url(url1).intersection(extract_vocab_from_text_url(url2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22aacfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6597"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = 'https://www.gutenberg.org/cache/epub/6130/pg6130.txt'\n",
    "url2 = 'https://www.gutenberg.org/cache/epub/1727/pg1727.txt'\n",
    "common_vocab1 = extract_shared_vocab_from_text_urls(url1,url2)\n",
    "len(common_vocab1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa171ef",
   "metadata": {},
   "source": [
    "# Exercise 4a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63493c4b",
   "metadata": {},
   "source": [
    "**Optional advanced problem**:  Define a new version of `extract_vocab_from_text_url`\n",
    "called `extract_shared_vocab_from_text_urls`\n",
    "that takes *any number of url arguments* and returns the vocabulary common\n",
    "to all the URLs.\n",
    "\n",
    "As an example, suppose we have four URLs containing the following very short texts:\n",
    "\n",
    "```\n",
    "url1: cats dogs urchin\n",
    "url2: dogs my trail\n",
    "url3: my dogs hurt\n",
    "url4: raining cats and dogs\n",
    "```\n",
    "\n",
    "Then this is the behavior we want:\n",
    "\n",
    "```\n",
    ">>> extract_shared_vocab_from_text_urls(url1,url2,url3,url4)\n",
    "{'dogs'}\n",
    "```\n",
    "\n",
    "To help streamline this task, we present some facts about \n",
    "the asterix prefix (`*`) in Python.  This prefix can be used\n",
    "to define functions that take any arbitrary number of arguments\n",
    "(which is what `extract_shared_vocab_from_text_urls` should be),\n",
    "and it can also be used to pass the contents of a container\n",
    "as arguments to a function without having to \"take it apart\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c8908",
   "metadata": {},
   "source": [
    "First we define a tuple and apply `print` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a92d19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'c', 'b', 'a'}, {'c', 'b', 'd'}, {'e', 'c', 'd'}, {'h', 'c', 'g'})\n"
     ]
    }
   ],
   "source": [
    "set_tuple = (set('abc'), set('bcd'), set('cde'), set('cgh'))\n",
    "print(set_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97389a97",
   "metadata": {},
   "source": [
    "Note that a tuple was printed out, complete with surrounding parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bba1fe",
   "metadata": {},
   "source": [
    "Suppose we want to print the individual elements of the tuple\n",
    "instead of the tuple as a unit.  Then we could do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4c0cf18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c', 'b', 'a'} {'c', 'b', 'd'} {'e', 'c', 'd'} {'h', 'c', 'g'}\n"
     ]
    }
   ],
   "source": [
    "print(set_tuple[0],set_tuple[1],set_tuple[2],set_tuple[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929230d",
   "metadata": {},
   "source": [
    "Note:  No surrounding parentheses around the tuple elements:\n",
    "But we can get exactly the same result using the asterisk prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "18ea4e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c', 'b', 'a'} {'c', 'b', 'd'} {'e', 'c', 'd'} {'h', 'c', 'g'}\n"
     ]
    }
   ],
   "source": [
    "print(*set_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac2c99",
   "metadata": {},
   "source": [
    "In the first case\n",
    "\n",
    "```\n",
    "print(set_tuple)\n",
    "```\n",
    "\n",
    "we print a tuple; in the second, \n",
    "\n",
    "```\n",
    "print(*set_tuple)\n",
    "```\n",
    "\n",
    "the individual elements of the tuple are passed as arguments to the print command, so it prints each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090eae53",
   "metadata": {},
   "source": [
    "Similarly, since the intersection method on sets allows any number of container arguments,\n",
    "the two python expressions executed in the `print` commands in the next cell are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd86440c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c'}\n",
      "{'c'}\n"
     ]
    }
   ],
   "source": [
    "set_tuple = (set('abc'), set('bcd'), set('cde'), set('cgh'))\n",
    "print(set('cat').intersection(set_tuple[0],set_tuple[1],set_tuple[2],set_tuple[3]))\n",
    "print(set('cat').intersection(*set_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bfef7",
   "metadata": {},
   "source": [
    "We can also use the asterisk prefix in function signatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c9fbe",
   "metadata": {},
   "source": [
    "The following two functions have exactly the same definition\n",
    "but different argument **signatures** (different ways of defining the function parameters), so they are called in slightly different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e428d2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "====================\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def a_single_container_arg (args):\n",
    "    for x in args:\n",
    "        print(x)\n",
    "def any_number_of_args (*args):\n",
    "    for x in args:\n",
    "        print(x)\n",
    "\n",
    "\n",
    "a_single_container_arg ((1,2,3,4))\n",
    "print('='*20)\n",
    "any_number_of_args(1,2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d1713",
   "metadata": {},
   "source": [
    "Using asterisks and `extract_vocab_from_text_url`, it should be easy to define\n",
    "`extract_shared_vocab_from_text_urls`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760bdb8c",
   "metadata": {},
   "source": [
    "Here are some docs to test on:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce1d33",
   "metadata": {},
   "source": [
    "Add your definition to the next cell then execute it to run the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3082918a",
   "metadata": {},
   "source": [
    "Hint:  It may help to know that set method `.intersection()`, like `print`, takes any number of arguments, and the method can be called using the type name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fd726735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.intersection(set(\"abc\"),set(\"bcd\"),set(\"cde\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53febaf2",
   "metadata": {},
   "source": [
    "Here are three distinct ways to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Here is a repeat definition of the function defined above\n",
    "\n",
    "def extract_vocab_from_text_url(url):\n",
    "    with urlopen(url) as page:\n",
    "        page_bytes = page.read()\n",
    "    page_text = page_bytes.decode('utf-8')\n",
    "    words = page_text.split()\n",
    "    return set(words)\n",
    "\n",
    "#Here are three equivalent answers using that definition\n",
    "\n",
    "def extract_shared_vocab_from_text_urls0(*urls):\n",
    "    result = extract_vocab_from_text_url(urls[0])\n",
    "    for url in urls[1:]:\n",
    "        result.intersection_update(extract_vocab_from_text_url(url))\n",
    "    return result\n",
    "\n",
    "def extract_shared_vocab_from_text_urls1(*urls):\n",
    "    result = extract_vocab_from_text_url(urls[0])\n",
    "    for url in urls[1:]:\n",
    "        result = result.intersection(extract_vocab_from_text_url(url))\n",
    "    return result\n",
    "\n",
    "def extract_shared_vocab_from_text_urls2(*urls):\n",
    "    return set.intersection(*[extract_vocab_from_text_url(url) for url in urls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c642d006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3201"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_vocab2 = extract_shared_vocab_from_text_urls2 (url0,url1,url2,url3)\n",
    "len(common_vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c1879ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3201"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "common_vocab1 = extract_shared_vocab_from_text_urls1 (url0,url1,url2,url3)\n",
    "len(common_vocab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cff02858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3201"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_vocab0 = extract_shared_vocab_from_text_urls0 (url0,url1,url2,url3)\n",
    "len(common_vocab0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a768c0",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9025a3",
   "metadata": {},
   "source": [
    "Copy and paste the definition of the function `extract_vocab_from_text_url` from above into a code cell and modify it so that it can accept an encoding\n",
    "as an additional argument. This additional argument should be optional\n",
    "and it should have `utf8` as its default value.  Call the modified version `new_extract_vocab_from_text_url`. \n",
    "\n",
    "The function `new_extract_vocab_from_text_url`\n",
    "should work exactly like the\n",
    "original version on, say, the Odyssey page,\n",
    "`'https://www.gutenberg.org/cache/epub/1727/pg1727.txt'`,\n",
    "but it should also work on text pages encoded in, say, UTF-16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b9a9c",
   "metadata": {},
   "source": [
    "You can test `new_extract_vocab_from_text_url` two ways.\n",
    "\n",
    "#### test # 1\n",
    "\n",
    "After defining `new_extract_vocab_from_text_url` execute the cell below to make sure it works the same way `extract_vocab_from_text_url` does on the motivating examples. That is, using `new_extract_vocab_from_text_url` on a gutenberg.org URL should still work without supplying an encoding argument and it should return the same value as \n",
    "`extract_vocab_from_text_url` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf94d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_extract_vocab_from_text_url(url,encoding=\"utf-8\"):\n",
    "    with urlopen(url) as page:\n",
    "        page_bytes = page.read()\n",
    "    page_text = page_bytes.decode(encoding)\n",
    "    words = page_text.split()\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "789a72c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test #1\n",
    "new_iliad_vocab = \\\n",
    "   new_extract_vocab_from_text_url('https://www.gutenberg.org/cache/epub/6130/pg6130.txt')\n",
    "new_iliad_vocab == iliad_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbcb065",
   "metadata": {},
   "source": [
    "#### test #2\n",
    "\n",
    "It should also work on a utf16 version of *the Iliad*, which has been conveniently provided for you in the next cell; `new_extract_vocab_from_text_url` should return exactly the same vocabulary it did for the utf8 version on gutenberg.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dddbbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test #2\n",
    "iliad16_url = 'https://gawron.sdsu.edu/python_for_ss/course_core/data/iliad_utf16.txt'\n",
    "iliad_vocab16 = new_extract_vocab_from_text_url(iliad16_url, encoding='utf16')\n",
    "iliad_vocab16 == iliad_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b76cc",
   "metadata": {},
   "source": [
    "Comment: if test #2 raises a `UnicodeDecodeError` error like the one in the code cell below, that's probably because you are still using the default encoding to try to read the UTF16 version of the file.  Check to make sure you aren't always using UTF-8 in \n",
    "the line calling `page_bytes.decode`.\n",
    "\n",
    "We can say something stronger: Using the default encoding to try to read a UTF16 file *should* cause an error (We will return to this fact when we discuss unicode and text encodings later on in the course). So for example, if you've\n",
    "correctly defined `new_extract_vocab_from_text_url`, the following code cell raises an error: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76c9a834",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_q/2s1hy5bx1l7f9j1lw9zjgt19_wb463/T/ipykernel_75672/3397016352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miliad_vocabx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_extract_vocab_from_text_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miliad16_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miliad_vocabx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miliad_vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_q/2s1hy5bx1l7f9j1lw9zjgt19_wb463/T/ipykernel_75672/3231712805.py\u001b[0m in \u001b[0;36mnew_extract_vocab_from_text_url\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mpage_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Correctly an error\n",
    "iliad_vocabx = new_extract_vocab_from_text_url(iliad16_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd5a5c",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e28907",
   "metadata": {},
   "source": [
    "Here are two more complicated snippets that do the same thing to two different datasets.\n",
    "\n",
    "\n",
    "1.  Write a description of what they do.\n",
    "2.  Write a function that does what the code snippets do, consistent with your description of what they do.  Choose a good name consistent with your description.\n",
    "3.  Test it by calling it on the appropriate arguments to reproduce what snippet #1\n",
    "and snippet #2 do.  Check to see the results are different.\n",
    "\n",
    "\n",
    "A common sense constraint:  Your function should return\n",
    "the right data structure to represent the work that\n",
    "was done in the code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ffec5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet # 1\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "with urlopen(urls[0])  as zero_page:\n",
    "    zero_bytes = zero_page.read()\n",
    "\n",
    "zero_text = zero_bytes.decode('utf-8')\n",
    "zero_words = zero_text.lower().split()\n",
    "\n",
    "zero_dd = dict()\n",
    "\n",
    "for word in zero_words:\n",
    "    if word in zero_dd:\n",
    "        zero_dd[word]  += 1\n",
    "    else:\n",
    "        zero_dd[word]  = 1      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3d2297c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet # 2\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "with urlopen(urls[1])  as one_page:\n",
    "    one_bytes = one_page.read()\n",
    "\n",
    "one_text = one_bytes.decode('utf-8')\n",
    "one_words = one_text.lower().split()\n",
    "\n",
    "one_dd = dict()\n",
    "\n",
    "for word in one_words:\n",
    "    if word in one_dd:\n",
    "        one_dd[word]  += 1\n",
    "    else:\n",
    "        one_dd[word]  = 1      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e81e2ed",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "These code snippers get the frequency counts for each vocabulary item of the text at the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20a14b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your function definition in the cell\n",
    "\n",
    "def get_word_counts(url,encoding=\"utf-8\"):\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "    with urlopen(url)  as one_page:\n",
    "        one_bytes = one_page.read()\n",
    "\n",
    "    one_words = one_bytes.decode(encoding).lower().split()\n",
    "\n",
    "    one_dd = dict()\n",
    "\n",
    "    for word in one_words:\n",
    "        if word in one_dd:\n",
    "            one_dd[word]  += 1\n",
    "        else:\n",
    "            one_dd[word]  = 1      \n",
    "\n",
    "    return one_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c654a185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Put your test code in this cell.\n",
    "url0 = 'https://www.gutenberg.org/cache/epub/6130/pg6130.txt'\n",
    "wc0 = get_word_counts(urls[0],encoding=\"utf-8\")\n",
    "wc1 = get_word_counts(urls[1],encoding=\"utf-8\")\n",
    "print(wc0 == zero_dd)\n",
    "print(wc1 == one_dd)\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d052a4",
   "metadata": {},
   "source": [
    "# Exercise  7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd79831",
   "metadata": {},
   "source": [
    "Write a function that does what the following snippet does.  The\n",
    "function you define can (and should) make use of a function previously\n",
    "defined in this notebook.\n",
    "\n",
    "After you've written your function, use it to answer the following questions.\n",
    "\n",
    "1.  What are the 20 most common content words in *The Odyssey*? The best definition of a content word is negative:  A content word is not a **function** word, a word like *the*, *and*, or *in*, a word that is extremely frequent amd serves a grammatical function (More examples below). \n",
    "2.  What are the 20 most common content words in *The Iliad*? \n",
    "\n",
    "For distinguishing content words from function words, here's some help.  Function words are sometimes\n",
    "called stop words in natural language processing.  Use the list of `cutom_stops` defined below\n",
    "and find the 20 most frequent words from each text that are **not** stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df4cd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "with urlopen(urls[1\n",
    "                 ])  as odyssey_page:\n",
    "    odyssey_bytes = odyssey_page.read()\n",
    "\n",
    "odyssey_text = odyssey_bytes.decode('utf-8')\n",
    "odyssey_words = odyssey_text.lower().split()\n",
    "\n",
    "odyssey_dd = dict()\n",
    "\n",
    "for word in odyssey_words:\n",
    "    if word in odyssey_dd:\n",
    "        odyssey_dd[word]  += 1\n",
    "    else:\n",
    "        odyssey_dd[word]  = 1      \n",
    "\n",
    "LL = sorted(odyssey_dd.items(),key=lambda x:x[1],reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfccdb9",
   "metadata": {},
   "source": [
    "In order to help you understand this code, you should look at the first 25 elements of `LL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "71c2db9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 7016),\n",
       " ('and', 5320),\n",
       " ('of', 3626),\n",
       " ('to', 3557),\n",
       " ('a', 2030),\n",
       " ('in', 1897),\n",
       " ('i', 1860),\n",
       " ('he', 1811),\n",
       " ('you', 1675),\n",
       " ('for', 1368),\n",
       " ('his', 1341),\n",
       " ('as', 1291),\n",
       " ('that', 1275),\n",
       " ('with', 1236),\n",
       " ('was', 1033),\n",
       " ('it', 1005),\n",
       " ('they', 952),\n",
       " ('is', 934),\n",
       " ('on', 882),\n",
       " ('had', 880),\n",
       " ('have', 858),\n",
       " ('but', 849),\n",
       " ('all', 828),\n",
       " ('my', 816),\n",
       " ('not', 772)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3ba1f",
   "metadata": {},
   "source": [
    "It's a list of the pairs extracted from the dictionary `odyssey_dd`.  They have been sorted by the value of the second element,\n",
    "from the largest value for that second element to the smallest value for that second element.  You're looking at the top 25 pairs after the sort.\n",
    "\n",
    "All 25 of the top 25 words in `LL` are function words according to the list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b39404d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords,brown\n",
    "# This \n",
    "#from nltk.corpus import stopwords\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "#function_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f992f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stops = {wd.lower() for (wd,tag) in brown_news_tagged if (tag in {\"DET\",\".\",\"CONJ\",\"PRT\",\"ADP\",\"PRON\",\"NUM\"})}\n",
    "custom_stops.update({\"thy\",\"thou\",\"thee\",\"thine\"})\n",
    "custom_stops.update(  {\"have\",\"has\", \"had\",\"having\",\"has\",\"\\'ve\"} )\n",
    "custom_stops.update( {\"do\",\"does\",\"did\",\"done\",\"doing\"}  )\n",
    "custom_stops.update(   {\"go\",\"goes\",\"went\",\"gone\",\"going\"} )\n",
    "custom_stops.update(  {\"get\",\"gets\",\"got\",\"gotten\",\"getting\"} )\n",
    "custom_stops.update(  {\"come\",\"comes\",\"came\",\"coming\"} )\n",
    "custom_stops.update(   {\"say\",\"says\",\"said\",\"saying\"} )\n",
    "custom_stops.update(  {\"tell\",\"tells\", \"told\",\"telling\"} )\n",
    "custom_stops.update(   {\"take\",\"takes,\",\"took\",\"taken\",\"telling\"} )\n",
    "custom_stops.update(   {\"let\",\"lets\",\"letting\"})\n",
    "custom_stops.update(   {\"make\",\"makes\",\"made\",\"making\"})\n",
    "\n",
    "custom_stops.update({\"be\",\"is\",\"was\",\"were\",\"am\", \"are\",\"been\",\"being\",}   )\n",
    "custom_stops.update( {\"will\",\"would\",\"may\",\"might\",\"should\",\n",
    "                                                       \"shall\",\"must\",\"can\",\"could\"}  )\n",
    "custom_stops.update( {\"not\",\"\\'nt\"}  )\n",
    "custom_stops.update( {\"when\",\"where\",\"how\", \"then\",\"now\",\"here\",\"there\",\"back\",\"other\",\"very\",\n",
    "                                                      \"more\",\"less\",\"much\",\"also\",\"thus\",\"o\\'er\",\"o’er\",\"first\",\n",
    "                                                      \"second\",\"third\",\"fourth\",\"fifth\",\"sixth\",\"seventh\",\n",
    "                                                      \"eighth\",\"ninth\",\"tenth\"}  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "852d99d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(wd,ct) for(wd,ct) in LL[:25] if wd not in custom_stops]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f86923",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "18b7a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_words_by_frequency(url):\n",
    "    with urlopen(url)  as page:\n",
    "        p_bytes = page.read()\n",
    "\n",
    "    words = p_bytes.decode('utf-8').lower().split()\n",
    "\n",
    "    dd = dict()\n",
    "\n",
    "    for word in words:\n",
    "        if word in dd:\n",
    "            dd[word]  += 1\n",
    "        else:\n",
    "            dd[word]  = 1      \n",
    "\n",
    "    return sorted(dd.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "560f5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list_odyssey = sort_words_by_frequency(urls[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5579524",
   "metadata": {},
   "source": [
    "We show the 20 most common content words, as well as their count and rank.  Notably\n",
    "none of the top 46 most frequent words count as content words.  Many\n",
    "of the qualifying words are due to errornof **tokenization** (\"him,\",\"and,\", and \"them,\"\n",
    "should not be words).  These are due to using `.split()` to tokenize.  If instead we\n",
    "use a regular expression based tokenizer, teh results improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6a41f85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47, ('ulysses', 434)),\n",
       " (66, ('own', 264)),\n",
       " (71, ('see', 249)),\n",
       " (72, ('man', 248)),\n",
       " (74, ('men', 246)),\n",
       " (78, ('house', 228)),\n",
       " (81, ('son', 218)),\n",
       " (89, ('good', 199)),\n",
       " (97, ('[', 186)),\n",
       " (99, ('great', 184)),\n",
       " (104, ('him,', 173)),\n",
       " (105, ('said,', 173)),\n",
       " (107, ('set', 166)),\n",
       " (108, ('telemachus', 165)),\n",
       " (112, ('till', 158)),\n",
       " (113, ('ship', 158)),\n",
       " (119, ('suitors', 149)),\n",
       " (125, ('home', 143)),\n",
       " (126, ('them,', 142)),\n",
       " (127, ('even', 142))]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,(wd, freq)) for (i,(wd,freq)) in enumerate(freq_list_odyssey) if wd not in custom_stops][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d2c00410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, ('great', 445)),\n",
       " (59, ('hector', 282)),\n",
       " (63, ('arms', 257)),\n",
       " (70, ('achilles', 232)),\n",
       " (76, ('trojan', 215)),\n",
       " (77, ('jove', 206)),\n",
       " (79, ('gods', 195)),\n",
       " (81, ('chief', 187)),\n",
       " (82, ('high', 187)),\n",
       " (86, ('god', 180)),\n",
       " (90, ('son', 165)),\n",
       " (91, ('grecian', 161)),\n",
       " (92, ('greece', 161)),\n",
       " (95, ('and,', 153)),\n",
       " (96, ('troy', 148)),\n",
       " (97, ('greeks', 148)),\n",
       " (98, ('still', 148)),\n",
       " (99, ('fierce', 146)),\n",
       " (102, ('till', 143)),\n",
       " (103, ('hand', 143))]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_list_iliad = sort_words_by_frequency('https://www.gutenberg.org/cache/epub/6130/pg6130.txt')\n",
    "[(i,(wd, freq)) for (i,(wd,freq)) in enumerate(freq_list_iliad) if wd not in custom_stops][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9b18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
